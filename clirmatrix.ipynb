{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "678733cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0eecb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/DPR\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "data_path = os.path.join(os.getcwd(),'clirmatrix')\n",
    "train_data_path = os.path.join(data_path,'fr.en.train.jl')\n",
    "dev_data_path = os.path.join(data_path,'fr.en.dev.jl')\n",
    "test1_data_path = os.path.join(data_path,'fr.en.test1.jl')\n",
    "test2_data_path = os.path.join(data_path,'fr.en.test2.jl')\n",
    "total_data_path = os.path.join(data_path,'en.tsv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690fa12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/DPR/clirmatrix/fr.en.train.jl\n"
     ]
    }
   ],
   "source": [
    "print(train_data_path)\n",
    "train_data = pd.read_json(train_data_path,lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf0400bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_json(dev_data_path,lines=True)\n",
    "test1_data = pd.read_json(test1_data_path, lines=True)\n",
    "test2_data = pd.read_json(test2_data_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0237cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           src_id              src_query  \\\n",
      "0               3        Antoine Meillet   \n",
      "1               7       Algèbre linéaire   \n",
      "2               9       Algèbre générale   \n",
      "3              15               Autriche   \n",
      "4              19             Algorithme   \n",
      "...           ...                    ...   \n",
      "1394975  13032266         Paulo Henrique   \n",
      "1394976  13033283       Gregory Campbell   \n",
      "1394977  13035286  Fédération anarchiste   \n",
      "1394978  13035322          William Irwin   \n",
      "1394979  13036407   Gouvernement Sánchez   \n",
      "\n",
      "                                               tgt_results  \n",
      "0        [[797350, 6], [17671672, 3], [6304603, 3], [23...  \n",
      "1        [[18422, 6], [262107, 5], [18420, 5], [443235,...  \n",
      "2        [[19616384, 6], [7184, 5], [18716923, 5], [743...  \n",
      "3        [[26964606, 6], [10795689, 5], [14714962, 5], ...  \n",
      "4        [[17247558, 5], [775, 6], [99861, 5], [198156,...  \n",
      "...                                                    ...  \n",
      "1394975  [[22859207, 6], [21286345, 3], [3195229, 3], [...  \n",
      "1394976  [[38233825, 6], [33442467, 4], [2334130, 2], [...  \n",
      "1394977  [[293649, 5], [28378594, 6], [497999, 5], [145...  \n",
      "1394978  [[738511, 6], [2271020, 5], [297742, 5], [1142...  \n",
      "1394979  [[5783391, 3], [39820723, 2], [32895206, 2], [...  \n",
      "\n",
      "[1394980 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "511435f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          src_id                                          src_query  \\\n",
      "0             10                                      Algorithmique   \n",
      "1             34                            Alpes-de-Haute-Provence   \n",
      "2            105  Association francophone des utilisateurs de lo...   \n",
      "3            126                                             Ampère   \n",
      "4            141                                      Alain Madelin   \n",
      "...          ...                                                ...   \n",
      "200327  13026110                                 Ruisseau Contourné   \n",
      "200328  13026140                                      Larca italica   \n",
      "200329  13035113                                            Cleyton   \n",
      "200330  13036265                                             Kamako   \n",
      "200331  13036746                                       Park Theatre   \n",
      "\n",
      "                                              tgt_results  \n",
      "0       [[17247558, 5], [775, 5], [99861, 6], [198156,...  \n",
      "1       [[26267882, 6], [15415955, 5], [15417874, 5], ...  \n",
      "2       [[10635, 3], [369400, 3], [3666706, 3], [93251...  \n",
      "3       [[772, 6], [23890234, 5], [976737, 5], [609650...  \n",
      "4       [[215910, 6], [50020017, 5], [61602725, 5], [6...  \n",
      "...                                                   ...  \n",
      "200327  [[62733696, 6], [28698611, 5], [33084945, 4], ...  \n",
      "200328  [[12409269, 4], [23463411, 4], [2200906, 4], [...  \n",
      "200329                       [[43077376, 6], [895585, 3]]  \n",
      "200330                      [[2341895, 3], [17311374, 1]]  \n",
      "200331  [[34554615, 6], [20015794, 5], [51999416, 4], ...  \n",
      "\n",
      "[200332 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15e88d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          src_id                   src_query  \\\n",
      "0             11      Politique en Argentine   \n",
      "1             18                Arsène Lupin   \n",
      "2             24  Algèbre de Boole (logique)   \n",
      "3             33        Allier (département)   \n",
      "4             38        Ariège (département)   \n",
      "...          ...                         ...   \n",
      "199487  13025818                Seututie 132   \n",
      "199488  13025925  University Press of Kansas   \n",
      "199489  13026149               Amaya Coppens   \n",
      "199490  13026179                     Naurois   \n",
      "199491  13026355     Jean-Baptiste Le Gobien   \n",
      "\n",
      "                                              tgt_results  \n",
      "0       [[67621, 6], [1765711, 4], [28820502, 3], [189...  \n",
      "1       [[562921, 6], [34206604, 5], [31501305, 5], [3...  \n",
      "2       [[54476844, 6], [12351101, 5], [3959, 4], [172...  \n",
      "3       [[83188, 6], [6815222, 4], [5509252, 4], [2646...  \n",
      "4       [[90516, 6], [44740134, 5], [15431398, 4], [15...  \n",
      "...                                                   ...  \n",
      "199487  [[35431, 5], [10470604, 4], [1643328, 4], [303...  \n",
      "199488  [[9583161, 6], [13576372, 5], [1964954, 5], [9...  \n",
      "199489  [[45866, 5], [17518264, 4], [13449420, 4], [17...  \n",
      "199490  [[25845616, 5], [70180, 3], [60910932, 2], [15...  \n",
      "199491  [[17180331, 5], [16125, 4], [4029003, 2], [190...  \n",
      "\n",
      "[199492 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c70c6832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          src_id                      src_query  \\\n",
      "0             12  Armée républicaine irlandaise   \n",
      "1             30                       Auvergne   \n",
      "2             36          Ardèche (département)   \n",
      "3             46                 Afrique du Sud   \n",
      "4             91                    Abréviation   \n",
      "...          ...                            ...   \n",
      "199378  13026431      Parti populaire taïwanais   \n",
      "199379  13027196            Ultratop 50 Singles   \n",
      "199380  13033303                           Paws   \n",
      "199381  13033673                           Kymi   \n",
      "199382  13034393                        Toninho   \n",
      "\n",
      "                                              tgt_results  \n",
      "0       [[2261091, 6], [5859, 5], [25731, 5], [23299, ...  \n",
      "1       [[1652343, 6], [38828087, 5], [97133, 5], [542...  \n",
      "2       [[90510, 6], [15429574, 4], [15428857, 4], [14...  \n",
      "3       [[17416221, 6], [1512718, 5], [11791906, 5], [...  \n",
      "4       [[1171, 6], [12984404, 5], [50969, 5], [113095...  \n",
      "...                                                   ...  \n",
      "199378  [[908400, 5], [58791, 4], [38663457, 4], [1601...  \n",
      "199379  [[6836546, 4], [48301717, 2], [47931931, 2], [...  \n",
      "199380  [[4104102, 5], [474945, 5], [3924125, 5], [169...  \n",
      "199381  [[33220584, 6], [23625680, 5], [31201653, 5], ...  \n",
      "199382  [[11773819, 6], [28605205, 5], [2053737, 5], [...  \n",
      "\n",
      "[199383 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285bbdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "total_data = gzip.open(total_data_path,'r')\n",
    "documents = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2debdd67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5984196\n"
     ]
    }
   ],
   "source": [
    "for line in total_data:\n",
    "    tmp = line.decode().split('\\t')\n",
    "    documents[int(tmp[0])] = tmp[1]\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "590d4ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The benefactive case (abbreviated BEN, or sometimes B when it is a core argument) is a grammatical case used where English would use \"for\", \"for the benefit of\", or \"intended for\", e.g. \"She opened the door for Tom\" or \"This book is for Bob\". The benefactive case expresses that the referent of the noun it marks receives the benefit of the situation expressed by the clause. This meaning is often incorporated in a dative case. In Latin this type of dative is called the dativus commodi. An example of a language with a benefactive case is Basque, which has a benefactive case ending in -entzat. Quechua is another example, and the benefactive case ending in Quechua is -paq. Tangkhul-Naga (from the Tibeto-Burman group of languages) has the benefactive case marker -wiʋaŋ. In Aymaran, the benefactive case is marked with -taki, expressing that the referent of the inflected noun benefits from the situation expressed by the verb, or, when there is no verb, that the noun to which it attaches is a recipient, as in the word below: Benefactive meaning may also be marked on the verb, in a common type of applicative voice.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[617841]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca51ac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "1394980\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for _,row in train_data.iterrows():\n",
    "    row_data = {}\n",
    "    \n",
    "    # question\n",
    "    row_data['question'] = row['src_query']\n",
    "    # answer\n",
    "    row_data['answers'] = [row['src_query']]\n",
    "    \n",
    "    # positive_ctxs\n",
    "    row_data['positive_ctxs'] = []\n",
    "    positive_ctxs={}\n",
    "    # negative_ctxs\n",
    "    row_data['negative_ctxs'] = []\n",
    "    negative_ctxs={}\n",
    "    # hard_negative_ctxs\n",
    "    row_data['hard_negative_ctxs'] = []\n",
    "    hard_negative_ctxs={}\n",
    "    #########\n",
    "    #print('Starting PHASE 1')\n",
    "    # process through whole data (positive)\n",
    "    found_positive = False\n",
    "    for item in row['tgt_results']:\n",
    "        #positive_ctxs['title']=row['src_query']\n",
    "        if item[1]==6:\n",
    "            positive_ctxs['text']=documents[int(item[0])]\n",
    "            found_positive = True\n",
    "            break\n",
    "    if found_positive==False:\n",
    "        for item in row['tgt_results']:\n",
    "            if item[1]==5:\n",
    "                positive_ctxs['text']=documents[int(item[0])]\n",
    "                found_positive=True\n",
    "                break\n",
    "    if found_positive==False:\n",
    "        positive_ctxs['text']=documents[int(row['tgt_results'][0][0])]\n",
    "        found_positive=True\n",
    "    #print('Ending PHASE 1')\n",
    "    #########\n",
    "    #print('Starting PHASE 2')\n",
    "    # process through whole data (negative)\n",
    "    negative_ctxs['text']=documents[int(row['tgt_results'][int(len(row['tgt_results'])*0.4)][0])]\n",
    "    #print('Ending PHASE 2')\n",
    "    #########\n",
    "    # process through whole data (hard_negative)\n",
    "    hard_negative_ctxs['text']=documents[int(row['tgt_results'][-1][0])]\n",
    "    #########\n",
    "    row_data['positive_ctxs'].append(positive_ctxs)\n",
    "    row_data['negative_ctxs'].append(negative_ctxs)\n",
    "    row_data['hard_negative_ctxs'].append(hard_negative_ctxs)\n",
    "    data.append(row_data)\n",
    "    if _ % 139498==0:\n",
    "        print('Good!')\n",
    "        \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15be2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_data_path = os.path.join(data_path,'clirmatrix_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2448577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = json.dumps(data, indent=4)\n",
    "with open(output_data_path,'w') as o:\n",
    "    o.write(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b694ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "200332\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for _,row in dev_data.iterrows():\n",
    "    row_data = {}\n",
    "    \n",
    "    # question\n",
    "    row_data['question'] = row['src_query']\n",
    "    # answer\n",
    "    row_data['answers'] = [row['src_query']]\n",
    "    \n",
    "    # positive_ctxs\n",
    "    row_data['positive_ctxs'] = []\n",
    "    positive_ctxs={}\n",
    "    # negative_ctxs\n",
    "    row_data['negative_ctxs'] = []\n",
    "    negative_ctxs={}\n",
    "    # hard_negative_ctxs\n",
    "    row_data['hard_negative_ctxs'] = []\n",
    "    hard_negative_ctxs={}\n",
    "    #########\n",
    "    #print('Starting PHASE 1')\n",
    "    # process through whole data (positive)\n",
    "    found_positive = False\n",
    "    for item in row['tgt_results']:\n",
    "        #positive_ctxs['title']=row['src_query']\n",
    "        if item[1]==6:\n",
    "            positive_ctxs['text']=documents[int(item[0])]\n",
    "            found_positive = True\n",
    "            break\n",
    "    if found_positive==False:\n",
    "        for item in row['tgt_results']:\n",
    "            if item[1]==5:\n",
    "                positive_ctxs['text']=documents[int(item[0])]\n",
    "                found_positive=True\n",
    "                break\n",
    "    if found_positive==False:\n",
    "        positive_ctxs['text']=documents[int(row['tgt_results'][0][0])]\n",
    "        found_positive=True\n",
    "    #print('Ending PHASE 1')\n",
    "    #########\n",
    "    #print('Starting PHASE 2')\n",
    "    # process through whole data (negative)\n",
    "    negative_ctxs['text']=documents[int(row['tgt_results'][int(len(row['tgt_results'])*0.4)][0])]\n",
    "    #print('Ending PHASE 2')\n",
    "    #########\n",
    "    # process through whole data (hard_negative)\n",
    "    hard_negative_ctxs['text']=documents[int(row['tgt_results'][-1][0])]\n",
    "    #########\n",
    "    row_data['positive_ctxs'].append(positive_ctxs)\n",
    "    row_data['negative_ctxs'].append(negative_ctxs)\n",
    "    row_data['hard_negative_ctxs'].append(hard_negative_ctxs)\n",
    "    data.append(row_data)\n",
    "    if _ % 20033==0:\n",
    "        print('Good!')\n",
    "        \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adaf7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_path = os.path.join(data_path,'clirmatrix_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bda980a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = json.dumps(data, indent=4)\n",
    "with open(output_data_path,'w') as o:\n",
    "    o.write(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fe8558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "Good!\n",
      "398875\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for _,row in test1_data.iterrows():\n",
    "    row_data = {}\n",
    "    \n",
    "    # question\n",
    "    row_data['question'] = row['src_query']\n",
    "    # answer\n",
    "    row_data['answers'] = [row['src_query']]\n",
    "    \n",
    "    # positive_ctxs\n",
    "    row_data['positive_ctxs'] = []\n",
    "    positive_ctxs={}\n",
    "    # negative_ctxs\n",
    "    row_data['negative_ctxs'] = []\n",
    "    negative_ctxs={}\n",
    "    # hard_negative_ctxs\n",
    "    row_data['hard_negative_ctxs'] = []\n",
    "    hard_negative_ctxs={}\n",
    "    #########\n",
    "    #print('Starting PHASE 1')\n",
    "    # process through whole data (positive)\n",
    "    found_positive = False\n",
    "    for item in row['tgt_results']:\n",
    "        #positive_ctxs['title']=row['src_query']\n",
    "        if item[1]==6:\n",
    "            positive_ctxs['text']=documents[int(item[0])]\n",
    "            found_positive = True\n",
    "            break\n",
    "    if found_positive==False:\n",
    "        for item in row['tgt_results']:\n",
    "            if item[1]==5:\n",
    "                positive_ctxs['text']=documents[int(item[0])]\n",
    "                found_positive=True\n",
    "                break\n",
    "    if found_positive==False:\n",
    "        positive_ctxs['text']=documents[int(row['tgt_results'][0][0])]\n",
    "        found_positive=True\n",
    "    #print('Ending PHASE 1')\n",
    "    #########\n",
    "    #print('Starting PHASE 2')\n",
    "    # process through whole data (negative)\n",
    "    negative_ctxs['text']=documents[int(row['tgt_results'][int(len(row['tgt_results'])*0.4)][0])]\n",
    "    #print('Ending PHASE 2')\n",
    "    #########\n",
    "    # process through whole data (hard_negative)\n",
    "    hard_negative_ctxs['text']=documents[int(row['tgt_results'][-1][0])]\n",
    "    #########\n",
    "    row_data['positive_ctxs'].append(positive_ctxs)\n",
    "    row_data['negative_ctxs'].append(negative_ctxs)\n",
    "    row_data['hard_negative_ctxs'].append(hard_negative_ctxs)\n",
    "    data.append(row_data)\n",
    "    if _ % 19949==0:\n",
    "        print('Good!')\n",
    "for _,row in test2_data.iterrows():\n",
    "    row_data = {}\n",
    "    \n",
    "    # question\n",
    "    row_data['question'] = row['src_query']\n",
    "    # answer\n",
    "    row_data['answers'] = [row['src_query']]\n",
    "    \n",
    "    # positive_ctxs\n",
    "    row_data['positive_ctxs'] = []\n",
    "    positive_ctxs={}\n",
    "    # negative_ctxs\n",
    "    row_data['negative_ctxs'] = []\n",
    "    negative_ctxs={}\n",
    "    # hard_negative_ctxs\n",
    "    row_data['hard_negative_ctxs'] = []\n",
    "    hard_negative_ctxs={}\n",
    "    #########\n",
    "    #print('Starting PHASE 1')\n",
    "    # process through whole data (positive)\n",
    "    found_positive = False\n",
    "    for item in row['tgt_results']:\n",
    "        #positive_ctxs['title']=row['src_query']\n",
    "        if item[1]==6:\n",
    "            positive_ctxs['text']=documents[int(item[0])]\n",
    "            found_positive = True\n",
    "            break\n",
    "    if found_positive==False:\n",
    "        for item in row['tgt_results']:\n",
    "            if item[1]==5:\n",
    "                positive_ctxs['text']=documents[int(item[0])]\n",
    "                found_positive=True\n",
    "                break\n",
    "    if found_positive==False:\n",
    "        positive_ctxs['text']=documents[int(row['tgt_results'][0][0])]\n",
    "        found_positive=True\n",
    "    #print('Ending PHASE 1')\n",
    "    #########\n",
    "    #print('Starting PHASE 2')\n",
    "    # process through whole data (negative)\n",
    "    negative_ctxs['text']=documents[int(row['tgt_results'][int(len(row['tgt_results'])*0.4)][0])]\n",
    "    #print('Ending PHASE 2')\n",
    "    #########\n",
    "    # process through whole data (hard_negative)\n",
    "    hard_negative_ctxs['text']=documents[int(row['tgt_results'][-1][0])]\n",
    "    #########\n",
    "    row_data['positive_ctxs'].append(positive_ctxs)\n",
    "    row_data['negative_ctxs'].append(negative_ctxs)\n",
    "    row_data['hard_negative_ctxs'].append(hard_negative_ctxs)\n",
    "    data.append(row_data)\n",
    "    if _ % 19949==0:\n",
    "        print('Good!')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6840b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_path = os.path.join(data_path,'clirmatrix_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb1125d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = json.dumps(data, indent=4)\n",
    "with open(output_data_path,'w') as o:\n",
    "    o.write(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40674371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitachiōmiya\n"
     ]
    }
   ],
   "source": [
    "print(\"Hitachi\\u014dmiya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9864d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
