[2022-01-11 10:39:38,688][root][INFO] - args.local_rank 1
[2022-01-11 10:39:38,689][root][INFO] - WORLD_SIZE 4
[2022-01-11 10:39:38,697][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 1
[2022-01-11 10:39:38,734][root][INFO] - args.local_rank 3
[2022-01-11 10:39:38,734][root][INFO] - WORLD_SIZE 4
[2022-01-11 10:39:38,740][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 3
[2022-01-11 10:39:38,747][root][INFO] - args.local_rank 2
[2022-01-11 10:39:38,747][root][INFO] - WORLD_SIZE 4
[2022-01-11 10:39:38,754][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 2
[2022-01-11 10:39:38,768][root][INFO] - args.local_rank 0
[2022-01-11 10:39:38,768][root][INFO] - WORLD_SIZE 4
[2022-01-11 10:39:38,777][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2022-01-11 10:39:38,777][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-01-11 10:39:38,777][root][INFO] - Initialized host 0de619824160 as d.rank 0 on device=cuda:0, n_gpu=1, world size=4
[2022-01-11 10:39:38,777][root][INFO] - 16-bits training: False 
[2022-01-11 10:39:38,777][root][INFO] - CFG (after gpu  configuration):
[2022-01-11 10:39:38,780][torch.distributed.distributed_c10d][INFO] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-01-11 10:39:38,781][root][INFO] - Initialized host 0de619824160 as d.rank 1 on device=cuda:1, n_gpu=1, world size=4
[2022-01-11 10:39:38,781][root][INFO] - 16-bits training: False 
[2022-01-11 10:39:38,781][root][INFO] - ***** Initializing components for training *****
[2022-01-11 10:39:38,782][torch.distributed.distributed_c10d][INFO] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-01-11 10:39:38,782][root][INFO] - Checkpoint files []
[2022-01-11 10:39:38,783][root][INFO] - Initialized host 0de619824160 as d.rank 3 on device=cuda:3, n_gpu=1, world size=4
[2022-01-11 10:39:38,783][root][INFO] - 16-bits training: False 
[2022-01-11 10:39:38,783][root][INFO] - encoder:
  encoder_model_type: hf_bert
  pretrained_model_cfg: bert-base-uncased
  pretrained_file: null
  projection_dim: 0
  sequence_length: 256
  dropout: 0.1
  fix_ctx_encoder: false
  pretrained: true
train:
  batch_size: 16
  dev_batch_size: 64
  adam_eps: 1.0e-08
  adam_betas: (0.9, 0.999)
  max_grad_norm: 2.0
  log_batch_step: 100
  train_rolling_loss_step: 100
  weight_decay: 0.0
  learning_rate: 1.0e-05
  warmup_steps: 2474
  gradient_accumulation_steps: 1
  num_train_epochs: 40
  eval_per_epoch: 1
  hard_negatives: 1
  other_negatives: 0
  val_av_rank_hard_neg: 30
  val_av_rank_other_neg: 30
  val_av_rank_bsz: 128
  val_av_rank_max_qs: 10000
datasets:
  nq_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-train
  nq_train_hn1:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-adv-hn-train
  nq_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-dev
  trivia_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.trivia-train
  trivia_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.trivia-dev
  squad1_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.squad1-train
  squad1_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.squad1-dev
  webq_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.webq-train
  webq_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.webq-dev
  curatedtrec_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.curatedtrec-train
  curatedtrec_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.curatedtrec-dev
train_datasets:
- nq_train
dev_datasets:
- nq_dev
output_dir: ./nq_out
train_sampling_rates: null
loss_scale_factors: null
do_lower_case: true
fix_ctx_encoder: false
val_av_rank_start_epoch: 30
seed: 12345
checkpoint_file_name: dpr_biencoder
model_file: null
local_rank: 0
global_loss_buf_sz: 592000
device: cuda:0
distributed_world_size: 4
distributed_port: null
no_cuda: false
n_gpu: 1
fp16: false
fp16_opt_level: O1
special_tokens: null
ignore_checkpoint_offset: false
ignore_checkpoint_optimizer: false
multi_q_encoder: false

[2022-01-11 10:39:38,783][root][INFO] - ***** Initializing components for training *****
[2022-01-11 10:39:38,783][root][INFO] - Checkpoint files []
[2022-01-11 10:39:38,784][root][INFO] - ***** Initializing components for training *****
[2022-01-11 10:39:38,784][root][INFO] - Checkpoint files []
[2022-01-11 10:39:38,785][torch.distributed.distributed_c10d][INFO] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-01-11 10:39:38,785][root][INFO] - Initialized host 0de619824160 as d.rank 2 on device=cuda:2, n_gpu=1, world size=4
[2022-01-11 10:39:38,786][root][INFO] - 16-bits training: False 
[2022-01-11 10:39:38,786][root][INFO] - ***** Initializing components for training *****
[2022-01-11 10:39:38,786][transformers.file_utils][INFO] - PyTorch version 1.10.1 available.
[2022-01-11 10:39:38,786][root][INFO] - Checkpoint files []
[2022-01-11 10:39:38,790][transformers.file_utils][INFO] - PyTorch version 1.10.1 available.
[2022-01-11 10:39:38,792][transformers.file_utils][INFO] - PyTorch version 1.10.1 available.
[2022-01-11 10:39:38,792][transformers.file_utils][INFO] - PyTorch version 1.10.1 available.
[2022-01-11 10:39:39,988][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2022-01-11 10:39:39,989][transformers.configuration_utils][INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2022-01-11 10:39:39,993][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2022-01-11 10:39:39,994][transformers.configuration_utils][INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2022-01-11 10:39:39,998][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2022-01-11 10:39:39,999][transformers.configuration_utils][INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2022-01-11 10:39:40,037][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2022-01-11 10:39:40,038][transformers.configuration_utils][INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2022-01-11 10:39:40,211][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2022-01-11 10:39:40,212][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2022-01-11 10:39:40,216][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2022-01-11 10:39:40,219][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2022-01-11 10:39:42,736][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing HFBertEncoder.

[2022-01-11 10:39:42,737][transformers.modeling_utils][INFO] - All the weights of HFBertEncoder were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use HFBertEncoder for predictions without further training.
[2022-01-11 10:39:42,739][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing HFBertEncoder.

[2022-01-11 10:39:42,740][transformers.modeling_utils][INFO] - All the weights of HFBertEncoder were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use HFBertEncoder for predictions without further training.
[2022-01-11 10:39:42,744][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing HFBertEncoder.

[2022-01-11 10:39:42,744][transformers.modeling_utils][INFO] - All the weights of HFBertEncoder were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use HFBertEncoder for predictions without further training.
[2022-01-11 10:39:42,750][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing HFBertEncoder.

[2022-01-11 10:39:42,750][transformers.modeling_utils][INFO] - All the weights of HFBertEncoder were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use HFBertEncoder for predictions without further training.
[2022-01-11 10:39:43,572][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2022-01-11 10:39:43,573][transformers.configuration_utils][INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2022-01-11 10:39:43,576][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2022-01-11 10:39:43,577][transformers.configuration_utils][INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2022-01-11 10:39:43,580][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2022-01-11 10:39:43,581][transformers.configuration_utils][INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2022-01-11 10:39:43,588][transformers.configuration_utils][INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2022-01-11 10:39:43,589][transformers.configuration_utils][INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2022-01-11 10:39:43,630][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2022-01-11 10:39:43,630][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2022-01-11 10:39:43,647][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2022-01-11 10:39:43,648][transformers.modeling_utils][INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2022-01-11 10:39:46,096][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing HFBertEncoder.

[2022-01-11 10:39:46,097][transformers.modeling_utils][INFO] - All the weights of HFBertEncoder were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use HFBertEncoder for predictions without further training.
[2022-01-11 10:39:46,097][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing HFBertEncoder.

[2022-01-11 10:39:46,097][transformers.modeling_utils][INFO] - All the weights of HFBertEncoder were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use HFBertEncoder for predictions without further training.
[2022-01-11 10:39:46,103][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing HFBertEncoder.

[2022-01-11 10:39:46,103][transformers.modeling_utils][INFO] - All the weights of HFBertEncoder were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use HFBertEncoder for predictions without further training.
[2022-01-11 10:39:46,464][transformers.modeling_utils][INFO] - All model checkpoint weights were used when initializing HFBertEncoder.

[2022-01-11 10:39:46,464][transformers.modeling_utils][INFO] - All the weights of HFBertEncoder were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use HFBertEncoder for predictions without further training.
[2022-01-11 10:39:46,948][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
[2022-01-11 10:39:46,951][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
[2022-01-11 10:39:46,987][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
[2022-01-11 10:39:47,326][transformers.tokenization_utils_base][INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
[2022-01-11 10:39:52,634][dpr.utils.conf_utils][INFO] - train_datasets: ['nq_train']
[2022-01-11 10:39:52,638][dpr.data.biencoder_data][INFO] - Data files: []
[2022-01-11 10:39:52,638][dpr.utils.conf_utils][INFO] - train_datasets: ['nq_train']
[2022-01-11 10:39:52,639][dpr.utils.conf_utils][INFO] - dev_datasets: ['nq_dev']
[2022-01-11 10:39:52,640][dpr.data.biencoder_data][INFO] - Data files: []
[2022-01-11 10:39:52,640][root][INFO] - Initializing task/set data ['nq_train']
[2022-01-11 10:39:52,640][dpr.utils.conf_utils][INFO] - train_datasets: ['nq_train']
[2022-01-11 10:39:52,641][dpr.data.biencoder_data][INFO] - Data files: []
[2022-01-11 10:39:52,641][dpr.utils.conf_utils][INFO] - dev_datasets: ['nq_dev']
[2022-01-11 10:39:52,643][dpr.data.biencoder_data][INFO] - Data files: []
[2022-01-11 10:39:52,643][dpr.data.biencoder_data][INFO] - Data files: []
[2022-01-11 10:39:52,643][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz
[2022-01-11 10:39:52,643][dpr.data.download_data][INFO] - Download root_dir /root/DPR
[2022-01-11 10:39:52,643][dpr.utils.conf_utils][INFO] - dev_datasets: ['nq_dev']
[2022-01-11 10:39:52,643][root][INFO] - Initializing task/set data ['nq_train']
[2022-01-11 10:39:52,644][dpr.data.download_data][INFO] - File to be downloaded as /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,644][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,644][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2022-01-11 10:39:52,644][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/LICENSE
[2022-01-11 10:39:52,644][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2022-01-11 10:39:52,644][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/README
[2022-01-11 10:39:52,644][root][INFO] - Reading file /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,645][dpr.data.biencoder_data][INFO] - Data files: []
[2022-01-11 10:39:52,645][root][INFO] - Initializing task/set data ['nq_train']
[2022-01-11 10:39:52,645][dpr.utils.conf_utils][INFO] - train_datasets: ['nq_train']
[2022-01-11 10:39:52,646][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz
[2022-01-11 10:39:52,646][dpr.data.download_data][INFO] - Download root_dir /root/DPR
[2022-01-11 10:39:52,646][dpr.data.download_data][INFO] - File to be downloaded as /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,647][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,647][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2022-01-11 10:39:52,647][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/LICENSE
[2022-01-11 10:39:52,647][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2022-01-11 10:39:52,647][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/README
[2022-01-11 10:39:52,647][root][INFO] - Reading file /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,648][dpr.data.biencoder_data][INFO] - Data files: []
[2022-01-11 10:39:52,648][dpr.utils.conf_utils][INFO] - dev_datasets: ['nq_dev']
[2022-01-11 10:39:52,648][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz
[2022-01-11 10:39:52,649][dpr.data.download_data][INFO] - Download root_dir /root/DPR
[2022-01-11 10:39:52,649][dpr.data.biencoder_data][INFO] - Data files: []
[2022-01-11 10:39:52,649][dpr.data.download_data][INFO] - File to be downloaded as /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,649][root][INFO] - Initializing task/set data ['nq_train']
[2022-01-11 10:39:52,649][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,649][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2022-01-11 10:39:52,649][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/LICENSE
[2022-01-11 10:39:52,650][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2022-01-11 10:39:52,650][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/README
[2022-01-11 10:39:52,650][root][INFO] - Reading file /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,651][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz
[2022-01-11 10:39:52,652][dpr.data.download_data][INFO] - Download root_dir /root/DPR
[2022-01-11 10:39:52,652][dpr.data.download_data][INFO] - File to be downloaded as /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,652][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:39:52,652][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2022-01-11 10:39:52,652][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/LICENSE
[2022-01-11 10:39:52,652][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2022-01-11 10:39:52,652][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/README
[2022-01-11 10:39:52,652][root][INFO] - Reading file /root/DPR/downloads/data/retriever/nq-train.json
[2022-01-11 10:40:32,823][root][INFO] - Aggregated data size: 58880
[2022-01-11 10:40:32,847][dpr.data.biencoder_data][INFO] - Total cleaned data size: 58880
[2022-01-11 10:40:32,849][root][INFO] - samples_per_shard=14720, shard_start_idx=0, shard_end_idx=14720, max_iterations=920
[2022-01-11 10:40:32,849][root][INFO] - rank=0; Multi set data sizes [58880]
[2022-01-11 10:40:32,849][root][INFO] - rank=0; Multi set total data 58880
[2022-01-11 10:40:32,849][root][INFO] - rank=0; Multi set sampling_rates None
[2022-01-11 10:40:32,849][root][INFO] - rank=0; Multi set max_iterations per dataset [920]
[2022-01-11 10:40:32,849][root][INFO] - rank=0; Multi set max_iterations 920
[2022-01-11 10:40:32,849][root][INFO] -   Total iterations per epoch=920
[2022-01-11 10:40:32,849][root][INFO] -  Total updates=36800
[2022-01-11 10:40:32,849][root][INFO] -   Eval step = 920
[2022-01-11 10:40:32,849][root][INFO] - ***** Training *****
[2022-01-11 10:40:32,849][root][INFO] - ***** Epoch 0 *****
[2022-01-11 10:40:32,851][root][INFO] - rank=0; Iteration start
[2022-01-11 10:40:32,851][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:40:32,851][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 10:40:32,851][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 10:40:34,458][root][INFO] - Aggregated data size: 58880
[2022-01-11 10:40:34,522][dpr.data.biencoder_data][INFO] - Total cleaned data size: 58880
[2022-01-11 10:40:34,524][root][INFO] - samples_per_shard=14720, shard_start_idx=44160, shard_end_idx=58880, max_iterations=920
[2022-01-11 10:40:34,524][root][INFO] - rank=3; Multi set data sizes [58880]
[2022-01-11 10:40:34,525][root][INFO] - rank=3; Multi set total data 58880
[2022-01-11 10:40:34,525][root][INFO] - rank=3; Multi set sampling_rates None
[2022-01-11 10:40:34,525][root][INFO] - rank=3; Multi set max_iterations per dataset [920]
[2022-01-11 10:40:34,525][root][INFO] - rank=3; Multi set max_iterations 920
[2022-01-11 10:40:34,525][root][INFO] -   Total iterations per epoch=920
[2022-01-11 10:40:34,525][root][INFO] -  Total updates=36800
[2022-01-11 10:40:34,525][root][INFO] -   Eval step = 920
[2022-01-11 10:40:34,525][root][INFO] - ***** Training *****
[2022-01-11 10:40:34,525][root][INFO] - ***** Epoch 0 *****
[2022-01-11 10:40:34,527][root][INFO] - rank=3; Iteration start
[2022-01-11 10:40:34,527][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:40:34,527][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 10:40:34,527][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 10:40:34,609][root][INFO] - Aggregated data size: 58880
[2022-01-11 10:40:34,668][dpr.data.biencoder_data][INFO] - Total cleaned data size: 58880
[2022-01-11 10:40:34,670][root][INFO] - samples_per_shard=14720, shard_start_idx=14720, shard_end_idx=29440, max_iterations=920
[2022-01-11 10:40:34,671][root][INFO] - rank=1; Multi set data sizes [58880]
[2022-01-11 10:40:34,671][root][INFO] - rank=1; Multi set total data 58880
[2022-01-11 10:40:34,671][root][INFO] - rank=1; Multi set sampling_rates None
[2022-01-11 10:40:34,671][root][INFO] - rank=1; Multi set max_iterations per dataset [920]
[2022-01-11 10:40:34,671][root][INFO] - rank=1; Multi set max_iterations 920
[2022-01-11 10:40:34,671][root][INFO] -   Total iterations per epoch=920
[2022-01-11 10:40:34,671][root][INFO] -  Total updates=36800
[2022-01-11 10:40:34,671][root][INFO] -   Eval step = 920
[2022-01-11 10:40:34,671][root][INFO] - ***** Training *****
[2022-01-11 10:40:34,671][root][INFO] - ***** Epoch 0 *****
[2022-01-11 10:40:34,673][root][INFO] - rank=1; Iteration start
[2022-01-11 10:40:34,673][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:40:34,673][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 10:40:34,673][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 10:40:35,843][root][INFO] - Aggregated data size: 58880
[2022-01-11 10:40:35,867][dpr.data.biencoder_data][INFO] - Total cleaned data size: 58880
[2022-01-11 10:40:35,869][root][INFO] - samples_per_shard=14720, shard_start_idx=29440, shard_end_idx=44160, max_iterations=920
[2022-01-11 10:40:35,869][root][INFO] - rank=2; Multi set data sizes [58880]
[2022-01-11 10:40:35,869][root][INFO] - rank=2; Multi set total data 58880
[2022-01-11 10:40:35,869][root][INFO] - rank=2; Multi set sampling_rates None
[2022-01-11 10:40:35,869][root][INFO] - rank=2; Multi set max_iterations per dataset [920]
[2022-01-11 10:40:35,869][root][INFO] - rank=2; Multi set max_iterations 920
[2022-01-11 10:40:35,869][root][INFO] -   Total iterations per epoch=920
[2022-01-11 10:40:35,869][root][INFO] -  Total updates=36800
[2022-01-11 10:40:35,870][root][INFO] -   Eval step = 920
[2022-01-11 10:40:35,870][root][INFO] - ***** Training *****
[2022-01-11 10:40:35,870][root][INFO] - ***** Epoch 0 *****
[2022-01-11 10:40:35,871][root][INFO] - rank=2; Iteration start
[2022-01-11 10:40:35,871][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:40:35,871][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 10:40:35,872][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 10:40:37,820][root][INFO] - Epoch: 0: Step: 1/920, loss=28.257212, lr=0.000000
[2022-01-11 10:40:37,837][root][INFO] - Epoch: 0: Step: 1/920, loss=28.257212, lr=0.000000
[2022-01-11 10:40:37,850][root][INFO] - Epoch: 0: Step: 1/920, loss=28.257212, lr=0.000000
[2022-01-11 10:40:37,886][root][INFO] - Epoch: 0: Step: 1/920, loss=28.257212, lr=0.000000
[2022-01-11 10:42:02,945][root][INFO] - Train batch 100
[2022-01-11 10:42:02,945][root][INFO] - Avg. loss per last 100 batches: 22.479512
[2022-01-11 10:42:02,945][root][INFO] - Train batch 100
[2022-01-11 10:42:02,946][root][INFO] - Avg. loss per last 100 batches: 22.479512
[2022-01-11 10:42:02,946][root][INFO] - Train batch 100
[2022-01-11 10:42:02,946][root][INFO] - Avg. loss per last 100 batches: 22.479512
[2022-01-11 10:42:02,946][root][INFO] - Train batch 100
[2022-01-11 10:42:02,946][root][INFO] - Avg. loss per last 100 batches: 22.479512
[2022-01-11 10:42:03,792][root][INFO] - Epoch: 0: Step: 101/920, loss=13.206161, lr=0.000000
[2022-01-11 10:42:03,794][root][INFO] - Epoch: 0: Step: 101/920, loss=13.206161, lr=0.000000
[2022-01-11 10:42:03,795][root][INFO] - Epoch: 0: Step: 101/920, loss=13.206161, lr=0.000000
[2022-01-11 10:42:03,796][root][INFO] - Epoch: 0: Step: 101/920, loss=13.206161, lr=0.000000
[2022-01-11 10:43:28,684][root][INFO] - Train batch 200
[2022-01-11 10:43:28,684][root][INFO] - Avg. loss per last 100 batches: 7.353973
[2022-01-11 10:43:28,691][root][INFO] - Train batch 200
[2022-01-11 10:43:28,691][root][INFO] - Avg. loss per last 100 batches: 7.353973
[2022-01-11 10:43:28,692][root][INFO] - Train batch 200
[2022-01-11 10:43:28,692][root][INFO] - Avg. loss per last 100 batches: 7.353973
[2022-01-11 10:43:28,695][root][INFO] - Train batch 200
[2022-01-11 10:43:28,695][root][INFO] - Avg. loss per last 100 batches: 7.353973
[2022-01-11 10:43:29,541][root][INFO] - Epoch: 0: Step: 201/920, loss=6.872649, lr=0.000001
[2022-01-11 10:43:29,542][root][INFO] - Epoch: 0: Step: 201/920, loss=6.872649, lr=0.000001
[2022-01-11 10:43:29,543][root][INFO] - Epoch: 0: Step: 201/920, loss=6.872649, lr=0.000001
[2022-01-11 10:43:29,544][root][INFO] - Epoch: 0: Step: 201/920, loss=6.872649, lr=0.000001
[2022-01-11 10:44:53,393][root][INFO] - Train batch 300
[2022-01-11 10:44:53,393][root][INFO] - Avg. loss per last 100 batches: 3.647384
[2022-01-11 10:44:53,395][root][INFO] - Train batch 300
[2022-01-11 10:44:53,396][root][INFO] - Avg. loss per last 100 batches: 3.647384
[2022-01-11 10:44:53,401][root][INFO] - Train batch 300
[2022-01-11 10:44:53,401][root][INFO] - Avg. loss per last 100 batches: 3.647384
[2022-01-11 10:44:53,405][root][INFO] - Train batch 300
[2022-01-11 10:44:53,406][root][INFO] - Avg. loss per last 100 batches: 3.647384
[2022-01-11 10:44:54,249][root][INFO] - Epoch: 0: Step: 301/920, loss=2.486540, lr=0.000001
[2022-01-11 10:44:54,253][root][INFO] - Epoch: 0: Step: 301/920, loss=2.486540, lr=0.000001
[2022-01-11 10:44:54,254][root][INFO] - Epoch: 0: Step: 301/920, loss=2.486540, lr=0.000001
[2022-01-11 10:44:54,254][root][INFO] - Epoch: 0: Step: 301/920, loss=2.486540, lr=0.000001
[2022-01-11 10:46:18,968][root][INFO] - Train batch 400
[2022-01-11 10:46:18,969][root][INFO] - Avg. loss per last 100 batches: 1.825108
[2022-01-11 10:46:18,970][root][INFO] - Train batch 400
[2022-01-11 10:46:18,970][root][INFO] - Avg. loss per last 100 batches: 1.825108
[2022-01-11 10:46:18,970][root][INFO] - Train batch 400
[2022-01-11 10:46:18,971][root][INFO] - Avg. loss per last 100 batches: 1.825108
[2022-01-11 10:46:18,971][root][INFO] - Train batch 400
[2022-01-11 10:46:18,971][root][INFO] - Avg. loss per last 100 batches: 1.825108
[2022-01-11 10:46:19,801][root][INFO] - Epoch: 0: Step: 401/920, loss=0.835052, lr=0.000002
[2022-01-11 10:46:19,802][root][INFO] - Epoch: 0: Step: 401/920, loss=0.835052, lr=0.000002
[2022-01-11 10:46:19,806][root][INFO] - Epoch: 0: Step: 401/920, loss=0.835052, lr=0.000002
[2022-01-11 10:46:19,816][root][INFO] - Epoch: 0: Step: 401/920, loss=0.835052, lr=0.000002
[2022-01-11 10:47:44,616][root][INFO] - Train batch 500
[2022-01-11 10:47:44,617][root][INFO] - Avg. loss per last 100 batches: 0.934813
[2022-01-11 10:47:44,618][root][INFO] - Train batch 500
[2022-01-11 10:47:44,618][root][INFO] - Avg. loss per last 100 batches: 0.934813
[2022-01-11 10:47:44,627][root][INFO] - Train batch 500
[2022-01-11 10:47:44,627][root][INFO] - Avg. loss per last 100 batches: 0.934813
[2022-01-11 10:47:44,628][root][INFO] - Train batch 500
[2022-01-11 10:47:44,628][root][INFO] - Avg. loss per last 100 batches: 0.934813
[2022-01-11 10:47:45,471][root][INFO] - Epoch: 0: Step: 501/920, loss=0.677033, lr=0.000002
[2022-01-11 10:47:45,472][root][INFO] - Epoch: 0: Step: 501/920, loss=0.677033, lr=0.000002
[2022-01-11 10:47:45,473][root][INFO] - Epoch: 0: Step: 501/920, loss=0.677033, lr=0.000002
[2022-01-11 10:47:45,473][root][INFO] - Epoch: 0: Step: 501/920, loss=0.677033, lr=0.000002
[2022-01-11 10:49:10,366][root][INFO] - Train batch 600
[2022-01-11 10:49:10,366][root][INFO] - Avg. loss per last 100 batches: 0.621882
[2022-01-11 10:49:10,373][root][INFO] - Train batch 600
[2022-01-11 10:49:10,374][root][INFO] - Avg. loss per last 100 batches: 0.621882
[2022-01-11 10:49:10,376][root][INFO] - Train batch 600
[2022-01-11 10:49:10,376][root][INFO] - Avg. loss per last 100 batches: 0.621882
[2022-01-11 10:49:10,376][root][INFO] - Train batch 600
[2022-01-11 10:49:10,376][root][INFO] - Avg. loss per last 100 batches: 0.621882
[2022-01-11 10:49:11,215][root][INFO] - Epoch: 0: Step: 601/920, loss=0.664254, lr=0.000002
[2022-01-11 10:49:11,224][root][INFO] - Epoch: 0: Step: 601/920, loss=0.664254, lr=0.000002
[2022-01-11 10:49:11,224][root][INFO] - Epoch: 0: Step: 601/920, loss=0.664254, lr=0.000002
[2022-01-11 10:49:11,224][root][INFO] - Epoch: 0: Step: 601/920, loss=0.664254, lr=0.000002
[2022-01-11 10:50:35,163][root][INFO] - Train batch 700
[2022-01-11 10:50:35,164][root][INFO] - Avg. loss per last 100 batches: 0.474370
[2022-01-11 10:50:35,165][root][INFO] - Train batch 700
[2022-01-11 10:50:35,165][root][INFO] - Avg. loss per last 100 batches: 0.474370
[2022-01-11 10:50:35,169][root][INFO] - Train batch 700
[2022-01-11 10:50:35,169][root][INFO] - Avg. loss per last 100 batches: 0.474370
[2022-01-11 10:50:35,173][root][INFO] - Train batch 700
[2022-01-11 10:50:35,173][root][INFO] - Avg. loss per last 100 batches: 0.474370
[2022-01-11 10:50:36,007][root][INFO] - Epoch: 0: Step: 701/920, loss=0.232683, lr=0.000003
[2022-01-11 10:50:36,010][root][INFO] - Epoch: 0: Step: 701/920, loss=0.232683, lr=0.000003
[2022-01-11 10:50:36,016][root][INFO] - Epoch: 0: Step: 701/920, loss=0.232683, lr=0.000003
[2022-01-11 10:50:36,020][root][INFO] - Epoch: 0: Step: 701/920, loss=0.232683, lr=0.000003
[2022-01-11 10:52:00,802][root][INFO] - Train batch 800
[2022-01-11 10:52:00,802][root][INFO] - Avg. loss per last 100 batches: 0.390619
[2022-01-11 10:52:00,805][root][INFO] - Train batch 800
[2022-01-11 10:52:00,805][root][INFO] - Avg. loss per last 100 batches: 0.390619
[2022-01-11 10:52:00,815][root][INFO] - Train batch 800
[2022-01-11 10:52:00,815][root][INFO] - Avg. loss per last 100 batches: 0.390619
[2022-01-11 10:52:00,815][root][INFO] - Train batch 800
[2022-01-11 10:52:00,815][root][INFO] - Avg. loss per last 100 batches: 0.390619
[2022-01-11 10:52:01,659][root][INFO] - Epoch: 0: Step: 801/920, loss=0.526119, lr=0.000003
[2022-01-11 10:52:01,661][root][INFO] - Epoch: 0: Step: 801/920, loss=0.526119, lr=0.000003
[2022-01-11 10:52:01,663][root][INFO] - Epoch: 0: Step: 801/920, loss=0.526119, lr=0.000003
[2022-01-11 10:52:01,663][root][INFO] - Epoch: 0: Step: 801/920, loss=0.526119, lr=0.000003
[2022-01-11 10:53:26,388][root][INFO] - Train batch 900
[2022-01-11 10:53:26,388][root][INFO] - Avg. loss per last 100 batches: 0.363662
[2022-01-11 10:53:26,388][root][INFO] - Train batch 900
[2022-01-11 10:53:26,388][root][INFO] - Avg. loss per last 100 batches: 0.363662
[2022-01-11 10:53:26,389][root][INFO] - Train batch 900
[2022-01-11 10:53:26,389][root][INFO] - Avg. loss per last 100 batches: 0.363662
[2022-01-11 10:53:26,392][root][INFO] - Train batch 900
[2022-01-11 10:53:26,392][root][INFO] - Avg. loss per last 100 batches: 0.363662
[2022-01-11 10:53:27,232][root][INFO] - Epoch: 0: Step: 901/920, loss=0.351189, lr=0.000004
[2022-01-11 10:53:27,240][root][INFO] - Epoch: 0: Step: 901/920, loss=0.351189, lr=0.000004
[2022-01-11 10:53:27,241][root][INFO] - Epoch: 0: Step: 901/920, loss=0.351189, lr=0.000004
[2022-01-11 10:53:27,241][root][INFO] - Epoch: 0: Step: 901/920, loss=0.351189, lr=0.000004
[2022-01-11 10:53:43,354][root][INFO] - rank=1, Validation: Epoch: 0 Step: 920/920
[2022-01-11 10:53:43,355][root][INFO] - NLL validation ...
[2022-01-11 10:53:43,356][root][INFO] - Initializing task/set data ['nq_dev']
[2022-01-11 10:53:43,356][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz
[2022-01-11 10:53:43,356][dpr.data.download_data][INFO] - Download root_dir /root/DPR
[2022-01-11 10:53:43,356][dpr.data.download_data][INFO] - File to be downloaded as /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,356][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,356][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2022-01-11 10:53:43,356][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/LICENSE
[2022-01-11 10:53:43,356][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2022-01-11 10:53:43,357][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/README
[2022-01-11 10:53:43,357][root][INFO] - Reading file /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,359][root][INFO] - rank=2, Validation: Epoch: 0 Step: 920/920
[2022-01-11 10:53:43,359][root][INFO] - NLL validation ...
[2022-01-11 10:53:43,360][root][INFO] - rank=3, Validation: Epoch: 0 Step: 920/920
[2022-01-11 10:53:43,360][root][INFO] - NLL validation ...
[2022-01-11 10:53:43,360][root][INFO] - Initializing task/set data ['nq_dev']
[2022-01-11 10:53:43,360][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz
[2022-01-11 10:53:43,360][dpr.data.download_data][INFO] - Download root_dir /root/DPR
[2022-01-11 10:53:43,361][dpr.data.download_data][INFO] - File to be downloaded as /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,361][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,361][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2022-01-11 10:53:43,361][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/LICENSE
[2022-01-11 10:53:43,361][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2022-01-11 10:53:43,361][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/README
[2022-01-11 10:53:43,361][root][INFO] - Reading file /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,361][root][INFO] - Initializing task/set data ['nq_dev']
[2022-01-11 10:53:43,361][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz
[2022-01-11 10:53:43,361][dpr.data.download_data][INFO] - Download root_dir /root/DPR
[2022-01-11 10:53:43,361][root][INFO] - rank=0, Validation: Epoch: 0 Step: 920/920
[2022-01-11 10:53:43,362][dpr.data.download_data][INFO] - File to be downloaded as /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,362][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,362][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2022-01-11 10:53:43,362][root][INFO] - NLL validation ...
[2022-01-11 10:53:43,362][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/LICENSE
[2022-01-11 10:53:43,362][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2022-01-11 10:53:43,362][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/README
[2022-01-11 10:53:43,362][root][INFO] - Reading file /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,363][root][INFO] - Initializing task/set data ['nq_dev']
[2022-01-11 10:53:43,363][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz
[2022-01-11 10:53:43,363][dpr.data.download_data][INFO] - Download root_dir /root/DPR
[2022-01-11 10:53:43,363][dpr.data.download_data][INFO] - File to be downloaded as /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,363][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:43,363][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2022-01-11 10:53:43,363][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/LICENSE
[2022-01-11 10:53:43,363][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2022-01-11 10:53:43,364][dpr.data.download_data][INFO] - File already exist /root/DPR/downloads/data/retriever/README
[2022-01-11 10:53:43,364][root][INFO] - Reading file /root/DPR/downloads/data/retriever/nq-dev.json
[2022-01-11 10:53:48,442][root][INFO] - Aggregated data size: 6515
[2022-01-11 10:53:48,444][dpr.data.biencoder_data][INFO] - Total cleaned data size: 6515
[2022-01-11 10:53:48,444][root][INFO] - samples_per_shard=1629, shard_start_idx=4887, shard_end_idx=6515, max_iterations=25
[2022-01-11 10:53:48,444][root][INFO] - rank=3; Multi set data sizes [6515]
[2022-01-11 10:53:48,444][root][INFO] - rank=3; Multi set total data 6515
[2022-01-11 10:53:48,444][root][INFO] - rank=3; Multi set sampling_rates [1]
[2022-01-11 10:53:48,444][root][INFO] - rank=3; Multi set max_iterations per dataset [25]
[2022-01-11 10:53:48,444][root][INFO] - rank=3; Multi set max_iterations 25
[2022-01-11 10:53:48,445][root][INFO] - rank=3; Iteration start
[2022-01-11 10:53:48,445][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:53:48,445][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 10:53:48,445][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 10:53:48,450][root][INFO] - Aggregated data size: 6515
[2022-01-11 10:53:48,453][dpr.data.biencoder_data][INFO] - Total cleaned data size: 6515
[2022-01-11 10:53:48,453][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 10:53:48,453][root][INFO] - samples_per_shard=1629, shard_start_idx=1629, shard_end_idx=3258, max_iterations=25
[2022-01-11 10:53:48,453][root][INFO] - rank=1; Multi set data sizes [6515]
[2022-01-11 10:53:48,453][root][INFO] - rank=1; Multi set total data 6515
[2022-01-11 10:53:48,453][root][INFO] - rank=1; Multi set sampling_rates [1]
[2022-01-11 10:53:48,453][root][INFO] - rank=1; Multi set max_iterations per dataset [25]
[2022-01-11 10:53:48,453][root][INFO] - rank=1; Multi set max_iterations 25
[2022-01-11 10:53:48,454][root][INFO] - rank=1; Iteration start
[2022-01-11 10:53:48,454][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:53:48,454][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 10:53:48,454][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 10:53:48,462][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 10:53:48,471][root][INFO] - Aggregated data size: 6515
[2022-01-11 10:53:48,472][root][INFO] - Aggregated data size: 6515
[2022-01-11 10:53:48,473][dpr.data.biencoder_data][INFO] - Total cleaned data size: 6515
[2022-01-11 10:53:48,474][root][INFO] - samples_per_shard=1629, shard_start_idx=3258, shard_end_idx=4887, max_iterations=25
[2022-01-11 10:53:48,474][root][INFO] - rank=2; Multi set data sizes [6515]
[2022-01-11 10:53:48,474][root][INFO] - rank=2; Multi set total data 6515
[2022-01-11 10:53:48,474][root][INFO] - rank=2; Multi set sampling_rates [1]
[2022-01-11 10:53:48,474][root][INFO] - rank=2; Multi set max_iterations per dataset [25]
[2022-01-11 10:53:48,474][root][INFO] - rank=2; Multi set max_iterations 25
[2022-01-11 10:53:48,474][root][INFO] - rank=2; Iteration start
[2022-01-11 10:53:48,474][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:53:48,474][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 10:53:48,474][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 10:53:48,475][dpr.data.biencoder_data][INFO] - Total cleaned data size: 6515
[2022-01-11 10:53:48,475][root][INFO] - samples_per_shard=1629, shard_start_idx=0, shard_end_idx=1629, max_iterations=25
[2022-01-11 10:53:48,475][root][INFO] - rank=0; Multi set data sizes [6515]
[2022-01-11 10:53:48,475][root][INFO] - rank=0; Multi set total data 6515
[2022-01-11 10:53:48,475][root][INFO] - rank=0; Multi set sampling_rates [1]
[2022-01-11 10:53:48,475][root][INFO] - rank=0; Multi set max_iterations per dataset [25]
[2022-01-11 10:53:48,475][root][INFO] - rank=0; Multi set max_iterations 25
[2022-01-11 10:53:48,475][root][INFO] - rank=0; Iteration start
[2022-01-11 10:53:48,476][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:53:48,476][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 10:53:48,476][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 10:53:48,483][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 10:53:48,486][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 10:53:49,230][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 10:53:49,230][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 10:53:49,232][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 10:53:49,233][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 10:53:49,961][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 10:53:49,962][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 10:53:49,962][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 10:53:49,964][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 10:53:50,690][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 10:53:50,690][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 10:53:50,691][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 10:53:50,692][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 10:53:51,422][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 10:53:51,422][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 10:53:51,422][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 10:53:51,423][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 10:53:52,154][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 10:53:52,154][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 10:53:52,154][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 10:53:52,156][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 10:53:52,884][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 10:53:52,884][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 10:53:52,884][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 10:53:52,886][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 10:53:53,614][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 10:53:53,614][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 10:53:53,614][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 10:53:53,616][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 10:53:54,346][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 10:53:54,347][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 10:53:54,348][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 10:53:54,349][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 10:53:55,078][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 10:53:55,078][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 10:53:55,079][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 10:53:55,079][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 10:53:55,809][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 10:53:55,810][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 10:53:55,811][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 10:53:55,812][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 10:53:57,157][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 10:53:57,159][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 10:53:57,192][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 10:53:57,261][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 10:53:57,988][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 10:53:57,989][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 10:53:57,989][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 10:53:57,991][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 10:53:58,724][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 10:53:58,725][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 10:53:58,725][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 10:53:58,726][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 10:53:59,454][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 10:53:59,456][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 10:53:59,456][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 10:53:59,456][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 10:54:00,185][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 10:54:00,186][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 10:54:00,186][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 10:54:00,188][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 10:54:00,921][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 10:54:00,921][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 10:54:00,921][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 10:54:00,921][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 10:54:01,655][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 10:54:01,655][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 10:54:01,656][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 10:54:01,658][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 10:54:02,387][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 10:54:02,388][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 10:54:02,388][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 10:54:02,388][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 10:54:03,122][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 10:54:03,122][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 10:54:03,123][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 10:54:03,123][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 10:54:03,857][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 10:54:03,857][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 10:54:03,857][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 10:54:03,857][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 10:54:04,591][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 10:54:04,591][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 10:54:04,591][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 10:54:04,592][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 10:54:05,325][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 10:54:05,326][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 10:54:05,326][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 10:54:05,326][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 10:54:06,060][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 10:54:06,060][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 10:54:06,060][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 10:54:06,062][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 10:54:07,511][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 10:54:07,600][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 10:54:07,610][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 10:54:07,614][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 10:54:08,335][root][INFO] - rank=2; last iteration 25
[2022-01-11 10:54:08,335][root][INFO] - rank=0; last iteration 25
[2022-01-11 10:54:08,335][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 10:54:08,335][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 10:54:08,335][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 10:54:08,335][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 10:54:08,335][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:08,335][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:08,335][root][INFO] - rank=3; last iteration 25
[2022-01-11 10:54:08,335][root][INFO] - NLL Validation: loss = 0.644738. correct prediction ratio  5075/6400 ~  0.792969
[2022-01-11 10:54:08,335][root][INFO] - NLL Validation: loss = 0.644738. correct prediction ratio  5075/6400 ~  0.792969
[2022-01-11 10:54:08,335][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 10:54:08,335][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 10:54:08,335][root][INFO] - rank=1; last iteration 25
[2022-01-11 10:54:08,335][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:08,335][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 10:54:08,335][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 10:54:08,335][root][INFO] - NLL Validation: loss = 0.644738. correct prediction ratio  5075/6400 ~  0.792969
[2022-01-11 10:54:08,335][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:08,335][root][INFO] - NLL Validation: loss = 0.644738. correct prediction ratio  5075/6400 ~  0.792969
[2022-01-11 10:54:08,337][root][INFO] - rank=2; last iteration 920
[2022-01-11 10:54:08,338][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 10:54:08,338][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 10:54:08,338][root][INFO] - rank=3; last iteration 920
[2022-01-11 10:54:08,338][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 10:54:08,338][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 10:54:08,338][root][INFO] - rank=1; last iteration 920
[2022-01-11 10:54:08,338][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 10:54:08,338][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 10:54:08,338][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:08,338][root][INFO] - Epoch finished on 2
[2022-01-11 10:54:08,338][root][INFO] - NLL validation ...
[2022-01-11 10:54:08,338][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:08,338][root][INFO] - Epoch finished on 3
[2022-01-11 10:54:08,338][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:08,338][root][INFO] - NLL validation ...
[2022-01-11 10:54:08,339][root][INFO] - Epoch finished on 1
[2022-01-11 10:54:08,339][root][INFO] - NLL validation ...
[2022-01-11 10:54:08,339][root][INFO] - rank=2; Iteration start
[2022-01-11 10:54:08,339][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:54:08,339][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 10:54:08,340][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 10:54:08,340][root][INFO] - rank=3; Iteration start
[2022-01-11 10:54:08,340][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:54:08,340][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 10:54:08,340][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 10:54:08,340][root][INFO] - rank=1; Iteration start
[2022-01-11 10:54:08,340][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:54:08,340][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 10:54:08,340][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 10:54:08,349][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 10:54:08,349][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 10:54:08,349][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 10:54:11,705][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.0
[2022-01-11 10:54:11,706][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.0
[2022-01-11 10:54:11,706][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.0
[2022-01-11 10:54:11,707][root][INFO] - rank=0; last iteration 920
[2022-01-11 10:54:11,707][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 10:54:11,707][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 10:54:11,708][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:11,708][root][INFO] - Epoch finished on 0
[2022-01-11 10:54:11,708][root][INFO] - NLL validation ...
[2022-01-11 10:54:11,709][root][INFO] - rank=0; Iteration start
[2022-01-11 10:54:11,709][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:54:11,709][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 10:54:11,709][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 10:54:11,717][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 10:54:12,455][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 10:54:12,457][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 10:54:12,457][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 10:54:12,458][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 10:54:13,188][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 10:54:13,189][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 10:54:13,189][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 10:54:13,190][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 10:54:13,921][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 10:54:13,922][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 10:54:13,922][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 10:54:13,922][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 10:54:14,655][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 10:54:14,656][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 10:54:14,657][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 10:54:14,657][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 10:54:15,389][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 10:54:15,390][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 10:54:15,391][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 10:54:15,391][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 10:54:16,122][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 10:54:16,124][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 10:54:16,124][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 10:54:16,124][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 10:54:16,854][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 10:54:16,855][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 10:54:16,855][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 10:54:16,856][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 10:54:17,590][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 10:54:17,591][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 10:54:17,591][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 10:54:17,592][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 10:54:18,323][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 10:54:18,324][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 10:54:18,324][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 10:54:18,324][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 10:54:19,058][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 10:54:19,058][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 10:54:19,059][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 10:54:19,059][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 10:54:19,791][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 10:54:19,791][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 10:54:19,791][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 10:54:19,792][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 10:54:20,525][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 10:54:20,525][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 10:54:20,525][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 10:54:20,526][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 10:54:21,882][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 10:54:21,960][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 10:54:21,975][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 10:54:22,079][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 10:54:22,808][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 10:54:22,808][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 10:54:22,808][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 10:54:22,809][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 10:54:23,537][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 10:54:23,538][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 10:54:23,538][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 10:54:23,538][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 10:54:24,265][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 10:54:24,266][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 10:54:24,267][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 10:54:24,267][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 10:54:24,999][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 10:54:25,000][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 10:54:25,001][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 10:54:25,001][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 10:54:25,730][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 10:54:25,731][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 10:54:25,731][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 10:54:25,731][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 10:54:26,462][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 10:54:26,462][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 10:54:26,464][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 10:54:26,464][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 10:54:27,194][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 10:54:27,194][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 10:54:27,195][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 10:54:27,196][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 10:54:27,926][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 10:54:27,927][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 10:54:27,927][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 10:54:27,927][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 10:54:28,657][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 10:54:28,657][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 10:54:28,658][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 10:54:28,659][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 10:54:29,391][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 10:54:29,391][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 10:54:29,392][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 10:54:29,392][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 10:54:30,122][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 10:54:30,123][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 10:54:30,123][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 10:54:30,124][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 10:54:30,847][root][INFO] - rank=3; last iteration 25
[2022-01-11 10:54:30,847][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 10:54:30,847][root][INFO] - rank=1; last iteration 25
[2022-01-11 10:54:30,847][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 10:54:30,847][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 10:54:30,847][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:30,847][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 10:54:30,847][root][INFO] - NLL Validation: loss = 0.644738. correct prediction ratio  5075/6400 ~  0.792969
[2022-01-11 10:54:30,848][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:30,848][root][INFO] - NLL Validation: loss = 0.644738. correct prediction ratio  5075/6400 ~  0.792969
[2022-01-11 10:54:30,848][root][INFO] - rank=0; last iteration 25
[2022-01-11 10:54:30,848][root][INFO] - rank=2; last iteration 25
[2022-01-11 10:54:30,848][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 10:54:30,848][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 10:54:30,848][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 10:54:30,848][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 10:54:30,848][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:30,848][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 10:54:30,848][root][INFO] - NLL Validation: loss = 0.644738. correct prediction ratio  5075/6400 ~  0.792969
[2022-01-11 10:54:30,848][root][INFO] - NLL Validation: loss = 0.644738. correct prediction ratio  5075/6400 ~  0.792969
[2022-01-11 10:54:30,849][root][INFO] - Av Loss per epoch=4.148094
[2022-01-11 10:54:30,849][root][INFO] - epoch total correct predictions=37383
[2022-01-11 10:54:30,849][root][INFO] - Av Loss per epoch=4.148094
[2022-01-11 10:54:30,849][root][INFO] - epoch total correct predictions=37383
[2022-01-11 10:54:30,850][root][INFO] - Av Loss per epoch=4.148094
[2022-01-11 10:54:30,850][root][INFO] - epoch total correct predictions=37383
[2022-01-11 10:54:30,850][root][INFO] - ***** Epoch 1 *****
[2022-01-11 10:54:30,850][root][INFO] - ***** Epoch 1 *****
[2022-01-11 10:54:30,852][root][INFO] - ***** Epoch 1 *****
[2022-01-11 10:54:30,852][root][INFO] - rank=3; Iteration start
[2022-01-11 10:54:30,852][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:54:30,852][root][INFO] - rank=1; Iteration start
[2022-01-11 10:54:30,852][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 10:54:30,852][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:54:30,852][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 10:54:30,853][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 10:54:30,853][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 10:54:30,853][root][INFO] - rank=2; Iteration start
[2022-01-11 10:54:30,853][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:54:30,853][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 10:54:30,854][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 10:54:35,328][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.0
[2022-01-11 10:54:35,329][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.0
[2022-01-11 10:54:35,329][root][INFO] - Av Loss per epoch=4.148094
[2022-01-11 10:54:35,329][root][INFO] - epoch total correct predictions=37383
[2022-01-11 10:54:35,331][root][INFO] - ***** Epoch 1 *****
[2022-01-11 10:54:35,332][root][INFO] - rank=0; Iteration start
[2022-01-11 10:54:35,332][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 10:54:35,333][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 10:54:35,333][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 10:54:36,207][root][INFO] - Epoch: 1: Step: 1/920, loss=0.231082, lr=0.000004
[2022-01-11 10:54:36,210][root][INFO] - Epoch: 1: Step: 1/920, loss=0.231082, lr=0.000004
[2022-01-11 10:54:36,212][root][INFO] - Epoch: 1: Step: 1/920, loss=0.231082, lr=0.000004
[2022-01-11 10:54:36,213][root][INFO] - Epoch: 1: Step: 1/920, loss=0.231082, lr=0.000004
[2022-01-11 10:56:01,390][root][INFO] - Train batch 100
[2022-01-11 10:56:01,390][root][INFO] - Avg. loss per last 100 batches: 0.321521
[2022-01-11 10:56:01,399][root][INFO] - Train batch 100
[2022-01-11 10:56:01,399][root][INFO] - Avg. loss per last 100 batches: 0.321521
[2022-01-11 10:56:01,402][root][INFO] - Train batch 100
[2022-01-11 10:56:01,402][root][INFO] - Avg. loss per last 100 batches: 0.321521
[2022-01-11 10:56:01,402][root][INFO] - Train batch 100
[2022-01-11 10:56:01,402][root][INFO] - Avg. loss per last 100 batches: 0.321521
[2022-01-11 10:56:02,243][root][INFO] - Epoch: 1: Step: 101/920, loss=0.163800, lr=0.000004
[2022-01-11 10:56:02,250][root][INFO] - Epoch: 1: Step: 101/920, loss=0.163800, lr=0.000004
[2022-01-11 10:56:02,250][root][INFO] - Epoch: 1: Step: 101/920, loss=0.163800, lr=0.000004
[2022-01-11 10:56:02,251][root][INFO] - Epoch: 1: Step: 101/920, loss=0.163800, lr=0.000004
[2022-01-11 10:57:28,059][root][INFO] - Train batch 200
[2022-01-11 10:57:28,059][root][INFO] - Avg. loss per last 100 batches: 0.285022
[2022-01-11 10:57:28,067][root][INFO] - Train batch 200
[2022-01-11 10:57:28,067][root][INFO] - Avg. loss per last 100 batches: 0.285022
[2022-01-11 10:57:28,067][root][INFO] - Train batch 200
[2022-01-11 10:57:28,068][root][INFO] - Avg. loss per last 100 batches: 0.285022
[2022-01-11 10:57:28,068][root][INFO] - Train batch 200
[2022-01-11 10:57:28,068][root][INFO] - Avg. loss per last 100 batches: 0.285022
[2022-01-11 10:57:28,907][root][INFO] - Epoch: 1: Step: 201/920, loss=0.241788, lr=0.000005
[2022-01-11 10:57:28,915][root][INFO] - Epoch: 1: Step: 201/920, loss=0.241788, lr=0.000005
[2022-01-11 10:57:28,916][root][INFO] - Epoch: 1: Step: 201/920, loss=0.241788, lr=0.000005
[2022-01-11 10:57:28,917][root][INFO] - Epoch: 1: Step: 201/920, loss=0.241788, lr=0.000005
[2022-01-11 10:58:54,849][root][INFO] - Train batch 300
[2022-01-11 10:58:54,849][root][INFO] - Avg. loss per last 100 batches: 0.269466
[2022-01-11 10:58:54,853][root][INFO] - Train batch 300
[2022-01-11 10:58:54,853][root][INFO] - Avg. loss per last 100 batches: 0.269466
[2022-01-11 10:58:54,859][root][INFO] - Train batch 300
[2022-01-11 10:58:54,859][root][INFO] - Avg. loss per last 100 batches: 0.269466
[2022-01-11 10:58:54,863][root][INFO] - Train batch 300
[2022-01-11 10:58:54,863][root][INFO] - Avg. loss per last 100 batches: 0.269466
[2022-01-11 10:58:55,702][root][INFO] - Epoch: 1: Step: 301/920, loss=0.152184, lr=0.000005
[2022-01-11 10:58:55,706][root][INFO] - Epoch: 1: Step: 301/920, loss=0.152184, lr=0.000005
[2022-01-11 10:58:55,707][root][INFO] - Epoch: 1: Step: 301/920, loss=0.152184, lr=0.000005
[2022-01-11 10:58:55,713][root][INFO] - Epoch: 1: Step: 301/920, loss=0.152184, lr=0.000005
[2022-01-11 11:00:19,593][root][INFO] - Train batch 400
[2022-01-11 11:00:19,593][root][INFO] - Avg. loss per last 100 batches: 0.248518
[2022-01-11 11:00:19,597][root][INFO] - Train batch 400
[2022-01-11 11:00:19,597][root][INFO] - Avg. loss per last 100 batches: 0.248518
[2022-01-11 11:00:19,606][root][INFO] - Train batch 400
[2022-01-11 11:00:19,606][root][INFO] - Avg. loss per last 100 batches: 0.248518
[2022-01-11 11:00:19,607][root][INFO] - Train batch 400
[2022-01-11 11:00:19,607][root][INFO] - Avg. loss per last 100 batches: 0.248518
[2022-01-11 11:00:20,452][root][INFO] - Epoch: 1: Step: 401/920, loss=0.270676, lr=0.000005
[2022-01-11 11:00:20,456][root][INFO] - Epoch: 1: Step: 401/920, loss=0.270676, lr=0.000005
[2022-01-11 11:00:20,456][root][INFO] - Epoch: 1: Step: 401/920, loss=0.270676, lr=0.000005
[2022-01-11 11:00:20,457][root][INFO] - Epoch: 1: Step: 401/920, loss=0.270676, lr=0.000005
[2022-01-11 11:01:46,312][root][INFO] - Train batch 500
[2022-01-11 11:01:46,312][root][INFO] - Avg. loss per last 100 batches: 0.257444
[2022-01-11 11:01:46,315][root][INFO] - Train batch 500
[2022-01-11 11:01:46,315][root][INFO] - Avg. loss per last 100 batches: 0.257444
[2022-01-11 11:01:46,317][root][INFO] - Train batch 500
[2022-01-11 11:01:46,317][root][INFO] - Avg. loss per last 100 batches: 0.257444
[2022-01-11 11:01:46,317][root][INFO] - Train batch 500
[2022-01-11 11:01:46,318][root][INFO] - Avg. loss per last 100 batches: 0.257444
[2022-01-11 11:01:47,157][root][INFO] - Epoch: 1: Step: 501/920, loss=0.235870, lr=0.000006
[2022-01-11 11:01:47,162][root][INFO] - Epoch: 1: Step: 501/920, loss=0.235870, lr=0.000006
[2022-01-11 11:01:47,166][root][INFO] - Epoch: 1: Step: 501/920, loss=0.235870, lr=0.000006
[2022-01-11 11:01:47,167][root][INFO] - Epoch: 1: Step: 501/920, loss=0.235870, lr=0.000006
[2022-01-11 11:03:13,034][root][INFO] - Train batch 600
[2022-01-11 11:03:13,035][root][INFO] - Avg. loss per last 100 batches: 0.235473
[2022-01-11 11:03:13,042][root][INFO] - Train batch 600
[2022-01-11 11:03:13,042][root][INFO] - Avg. loss per last 100 batches: 0.235473
[2022-01-11 11:03:13,042][root][INFO] - Train batch 600
[2022-01-11 11:03:13,042][root][INFO] - Avg. loss per last 100 batches: 0.235473
[2022-01-11 11:03:13,045][root][INFO] - Train batch 600
[2022-01-11 11:03:13,045][root][INFO] - Avg. loss per last 100 batches: 0.235473
[2022-01-11 11:03:13,891][root][INFO] - Epoch: 1: Step: 601/920, loss=0.261642, lr=0.000006
[2022-01-11 11:03:13,892][root][INFO] - Epoch: 1: Step: 601/920, loss=0.261642, lr=0.000006
[2022-01-11 11:03:13,893][root][INFO] - Epoch: 1: Step: 601/920, loss=0.261642, lr=0.000006
[2022-01-11 11:03:13,894][root][INFO] - Epoch: 1: Step: 601/920, loss=0.261642, lr=0.000006
[2022-01-11 11:04:37,871][root][INFO] - Train batch 700
[2022-01-11 11:04:37,872][root][INFO] - Avg. loss per last 100 batches: 0.238087
[2022-01-11 11:04:37,875][root][INFO] - Train batch 700
[2022-01-11 11:04:37,875][root][INFO] - Avg. loss per last 100 batches: 0.238087
[2022-01-11 11:04:37,876][root][INFO] - Train batch 700
[2022-01-11 11:04:37,876][root][INFO] - Avg. loss per last 100 batches: 0.238087
[2022-01-11 11:04:37,877][root][INFO] - Train batch 700
[2022-01-11 11:04:37,877][root][INFO] - Avg. loss per last 100 batches: 0.238087
[2022-01-11 11:04:38,714][root][INFO] - Epoch: 1: Step: 701/920, loss=0.226298, lr=0.000007
[2022-01-11 11:04:38,715][root][INFO] - Epoch: 1: Step: 701/920, loss=0.226298, lr=0.000007
[2022-01-11 11:04:38,720][root][INFO] - Epoch: 1: Step: 701/920, loss=0.226298, lr=0.000007
[2022-01-11 11:04:38,725][root][INFO] - Epoch: 1: Step: 701/920, loss=0.226298, lr=0.000007
[2022-01-11 11:06:04,605][root][INFO] - Train batch 800
[2022-01-11 11:06:04,605][root][INFO] - Avg. loss per last 100 batches: 0.248711
[2022-01-11 11:06:04,607][root][INFO] - Train batch 800
[2022-01-11 11:06:04,607][root][INFO] - Train batch 800
[2022-01-11 11:06:04,607][root][INFO] - Avg. loss per last 100 batches: 0.248711
[2022-01-11 11:06:04,607][root][INFO] - Avg. loss per last 100 batches: 0.248711
[2022-01-11 11:06:04,607][root][INFO] - Train batch 800
[2022-01-11 11:06:04,608][root][INFO] - Avg. loss per last 100 batches: 0.248711
[2022-01-11 11:06:05,452][root][INFO] - Epoch: 1: Step: 801/920, loss=0.236888, lr=0.000007
[2022-01-11 11:06:05,453][root][INFO] - Epoch: 1: Step: 801/920, loss=0.236888, lr=0.000007
[2022-01-11 11:06:05,454][root][INFO] - Epoch: 1: Step: 801/920, loss=0.236888, lr=0.000007
[2022-01-11 11:06:05,454][root][INFO] - Epoch: 1: Step: 801/920, loss=0.236888, lr=0.000007
[2022-01-11 11:07:31,347][root][INFO] - Train batch 900
[2022-01-11 11:07:31,347][root][INFO] - Avg. loss per last 100 batches: 0.211827
[2022-01-11 11:07:31,348][root][INFO] - Train batch 900
[2022-01-11 11:07:31,348][root][INFO] - Avg. loss per last 100 batches: 0.211827
[2022-01-11 11:07:31,349][root][INFO] - Train batch 900
[2022-01-11 11:07:31,349][root][INFO] - Avg. loss per last 100 batches: 0.211827
[2022-01-11 11:07:31,351][root][INFO] - Train batch 900
[2022-01-11 11:07:31,351][root][INFO] - Avg. loss per last 100 batches: 0.211827
[2022-01-11 11:07:32,194][root][INFO] - Epoch: 1: Step: 901/920, loss=0.192883, lr=0.000007
[2022-01-11 11:07:32,194][root][INFO] - Epoch: 1: Step: 901/920, loss=0.192883, lr=0.000007
[2022-01-11 11:07:32,195][root][INFO] - Epoch: 1: Step: 901/920, loss=0.192883, lr=0.000007
[2022-01-11 11:07:32,195][root][INFO] - Epoch: 1: Step: 901/920, loss=0.192883, lr=0.000007
[2022-01-11 11:07:48,305][root][INFO] - rank=0, Validation: Epoch: 1 Step: 920/920
[2022-01-11 11:07:48,305][root][INFO] - NLL validation ...
[2022-01-11 11:07:48,305][root][INFO] - rank=1, Validation: Epoch: 1 Step: 920/920
[2022-01-11 11:07:48,305][root][INFO] - NLL validation ...
[2022-01-11 11:07:48,306][root][INFO] - rank=0; Iteration start
[2022-01-11 11:07:48,306][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:07:48,306][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:07:48,306][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 11:07:48,306][root][INFO] - rank=1; Iteration start
[2022-01-11 11:07:48,306][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:07:48,306][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:07:48,306][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 11:07:48,308][root][INFO] - rank=3, Validation: Epoch: 1 Step: 920/920
[2022-01-11 11:07:48,308][root][INFO] - NLL validation ...
[2022-01-11 11:07:48,309][root][INFO] - rank=2, Validation: Epoch: 1 Step: 920/920
[2022-01-11 11:07:48,309][root][INFO] - NLL validation ...
[2022-01-11 11:07:48,310][root][INFO] - rank=3; Iteration start
[2022-01-11 11:07:48,310][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:07:48,310][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:07:48,310][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 11:07:48,310][root][INFO] - rank=2; Iteration start
[2022-01-11 11:07:48,310][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:07:48,310][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:07:48,310][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 11:07:48,316][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 11:07:48,316][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 11:07:48,319][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 11:07:48,320][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 11:07:49,053][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 11:07:49,054][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 11:07:49,054][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 11:07:49,056][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 11:07:49,786][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 11:07:49,786][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 11:07:49,786][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 11:07:49,786][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 11:07:50,518][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 11:07:50,518][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 11:07:50,519][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 11:07:51,336][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 11:07:52,064][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 11:07:53,014][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 11:07:53,031][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 11:07:53,044][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 11:07:53,774][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 11:07:53,775][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 11:07:53,775][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 11:07:53,775][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 11:07:54,506][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 11:07:54,507][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 11:07:54,507][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 11:07:54,507][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 11:07:55,238][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 11:07:55,239][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 11:07:55,239][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 11:07:55,239][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 11:07:55,972][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 11:07:55,973][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 11:07:55,973][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 11:07:55,973][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 11:07:56,705][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 11:07:56,706][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 11:07:56,706][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 11:07:56,706][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 11:07:57,439][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 11:07:57,439][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 11:07:57,439][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 11:07:57,440][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 11:07:58,172][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 11:07:58,173][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 11:07:58,173][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 11:07:58,173][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 11:07:58,904][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 11:07:58,904][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 11:07:58,905][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 11:07:58,905][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 11:07:59,638][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 11:07:59,638][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 11:07:59,640][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 11:07:59,640][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 11:08:00,371][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 11:08:00,371][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 11:08:00,372][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 11:08:00,372][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 11:08:01,103][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 11:08:01,103][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 11:08:01,104][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 11:08:01,104][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 11:08:01,834][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 11:08:01,834][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 11:08:01,836][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 11:08:01,836][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 11:08:02,570][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 11:08:02,570][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 11:08:02,572][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 11:08:03,305][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 11:08:04,035][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 11:08:04,630][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 11:08:04,643][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 11:08:04,668][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 11:08:05,402][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 11:08:05,402][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 11:08:05,403][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 11:08:05,403][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 11:08:06,135][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 11:08:06,135][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 11:08:06,136][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 11:08:06,136][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 11:08:06,868][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 11:08:06,868][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 11:08:06,869][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 11:08:06,870][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 11:08:07,601][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 11:08:07,601][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 11:08:07,602][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 11:08:07,603][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 11:08:08,334][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 11:08:08,334][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 11:08:08,336][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 11:08:08,336][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 11:08:09,067][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 11:08:09,068][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 11:08:09,068][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 11:08:09,069][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 11:08:09,791][root][INFO] - rank=1; last iteration 25
[2022-01-11 11:08:09,791][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:08:09,791][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 11:08:09,791][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:09,791][root][INFO] - NLL Validation: loss = 0.483367. correct prediction ratio  5396/6400 ~  0.843125
[2022-01-11 11:08:09,792][root][INFO] - rank=2; last iteration 25
[2022-01-11 11:08:09,792][root][INFO] - rank=0; last iteration 25
[2022-01-11 11:08:09,792][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:08:09,792][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:08:09,792][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 11:08:09,792][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 11:08:09,792][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:09,792][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:09,792][root][INFO] - NLL Validation: loss = 0.483367. correct prediction ratio  5396/6400 ~  0.843125
[2022-01-11 11:08:09,792][root][INFO] - NLL Validation: loss = 0.483367. correct prediction ratio  5396/6400 ~  0.843125
[2022-01-11 11:08:09,792][root][INFO] - rank=3; last iteration 25
[2022-01-11 11:08:09,792][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:08:09,792][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 11:08:09,792][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:09,792][root][INFO] - NLL Validation: loss = 0.483367. correct prediction ratio  5396/6400 ~  0.843125
[2022-01-11 11:08:09,793][root][INFO] - rank=1; last iteration 920
[2022-01-11 11:08:09,794][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:08:09,794][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 11:08:09,794][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:09,794][root][INFO] - Epoch finished on 1
[2022-01-11 11:08:09,794][root][INFO] - NLL validation ...
[2022-01-11 11:08:09,795][root][INFO] - rank=2; last iteration 920
[2022-01-11 11:08:09,795][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:08:09,795][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 11:08:09,795][root][INFO] - rank=3; last iteration 920
[2022-01-11 11:08:09,795][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:08:09,795][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 11:08:09,795][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:09,795][root][INFO] - Epoch finished on 2
[2022-01-11 11:08:09,795][root][INFO] - NLL validation ...
[2022-01-11 11:08:09,795][root][INFO] - rank=1; Iteration start
[2022-01-11 11:08:09,795][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:08:09,795][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:09,796][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:08:09,796][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 11:08:09,796][root][INFO] - Epoch finished on 3
[2022-01-11 11:08:09,796][root][INFO] - NLL validation ...
[2022-01-11 11:08:09,797][root][INFO] - rank=2; Iteration start
[2022-01-11 11:08:09,797][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:08:09,797][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:08:09,797][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 11:08:09,797][root][INFO] - rank=3; Iteration start
[2022-01-11 11:08:09,797][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:08:09,797][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:08:09,797][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 11:08:09,803][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 11:08:09,805][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 11:08:09,805][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 11:08:13,170][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.1
[2022-01-11 11:08:13,170][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.1
[2022-01-11 11:08:13,170][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.1
[2022-01-11 11:08:13,172][root][INFO] - rank=0; last iteration 920
[2022-01-11 11:08:13,172][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:08:13,172][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 11:08:13,172][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:13,172][root][INFO] - Epoch finished on 0
[2022-01-11 11:08:13,172][root][INFO] - NLL validation ...
[2022-01-11 11:08:13,174][root][INFO] - rank=0; Iteration start
[2022-01-11 11:08:13,174][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:08:13,174][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:08:13,174][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 11:08:13,182][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 11:08:13,917][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 11:08:13,917][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 11:08:13,918][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 11:08:13,924][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 11:08:14,655][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 11:08:14,655][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 11:08:14,656][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 11:08:14,658][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 11:08:15,390][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 11:08:15,391][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 11:08:15,392][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 11:08:15,394][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 11:08:16,122][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 11:08:16,122][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 11:08:16,123][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 11:08:16,125][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 11:08:16,856][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 11:08:16,856][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 11:08:16,857][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 11:08:16,859][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 11:08:17,591][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 11:08:17,592][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 11:08:17,596][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 11:08:18,181][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 11:08:18,908][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 11:08:19,517][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 11:08:19,522][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 11:08:19,689][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 11:08:20,420][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 11:08:20,421][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 11:08:20,422][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 11:08:20,424][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 11:08:21,151][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 11:08:21,152][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 11:08:21,153][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 11:08:21,153][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 11:08:21,887][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 11:08:21,889][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 11:08:21,890][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 11:08:21,890][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 11:08:22,620][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 11:08:22,621][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 11:08:22,622][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 11:08:22,623][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 11:08:23,356][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 11:08:23,356][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 11:08:23,358][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 11:08:23,358][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 11:08:24,089][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 11:08:24,091][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 11:08:24,091][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 11:08:24,094][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 11:08:24,826][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 11:08:24,827][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 11:08:24,827][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 11:08:24,827][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 11:08:25,558][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 11:08:25,560][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 11:08:25,560][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 11:08:25,561][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 11:08:26,291][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 11:08:26,291][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 11:08:26,292][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 11:08:26,293][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 11:08:27,025][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 11:08:27,026][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 11:08:27,026][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 11:08:27,027][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 11:08:27,758][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 11:08:27,759][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 11:08:27,760][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 11:08:27,761][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 11:08:28,493][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 11:08:28,494][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 11:08:28,494][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 11:08:28,495][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 11:08:29,230][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 11:08:29,230][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 11:08:29,230][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 11:08:29,820][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 11:08:30,546][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 11:08:31,272][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 11:08:31,332][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 11:08:31,384][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 11:08:32,117][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 11:08:32,118][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 11:08:32,118][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 11:08:32,118][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 11:08:32,851][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 11:08:32,853][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 11:08:32,853][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 11:08:32,853][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 11:08:33,585][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 11:08:33,587][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 11:08:33,587][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 11:08:33,587][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 11:08:34,309][root][INFO] - rank=1; last iteration 25
[2022-01-11 11:08:34,309][root][INFO] - rank=3; last iteration 25
[2022-01-11 11:08:34,309][root][INFO] - rank=0; last iteration 25
[2022-01-11 11:08:34,309][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:08:34,309][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:08:34,309][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:08:34,309][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 11:08:34,309][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 11:08:34,309][root][INFO] - rank=2; last iteration 25
[2022-01-11 11:08:34,309][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 11:08:34,309][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:34,309][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:34,309][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:08:34,309][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:34,309][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 11:08:34,309][root][INFO] - NLL Validation: loss = 0.483367. correct prediction ratio  5396/6400 ~  0.843125
[2022-01-11 11:08:34,309][root][INFO] - NLL Validation: loss = 0.483367. correct prediction ratio  5396/6400 ~  0.843125
[2022-01-11 11:08:34,309][root][INFO] - NLL Validation: loss = 0.483367. correct prediction ratio  5396/6400 ~  0.843125
[2022-01-11 11:08:34,309][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:08:34,309][root][INFO] - NLL Validation: loss = 0.483367. correct prediction ratio  5396/6400 ~  0.843125
[2022-01-11 11:08:34,310][root][INFO] - Av Loss per epoch=0.256347
[2022-01-11 11:08:34,310][root][INFO] - Av Loss per epoch=0.256347
[2022-01-11 11:08:34,310][root][INFO] - epoch total correct predictions=53935
[2022-01-11 11:08:34,310][root][INFO] - epoch total correct predictions=53935
[2022-01-11 11:08:34,311][root][INFO] - Av Loss per epoch=0.256347
[2022-01-11 11:08:34,311][root][INFO] - epoch total correct predictions=53935
[2022-01-11 11:08:34,312][root][INFO] - ***** Epoch 2 *****
[2022-01-11 11:08:34,312][root][INFO] - ***** Epoch 2 *****
[2022-01-11 11:08:34,312][root][INFO] - ***** Epoch 2 *****
[2022-01-11 11:08:34,314][root][INFO] - rank=3; Iteration start
[2022-01-11 11:08:34,314][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:08:34,314][root][INFO] - rank=1; Iteration start
[2022-01-11 11:08:34,314][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:08:34,314][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:08:34,314][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:08:34,314][root][INFO] - rank=2; Iteration start
[2022-01-11 11:08:34,314][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:08:34,314][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:08:34,314][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 11:08:34,314][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 11:08:34,315][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 11:08:38,772][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.1
[2022-01-11 11:08:38,773][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.1
[2022-01-11 11:08:38,773][root][INFO] - Av Loss per epoch=0.256347
[2022-01-11 11:08:38,773][root][INFO] - epoch total correct predictions=53935
[2022-01-11 11:08:38,775][root][INFO] - ***** Epoch 2 *****
[2022-01-11 11:08:38,777][root][INFO] - rank=0; Iteration start
[2022-01-11 11:08:38,777][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:08:38,777][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:08:38,778][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 11:08:39,648][root][INFO] - Epoch: 2: Step: 1/920, loss=0.341096, lr=0.000007
[2022-01-11 11:08:39,659][root][INFO] - Epoch: 2: Step: 1/920, loss=0.341096, lr=0.000007
[2022-01-11 11:08:39,659][root][INFO] - Epoch: 2: Step: 1/920, loss=0.341096, lr=0.000007
[2022-01-11 11:08:39,659][root][INFO] - Epoch: 2: Step: 1/920, loss=0.341096, lr=0.000007
[2022-01-11 11:10:05,504][root][INFO] - Train batch 100
[2022-01-11 11:10:05,504][root][INFO] - Avg. loss per last 100 batches: 0.174710
[2022-01-11 11:10:05,507][root][INFO] - Train batch 100
[2022-01-11 11:10:05,507][root][INFO] - Avg. loss per last 100 batches: 0.174710
[2022-01-11 11:10:05,507][root][INFO] - Train batch 100
[2022-01-11 11:10:05,508][root][INFO] - Avg. loss per last 100 batches: 0.174710
[2022-01-11 11:10:05,508][root][INFO] - Train batch 100
[2022-01-11 11:10:05,508][root][INFO] - Avg. loss per last 100 batches: 0.174710
[2022-01-11 11:10:06,348][root][INFO] - Epoch: 2: Step: 101/920, loss=0.269705, lr=0.000008
[2022-01-11 11:10:06,355][root][INFO] - Epoch: 2: Step: 101/920, loss=0.269705, lr=0.000008
[2022-01-11 11:10:06,356][root][INFO] - Epoch: 2: Step: 101/920, loss=0.269705, lr=0.000008
[2022-01-11 11:10:06,356][root][INFO] - Epoch: 2: Step: 101/920, loss=0.269705, lr=0.000008
[2022-01-11 11:11:30,315][root][INFO] - Train batch 200
[2022-01-11 11:11:30,315][root][INFO] - Avg. loss per last 100 batches: 0.191194
[2022-01-11 11:11:30,315][root][INFO] - Train batch 200
[2022-01-11 11:11:30,316][root][INFO] - Avg. loss per last 100 batches: 0.191194
[2022-01-11 11:11:30,316][root][INFO] - Train batch 200
[2022-01-11 11:11:30,316][root][INFO] - Avg. loss per last 100 batches: 0.191194
[2022-01-11 11:11:30,316][root][INFO] - Train batch 200
[2022-01-11 11:11:30,316][root][INFO] - Avg. loss per last 100 batches: 0.191194
[2022-01-11 11:11:31,158][root][INFO] - Epoch: 2: Step: 201/920, loss=0.276266, lr=0.000008
[2022-01-11 11:11:31,159][root][INFO] - Epoch: 2: Step: 201/920, loss=0.276266, lr=0.000008
[2022-01-11 11:11:31,162][root][INFO] - Epoch: 2: Step: 201/920, loss=0.276266, lr=0.000008
[2022-01-11 11:11:31,163][root][INFO] - Epoch: 2: Step: 201/920, loss=0.276266, lr=0.000008
[2022-01-11 11:12:57,015][root][INFO] - Train batch 300
[2022-01-11 11:12:57,015][root][INFO] - Avg. loss per last 100 batches: 0.170308
[2022-01-11 11:12:57,015][root][INFO] - Train batch 300
[2022-01-11 11:12:57,015][root][INFO] - Avg. loss per last 100 batches: 0.170308
[2022-01-11 11:12:57,025][root][INFO] - Train batch 300
[2022-01-11 11:12:57,025][root][INFO] - Avg. loss per last 100 batches: 0.170308
[2022-01-11 11:12:57,025][root][INFO] - Train batch 300
[2022-01-11 11:12:57,025][root][INFO] - Avg. loss per last 100 batches: 0.170308
[2022-01-11 11:12:57,864][root][INFO] - Epoch: 2: Step: 301/920, loss=0.054064, lr=0.000009
[2022-01-11 11:12:57,869][root][INFO] - Epoch: 2: Step: 301/920, loss=0.054064, lr=0.000009
[2022-01-11 11:12:57,871][root][INFO] - Epoch: 2: Step: 301/920, loss=0.054064, lr=0.000009
[2022-01-11 11:12:57,872][root][INFO] - Epoch: 2: Step: 301/920, loss=0.054064, lr=0.000009
[2022-01-11 11:14:23,693][root][INFO] - Train batch 400
[2022-01-11 11:14:23,693][root][INFO] - Avg. loss per last 100 batches: 0.172747
[2022-01-11 11:14:23,695][root][INFO] - Train batch 400
[2022-01-11 11:14:23,695][root][INFO] - Avg. loss per last 100 batches: 0.172747
[2022-01-11 11:14:23,699][root][INFO] - Train batch 400
[2022-01-11 11:14:23,699][root][INFO] - Avg. loss per last 100 batches: 0.172747
[2022-01-11 11:14:23,700][root][INFO] - Train batch 400
[2022-01-11 11:14:23,700][root][INFO] - Avg. loss per last 100 batches: 0.172747
[2022-01-11 11:14:24,536][root][INFO] - Epoch: 2: Step: 401/920, loss=0.162370, lr=0.000009
[2022-01-11 11:14:24,536][root][INFO] - Epoch: 2: Step: 401/920, loss=0.162370, lr=0.000009
[2022-01-11 11:14:24,543][root][INFO] - Epoch: 2: Step: 401/920, loss=0.162370, lr=0.000009
[2022-01-11 11:14:24,546][root][INFO] - Epoch: 2: Step: 401/920, loss=0.162370, lr=0.000009
[2022-01-11 11:15:49,369][root][INFO] - Train batch 500
[2022-01-11 11:15:49,369][root][INFO] - Avg. loss per last 100 batches: 0.166157
[2022-01-11 11:15:49,370][root][INFO] - Train batch 500
[2022-01-11 11:15:49,370][root][INFO] - Avg. loss per last 100 batches: 0.166157
[2022-01-11 11:15:49,371][root][INFO] - Train batch 500
[2022-01-11 11:15:49,371][root][INFO] - Train batch 500
[2022-01-11 11:15:49,371][root][INFO] - Avg. loss per last 100 batches: 0.166157
[2022-01-11 11:15:49,371][root][INFO] - Avg. loss per last 100 batches: 0.166157
[2022-01-11 11:15:50,206][root][INFO] - Epoch: 2: Step: 501/920, loss=0.297154, lr=0.000009
[2022-01-11 11:15:50,207][root][INFO] - Epoch: 2: Step: 501/920, loss=0.297154, lr=0.000009
[2022-01-11 11:15:50,207][root][INFO] - Epoch: 2: Step: 501/920, loss=0.297154, lr=0.000009
[2022-01-11 11:15:50,207][root][INFO] - Epoch: 2: Step: 501/920, loss=0.297154, lr=0.000009
[2022-01-11 11:17:25,157][root][INFO] - Train batch 600
[2022-01-11 11:17:25,157][root][INFO] - Avg. loss per last 100 batches: 0.177625
[2022-01-11 11:17:25,158][root][INFO] - Train batch 600
[2022-01-11 11:17:25,158][root][INFO] - Avg. loss per last 100 batches: 0.177625
[2022-01-11 11:17:25,158][root][INFO] - Train batch 600
[2022-01-11 11:17:25,158][root][INFO] - Avg. loss per last 100 batches: 0.177625
[2022-01-11 11:17:25,159][root][INFO] - Train batch 600
[2022-01-11 11:17:25,160][root][INFO] - Avg. loss per last 100 batches: 0.177625
[2022-01-11 11:17:26,194][root][INFO] - Epoch: 2: Step: 601/920, loss=0.133693, lr=0.000010
[2022-01-11 11:17:26,195][root][INFO] - Epoch: 2: Step: 601/920, loss=0.133693, lr=0.000010
[2022-01-11 11:17:26,195][root][INFO] - Epoch: 2: Step: 601/920, loss=0.133693, lr=0.000010
[2022-01-11 11:17:26,196][root][INFO] - Epoch: 2: Step: 601/920, loss=0.133693, lr=0.000010
[2022-01-11 11:19:04,974][root][INFO] - Train batch 700
[2022-01-11 11:19:04,974][root][INFO] - Avg. loss per last 100 batches: 0.150340
[2022-01-11 11:19:04,975][root][INFO] - Train batch 700
[2022-01-11 11:19:04,975][root][INFO] - Avg. loss per last 100 batches: 0.150340
[2022-01-11 11:19:04,975][root][INFO] - Train batch 700
[2022-01-11 11:19:04,975][root][INFO] - Avg. loss per last 100 batches: 0.150340
[2022-01-11 11:19:04,975][root][INFO] - Train batch 700
[2022-01-11 11:19:04,975][root][INFO] - Avg. loss per last 100 batches: 0.150340
[2022-01-11 11:19:06,013][root][INFO] - Epoch: 2: Step: 701/920, loss=0.096600, lr=0.000010
[2022-01-11 11:19:06,022][root][INFO] - Epoch: 2: Step: 701/920, loss=0.096600, lr=0.000010
[2022-01-11 11:19:06,023][root][INFO] - Epoch: 2: Step: 701/920, loss=0.096600, lr=0.000010
[2022-01-11 11:19:06,024][root][INFO] - Epoch: 2: Step: 701/920, loss=0.096600, lr=0.000010
[2022-01-11 11:20:45,201][root][INFO] - Train batch 800
[2022-01-11 11:20:45,201][root][INFO] - Avg. loss per last 100 batches: 0.169355
[2022-01-11 11:20:45,204][root][INFO] - Train batch 800
[2022-01-11 11:20:45,204][root][INFO] - Avg. loss per last 100 batches: 0.169355
[2022-01-11 11:20:45,205][root][INFO] - Train batch 800
[2022-01-11 11:20:45,205][root][INFO] - Train batch 800
[2022-01-11 11:20:45,205][root][INFO] - Avg. loss per last 100 batches: 0.169355
[2022-01-11 11:20:45,205][root][INFO] - Avg. loss per last 100 batches: 0.169355
[2022-01-11 11:20:46,143][root][INFO] - Epoch: 2: Step: 801/920, loss=0.047342, lr=0.000010
[2022-01-11 11:20:46,145][root][INFO] - Epoch: 2: Step: 801/920, loss=0.047342, lr=0.000010
[2022-01-11 11:20:46,145][root][INFO] - Epoch: 2: Step: 801/920, loss=0.047342, lr=0.000010
[2022-01-11 11:20:46,148][root][INFO] - Epoch: 2: Step: 801/920, loss=0.047342, lr=0.000010
[2022-01-11 11:22:20,912][root][INFO] - Train batch 900
[2022-01-11 11:22:20,912][root][INFO] - Avg. loss per last 100 batches: 0.164411
[2022-01-11 11:22:20,913][root][INFO] - Train batch 900
[2022-01-11 11:22:20,913][root][INFO] - Avg. loss per last 100 batches: 0.164411
[2022-01-11 11:22:20,914][root][INFO] - Train batch 900
[2022-01-11 11:22:20,914][root][INFO] - Avg. loss per last 100 batches: 0.164411
[2022-01-11 11:22:20,915][root][INFO] - Train batch 900
[2022-01-11 11:22:20,915][root][INFO] - Avg. loss per last 100 batches: 0.164411
[2022-01-11 11:22:21,961][root][INFO] - Epoch: 2: Step: 901/920, loss=0.135049, lr=0.000010
[2022-01-11 11:22:21,962][root][INFO] - Epoch: 2: Step: 901/920, loss=0.135049, lr=0.000010
[2022-01-11 11:22:21,962][root][INFO] - Epoch: 2: Step: 901/920, loss=0.135049, lr=0.000010
[2022-01-11 11:22:21,962][root][INFO] - Epoch: 2: Step: 901/920, loss=0.135049, lr=0.000010
[2022-01-11 11:22:42,588][root][INFO] - rank=1, Validation: Epoch: 2 Step: 920/920
[2022-01-11 11:22:42,588][root][INFO] - NLL validation ...
[2022-01-11 11:22:42,588][root][INFO] - rank=3, Validation: Epoch: 2 Step: 920/920
[2022-01-11 11:22:42,589][root][INFO] - NLL validation ...
[2022-01-11 11:22:42,590][root][INFO] - rank=1; Iteration start
[2022-01-11 11:22:42,590][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:22:42,590][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:22:42,590][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 11:22:42,590][root][INFO] - rank=3; Iteration start
[2022-01-11 11:22:42,590][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:22:42,590][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:22:42,590][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 11:22:42,590][root][INFO] - rank=2, Validation: Epoch: 2 Step: 920/920
[2022-01-11 11:22:42,591][root][INFO] - NLL validation ...
[2022-01-11 11:22:42,591][root][INFO] - rank=0, Validation: Epoch: 2 Step: 920/920
[2022-01-11 11:22:42,591][root][INFO] - NLL validation ...
[2022-01-11 11:22:42,592][root][INFO] - rank=2; Iteration start
[2022-01-11 11:22:42,592][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:22:42,592][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:22:42,592][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 11:22:42,593][root][INFO] - rank=0; Iteration start
[2022-01-11 11:22:42,593][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:22:42,593][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:22:42,593][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 11:22:42,600][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 11:22:42,600][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 11:22:42,602][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 11:22:42,603][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 11:22:43,337][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 11:22:43,339][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 11:22:43,339][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 11:22:43,339][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 11:22:44,073][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 11:22:44,074][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 11:22:44,074][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 11:22:44,074][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 11:22:44,809][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 11:22:44,809][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 11:22:44,810][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 11:22:44,810][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 11:22:45,546][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 11:22:45,546][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 11:22:45,546][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 11:22:45,546][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 11:22:46,284][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 11:22:46,284][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 11:22:46,284][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 11:22:46,284][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 11:22:47,020][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 11:22:47,020][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 11:22:47,020][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 11:22:47,021][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 11:22:47,756][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 11:22:47,756][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 11:22:47,756][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 11:22:47,756][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 11:22:48,499][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 11:22:48,500][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 11:22:48,500][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 11:22:48,500][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 11:22:49,236][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 11:22:49,236][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 11:22:49,236][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 11:22:49,237][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 11:22:49,973][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 11:22:49,973][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 11:22:49,973][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 11:22:49,973][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 11:22:50,709][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 11:22:50,709][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 11:22:50,709][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 11:22:50,709][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 11:22:52,054][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 11:22:52,080][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 11:22:52,156][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 11:22:52,218][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 11:22:52,948][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 11:22:52,949][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 11:22:52,949][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 11:22:52,950][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 11:22:53,688][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 11:22:53,688][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 11:22:53,688][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 11:22:53,688][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 11:22:54,424][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 11:22:54,424][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 11:22:54,425][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 11:22:54,426][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 11:22:55,160][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 11:22:55,160][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 11:22:55,161][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 11:22:55,161][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 11:22:55,902][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 11:22:55,902][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 11:22:55,902][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 11:22:55,902][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 11:22:56,640][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 11:22:56,642][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 11:22:56,642][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 11:22:56,642][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 11:22:57,380][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 11:22:57,380][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 11:22:57,381][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 11:22:57,381][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 11:22:58,116][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 11:22:58,116][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 11:22:58,117][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 11:22:58,117][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 11:22:58,856][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 11:22:58,856][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 11:22:58,856][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 11:22:58,856][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 11:22:59,597][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 11:22:59,598][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 11:22:59,599][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 11:22:59,599][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 11:23:00,335][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 11:23:00,335][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 11:23:00,336][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 11:23:00,336][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 11:23:01,073][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 11:23:01,074][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 11:23:01,074][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 11:23:01,075][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 11:23:01,803][root][INFO] - rank=3; last iteration 25
[2022-01-11 11:23:01,803][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:23:01,803][root][INFO] - rank=1; last iteration 25
[2022-01-11 11:23:01,803][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 11:23:01,803][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:23:01,803][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:01,803][root][INFO] - rank=0; last iteration 25
[2022-01-11 11:23:01,803][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 11:23:01,803][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:23:01,803][root][INFO] - NLL Validation: loss = 0.421187. correct prediction ratio  5539/6400 ~  0.865469
[2022-01-11 11:23:01,803][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:01,803][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 11:23:01,803][root][INFO] - NLL Validation: loss = 0.421187. correct prediction ratio  5539/6400 ~  0.865469
[2022-01-11 11:23:01,803][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:01,803][root][INFO] - rank=2; last iteration 25
[2022-01-11 11:23:01,803][root][INFO] - NLL Validation: loss = 0.421187. correct prediction ratio  5539/6400 ~  0.865469
[2022-01-11 11:23:01,803][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:23:01,803][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 11:23:01,804][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:01,804][root][INFO] - NLL Validation: loss = 0.421187. correct prediction ratio  5539/6400 ~  0.865469
[2022-01-11 11:23:01,806][root][INFO] - rank=3; last iteration 920
[2022-01-11 11:23:01,806][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:23:01,806][root][INFO] - rank=1; last iteration 920
[2022-01-11 11:23:01,806][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 11:23:01,806][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:23:01,806][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 11:23:01,806][root][INFO] - rank=2; last iteration 920
[2022-01-11 11:23:01,806][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:23:01,806][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:01,806][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 11:23:01,806][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:01,806][root][INFO] - Epoch finished on 3
[2022-01-11 11:23:01,806][root][INFO] - Epoch finished on 1
[2022-01-11 11:23:01,806][root][INFO] - NLL validation ...
[2022-01-11 11:23:01,806][root][INFO] - NLL validation ...
[2022-01-11 11:23:01,807][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:01,807][root][INFO] - Epoch finished on 2
[2022-01-11 11:23:01,807][root][INFO] - NLL validation ...
[2022-01-11 11:23:01,808][root][INFO] - rank=3; Iteration start
[2022-01-11 11:23:01,808][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:23:01,808][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:23:01,808][root][INFO] - rank=1; Iteration start
[2022-01-11 11:23:01,808][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 11:23:01,808][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:23:01,808][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:23:01,808][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 11:23:01,809][root][INFO] - rank=2; Iteration start
[2022-01-11 11:23:01,809][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:23:01,809][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:23:01,809][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 11:23:01,815][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 11:23:01,816][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 11:23:01,818][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 11:23:05,771][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.2
[2022-01-11 11:23:05,772][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.2
[2022-01-11 11:23:05,772][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.2
[2022-01-11 11:23:05,773][root][INFO] - rank=0; last iteration 920
[2022-01-11 11:23:05,773][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:23:05,773][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 11:23:05,774][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:05,774][root][INFO] - Epoch finished on 0
[2022-01-11 11:23:05,774][root][INFO] - NLL validation ...
[2022-01-11 11:23:05,775][root][INFO] - rank=0; Iteration start
[2022-01-11 11:23:05,775][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:23:05,775][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:23:05,775][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 11:23:05,783][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 11:23:06,527][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 11:23:06,529][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 11:23:06,529][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 11:23:07,151][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 11:23:07,882][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 11:23:08,498][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 11:23:08,765][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 11:23:08,802][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 11:23:09,539][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 11:23:09,540][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 11:23:09,540][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 11:23:09,540][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 11:23:10,275][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 11:23:10,275][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 11:23:10,276][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 11:23:10,277][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 11:23:11,012][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 11:23:11,012][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 11:23:11,013][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 11:23:11,014][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 11:23:11,748][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 11:23:11,750][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 11:23:11,750][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 11:23:11,751][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 11:23:12,485][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 11:23:12,486][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 11:23:12,487][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 11:23:12,488][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 11:23:13,225][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 11:23:13,225][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 11:23:13,225][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 11:23:13,227][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 11:23:13,961][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 11:23:13,962][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 11:23:13,963][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 11:23:13,964][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 11:23:14,700][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 11:23:14,700][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 11:23:14,701][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 11:23:14,701][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 11:23:15,437][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 11:23:15,439][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 11:23:15,440][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 11:23:15,440][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 11:23:16,176][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 11:23:16,176][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 11:23:16,177][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 11:23:16,177][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 11:23:16,913][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 11:23:16,913][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 11:23:16,914][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 11:23:16,915][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 11:23:17,649][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 11:23:17,649][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 11:23:17,651][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 11:23:18,278][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 11:23:19,010][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 11:23:19,616][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 11:23:19,630][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 11:23:19,715][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 11:23:20,449][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 11:23:20,451][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 11:23:20,451][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 11:23:20,452][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 11:23:21,187][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 11:23:21,188][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 11:23:21,189][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 11:23:21,190][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 11:23:21,922][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 11:23:21,923][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 11:23:21,926][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 11:23:21,926][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 11:23:22,660][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 11:23:22,660][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 11:23:22,661][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 11:23:22,662][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 11:23:23,400][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 11:23:23,402][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 11:23:23,404][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 11:23:23,404][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 11:23:24,137][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 11:23:24,138][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 11:23:24,139][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 11:23:24,140][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 11:23:24,872][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 11:23:24,873][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 11:23:24,874][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 11:23:24,875][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 11:23:25,609][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 11:23:25,609][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 11:23:25,611][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 11:23:25,612][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 11:23:26,346][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 11:23:26,346][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 11:23:26,348][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 11:23:26,348][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 11:23:27,075][root][INFO] - rank=1; last iteration 25
[2022-01-11 11:23:27,075][root][INFO] - rank=3; last iteration 25
[2022-01-11 11:23:27,075][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:23:27,075][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:23:27,075][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 11:23:27,075][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 11:23:27,075][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:27,075][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:27,075][root][INFO] - NLL Validation: loss = 0.421187. correct prediction ratio  5539/6400 ~  0.865469
[2022-01-11 11:23:27,075][root][INFO] - NLL Validation: loss = 0.421187. correct prediction ratio  5539/6400 ~  0.865469
[2022-01-11 11:23:27,076][root][INFO] - rank=2; last iteration 25
[2022-01-11 11:23:27,076][root][INFO] - rank=0; last iteration 25
[2022-01-11 11:23:27,076][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:23:27,076][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:23:27,076][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 11:23:27,076][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 11:23:27,076][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:27,076][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:23:27,076][root][INFO] - NLL Validation: loss = 0.421187. correct prediction ratio  5539/6400 ~  0.865469
[2022-01-11 11:23:27,076][root][INFO] - NLL Validation: loss = 0.421187. correct prediction ratio  5539/6400 ~  0.865469
[2022-01-11 11:23:27,077][root][INFO] - Av Loss per epoch=0.170269
[2022-01-11 11:23:27,077][root][INFO] - Av Loss per epoch=0.170269
[2022-01-11 11:23:27,077][root][INFO] - epoch total correct predictions=55409
[2022-01-11 11:23:27,077][root][INFO] - epoch total correct predictions=55409
[2022-01-11 11:23:27,077][root][INFO] - Av Loss per epoch=0.170269
[2022-01-11 11:23:27,077][root][INFO] - epoch total correct predictions=55409
[2022-01-11 11:23:27,078][root][INFO] - ***** Epoch 3 *****
[2022-01-11 11:23:27,078][root][INFO] - ***** Epoch 3 *****
[2022-01-11 11:23:27,079][root][INFO] - ***** Epoch 3 *****
[2022-01-11 11:23:27,080][root][INFO] - rank=1; Iteration start
[2022-01-11 11:23:27,080][root][INFO] - rank=3; Iteration start
[2022-01-11 11:23:27,080][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:23:27,080][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:23:27,080][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:23:27,080][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:23:27,080][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 11:23:27,080][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 11:23:27,081][root][INFO] - rank=2; Iteration start
[2022-01-11 11:23:27,081][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:23:27,081][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:23:27,081][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 11:23:32,372][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.2
[2022-01-11 11:23:32,373][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.2
[2022-01-11 11:23:32,373][root][INFO] - Av Loss per epoch=0.170269
[2022-01-11 11:23:32,373][root][INFO] - epoch total correct predictions=55409
[2022-01-11 11:23:32,375][root][INFO] - ***** Epoch 3 *****
[2022-01-11 11:23:32,377][root][INFO] - rank=0; Iteration start
[2022-01-11 11:23:32,377][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:23:32,377][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:23:32,377][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 11:23:33,252][root][INFO] - Epoch: 3: Step: 1/920, loss=0.196153, lr=0.000010
[2022-01-11 11:23:33,265][root][INFO] - Epoch: 3: Step: 1/920, loss=0.196153, lr=0.000010
[2022-01-11 11:23:33,266][root][INFO] - Epoch: 3: Step: 1/920, loss=0.196153, lr=0.000010
[2022-01-11 11:23:33,266][root][INFO] - Epoch: 3: Step: 1/920, loss=0.196153, lr=0.000010
[2022-01-11 11:25:13,313][root][INFO] - Train batch 100
[2022-01-11 11:25:13,313][root][INFO] - Avg. loss per last 100 batches: 0.133354
[2022-01-11 11:25:13,313][root][INFO] - Train batch 100
[2022-01-11 11:25:13,314][root][INFO] - Avg. loss per last 100 batches: 0.133354
[2022-01-11 11:25:13,314][root][INFO] - Train batch 100
[2022-01-11 11:25:13,314][root][INFO] - Avg. loss per last 100 batches: 0.133354
[2022-01-11 11:25:13,315][root][INFO] - Train batch 100
[2022-01-11 11:25:13,315][root][INFO] - Avg. loss per last 100 batches: 0.133354
[2022-01-11 11:25:14,305][root][INFO] - Epoch: 3: Step: 101/920, loss=0.057420, lr=0.000010
[2022-01-11 11:25:14,308][root][INFO] - Epoch: 3: Step: 101/920, loss=0.057420, lr=0.000010
[2022-01-11 11:25:14,311][root][INFO] - Epoch: 3: Step: 101/920, loss=0.057420, lr=0.000010
[2022-01-11 11:25:14,314][root][INFO] - Epoch: 3: Step: 101/920, loss=0.057420, lr=0.000010
[2022-01-11 11:26:50,407][root][INFO] - Train batch 200
[2022-01-11 11:26:50,407][root][INFO] - Avg. loss per last 100 batches: 0.124944
[2022-01-11 11:26:50,411][root][INFO] - Train batch 200
[2022-01-11 11:26:50,411][root][INFO] - Avg. loss per last 100 batches: 0.124944
[2022-01-11 11:26:50,412][root][INFO] - Train batch 200
[2022-01-11 11:26:50,412][root][INFO] - Avg. loss per last 100 batches: 0.124944
[2022-01-11 11:26:50,424][root][INFO] - Train batch 200
[2022-01-11 11:26:50,424][root][INFO] - Avg. loss per last 100 batches: 0.124944
[2022-01-11 11:26:51,290][root][INFO] - Epoch: 3: Step: 201/920, loss=0.148061, lr=0.000010
[2022-01-11 11:26:51,290][root][INFO] - Epoch: 3: Step: 201/920, loss=0.148061, lr=0.000010
[2022-01-11 11:26:51,292][root][INFO] - Epoch: 3: Step: 201/920, loss=0.148061, lr=0.000010
[2022-01-11 11:26:51,302][root][INFO] - Epoch: 3: Step: 201/920, loss=0.148061, lr=0.000010
[2022-01-11 11:28:29,567][root][INFO] - Train batch 300
[2022-01-11 11:28:29,567][root][INFO] - Avg. loss per last 100 batches: 0.139335
[2022-01-11 11:28:29,567][root][INFO] - Train batch 300
[2022-01-11 11:28:29,567][root][INFO] - Avg. loss per last 100 batches: 0.139335
[2022-01-11 11:28:29,567][root][INFO] - Train batch 300
[2022-01-11 11:28:29,567][root][INFO] - Avg. loss per last 100 batches: 0.139335
[2022-01-11 11:28:29,568][root][INFO] - Train batch 300
[2022-01-11 11:28:29,568][root][INFO] - Avg. loss per last 100 batches: 0.139335
[2022-01-11 11:28:30,619][root][INFO] - Epoch: 3: Step: 301/920, loss=0.072146, lr=0.000010
[2022-01-11 11:28:30,619][root][INFO] - Epoch: 3: Step: 301/920, loss=0.072146, lr=0.000010
[2022-01-11 11:28:30,619][root][INFO] - Epoch: 3: Step: 301/920, loss=0.072146, lr=0.000010
[2022-01-11 11:28:30,619][root][INFO] - Epoch: 3: Step: 301/920, loss=0.072146, lr=0.000010
[2022-01-11 11:30:09,998][root][INFO] - Train batch 400
[2022-01-11 11:30:09,998][root][INFO] - Avg. loss per last 100 batches: 0.117868
[2022-01-11 11:30:10,003][root][INFO] - Train batch 400
[2022-01-11 11:30:10,003][root][INFO] - Avg. loss per last 100 batches: 0.117868
[2022-01-11 11:30:10,003][root][INFO] - Train batch 400
[2022-01-11 11:30:10,003][root][INFO] - Avg. loss per last 100 batches: 0.117868
[2022-01-11 11:30:10,003][root][INFO] - Train batch 400
[2022-01-11 11:30:10,003][root][INFO] - Avg. loss per last 100 batches: 0.117868
[2022-01-11 11:30:11,048][root][INFO] - Epoch: 3: Step: 401/920, loss=0.194297, lr=0.000010
[2022-01-11 11:30:11,054][root][INFO] - Epoch: 3: Step: 401/920, loss=0.194297, lr=0.000010
[2022-01-11 11:30:11,054][root][INFO] - Epoch: 3: Step: 401/920, loss=0.194297, lr=0.000010
[2022-01-11 11:30:11,054][root][INFO] - Epoch: 3: Step: 401/920, loss=0.194297, lr=0.000010
[2022-01-11 11:31:47,990][root][INFO] - Train batch 500
[2022-01-11 11:31:47,990][root][INFO] - Avg. loss per last 100 batches: 0.121108
[2022-01-11 11:31:47,991][root][INFO] - Train batch 500
[2022-01-11 11:31:47,992][root][INFO] - Avg. loss per last 100 batches: 0.121108
[2022-01-11 11:31:47,993][root][INFO] - Train batch 500
[2022-01-11 11:31:47,993][root][INFO] - Avg. loss per last 100 batches: 0.121108
[2022-01-11 11:31:47,995][root][INFO] - Train batch 500
[2022-01-11 11:31:47,995][root][INFO] - Avg. loss per last 100 batches: 0.121108
[2022-01-11 11:31:48,854][root][INFO] - Epoch: 3: Step: 501/920, loss=0.077624, lr=0.000010
[2022-01-11 11:31:48,855][root][INFO] - Epoch: 3: Step: 501/920, loss=0.077624, lr=0.000010
[2022-01-11 11:31:48,855][root][INFO] - Epoch: 3: Step: 501/920, loss=0.077624, lr=0.000010
[2022-01-11 11:31:48,868][root][INFO] - Epoch: 3: Step: 501/920, loss=0.077624, lr=0.000010
[2022-01-11 11:33:26,519][root][INFO] - Train batch 600
[2022-01-11 11:33:26,519][root][INFO] - Avg. loss per last 100 batches: 0.113856
[2022-01-11 11:33:26,522][root][INFO] - Train batch 600
[2022-01-11 11:33:26,522][root][INFO] - Avg. loss per last 100 batches: 0.113856
[2022-01-11 11:33:26,524][root][INFO] - Train batch 600
[2022-01-11 11:33:26,524][root][INFO] - Avg. loss per last 100 batches: 0.113856
[2022-01-11 11:33:26,525][root][INFO] - Train batch 600
[2022-01-11 11:33:26,525][root][INFO] - Avg. loss per last 100 batches: 0.113856
[2022-01-11 11:33:27,448][root][INFO] - Epoch: 3: Step: 601/920, loss=0.079297, lr=0.000010
[2022-01-11 11:33:27,458][root][INFO] - Epoch: 3: Step: 601/920, loss=0.079297, lr=0.000010
[2022-01-11 11:33:27,460][root][INFO] - Epoch: 3: Step: 601/920, loss=0.079297, lr=0.000010
[2022-01-11 11:33:27,460][root][INFO] - Epoch: 3: Step: 601/920, loss=0.079297, lr=0.000010
[2022-01-11 11:35:07,019][root][INFO] - Train batch 700
[2022-01-11 11:35:07,019][root][INFO] - Avg. loss per last 100 batches: 0.108342
[2022-01-11 11:35:07,026][root][INFO] - Train batch 700
[2022-01-11 11:35:07,026][root][INFO] - Avg. loss per last 100 batches: 0.108342
[2022-01-11 11:35:07,027][root][INFO] - Train batch 700
[2022-01-11 11:35:07,027][root][INFO] - Avg. loss per last 100 batches: 0.108342
[2022-01-11 11:35:07,027][root][INFO] - Train batch 700
[2022-01-11 11:35:07,027][root][INFO] - Avg. loss per last 100 batches: 0.108342
[2022-01-11 11:35:08,011][root][INFO] - Epoch: 3: Step: 701/920, loss=0.170748, lr=0.000010
[2022-01-11 11:35:08,015][root][INFO] - Epoch: 3: Step: 701/920, loss=0.170748, lr=0.000010
[2022-01-11 11:35:08,016][root][INFO] - Epoch: 3: Step: 701/920, loss=0.170748, lr=0.000010
[2022-01-11 11:35:08,017][root][INFO] - Epoch: 3: Step: 701/920, loss=0.170748, lr=0.000010
[2022-01-11 11:36:44,729][root][INFO] - Train batch 800
[2022-01-11 11:36:44,729][root][INFO] - Avg. loss per last 100 batches: 0.128074
[2022-01-11 11:36:44,729][root][INFO] - Train batch 800
[2022-01-11 11:36:44,730][root][INFO] - Avg. loss per last 100 batches: 0.128074
[2022-01-11 11:36:44,730][root][INFO] - Train batch 800
[2022-01-11 11:36:44,730][root][INFO] - Avg. loss per last 100 batches: 0.128074
[2022-01-11 11:36:44,730][root][INFO] - Train batch 800
[2022-01-11 11:36:44,731][root][INFO] - Avg. loss per last 100 batches: 0.128074
[2022-01-11 11:36:45,583][root][INFO] - Epoch: 3: Step: 801/920, loss=0.203738, lr=0.000010
[2022-01-11 11:36:45,584][root][INFO] - Epoch: 3: Step: 801/920, loss=0.203738, lr=0.000010
[2022-01-11 11:36:45,584][root][INFO] - Epoch: 3: Step: 801/920, loss=0.203738, lr=0.000010
[2022-01-11 11:36:45,585][root][INFO] - Epoch: 3: Step: 801/920, loss=0.203738, lr=0.000010
[2022-01-11 11:38:25,126][root][INFO] - Train batch 900
[2022-01-11 11:38:25,127][root][INFO] - Avg. loss per last 100 batches: 0.121209
[2022-01-11 11:38:25,127][root][INFO] - Train batch 900
[2022-01-11 11:38:25,127][root][INFO] - Avg. loss per last 100 batches: 0.121209
[2022-01-11 11:38:25,128][root][INFO] - Train batch 900
[2022-01-11 11:38:25,129][root][INFO] - Avg. loss per last 100 batches: 0.121209
[2022-01-11 11:38:25,141][root][INFO] - Train batch 900
[2022-01-11 11:38:25,141][root][INFO] - Avg. loss per last 100 batches: 0.121209
[2022-01-11 11:38:26,103][root][INFO] - Epoch: 3: Step: 901/920, loss=0.097016, lr=0.000010
[2022-01-11 11:38:26,118][root][INFO] - Epoch: 3: Step: 901/920, loss=0.097016, lr=0.000010
[2022-01-11 11:38:26,118][root][INFO] - Epoch: 3: Step: 901/920, loss=0.097016, lr=0.000010
[2022-01-11 11:38:26,118][root][INFO] - Epoch: 3: Step: 901/920, loss=0.097016, lr=0.000010
[2022-01-11 11:38:44,334][root][INFO] - rank=1, Validation: Epoch: 3 Step: 920/920
[2022-01-11 11:38:44,334][root][INFO] - NLL validation ...
[2022-01-11 11:38:44,334][root][INFO] - rank=3, Validation: Epoch: 3 Step: 920/920
[2022-01-11 11:38:44,335][root][INFO] - NLL validation ...
[2022-01-11 11:38:44,335][root][INFO] - rank=0, Validation: Epoch: 3 Step: 920/920
[2022-01-11 11:38:44,335][root][INFO] - NLL validation ...
[2022-01-11 11:38:44,335][root][INFO] - rank=2, Validation: Epoch: 3 Step: 920/920
[2022-01-11 11:38:44,335][root][INFO] - NLL validation ...
[2022-01-11 11:38:44,335][root][INFO] - rank=1; Iteration start
[2022-01-11 11:38:44,336][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:38:44,336][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:38:44,336][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 11:38:44,336][root][INFO] - rank=3; Iteration start
[2022-01-11 11:38:44,336][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:38:44,336][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:38:44,336][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 11:38:44,336][root][INFO] - rank=0; Iteration start
[2022-01-11 11:38:44,336][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:38:44,336][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:38:44,336][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 11:38:44,336][root][INFO] - rank=2; Iteration start
[2022-01-11 11:38:44,336][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:38:44,337][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:38:44,337][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 11:38:44,346][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 11:38:44,346][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 11:38:44,346][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 11:38:44,347][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 11:38:45,082][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 11:38:45,082][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 11:38:45,082][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 11:38:45,082][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 11:38:45,822][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 11:38:45,824][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 11:38:45,825][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 11:38:45,826][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 11:38:46,561][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 11:38:46,561][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 11:38:46,561][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 11:38:46,562][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 11:38:47,299][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 11:38:47,300][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 11:38:47,300][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 11:38:47,300][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 11:38:48,037][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 11:38:48,037][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 11:38:48,038][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 11:38:48,038][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 11:38:48,778][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 11:38:48,781][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 11:38:48,781][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 11:38:48,781][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 11:38:49,516][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 11:38:49,516][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 11:38:49,518][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 11:38:50,228][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 11:38:50,959][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 11:38:51,862][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 11:38:51,862][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 11:38:51,961][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 11:38:52,699][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 11:38:52,700][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 11:38:52,701][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 11:38:52,701][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 11:38:53,437][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 11:38:53,437][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 11:38:53,437][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 11:38:53,437][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 11:38:54,174][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 11:38:54,174][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 11:38:54,174][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 11:38:54,175][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 11:38:54,916][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 11:38:54,917][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 11:38:54,917][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 11:38:54,917][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 11:38:55,657][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 11:38:55,657][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 11:38:55,657][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 11:38:55,657][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 11:38:56,391][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 11:38:56,392][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 11:38:56,392][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 11:38:56,392][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 11:38:57,130][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 11:38:57,131][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 11:38:57,132][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 11:38:57,132][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 11:38:57,868][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 11:38:57,868][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 11:38:57,869][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 11:38:57,869][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 11:38:58,607][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 11:38:58,607][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 11:38:58,608][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 11:38:58,608][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 11:38:59,345][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 11:38:59,345][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 11:38:59,345][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 11:38:59,346][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 11:39:00,085][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 11:39:00,086][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 11:39:00,086][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 11:39:00,086][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 11:39:00,823][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 11:39:00,823][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 11:39:00,824][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 11:39:00,824][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 11:39:01,558][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 11:39:01,558][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 11:39:01,558][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 11:39:02,418][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 11:39:03,150][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 11:39:03,784][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 11:39:03,857][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 11:39:03,866][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 11:39:04,602][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 11:39:04,602][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 11:39:04,602][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 11:39:04,602][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 11:39:05,337][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 11:39:05,337][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 11:39:05,337][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 11:39:05,337][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 11:39:06,064][root][INFO] - rank=3; last iteration 25
[2022-01-11 11:39:06,064][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:39:06,064][root][INFO] - rank=1; last iteration 25
[2022-01-11 11:39:06,064][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 11:39:06,064][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:39:06,065][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:06,065][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 11:39:06,065][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:06,065][root][INFO] - NLL Validation: loss = 0.402454. correct prediction ratio  5575/6400 ~  0.871094
[2022-01-11 11:39:06,065][root][INFO] - rank=0; last iteration 25
[2022-01-11 11:39:06,065][root][INFO] - rank=2; last iteration 25
[2022-01-11 11:39:06,065][root][INFO] - NLL Validation: loss = 0.402454. correct prediction ratio  5575/6400 ~  0.871094
[2022-01-11 11:39:06,065][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:39:06,065][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:39:06,065][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 11:39:06,065][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 11:39:06,065][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:06,065][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:06,065][root][INFO] - NLL Validation: loss = 0.402454. correct prediction ratio  5575/6400 ~  0.871094
[2022-01-11 11:39:06,065][root][INFO] - NLL Validation: loss = 0.402454. correct prediction ratio  5575/6400 ~  0.871094
[2022-01-11 11:39:06,067][root][INFO] - rank=1; last iteration 920
[2022-01-11 11:39:06,067][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:39:06,067][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 11:39:06,067][root][INFO] - rank=2; last iteration 920
[2022-01-11 11:39:06,068][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:39:06,067][root][INFO] - rank=3; last iteration 920
[2022-01-11 11:39:06,068][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 11:39:06,068][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:39:06,068][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 11:39:06,068][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:06,068][root][INFO] - Epoch finished on 1
[2022-01-11 11:39:06,068][root][INFO] - NLL validation ...
[2022-01-11 11:39:06,068][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:06,068][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:06,068][root][INFO] - Epoch finished on 2
[2022-01-11 11:39:06,068][root][INFO] - Epoch finished on 3
[2022-01-11 11:39:06,068][root][INFO] - NLL validation ...
[2022-01-11 11:39:06,068][root][INFO] - NLL validation ...
[2022-01-11 11:39:06,069][root][INFO] - rank=1; Iteration start
[2022-01-11 11:39:06,069][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:39:06,069][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:39:06,069][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 11:39:06,069][root][INFO] - rank=2; Iteration start
[2022-01-11 11:39:06,070][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:39:06,070][root][INFO] - rank=3; Iteration start
[2022-01-11 11:39:06,070][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:39:06,070][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:39:06,070][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 11:39:06,070][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:39:06,070][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 11:39:06,077][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 11:39:06,077][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 11:39:06,077][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 11:39:10,167][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.3
[2022-01-11 11:39:10,167][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.3
[2022-01-11 11:39:10,167][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.3
[2022-01-11 11:39:10,169][root][INFO] - rank=0; last iteration 920
[2022-01-11 11:39:10,169][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:39:10,169][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 11:39:10,169][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:10,169][root][INFO] - Epoch finished on 0
[2022-01-11 11:39:10,169][root][INFO] - NLL validation ...
[2022-01-11 11:39:10,171][root][INFO] - rank=0; Iteration start
[2022-01-11 11:39:10,171][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:39:10,171][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:39:10,171][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 11:39:10,179][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 11:39:10,923][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 11:39:10,923][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 11:39:10,923][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 11:39:10,924][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 11:39:11,656][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 11:39:11,656][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 11:39:11,657][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 11:39:11,657][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 11:39:12,390][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 11:39:12,391][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 11:39:12,391][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 11:39:12,391][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 11:39:13,128][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 11:39:13,131][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 11:39:13,131][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 11:39:13,131][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 11:39:13,868][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 11:39:13,868][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 11:39:13,869][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 11:39:13,869][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 11:39:14,604][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 11:39:14,605][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 11:39:14,605][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 11:39:14,605][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 11:39:15,338][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 11:39:15,339][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 11:39:15,339][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 11:39:15,339][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 11:39:16,078][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 11:39:16,078][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 11:39:16,079][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 11:39:16,079][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 11:39:16,814][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 11:39:16,814][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 11:39:16,814][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 11:39:16,814][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 11:39:18,169][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 11:39:18,177][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 11:39:18,190][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 11:39:18,195][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 11:39:18,938][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 11:39:18,938][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 11:39:18,938][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 11:39:18,940][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 11:39:19,676][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 11:39:19,676][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 11:39:19,676][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 11:39:19,679][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 11:39:20,415][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 11:39:20,415][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 11:39:20,415][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 11:39:20,416][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 11:39:21,151][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 11:39:21,151][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 11:39:21,151][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 11:39:21,154][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 11:39:21,890][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 11:39:21,890][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 11:39:21,891][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 11:39:21,891][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 11:39:22,628][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 11:39:22,629][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 11:39:22,629][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 11:39:22,630][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 11:39:23,365][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 11:39:23,365][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 11:39:23,365][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 11:39:23,366][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 11:39:24,101][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 11:39:24,102][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 11:39:24,102][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 11:39:24,102][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 11:39:24,839][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 11:39:24,839][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 11:39:24,839][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 11:39:24,840][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 11:39:25,576][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 11:39:25,576][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 11:39:25,576][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 11:39:25,577][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 11:39:26,313][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 11:39:26,313][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 11:39:26,314][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 11:39:26,315][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 11:39:27,053][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 11:39:27,054][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 11:39:27,054][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 11:39:27,056][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 11:39:27,793][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 11:39:27,794][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 11:39:27,794][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 11:39:28,400][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 11:39:29,131][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 11:39:29,756][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 11:39:29,758][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 11:39:30,014][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 11:39:30,738][root][INFO] - rank=3; last iteration 25
[2022-01-11 11:39:30,738][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:39:30,738][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 11:39:30,738][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:30,738][root][INFO] - NLL Validation: loss = 0.402454. correct prediction ratio  5575/6400 ~  0.871094
[2022-01-11 11:39:30,738][root][INFO] - rank=2; last iteration 25
[2022-01-11 11:39:30,739][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:39:30,739][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 11:39:30,739][root][INFO] - rank=1; last iteration 25
[2022-01-11 11:39:30,739][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:30,739][root][INFO] - rank=0; last iteration 25
[2022-01-11 11:39:30,739][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:39:30,739][root][INFO] - NLL Validation: loss = 0.402454. correct prediction ratio  5575/6400 ~  0.871094
[2022-01-11 11:39:30,739][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:39:30,739][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 11:39:30,739][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 11:39:30,739][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:30,739][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:39:30,739][root][INFO] - NLL Validation: loss = 0.402454. correct prediction ratio  5575/6400 ~  0.871094
[2022-01-11 11:39:30,739][root][INFO] - NLL Validation: loss = 0.402454. correct prediction ratio  5575/6400 ~  0.871094
[2022-01-11 11:39:30,740][root][INFO] - Av Loss per epoch=0.122638
[2022-01-11 11:39:30,740][root][INFO] - epoch total correct predictions=56310
[2022-01-11 11:39:30,740][root][INFO] - Av Loss per epoch=0.122638
[2022-01-11 11:39:30,740][root][INFO] - epoch total correct predictions=56310
[2022-01-11 11:39:30,740][root][INFO] - Av Loss per epoch=0.122638
[2022-01-11 11:39:30,740][root][INFO] - epoch total correct predictions=56310
[2022-01-11 11:39:30,742][root][INFO] - ***** Epoch 4 *****
[2022-01-11 11:39:30,742][root][INFO] - ***** Epoch 4 *****
[2022-01-11 11:39:30,742][root][INFO] - ***** Epoch 4 *****
[2022-01-11 11:39:30,743][root][INFO] - rank=3; Iteration start
[2022-01-11 11:39:30,743][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:39:30,743][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:39:30,743][root][INFO] - rank=2; Iteration start
[2022-01-11 11:39:30,743][root][INFO] - rank=1; Iteration start
[2022-01-11 11:39:30,744][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:39:30,744][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:39:30,744][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:39:30,744][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:39:30,744][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 11:39:30,744][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 11:39:30,744][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 11:39:35,895][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.3
[2022-01-11 11:39:35,896][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.3
[2022-01-11 11:39:35,896][root][INFO] - Av Loss per epoch=0.122638
[2022-01-11 11:39:35,896][root][INFO] - epoch total correct predictions=56310
[2022-01-11 11:39:35,898][root][INFO] - ***** Epoch 4 *****
[2022-01-11 11:39:35,901][root][INFO] - rank=0; Iteration start
[2022-01-11 11:39:35,901][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:39:35,901][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:39:35,902][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 11:39:36,986][root][INFO] - Epoch: 4: Step: 1/920, loss=0.030293, lr=0.000010
[2022-01-11 11:39:36,986][root][INFO] - Epoch: 4: Step: 1/920, loss=0.030293, lr=0.000010
[2022-01-11 11:39:36,987][root][INFO] - Epoch: 4: Step: 1/920, loss=0.030293, lr=0.000010
[2022-01-11 11:39:36,987][root][INFO] - Epoch: 4: Step: 1/920, loss=0.030293, lr=0.000010
[2022-01-11 11:41:14,736][root][INFO] - Train batch 100
[2022-01-11 11:41:14,736][root][INFO] - Avg. loss per last 100 batches: 0.093048
[2022-01-11 11:41:14,736][root][INFO] - Train batch 100
[2022-01-11 11:41:14,737][root][INFO] - Avg. loss per last 100 batches: 0.093048
[2022-01-11 11:41:14,737][root][INFO] - Train batch 100
[2022-01-11 11:41:14,737][root][INFO] - Avg. loss per last 100 batches: 0.093048
[2022-01-11 11:41:14,737][root][INFO] - Train batch 100
[2022-01-11 11:41:14,737][root][INFO] - Avg. loss per last 100 batches: 0.093048
[2022-01-11 11:41:15,706][root][INFO] - Epoch: 4: Step: 101/920, loss=0.084951, lr=0.000010
[2022-01-11 11:41:15,710][root][INFO] - Epoch: 4: Step: 101/920, loss=0.084951, lr=0.000010
[2022-01-11 11:41:15,714][root][INFO] - Epoch: 4: Step: 101/920, loss=0.084951, lr=0.000010
[2022-01-11 11:41:15,714][root][INFO] - Epoch: 4: Step: 101/920, loss=0.084951, lr=0.000010
[2022-01-11 11:42:52,268][root][INFO] - Train batch 200
[2022-01-11 11:42:52,268][root][INFO] - Avg. loss per last 100 batches: 0.100118
[2022-01-11 11:42:52,277][root][INFO] - Train batch 200
[2022-01-11 11:42:52,277][root][INFO] - Avg. loss per last 100 batches: 0.100118
[2022-01-11 11:42:52,277][root][INFO] - Train batch 200
[2022-01-11 11:42:52,278][root][INFO] - Avg. loss per last 100 batches: 0.100118
[2022-01-11 11:42:52,278][root][INFO] - Train batch 200
[2022-01-11 11:42:52,278][root][INFO] - Avg. loss per last 100 batches: 0.100118
[2022-01-11 11:42:53,230][root][INFO] - Epoch: 4: Step: 201/920, loss=0.148072, lr=0.000010
[2022-01-11 11:42:53,231][root][INFO] - Epoch: 4: Step: 201/920, loss=0.148072, lr=0.000010
[2022-01-11 11:42:53,232][root][INFO] - Epoch: 4: Step: 201/920, loss=0.148072, lr=0.000010
[2022-01-11 11:42:53,232][root][INFO] - Epoch: 4: Step: 201/920, loss=0.148072, lr=0.000010
[2022-01-11 11:44:32,591][root][INFO] - Train batch 300
[2022-01-11 11:44:32,591][root][INFO] - Avg. loss per last 100 batches: 0.091284
[2022-01-11 11:44:32,604][root][INFO] - Train batch 300
[2022-01-11 11:44:32,604][root][INFO] - Train batch 300
[2022-01-11 11:44:32,604][root][INFO] - Avg. loss per last 100 batches: 0.091284
[2022-01-11 11:44:32,604][root][INFO] - Avg. loss per last 100 batches: 0.091284
[2022-01-11 11:44:32,604][root][INFO] - Train batch 300
[2022-01-11 11:44:32,604][root][INFO] - Avg. loss per last 100 batches: 0.091284
[2022-01-11 11:44:33,582][root][INFO] - Epoch: 4: Step: 301/920, loss=0.127217, lr=0.000010
[2022-01-11 11:44:33,585][root][INFO] - Epoch: 4: Step: 301/920, loss=0.127217, lr=0.000010
[2022-01-11 11:44:33,586][root][INFO] - Epoch: 4: Step: 301/920, loss=0.127217, lr=0.000010
[2022-01-11 11:44:33,586][root][INFO] - Epoch: 4: Step: 301/920, loss=0.127217, lr=0.000010
[2022-01-11 11:46:11,538][root][INFO] - Train batch 400
[2022-01-11 11:46:11,538][root][INFO] - Train batch 400
[2022-01-11 11:46:11,538][root][INFO] - Avg. loss per last 100 batches: 0.099796
[2022-01-11 11:46:11,538][root][INFO] - Avg. loss per last 100 batches: 0.099796
[2022-01-11 11:46:11,539][root][INFO] - Train batch 400
[2022-01-11 11:46:11,540][root][INFO] - Avg. loss per last 100 batches: 0.099796
[2022-01-11 11:46:11,540][root][INFO] - Train batch 400
[2022-01-11 11:46:11,540][root][INFO] - Avg. loss per last 100 batches: 0.099796
[2022-01-11 11:46:12,589][root][INFO] - Epoch: 4: Step: 401/920, loss=0.187662, lr=0.000010
[2022-01-11 11:46:12,590][root][INFO] - Epoch: 4: Step: 401/920, loss=0.187662, lr=0.000010
[2022-01-11 11:46:12,591][root][INFO] - Epoch: 4: Step: 401/920, loss=0.187662, lr=0.000010
[2022-01-11 11:46:12,592][root][INFO] - Epoch: 4: Step: 401/920, loss=0.187662, lr=0.000010
[2022-01-11 11:47:48,860][root][INFO] - Train batch 500
[2022-01-11 11:47:48,860][root][INFO] - Avg. loss per last 100 batches: 0.095388
[2022-01-11 11:47:48,865][root][INFO] - Train batch 500
[2022-01-11 11:47:48,865][root][INFO] - Avg. loss per last 100 batches: 0.095388
[2022-01-11 11:47:48,865][root][INFO] - Train batch 500
[2022-01-11 11:47:48,866][root][INFO] - Avg. loss per last 100 batches: 0.095388
[2022-01-11 11:47:48,867][root][INFO] - Train batch 500
[2022-01-11 11:47:48,867][root][INFO] - Avg. loss per last 100 batches: 0.095388
[2022-01-11 11:47:49,820][root][INFO] - Epoch: 4: Step: 501/920, loss=0.082228, lr=0.000010
[2022-01-11 11:47:49,820][root][INFO] - Epoch: 4: Step: 501/920, loss=0.082228, lr=0.000010
[2022-01-11 11:47:49,821][root][INFO] - Epoch: 4: Step: 501/920, loss=0.082228, lr=0.000010
[2022-01-11 11:47:49,821][root][INFO] - Epoch: 4: Step: 501/920, loss=0.082228, lr=0.000010
[2022-01-11 11:49:29,600][root][INFO] - Train batch 600
[2022-01-11 11:49:29,600][root][INFO] - Avg. loss per last 100 batches: 0.096051
[2022-01-11 11:49:29,601][root][INFO] - Train batch 600
[2022-01-11 11:49:29,601][root][INFO] - Avg. loss per last 100 batches: 0.096051
[2022-01-11 11:49:29,602][root][INFO] - Train batch 600
[2022-01-11 11:49:29,602][root][INFO] - Avg. loss per last 100 batches: 0.096051
[2022-01-11 11:49:29,603][root][INFO] - Train batch 600
[2022-01-11 11:49:29,603][root][INFO] - Avg. loss per last 100 batches: 0.096051
[2022-01-11 11:49:30,471][root][INFO] - Epoch: 4: Step: 601/920, loss=0.185153, lr=0.000009
[2022-01-11 11:49:30,472][root][INFO] - Epoch: 4: Step: 601/920, loss=0.185153, lr=0.000009
[2022-01-11 11:49:30,472][root][INFO] - Epoch: 4: Step: 601/920, loss=0.185153, lr=0.000009
[2022-01-11 11:49:30,473][root][INFO] - Epoch: 4: Step: 601/920, loss=0.185153, lr=0.000009
[2022-01-11 11:51:09,191][root][INFO] - Train batch 700
[2022-01-11 11:51:09,192][root][INFO] - Avg. loss per last 100 batches: 0.101742
[2022-01-11 11:51:09,200][root][INFO] - Train batch 700
[2022-01-11 11:51:09,200][root][INFO] - Avg. loss per last 100 batches: 0.101742
[2022-01-11 11:51:09,201][root][INFO] - Train batch 700
[2022-01-11 11:51:09,201][root][INFO] - Avg. loss per last 100 batches: 0.101742
[2022-01-11 11:51:09,202][root][INFO] - Train batch 700
[2022-01-11 11:51:09,203][root][INFO] - Avg. loss per last 100 batches: 0.101742
[2022-01-11 11:51:10,243][root][INFO] - Epoch: 4: Step: 701/920, loss=0.088682, lr=0.000009
[2022-01-11 11:51:10,246][root][INFO] - Epoch: 4: Step: 701/920, loss=0.088682, lr=0.000009
[2022-01-11 11:51:10,247][root][INFO] - Epoch: 4: Step: 701/920, loss=0.088682, lr=0.000009
[2022-01-11 11:51:10,248][root][INFO] - Epoch: 4: Step: 701/920, loss=0.088682, lr=0.000009
[2022-01-11 11:52:46,353][root][INFO] - Train batch 800
[2022-01-11 11:52:46,353][root][INFO] - Avg. loss per last 100 batches: 0.082549
[2022-01-11 11:52:46,357][root][INFO] - Train batch 800
[2022-01-11 11:52:46,357][root][INFO] - Train batch 800
[2022-01-11 11:52:46,358][root][INFO] - Avg. loss per last 100 batches: 0.082549
[2022-01-11 11:52:46,358][root][INFO] - Avg. loss per last 100 batches: 0.082549
[2022-01-11 11:52:46,358][root][INFO] - Train batch 800
[2022-01-11 11:52:46,358][root][INFO] - Avg. loss per last 100 batches: 0.082549
[2022-01-11 11:52:47,295][root][INFO] - Epoch: 4: Step: 801/920, loss=0.091620, lr=0.000009
[2022-01-11 11:52:47,302][root][INFO] - Epoch: 4: Step: 801/920, loss=0.091620, lr=0.000009
[2022-01-11 11:52:47,304][root][INFO] - Epoch: 4: Step: 801/920, loss=0.091620, lr=0.000009
[2022-01-11 11:52:47,304][root][INFO] - Epoch: 4: Step: 801/920, loss=0.091620, lr=0.000009
[2022-01-11 11:54:26,773][root][INFO] - Train batch 900
[2022-01-11 11:54:26,774][root][INFO] - Avg. loss per last 100 batches: 0.100069
[2022-01-11 11:54:26,774][root][INFO] - Train batch 900
[2022-01-11 11:54:26,774][root][INFO] - Avg. loss per last 100 batches: 0.100069
[2022-01-11 11:54:26,775][root][INFO] - Train batch 900
[2022-01-11 11:54:26,775][root][INFO] - Avg. loss per last 100 batches: 0.100069
[2022-01-11 11:54:26,775][root][INFO] - Train batch 900
[2022-01-11 11:54:26,775][root][INFO] - Avg. loss per last 100 batches: 0.100069
[2022-01-11 11:54:27,632][root][INFO] - Epoch: 4: Step: 901/920, loss=0.070380, lr=0.000009
[2022-01-11 11:54:27,632][root][INFO] - Epoch: 4: Step: 901/920, loss=0.070380, lr=0.000009
[2022-01-11 11:54:27,632][root][INFO] - Epoch: 4: Step: 901/920, loss=0.070380, lr=0.000009
[2022-01-11 11:54:27,633][root][INFO] - Epoch: 4: Step: 901/920, loss=0.070380, lr=0.000009
[2022-01-11 11:54:46,251][root][INFO] - rank=1, Validation: Epoch: 4 Step: 920/920
[2022-01-11 11:54:46,252][root][INFO] - NLL validation ...
[2022-01-11 11:54:46,252][root][INFO] - rank=0, Validation: Epoch: 4 Step: 920/920
[2022-01-11 11:54:46,252][root][INFO] - NLL validation ...
[2022-01-11 11:54:46,252][root][INFO] - rank=3, Validation: Epoch: 4 Step: 920/920
[2022-01-11 11:54:46,252][root][INFO] - NLL validation ...
[2022-01-11 11:54:46,252][root][INFO] - rank=2, Validation: Epoch: 4 Step: 920/920
[2022-01-11 11:54:46,252][root][INFO] - NLL validation ...
[2022-01-11 11:54:46,253][root][INFO] - rank=1; Iteration start
[2022-01-11 11:54:46,253][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:54:46,253][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:54:46,253][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 11:54:46,253][root][INFO] - rank=0; Iteration start
[2022-01-11 11:54:46,253][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:54:46,253][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:54:46,253][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 11:54:46,253][root][INFO] - rank=3; Iteration start
[2022-01-11 11:54:46,253][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:54:46,253][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:54:46,253][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 11:54:46,254][root][INFO] - rank=2; Iteration start
[2022-01-11 11:54:46,254][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:54:46,254][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:54:46,254][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 11:54:46,264][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 11:54:46,264][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 11:54:46,264][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 11:54:46,264][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 11:54:47,003][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 11:54:47,003][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 11:54:47,003][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 11:54:47,003][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 11:54:47,739][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 11:54:47,739][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 11:54:47,740][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 11:54:47,740][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 11:54:48,477][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 11:54:48,477][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 11:54:48,477][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 11:54:48,477][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 11:54:49,217][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 11:54:49,217][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 11:54:49,217][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 11:54:50,199][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 11:54:50,929][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 11:54:51,908][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 11:54:51,915][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 11:54:51,925][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 11:54:52,661][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 11:54:52,661][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 11:54:52,662][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 11:54:52,662][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 11:54:53,402][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 11:54:53,403][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 11:54:53,403][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 11:54:53,404][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 11:54:54,143][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 11:54:54,143][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 11:54:54,143][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 11:54:54,143][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 11:54:54,880][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 11:54:54,880][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 11:54:54,880][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 11:54:54,881][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 11:54:55,618][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 11:54:55,619][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 11:54:55,619][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 11:54:55,619][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 11:54:56,357][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 11:54:56,358][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 11:54:56,358][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 11:54:56,358][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 11:54:57,095][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 11:54:57,096][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 11:54:57,096][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 11:54:57,097][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 11:54:57,835][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 11:54:57,835][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 11:54:57,836][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 11:54:57,836][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 11:54:58,572][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 11:54:58,573][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 11:54:58,573][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 11:54:58,574][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 11:54:59,315][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 11:54:59,316][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 11:54:59,317][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 11:54:59,318][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 11:55:00,052][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 11:55:00,052][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 11:55:00,052][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 11:55:00,052][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 11:55:00,790][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 11:55:00,791][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 11:55:00,791][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 11:55:00,791][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 11:55:02,146][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 11:55:02,158][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 11:55:02,217][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 11:55:02,360][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 11:55:03,097][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 11:55:03,098][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 11:55:03,098][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 11:55:03,099][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 11:55:03,836][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 11:55:03,836][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 11:55:03,836][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 11:55:03,837][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 11:55:04,573][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 11:55:04,573][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 11:55:04,573][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 11:55:04,573][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 11:55:05,318][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 11:55:05,319][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 11:55:05,319][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 11:55:05,320][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 11:55:06,056][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 11:55:06,056][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 11:55:06,056][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 11:55:06,056][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 11:55:06,794][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 11:55:06,794][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 11:55:06,794][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 11:55:06,794][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 11:55:07,523][root][INFO] - rank=1; last iteration 25
[2022-01-11 11:55:07,523][root][INFO] - rank=0; last iteration 25
[2022-01-11 11:55:07,523][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:55:07,523][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:55:07,523][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 11:55:07,523][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 11:55:07,523][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:07,523][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:07,523][root][INFO] - rank=3; last iteration 25
[2022-01-11 11:55:07,523][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:55:07,523][root][INFO] - NLL Validation: loss = 0.407432. correct prediction ratio  5569/6400 ~  0.870156
[2022-01-11 11:55:07,523][root][INFO] - NLL Validation: loss = 0.407432. correct prediction ratio  5569/6400 ~  0.870156
[2022-01-11 11:55:07,523][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 11:55:07,523][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:07,523][root][INFO] - NLL Validation: loss = 0.407432. correct prediction ratio  5569/6400 ~  0.870156
[2022-01-11 11:55:07,524][root][INFO] - rank=2; last iteration 25
[2022-01-11 11:55:07,524][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:55:07,524][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 11:55:07,524][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:07,524][root][INFO] - NLL Validation: loss = 0.407432. correct prediction ratio  5569/6400 ~  0.870156
[2022-01-11 11:55:07,526][root][INFO] - rank=1; last iteration 920
[2022-01-11 11:55:07,526][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:55:07,526][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 11:55:07,526][root][INFO] - rank=3; last iteration 920
[2022-01-11 11:55:07,526][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:55:07,526][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 11:55:07,526][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:07,526][root][INFO] - Epoch finished on 1
[2022-01-11 11:55:07,526][root][INFO] - rank=2; last iteration 920
[2022-01-11 11:55:07,526][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:55:07,526][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:07,526][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 11:55:07,526][root][INFO] - NLL validation ...
[2022-01-11 11:55:07,527][root][INFO] - Epoch finished on 3
[2022-01-11 11:55:07,527][root][INFO] - NLL validation ...
[2022-01-11 11:55:07,527][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:07,527][root][INFO] - Epoch finished on 2
[2022-01-11 11:55:07,527][root][INFO] - NLL validation ...
[2022-01-11 11:55:07,528][root][INFO] - rank=1; Iteration start
[2022-01-11 11:55:07,528][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:55:07,528][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:55:07,528][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 11:55:07,528][root][INFO] - rank=3; Iteration start
[2022-01-11 11:55:07,528][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:55:07,528][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:55:07,528][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 11:55:07,528][root][INFO] - rank=2; Iteration start
[2022-01-11 11:55:07,528][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:55:07,528][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:55:07,528][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 11:55:07,537][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 11:55:07,537][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 11:55:07,537][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 11:55:11,448][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.4
[2022-01-11 11:55:11,449][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.4
[2022-01-11 11:55:11,450][root][INFO] - rank=0; last iteration 920
[2022-01-11 11:55:11,450][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 11:55:11,450][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 11:55:11,451][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:11,451][root][INFO] - Epoch finished on 0
[2022-01-11 11:55:11,451][root][INFO] - NLL validation ...
[2022-01-11 11:55:11,452][root][INFO] - rank=0; Iteration start
[2022-01-11 11:55:11,452][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:55:11,452][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 11:55:11,452][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 11:55:11,460][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 11:55:12,198][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 11:55:12,199][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 11:55:12,200][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 11:55:12,200][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 11:55:12,934][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 11:55:12,935][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 11:55:12,935][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 11:55:12,936][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 11:55:13,669][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 11:55:13,669][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 11:55:13,670][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 11:55:13,670][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 11:55:14,405][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 11:55:14,406][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 11:55:14,406][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 11:55:14,407][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 11:55:15,142][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 11:55:15,143][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 11:55:15,144][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 11:55:15,766][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 11:55:16,493][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 11:55:16,493][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 11:55:16,493][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 11:55:16,495][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 11:55:17,229][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 11:55:17,858][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 11:55:17,870][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 11:55:18,087][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 11:55:18,821][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 11:55:18,822][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 11:55:18,823][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 11:55:18,824][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 11:55:19,559][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 11:55:19,561][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 11:55:19,561][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 11:55:19,563][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 11:55:20,302][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 11:55:20,303][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 11:55:20,304][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 11:55:20,305][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 11:55:21,042][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 11:55:21,043][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 11:55:21,043][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 11:55:21,045][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 11:55:21,782][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 11:55:21,782][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 11:55:21,784][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 11:55:21,785][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 11:55:22,521][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 11:55:22,522][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 11:55:22,523][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 11:55:22,524][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 11:55:23,260][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 11:55:23,261][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 11:55:23,262][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 11:55:23,262][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 11:55:23,999][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 11:55:24,000][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 11:55:24,002][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 11:55:24,002][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 11:55:24,735][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 11:55:24,735][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 11:55:24,736][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 11:55:24,737][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 11:55:25,476][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 11:55:25,476][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 11:55:25,478][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 11:55:25,478][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 11:55:26,213][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 11:55:26,213][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 11:55:26,215][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 11:55:26,215][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 11:55:26,952][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 11:55:26,952][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 11:55:26,954][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 11:55:27,623][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 11:55:28,356][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 11:55:28,356][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 11:55:28,357][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 11:55:28,358][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 11:55:29,095][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 11:55:29,697][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 11:55:29,712][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 11:55:29,958][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 11:55:30,692][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 11:55:30,692][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 11:55:30,693][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 11:55:30,693][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 11:55:31,434][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 11:55:31,436][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 11:55:31,437][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 11:55:31,437][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 11:55:32,172][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 11:55:32,173][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 11:55:32,174][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 11:55:32,175][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 11:55:32,903][root][INFO] - rank=3; last iteration 25
[2022-01-11 11:55:32,903][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:55:32,904][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 11:55:32,903][root][INFO] - rank=1; last iteration 25
[2022-01-11 11:55:32,904][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:32,904][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:55:32,904][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 11:55:32,904][root][INFO] - NLL Validation: loss = 0.407432. correct prediction ratio  5569/6400 ~  0.870156
[2022-01-11 11:55:32,904][root][INFO] - rank=0; last iteration 25
[2022-01-11 11:55:32,904][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:32,904][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:55:32,904][root][INFO] - NLL Validation: loss = 0.407432. correct prediction ratio  5569/6400 ~  0.870156
[2022-01-11 11:55:32,904][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 11:55:32,904][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:32,904][root][INFO] - NLL Validation: loss = 0.407432. correct prediction ratio  5569/6400 ~  0.870156
[2022-01-11 11:55:32,904][root][INFO] - rank=2; last iteration 25
[2022-01-11 11:55:32,904][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 11:55:32,904][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 11:55:32,904][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 11:55:32,904][root][INFO] - NLL Validation: loss = 0.407432. correct prediction ratio  5569/6400 ~  0.870156
[2022-01-11 11:55:32,905][root][INFO] - Av Loss per epoch=0.095343
[2022-01-11 11:55:32,905][root][INFO] - epoch total correct predictions=56897
[2022-01-11 11:55:32,905][root][INFO] - Av Loss per epoch=0.095343
[2022-01-11 11:55:32,905][root][INFO] - epoch total correct predictions=56897
[2022-01-11 11:55:32,906][root][INFO] - Av Loss per epoch=0.095343
[2022-01-11 11:55:32,906][root][INFO] - epoch total correct predictions=56897
[2022-01-11 11:55:32,907][root][INFO] - ***** Epoch 5 *****
[2022-01-11 11:55:32,907][root][INFO] - ***** Epoch 5 *****
[2022-01-11 11:55:32,907][root][INFO] - ***** Epoch 5 *****
[2022-01-11 11:55:32,908][root][INFO] - rank=3; Iteration start
[2022-01-11 11:55:32,908][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:55:32,908][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:55:32,908][root][INFO] - rank=1; Iteration start
[2022-01-11 11:55:32,909][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:55:32,909][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 11:55:32,909][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:55:32,909][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 11:55:32,909][root][INFO] - rank=2; Iteration start
[2022-01-11 11:55:32,909][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:55:32,909][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:55:32,910][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 11:55:37,722][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.4
[2022-01-11 11:55:37,723][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.4
[2022-01-11 11:55:37,723][root][INFO] - Av Loss per epoch=0.095343
[2022-01-11 11:55:37,723][root][INFO] - epoch total correct predictions=56897
[2022-01-11 11:55:37,725][root][INFO] - ***** Epoch 5 *****
[2022-01-11 11:55:37,726][root][INFO] - rank=0; Iteration start
[2022-01-11 11:55:37,726][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 11:55:37,726][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 11:55:37,727][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 11:55:38,809][root][INFO] - Epoch: 5: Step: 1/920, loss=0.092393, lr=0.000009
[2022-01-11 11:55:38,811][root][INFO] - Epoch: 5: Step: 1/920, loss=0.092393, lr=0.000009
[2022-01-11 11:55:38,811][root][INFO] - Epoch: 5: Step: 1/920, loss=0.092393, lr=0.000009
[2022-01-11 11:55:38,811][root][INFO] - Epoch: 5: Step: 1/920, loss=0.092393, lr=0.000009
[2022-01-11 11:57:14,994][root][INFO] - Train batch 100
[2022-01-11 11:57:14,994][root][INFO] - Avg. loss per last 100 batches: 0.081223
[2022-01-11 11:57:14,994][root][INFO] - Train batch 100
[2022-01-11 11:57:14,994][root][INFO] - Avg. loss per last 100 batches: 0.081223
[2022-01-11 11:57:14,994][root][INFO] - Train batch 100
[2022-01-11 11:57:14,994][root][INFO] - Avg. loss per last 100 batches: 0.081223
[2022-01-11 11:57:14,994][root][INFO] - Train batch 100
[2022-01-11 11:57:14,995][root][INFO] - Avg. loss per last 100 batches: 0.081223
[2022-01-11 11:57:16,049][root][INFO] - Epoch: 5: Step: 101/920, loss=0.069869, lr=0.000009
[2022-01-11 11:57:16,052][root][INFO] - Epoch: 5: Step: 101/920, loss=0.069869, lr=0.000009
[2022-01-11 11:57:16,052][root][INFO] - Epoch: 5: Step: 101/920, loss=0.069869, lr=0.000009
[2022-01-11 11:57:16,053][root][INFO] - Epoch: 5: Step: 101/920, loss=0.069869, lr=0.000009
[2022-01-11 11:58:53,994][root][INFO] - Train batch 200
[2022-01-11 11:58:53,994][root][INFO] - Avg. loss per last 100 batches: 0.071108
[2022-01-11 11:58:53,994][root][INFO] - Train batch 200
[2022-01-11 11:58:53,994][root][INFO] - Avg. loss per last 100 batches: 0.071108
[2022-01-11 11:58:53,996][root][INFO] - Train batch 200
[2022-01-11 11:58:53,996][root][INFO] - Avg. loss per last 100 batches: 0.071108
[2022-01-11 11:58:53,997][root][INFO] - Train batch 200
[2022-01-11 11:58:53,998][root][INFO] - Avg. loss per last 100 batches: 0.071108
[2022-01-11 11:58:55,036][root][INFO] - Epoch: 5: Step: 201/920, loss=0.071191, lr=0.000009
[2022-01-11 11:58:55,037][root][INFO] - Epoch: 5: Step: 201/920, loss=0.071191, lr=0.000009
[2022-01-11 11:58:55,037][root][INFO] - Epoch: 5: Step: 201/920, loss=0.071191, lr=0.000009
[2022-01-11 11:58:55,039][root][INFO] - Epoch: 5: Step: 201/920, loss=0.071191, lr=0.000009
[2022-01-11 12:00:33,933][root][INFO] - Train batch 300
[2022-01-11 12:00:33,933][root][INFO] - Avg. loss per last 100 batches: 0.075261
[2022-01-11 12:00:33,933][root][INFO] - Train batch 300
[2022-01-11 12:00:33,933][root][INFO] - Avg. loss per last 100 batches: 0.075261
[2022-01-11 12:00:33,934][root][INFO] - Train batch 300
[2022-01-11 12:00:33,934][root][INFO] - Avg. loss per last 100 batches: 0.075261
[2022-01-11 12:00:33,934][root][INFO] - Train batch 300
[2022-01-11 12:00:33,934][root][INFO] - Avg. loss per last 100 batches: 0.075261
[2022-01-11 12:00:34,937][root][INFO] - Epoch: 5: Step: 301/920, loss=0.147126, lr=0.000009
[2022-01-11 12:00:34,937][root][INFO] - Epoch: 5: Step: 301/920, loss=0.147126, lr=0.000009
[2022-01-11 12:00:34,938][root][INFO] - Epoch: 5: Step: 301/920, loss=0.147126, lr=0.000009
[2022-01-11 12:00:34,939][root][INFO] - Epoch: 5: Step: 301/920, loss=0.147126, lr=0.000009
[2022-01-11 12:02:11,927][root][INFO] - Train batch 400
[2022-01-11 12:02:11,927][root][INFO] - Avg. loss per last 100 batches: 0.075838
[2022-01-11 12:02:11,927][root][INFO] - Train batch 400
[2022-01-11 12:02:11,928][root][INFO] - Avg. loss per last 100 batches: 0.075838
[2022-01-11 12:02:11,928][root][INFO] - Train batch 400
[2022-01-11 12:02:11,929][root][INFO] - Avg. loss per last 100 batches: 0.075838
[2022-01-11 12:02:11,929][root][INFO] - Train batch 400
[2022-01-11 12:02:11,929][root][INFO] - Avg. loss per last 100 batches: 0.075838
[2022-01-11 12:02:12,980][root][INFO] - Epoch: 5: Step: 401/920, loss=0.049350, lr=0.000009
[2022-01-11 12:02:12,981][root][INFO] - Epoch: 5: Step: 401/920, loss=0.049350, lr=0.000009
[2022-01-11 12:02:12,981][root][INFO] - Epoch: 5: Step: 401/920, loss=0.049350, lr=0.000009
[2022-01-11 12:02:12,982][root][INFO] - Epoch: 5: Step: 401/920, loss=0.049350, lr=0.000009
[2022-01-11 12:03:50,129][root][INFO] - Train batch 500
[2022-01-11 12:03:50,129][root][INFO] - Avg. loss per last 100 batches: 0.081901
[2022-01-11 12:03:50,136][root][INFO] - Train batch 500
[2022-01-11 12:03:50,136][root][INFO] - Avg. loss per last 100 batches: 0.081901
[2022-01-11 12:03:50,137][root][INFO] - Train batch 500
[2022-01-11 12:03:50,137][root][INFO] - Avg. loss per last 100 batches: 0.081901
[2022-01-11 12:03:50,138][root][INFO] - Train batch 500
[2022-01-11 12:03:50,138][root][INFO] - Avg. loss per last 100 batches: 0.081901
[2022-01-11 12:03:51,191][root][INFO] - Epoch: 5: Step: 501/920, loss=0.027763, lr=0.000009
[2022-01-11 12:03:51,193][root][INFO] - Epoch: 5: Step: 501/920, loss=0.027763, lr=0.000009
[2022-01-11 12:03:51,193][root][INFO] - Epoch: 5: Step: 501/920, loss=0.027763, lr=0.000009
[2022-01-11 12:03:51,193][root][INFO] - Epoch: 5: Step: 501/920, loss=0.027763, lr=0.000009
[2022-01-11 12:05:30,540][root][INFO] - Train batch 600
[2022-01-11 12:05:30,540][root][INFO] - Avg. loss per last 100 batches: 0.076316
[2022-01-11 12:05:30,554][root][INFO] - Train batch 600
[2022-01-11 12:05:30,554][root][INFO] - Avg. loss per last 100 batches: 0.076316
[2022-01-11 12:05:30,556][root][INFO] - Train batch 600
[2022-01-11 12:05:30,556][root][INFO] - Avg. loss per last 100 batches: 0.076316
[2022-01-11 12:05:30,557][root][INFO] - Train batch 600
[2022-01-11 12:05:30,557][root][INFO] - Avg. loss per last 100 batches: 0.076316
[2022-01-11 12:05:31,609][root][INFO] - Epoch: 5: Step: 601/920, loss=0.108350, lr=0.000009
[2022-01-11 12:05:31,609][root][INFO] - Epoch: 5: Step: 601/920, loss=0.108350, lr=0.000009
[2022-01-11 12:05:31,609][root][INFO] - Epoch: 5: Step: 601/920, loss=0.108350, lr=0.000009
[2022-01-11 12:05:31,610][root][INFO] - Epoch: 5: Step: 601/920, loss=0.108350, lr=0.000009
[2022-01-11 12:07:08,668][root][INFO] - Train batch 700
[2022-01-11 12:07:08,668][root][INFO] - Avg. loss per last 100 batches: 0.074388
[2022-01-11 12:07:08,669][root][INFO] - Train batch 700
[2022-01-11 12:07:08,669][root][INFO] - Avg. loss per last 100 batches: 0.074388
[2022-01-11 12:07:08,670][root][INFO] - Train batch 700
[2022-01-11 12:07:08,670][root][INFO] - Avg. loss per last 100 batches: 0.074388
[2022-01-11 12:07:08,670][root][INFO] - Train batch 700
[2022-01-11 12:07:08,671][root][INFO] - Avg. loss per last 100 batches: 0.074388
[2022-01-11 12:07:09,601][root][INFO] - Epoch: 5: Step: 701/920, loss=0.118517, lr=0.000009
[2022-01-11 12:07:09,601][root][INFO] - Epoch: 5: Step: 701/920, loss=0.118517, lr=0.000009
[2022-01-11 12:07:09,601][root][INFO] - Epoch: 5: Step: 701/920, loss=0.118517, lr=0.000009
[2022-01-11 12:07:09,602][root][INFO] - Epoch: 5: Step: 701/920, loss=0.118517, lr=0.000009
[2022-01-11 12:08:48,893][root][INFO] - Train batch 800
[2022-01-11 12:08:48,893][root][INFO] - Avg. loss per last 100 batches: 0.077987
[2022-01-11 12:08:48,894][root][INFO] - Train batch 800
[2022-01-11 12:08:48,894][root][INFO] - Avg. loss per last 100 batches: 0.077987
[2022-01-11 12:08:48,895][root][INFO] - Train batch 800
[2022-01-11 12:08:48,895][root][INFO] - Avg. loss per last 100 batches: 0.077987
[2022-01-11 12:08:48,909][root][INFO] - Train batch 800
[2022-01-11 12:08:48,909][root][INFO] - Avg. loss per last 100 batches: 0.077987
[2022-01-11 12:08:49,951][root][INFO] - Epoch: 5: Step: 801/920, loss=0.071926, lr=0.000009
[2022-01-11 12:08:49,952][root][INFO] - Epoch: 5: Step: 801/920, loss=0.071926, lr=0.000009
[2022-01-11 12:08:49,952][root][INFO] - Epoch: 5: Step: 801/920, loss=0.071926, lr=0.000009
[2022-01-11 12:08:49,965][root][INFO] - Epoch: 5: Step: 801/920, loss=0.071926, lr=0.000009
[2022-01-11 12:10:27,583][root][INFO] - Train batch 900
[2022-01-11 12:10:27,583][root][INFO] - Avg. loss per last 100 batches: 0.091727
[2022-01-11 12:10:27,583][root][INFO] - Train batch 900
[2022-01-11 12:10:27,583][root][INFO] - Train batch 900
[2022-01-11 12:10:27,584][root][INFO] - Avg. loss per last 100 batches: 0.091727
[2022-01-11 12:10:27,584][root][INFO] - Avg. loss per last 100 batches: 0.091727
[2022-01-11 12:10:27,584][root][INFO] - Train batch 900
[2022-01-11 12:10:27,584][root][INFO] - Avg. loss per last 100 batches: 0.091727
[2022-01-11 12:10:28,433][root][INFO] - Epoch: 5: Step: 901/920, loss=0.013477, lr=0.000009
[2022-01-11 12:10:28,440][root][INFO] - Epoch: 5: Step: 901/920, loss=0.013477, lr=0.000009
[2022-01-11 12:10:28,440][root][INFO] - Epoch: 5: Step: 901/920, loss=0.013477, lr=0.000009
[2022-01-11 12:10:28,442][root][INFO] - Epoch: 5: Step: 901/920, loss=0.013477, lr=0.000009
[2022-01-11 12:10:48,034][root][INFO] - rank=3, Validation: Epoch: 5 Step: 920/920
[2022-01-11 12:10:48,034][root][INFO] - NLL validation ...
[2022-01-11 12:10:48,035][root][INFO] - rank=3; Iteration start
[2022-01-11 12:10:48,035][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:10:48,035][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:10:48,035][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 12:10:48,043][root][INFO] - rank=0, Validation: Epoch: 5 Step: 920/920
[2022-01-11 12:10:48,044][root][INFO] - NLL validation ...
[2022-01-11 12:10:48,044][root][INFO] - rank=2, Validation: Epoch: 5 Step: 920/920
[2022-01-11 12:10:48,044][root][INFO] - NLL validation ...
[2022-01-11 12:10:48,045][root][INFO] - rank=0; Iteration start
[2022-01-11 12:10:48,045][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:10:48,045][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:10:48,045][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 12:10:48,045][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 12:10:48,045][root][INFO] - rank=1, Validation: Epoch: 5 Step: 920/920
[2022-01-11 12:10:48,045][root][INFO] - rank=2; Iteration start
[2022-01-11 12:10:48,045][root][INFO] - NLL validation ...
[2022-01-11 12:10:48,045][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:10:48,045][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:10:48,045][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 12:10:48,047][root][INFO] - rank=1; Iteration start
[2022-01-11 12:10:48,047][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:10:48,047][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:10:48,047][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 12:10:48,054][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 12:10:48,055][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 12:10:48,057][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 12:10:48,794][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 12:10:49,774][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 12:10:49,781][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 12:10:49,785][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 12:10:50,520][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 12:10:50,521][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 12:10:50,521][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 12:10:50,521][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 12:10:51,256][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 12:10:51,256][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 12:10:51,257][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 12:10:51,257][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 12:10:51,992][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 12:10:51,992][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 12:10:51,993][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 12:10:51,993][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 12:10:52,730][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 12:10:52,731][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 12:10:52,731][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 12:10:52,731][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 12:10:53,470][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 12:10:53,471][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 12:10:53,471][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 12:10:53,471][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 12:10:54,208][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 12:10:54,209][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 12:10:54,209][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 12:10:54,209][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 12:10:54,945][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 12:10:54,945][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 12:10:54,945][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 12:10:54,945][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 12:10:55,679][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 12:10:55,680][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 12:10:55,680][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 12:10:55,680][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 12:10:56,420][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 12:10:56,422][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 12:10:56,422][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 12:10:56,422][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 12:10:57,159][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 12:10:57,159][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 12:10:57,159][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 12:10:57,160][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 12:10:57,898][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 12:10:57,898][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 12:10:57,899][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 12:10:57,900][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 12:10:58,638][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 12:10:58,639][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 12:10:58,639][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 12:10:59,238][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 12:10:59,971][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 12:10:59,971][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 12:10:59,972][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 12:10:59,972][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 12:11:00,709][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 12:11:01,309][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 12:11:01,317][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 12:11:01,318][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 12:11:02,054][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 12:11:02,054][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 12:11:02,055][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 12:11:02,055][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 12:11:02,792][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 12:11:02,793][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 12:11:02,793][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 12:11:02,794][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 12:11:03,532][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 12:11:03,532][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 12:11:03,532][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 12:11:03,533][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 12:11:04,272][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 12:11:04,274][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 12:11:04,274][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 12:11:04,275][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 12:11:05,012][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 12:11:05,012][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 12:11:05,012][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 12:11:05,012][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 12:11:05,752][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 12:11:05,752][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 12:11:05,752][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 12:11:05,753][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 12:11:06,496][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 12:11:06,497][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 12:11:06,498][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 12:11:06,498][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 12:11:07,236][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 12:11:07,236][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 12:11:07,237][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 12:11:07,237][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 12:11:07,973][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 12:11:07,974][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 12:11:07,974][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 12:11:07,976][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 12:11:08,704][root][INFO] - rank=3; last iteration 25
[2022-01-11 12:11:08,704][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:11:08,704][root][INFO] - rank=1; last iteration 25
[2022-01-11 12:11:08,704][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 12:11:08,704][root][INFO] - rank=0; last iteration 25
[2022-01-11 12:11:08,704][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:11:08,704][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:08,704][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:11:08,704][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 12:11:08,704][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 12:11:08,704][root][INFO] - rank=2; last iteration 25
[2022-01-11 12:11:08,704][root][INFO] - NLL Validation: loss = 0.391288. correct prediction ratio  5604/6400 ~  0.875625
[2022-01-11 12:11:08,704][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:08,704][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:08,704][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:11:08,704][root][INFO] - NLL Validation: loss = 0.391288. correct prediction ratio  5604/6400 ~  0.875625
[2022-01-11 12:11:08,704][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 12:11:08,704][root][INFO] - NLL Validation: loss = 0.391288. correct prediction ratio  5604/6400 ~  0.875625
[2022-01-11 12:11:08,704][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:08,704][root][INFO] - NLL Validation: loss = 0.391288. correct prediction ratio  5604/6400 ~  0.875625
[2022-01-11 12:11:08,706][root][INFO] - rank=3; last iteration 920
[2022-01-11 12:11:08,707][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:11:08,707][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 12:11:08,707][root][INFO] - rank=1; last iteration 920
[2022-01-11 12:11:08,707][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:11:08,707][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 12:11:08,707][root][INFO] - rank=2; last iteration 920
[2022-01-11 12:11:08,707][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:11:08,707][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 12:11:08,707][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:08,707][root][INFO] - Epoch finished on 3
[2022-01-11 12:11:08,707][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:08,707][root][INFO] - Epoch finished on 1
[2022-01-11 12:11:08,707][root][INFO] - NLL validation ...
[2022-01-11 12:11:08,707][root][INFO] - NLL validation ...
[2022-01-11 12:11:08,708][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:08,708][root][INFO] - Epoch finished on 2
[2022-01-11 12:11:08,708][root][INFO] - NLL validation ...
[2022-01-11 12:11:08,709][root][INFO] - rank=3; Iteration start
[2022-01-11 12:11:08,709][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:11:08,709][root][INFO] - rank=1; Iteration start
[2022-01-11 12:11:08,709][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:11:08,709][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 12:11:08,709][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:11:08,709][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:11:08,709][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 12:11:08,709][root][INFO] - rank=2; Iteration start
[2022-01-11 12:11:08,709][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:11:08,709][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:11:08,709][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 12:11:08,716][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 12:11:08,716][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 12:11:08,718][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 12:11:12,681][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.5
[2022-01-11 12:11:12,682][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.5
[2022-01-11 12:11:12,682][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.5
[2022-01-11 12:11:12,683][root][INFO] - rank=0; last iteration 920
[2022-01-11 12:11:12,683][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:11:12,683][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 12:11:12,684][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:12,684][root][INFO] - Epoch finished on 0
[2022-01-11 12:11:12,684][root][INFO] - NLL validation ...
[2022-01-11 12:11:12,685][root][INFO] - rank=0; Iteration start
[2022-01-11 12:11:12,685][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:11:12,685][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:11:12,685][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 12:11:12,694][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 12:11:13,442][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 12:11:13,443][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 12:11:13,444][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 12:11:13,445][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 12:11:14,180][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 12:11:14,180][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 12:11:14,182][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 12:11:15,078][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 12:11:15,805][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 12:11:15,806][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 12:11:15,807][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 12:11:15,808][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 12:11:16,541][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 12:11:16,541][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 12:11:16,543][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 12:11:16,543][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 12:11:17,288][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 12:11:17,896][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 12:11:17,901][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 12:11:18,197][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 12:11:18,935][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 12:11:18,935][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 12:11:18,936][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 12:11:18,937][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 12:11:19,677][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 12:11:19,679][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 12:11:19,679][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 12:11:19,679][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 12:11:20,417][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 12:11:20,417][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 12:11:20,417][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 12:11:20,418][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 12:11:21,159][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 12:11:21,160][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 12:11:21,160][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 12:11:21,160][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 12:11:21,898][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 12:11:21,898][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 12:11:21,898][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 12:11:21,900][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 12:11:22,635][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 12:11:22,637][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 12:11:22,637][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 12:11:22,639][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 12:11:23,373][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 12:11:23,374][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 12:11:23,374][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 12:11:23,374][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 12:11:24,114][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 12:11:24,114][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 12:11:24,115][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 12:11:24,115][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 12:11:24,851][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 12:11:24,852][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 12:11:24,853][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 12:11:24,853][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 12:11:25,587][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 12:11:25,588][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 12:11:25,588][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 12:11:25,588][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 12:11:26,324][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 12:11:26,324][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 12:11:26,325][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 12:11:26,931][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 12:11:27,661][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 12:11:27,662][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 12:11:27,663][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 12:11:27,663][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 12:11:28,397][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 12:11:28,398][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 12:11:28,399][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 12:11:28,401][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 12:11:29,142][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 12:11:29,757][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 12:11:29,923][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 12:11:29,960][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 12:11:30,695][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 12:11:30,696][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 12:11:30,696][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 12:11:30,697][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 12:11:31,430][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 12:11:31,430][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 12:11:31,431][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 12:11:31,432][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 12:11:32,170][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 12:11:32,170][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 12:11:32,171][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 12:11:32,173][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 12:11:32,908][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 12:11:32,908][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 12:11:32,909][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 12:11:32,910][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 12:11:33,645][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 12:11:33,645][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 12:11:33,647][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 12:11:33,647][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 12:11:34,376][root][INFO] - rank=3; last iteration 25
[2022-01-11 12:11:34,376][root][INFO] - rank=1; last iteration 25
[2022-01-11 12:11:34,376][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:11:34,376][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:11:34,376][root][INFO] - rank=0; last iteration 25
[2022-01-11 12:11:34,376][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 12:11:34,376][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 12:11:34,376][root][INFO] - rank=2; last iteration 25
[2022-01-11 12:11:34,376][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:11:34,376][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:11:34,376][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:34,376][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 12:11:34,376][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:34,376][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 12:11:34,376][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:34,376][root][INFO] - NLL Validation: loss = 0.391288. correct prediction ratio  5604/6400 ~  0.875625
[2022-01-11 12:11:34,376][root][INFO] - NLL Validation: loss = 0.391288. correct prediction ratio  5604/6400 ~  0.875625
[2022-01-11 12:11:34,376][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:11:34,376][root][INFO] - NLL Validation: loss = 0.391288. correct prediction ratio  5604/6400 ~  0.875625
[2022-01-11 12:11:34,377][root][INFO] - NLL Validation: loss = 0.391288. correct prediction ratio  5604/6400 ~  0.875625
[2022-01-11 12:11:34,378][root][INFO] - Av Loss per epoch=0.078784
[2022-01-11 12:11:34,378][root][INFO] - Av Loss per epoch=0.078784
[2022-01-11 12:11:34,378][root][INFO] - epoch total correct predictions=57181
[2022-01-11 12:11:34,378][root][INFO] - epoch total correct predictions=57181
[2022-01-11 12:11:34,378][root][INFO] - Av Loss per epoch=0.078784
[2022-01-11 12:11:34,378][root][INFO] - epoch total correct predictions=57181
[2022-01-11 12:11:34,380][root][INFO] - ***** Epoch 6 *****
[2022-01-11 12:11:34,380][root][INFO] - ***** Epoch 6 *****
[2022-01-11 12:11:34,380][root][INFO] - ***** Epoch 6 *****
[2022-01-11 12:11:34,381][root][INFO] - rank=3; Iteration start
[2022-01-11 12:11:34,381][root][INFO] - rank=2; Iteration start
[2022-01-11 12:11:34,381][root][INFO] - rank=1; Iteration start
[2022-01-11 12:11:34,381][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:11:34,381][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:11:34,381][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:11:34,381][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:11:34,381][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:11:34,381][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:11:34,382][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 12:11:34,382][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 12:11:34,382][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 12:11:39,407][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.5
[2022-01-11 12:11:39,407][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.5
[2022-01-11 12:11:39,407][root][INFO] - Av Loss per epoch=0.078784
[2022-01-11 12:11:39,407][root][INFO] - epoch total correct predictions=57181
[2022-01-11 12:11:39,410][root][INFO] - ***** Epoch 6 *****
[2022-01-11 12:11:39,413][root][INFO] - rank=0; Iteration start
[2022-01-11 12:11:39,413][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:11:39,413][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:11:39,414][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 12:11:40,315][root][INFO] - Epoch: 6: Step: 1/920, loss=0.082357, lr=0.000009
[2022-01-11 12:11:40,317][root][INFO] - Epoch: 6: Step: 1/920, loss=0.082357, lr=0.000009
[2022-01-11 12:11:40,317][root][INFO] - Epoch: 6: Step: 1/920, loss=0.082357, lr=0.000009
[2022-01-11 12:11:40,317][root][INFO] - Epoch: 6: Step: 1/920, loss=0.082357, lr=0.000009
[2022-01-11 12:13:17,808][root][INFO] - Train batch 100
[2022-01-11 12:13:17,808][root][INFO] - Avg. loss per last 100 batches: 0.067948
[2022-01-11 12:13:17,808][root][INFO] - Train batch 100
[2022-01-11 12:13:17,809][root][INFO] - Avg. loss per last 100 batches: 0.067948
[2022-01-11 12:13:17,809][root][INFO] - Train batch 100
[2022-01-11 12:13:17,809][root][INFO] - Avg. loss per last 100 batches: 0.067948
[2022-01-11 12:13:17,809][root][INFO] - Train batch 100
[2022-01-11 12:13:17,810][root][INFO] - Avg. loss per last 100 batches: 0.067948
[2022-01-11 12:13:19,816][root][INFO] - Epoch: 6: Step: 101/920, loss=0.106986, lr=0.000009
[2022-01-11 12:13:19,817][root][INFO] - Epoch: 6: Step: 101/920, loss=0.106986, lr=0.000009
[2022-01-11 12:13:19,818][root][INFO] - Epoch: 6: Step: 101/920, loss=0.106986, lr=0.000009
[2022-01-11 12:13:19,819][root][INFO] - Epoch: 6: Step: 101/920, loss=0.106986, lr=0.000009
[2022-01-11 12:14:55,087][root][INFO] - Train batch 200
[2022-01-11 12:14:55,087][root][INFO] - Avg. loss per last 100 batches: 0.070923
[2022-01-11 12:14:55,097][root][INFO] - Train batch 200
[2022-01-11 12:14:55,097][root][INFO] - Avg. loss per last 100 batches: 0.070923
[2022-01-11 12:14:55,097][root][INFO] - Train batch 200
[2022-01-11 12:14:55,097][root][INFO] - Avg. loss per last 100 batches: 0.070923
[2022-01-11 12:14:55,098][root][INFO] - Train batch 200
[2022-01-11 12:14:55,098][root][INFO] - Avg. loss per last 100 batches: 0.070923
[2022-01-11 12:14:57,108][root][INFO] - Epoch: 6: Step: 201/920, loss=0.079306, lr=0.000009
[2022-01-11 12:14:57,114][root][INFO] - Epoch: 6: Step: 201/920, loss=0.079306, lr=0.000009
[2022-01-11 12:14:57,114][root][INFO] - Epoch: 6: Step: 201/920, loss=0.079306, lr=0.000009
[2022-01-11 12:14:57,115][root][INFO] - Epoch: 6: Step: 201/920, loss=0.079306, lr=0.000009
[2022-01-11 12:16:35,617][root][INFO] - Train batch 300
[2022-01-11 12:16:35,617][root][INFO] - Avg. loss per last 100 batches: 0.082069
[2022-01-11 12:16:35,618][root][INFO] - Train batch 300
[2022-01-11 12:16:35,618][root][INFO] - Avg. loss per last 100 batches: 0.082069
[2022-01-11 12:16:35,618][root][INFO] - Train batch 300
[2022-01-11 12:16:35,618][root][INFO] - Avg. loss per last 100 batches: 0.082069
[2022-01-11 12:16:35,618][root][INFO] - Train batch 300
[2022-01-11 12:16:35,618][root][INFO] - Avg. loss per last 100 batches: 0.082069
[2022-01-11 12:16:36,657][root][INFO] - Epoch: 6: Step: 301/920, loss=0.055332, lr=0.000009
[2022-01-11 12:16:36,670][root][INFO] - Epoch: 6: Step: 301/920, loss=0.055332, lr=0.000009
[2022-01-11 12:16:36,671][root][INFO] - Epoch: 6: Step: 301/920, loss=0.055332, lr=0.000009
[2022-01-11 12:16:36,672][root][INFO] - Epoch: 6: Step: 301/920, loss=0.055332, lr=0.000009
[2022-01-11 12:18:14,277][root][INFO] - Train batch 400
[2022-01-11 12:18:14,278][root][INFO] - Avg. loss per last 100 batches: 0.071556
[2022-01-11 12:18:14,277][root][INFO] - Train batch 400
[2022-01-11 12:18:14,278][root][INFO] - Avg. loss per last 100 batches: 0.071556
[2022-01-11 12:18:14,278][root][INFO] - Train batch 400
[2022-01-11 12:18:14,278][root][INFO] - Avg. loss per last 100 batches: 0.071556
[2022-01-11 12:18:14,278][root][INFO] - Train batch 400
[2022-01-11 12:18:14,278][root][INFO] - Avg. loss per last 100 batches: 0.071556
[2022-01-11 12:18:15,165][root][INFO] - Epoch: 6: Step: 401/920, loss=0.055371, lr=0.000009
[2022-01-11 12:18:15,165][root][INFO] - Epoch: 6: Step: 401/920, loss=0.055371, lr=0.000009
[2022-01-11 12:18:15,165][root][INFO] - Epoch: 6: Step: 401/920, loss=0.055371, lr=0.000009
[2022-01-11 12:18:15,166][root][INFO] - Epoch: 6: Step: 401/920, loss=0.055371, lr=0.000009
[2022-01-11 12:19:53,735][root][INFO] - Train batch 500
[2022-01-11 12:19:53,735][root][INFO] - Avg. loss per last 100 batches: 0.070159
[2022-01-11 12:19:53,736][root][INFO] - Train batch 500
[2022-01-11 12:19:53,736][root][INFO] - Avg. loss per last 100 batches: 0.070159
[2022-01-11 12:19:53,737][root][INFO] - Train batch 500
[2022-01-11 12:19:53,737][root][INFO] - Avg. loss per last 100 batches: 0.070159
[2022-01-11 12:19:53,737][root][INFO] - Train batch 500
[2022-01-11 12:19:53,737][root][INFO] - Avg. loss per last 100 batches: 0.070159
[2022-01-11 12:19:54,753][root][INFO] - Epoch: 6: Step: 501/920, loss=0.070333, lr=0.000009
[2022-01-11 12:19:54,754][root][INFO] - Epoch: 6: Step: 501/920, loss=0.070333, lr=0.000009
[2022-01-11 12:19:54,754][root][INFO] - Epoch: 6: Step: 501/920, loss=0.070333, lr=0.000009
[2022-01-11 12:19:54,754][root][INFO] - Epoch: 6: Step: 501/920, loss=0.070333, lr=0.000009
[2022-01-11 12:21:32,995][root][INFO] - Train batch 600
[2022-01-11 12:21:32,996][root][INFO] - Avg. loss per last 100 batches: 0.071356
[2022-01-11 12:21:33,004][root][INFO] - Train batch 600
[2022-01-11 12:21:33,004][root][INFO] - Avg. loss per last 100 batches: 0.071356
[2022-01-11 12:21:33,004][root][INFO] - Train batch 600
[2022-01-11 12:21:33,005][root][INFO] - Avg. loss per last 100 batches: 0.071356
[2022-01-11 12:21:33,005][root][INFO] - Train batch 600
[2022-01-11 12:21:33,005][root][INFO] - Avg. loss per last 100 batches: 0.071356
[2022-01-11 12:21:33,874][root][INFO] - Epoch: 6: Step: 601/920, loss=0.026492, lr=0.000009
[2022-01-11 12:21:33,875][root][INFO] - Epoch: 6: Step: 601/920, loss=0.026492, lr=0.000009
[2022-01-11 12:21:33,875][root][INFO] - Epoch: 6: Step: 601/920, loss=0.026492, lr=0.000009
[2022-01-11 12:21:33,875][root][INFO] - Epoch: 6: Step: 601/920, loss=0.026492, lr=0.000009
[2022-01-11 12:23:10,737][root][INFO] - Train batch 700
[2022-01-11 12:23:10,737][root][INFO] - Train batch 700
[2022-01-11 12:23:10,737][root][INFO] - Avg. loss per last 100 batches: 0.071839
[2022-01-11 12:23:10,737][root][INFO] - Avg. loss per last 100 batches: 0.071839
[2022-01-11 12:23:10,738][root][INFO] - Train batch 700
[2022-01-11 12:23:10,738][root][INFO] - Avg. loss per last 100 batches: 0.071839
[2022-01-11 12:23:10,738][root][INFO] - Train batch 700
[2022-01-11 12:23:10,738][root][INFO] - Avg. loss per last 100 batches: 0.071839
[2022-01-11 12:23:11,751][root][INFO] - Epoch: 6: Step: 701/920, loss=0.069699, lr=0.000009
[2022-01-11 12:23:11,760][root][INFO] - Epoch: 6: Step: 701/920, loss=0.069699, lr=0.000009
[2022-01-11 12:23:11,761][root][INFO] - Epoch: 6: Step: 701/920, loss=0.069699, lr=0.000009
[2022-01-11 12:23:11,764][root][INFO] - Epoch: 6: Step: 701/920, loss=0.069699, lr=0.000009
[2022-01-11 12:24:51,018][root][INFO] - Train batch 800
[2022-01-11 12:24:51,018][root][INFO] - Avg. loss per last 100 batches: 0.069122
[2022-01-11 12:24:51,025][root][INFO] - Train batch 800
[2022-01-11 12:24:51,025][root][INFO] - Avg. loss per last 100 batches: 0.069122
[2022-01-11 12:24:51,025][root][INFO] - Train batch 800
[2022-01-11 12:24:51,025][root][INFO] - Avg. loss per last 100 batches: 0.069122
[2022-01-11 12:24:51,026][root][INFO] - Train batch 800
[2022-01-11 12:24:51,026][root][INFO] - Avg. loss per last 100 batches: 0.069122
[2022-01-11 12:24:52,077][root][INFO] - Epoch: 6: Step: 801/920, loss=0.138664, lr=0.000009
[2022-01-11 12:24:52,077][root][INFO] - Epoch: 6: Step: 801/920, loss=0.138664, lr=0.000009
[2022-01-11 12:24:52,077][root][INFO] - Epoch: 6: Step: 801/920, loss=0.138664, lr=0.000009
[2022-01-11 12:24:52,078][root][INFO] - Epoch: 6: Step: 801/920, loss=0.138664, lr=0.000009
[2022-01-11 12:26:30,759][root][INFO] - Train batch 900
[2022-01-11 12:26:30,759][root][INFO] - Avg. loss per last 100 batches: 0.069329
[2022-01-11 12:26:30,760][root][INFO] - Train batch 900
[2022-01-11 12:26:30,760][root][INFO] - Avg. loss per last 100 batches: 0.069329
[2022-01-11 12:26:30,760][root][INFO] - Train batch 900
[2022-01-11 12:26:30,760][root][INFO] - Train batch 900
[2022-01-11 12:26:30,760][root][INFO] - Avg. loss per last 100 batches: 0.069329
[2022-01-11 12:26:30,760][root][INFO] - Avg. loss per last 100 batches: 0.069329
[2022-01-11 12:26:31,798][root][INFO] - Epoch: 6: Step: 901/920, loss=0.040999, lr=0.000009
[2022-01-11 12:26:31,798][root][INFO] - Epoch: 6: Step: 901/920, loss=0.040999, lr=0.000009
[2022-01-11 12:26:31,806][root][INFO] - Epoch: 6: Step: 901/920, loss=0.040999, lr=0.000009
[2022-01-11 12:26:31,806][root][INFO] - Epoch: 6: Step: 901/920, loss=0.040999, lr=0.000009
[2022-01-11 12:26:51,146][root][INFO] - rank=0, Validation: Epoch: 6 Step: 920/920
[2022-01-11 12:26:51,146][root][INFO] - NLL validation ...
[2022-01-11 12:26:51,146][root][INFO] - rank=2, Validation: Epoch: 6 Step: 920/920
[2022-01-11 12:26:51,147][root][INFO] - NLL validation ...
[2022-01-11 12:26:51,147][root][INFO] - rank=0; Iteration start
[2022-01-11 12:26:51,148][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:26:51,148][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:26:51,148][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 12:26:51,148][root][INFO] - rank=2; Iteration start
[2022-01-11 12:26:51,148][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:26:51,148][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:26:51,148][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 12:26:51,153][root][INFO] - rank=1, Validation: Epoch: 6 Step: 920/920
[2022-01-11 12:26:51,153][root][INFO] - NLL validation ...
[2022-01-11 12:26:51,153][root][INFO] - rank=3, Validation: Epoch: 6 Step: 920/920
[2022-01-11 12:26:51,153][root][INFO] - NLL validation ...
[2022-01-11 12:26:51,154][root][INFO] - rank=1; Iteration start
[2022-01-11 12:26:51,154][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:26:51,154][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:26:51,154][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 12:26:51,154][root][INFO] - rank=3; Iteration start
[2022-01-11 12:26:51,155][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:26:51,155][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:26:51,155][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 12:26:51,157][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 12:26:51,159][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 12:26:51,164][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 12:26:51,164][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 12:26:51,900][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 12:26:51,900][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 12:26:51,901][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 12:26:51,901][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 12:26:52,638][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 12:26:52,639][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 12:26:52,639][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 12:26:52,639][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 12:26:53,375][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 12:26:53,375][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 12:26:53,376][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 12:26:53,377][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 12:26:54,114][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 12:26:54,115][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 12:26:54,115][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 12:26:54,115][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 12:26:54,852][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 12:26:54,853][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 12:26:54,853][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 12:26:54,853][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 12:26:55,593][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 12:26:55,593][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 12:26:55,594][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 12:26:55,594][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 12:26:56,332][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 12:26:56,332][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 12:26:56,332][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 12:26:56,333][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 12:26:57,069][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 12:26:57,070][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 12:26:57,070][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 12:26:57,070][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 12:26:57,808][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 12:26:57,808][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 12:26:57,808][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 12:26:58,495][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 12:26:59,227][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 12:26:59,228][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 12:26:59,229][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 12:26:59,230][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 12:26:59,975][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 12:26:59,975][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 12:26:59,977][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 12:26:59,977][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 12:27:00,719][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 12:27:00,719][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 12:27:00,719][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 12:27:00,721][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 12:27:01,462][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 12:27:02,103][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 12:27:02,315][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 12:27:02,334][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 12:27:03,068][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 12:27:03,069][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 12:27:03,069][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 12:27:03,070][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 12:27:03,804][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 12:27:03,804][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 12:27:03,805][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 12:27:03,805][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 12:27:04,538][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 12:27:04,539][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 12:27:04,539][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 12:27:04,539][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 12:27:05,280][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 12:27:05,281][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 12:27:05,281][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 12:27:05,281][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 12:27:06,018][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 12:27:06,019][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 12:27:06,019][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 12:27:06,019][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 12:27:06,758][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 12:27:06,758][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 12:27:06,758][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 12:27:06,758][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 12:27:07,495][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 12:27:07,495][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 12:27:07,496][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 12:27:07,496][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 12:27:08,239][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 12:27:08,239][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 12:27:08,239][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 12:27:08,240][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 12:27:08,978][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 12:27:08,979][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 12:27:08,979][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 12:27:08,980][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 12:27:09,717][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 12:27:09,718][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 12:27:09,718][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 12:27:10,331][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 12:27:11,065][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 12:27:11,065][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 12:27:11,065][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 12:27:11,066][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 12:27:11,793][root][INFO] - rank=3; last iteration 25
[2022-01-11 12:27:11,793][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:27:11,793][root][INFO] - rank=1; last iteration 25
[2022-01-11 12:27:11,793][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 12:27:11,793][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:27:11,793][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:11,793][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 12:27:11,793][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:11,793][root][INFO] - NLL Validation: loss = 0.395286. correct prediction ratio  5624/6400 ~  0.878750
[2022-01-11 12:27:11,794][root][INFO] - NLL Validation: loss = 0.395286. correct prediction ratio  5624/6400 ~  0.878750
[2022-01-11 12:27:11,793][root][INFO] - rank=2; last iteration 25
[2022-01-11 12:27:11,794][root][INFO] - rank=0; last iteration 25
[2022-01-11 12:27:11,794][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:27:11,794][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:27:11,794][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 12:27:11,794][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 12:27:11,794][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:11,794][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:11,794][root][INFO] - NLL Validation: loss = 0.395286. correct prediction ratio  5624/6400 ~  0.878750
[2022-01-11 12:27:11,794][root][INFO] - NLL Validation: loss = 0.395286. correct prediction ratio  5624/6400 ~  0.878750
[2022-01-11 12:27:11,796][root][INFO] - rank=3; last iteration 920
[2022-01-11 12:27:11,796][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:27:11,796][root][INFO] - rank=1; last iteration 920
[2022-01-11 12:27:11,796][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 12:27:11,796][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:27:11,796][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 12:27:11,796][root][INFO] - rank=2; last iteration 920
[2022-01-11 12:27:11,796][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:27:11,796][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 12:27:11,797][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:11,797][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:11,797][root][INFO] - Epoch finished on 1
[2022-01-11 12:27:11,797][root][INFO] - Epoch finished on 3
[2022-01-11 12:27:11,797][root][INFO] - NLL validation ...
[2022-01-11 12:27:11,797][root][INFO] - NLL validation ...
[2022-01-11 12:27:11,797][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:11,797][root][INFO] - Epoch finished on 2
[2022-01-11 12:27:11,797][root][INFO] - NLL validation ...
[2022-01-11 12:27:11,798][root][INFO] - rank=1; Iteration start
[2022-01-11 12:27:11,798][root][INFO] - rank=3; Iteration start
[2022-01-11 12:27:11,798][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:27:11,798][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:27:11,798][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:27:11,798][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:27:11,798][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 12:27:11,798][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 12:27:11,798][root][INFO] - rank=2; Iteration start
[2022-01-11 12:27:11,798][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:27:11,799][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:27:11,799][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 12:27:11,806][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 12:27:11,806][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 12:27:11,806][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 12:27:15,766][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.6
[2022-01-11 12:27:15,766][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.6
[2022-01-11 12:27:15,768][root][INFO] - rank=0; last iteration 920
[2022-01-11 12:27:15,768][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:27:15,768][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 12:27:15,768][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:15,768][root][INFO] - Epoch finished on 0
[2022-01-11 12:27:15,768][root][INFO] - NLL validation ...
[2022-01-11 12:27:15,770][root][INFO] - rank=0; Iteration start
[2022-01-11 12:27:15,770][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:27:15,770][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:27:15,770][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 12:27:15,777][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 12:27:16,518][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 12:27:16,518][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 12:27:16,518][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 12:27:16,519][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 12:27:17,259][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 12:27:17,875][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 12:27:17,917][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 12:27:17,969][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 12:27:18,702][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 12:27:18,702][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 12:27:18,702][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 12:27:18,703][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 12:27:19,441][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 12:27:19,441][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 12:27:19,441][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 12:27:19,441][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 12:27:20,178][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 12:27:20,178][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 12:27:20,178][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 12:27:20,178][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 12:27:20,913][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 12:27:20,913][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 12:27:20,913][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 12:27:20,913][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 12:27:21,649][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 12:27:21,649][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 12:27:21,650][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 12:27:21,650][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 12:27:22,387][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 12:27:22,388][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 12:27:22,388][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 12:27:22,390][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 12:27:23,123][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 12:27:23,124][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 12:27:23,124][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 12:27:23,126][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 12:27:23,859][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 12:27:23,859][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 12:27:23,859][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 12:27:23,860][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 12:27:24,593][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 12:27:24,593][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 12:27:24,594][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 12:27:24,595][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 12:27:25,333][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 12:27:25,333][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 12:27:25,334][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 12:27:25,957][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 12:27:26,691][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 12:27:26,691][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 12:27:26,691][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 12:27:26,693][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 12:27:27,428][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 12:27:27,428][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 12:27:27,429][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 12:27:27,429][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 12:27:28,166][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 12:27:28,168][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 12:27:28,168][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 12:27:28,171][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 12:27:28,904][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 12:27:29,520][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 12:27:29,524][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 12:27:29,526][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 12:27:30,261][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 12:27:30,262][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 12:27:30,262][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 12:27:30,264][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 12:27:30,998][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 12:27:30,998][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 12:27:30,999][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 12:27:31,000][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 12:27:31,734][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 12:27:31,735][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 12:27:31,735][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 12:27:31,736][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 12:27:32,470][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 12:27:32,470][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 12:27:32,471][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 12:27:32,472][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 12:27:33,208][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 12:27:33,208][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 12:27:33,209][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 12:27:33,210][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 12:27:33,946][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 12:27:33,948][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 12:27:33,949][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 12:27:33,952][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 12:27:34,683][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 12:27:34,684][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 12:27:34,685][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 12:27:34,686][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 12:27:35,422][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 12:27:35,423][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 12:27:35,424][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 12:27:35,425][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 12:27:36,150][root][INFO] - rank=1; last iteration 25
[2022-01-11 12:27:36,150][root][INFO] - rank=3; last iteration 25
[2022-01-11 12:27:36,150][root][INFO] - rank=0; last iteration 25
[2022-01-11 12:27:36,150][root][INFO] - rank=2; last iteration 25
[2022-01-11 12:27:36,150][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:27:36,150][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:27:36,150][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:27:36,150][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:27:36,150][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 12:27:36,150][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 12:27:36,150][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 12:27:36,150][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 12:27:36,151][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:36,151][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:36,151][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:36,151][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:27:36,151][root][INFO] - NLL Validation: loss = 0.395286. correct prediction ratio  5624/6400 ~  0.878750
[2022-01-11 12:27:36,151][root][INFO] - NLL Validation: loss = 0.395286. correct prediction ratio  5624/6400 ~  0.878750
[2022-01-11 12:27:36,151][root][INFO] - NLL Validation: loss = 0.395286. correct prediction ratio  5624/6400 ~  0.878750
[2022-01-11 12:27:36,151][root][INFO] - NLL Validation: loss = 0.395286. correct prediction ratio  5624/6400 ~  0.878750
[2022-01-11 12:27:36,152][root][INFO] - Av Loss per epoch=0.071247
[2022-01-11 12:27:36,152][root][INFO] - Av Loss per epoch=0.071247
[2022-01-11 12:27:36,152][root][INFO] - epoch total correct predictions=57338
[2022-01-11 12:27:36,152][root][INFO] - Av Loss per epoch=0.071247
[2022-01-11 12:27:36,152][root][INFO] - epoch total correct predictions=57338
[2022-01-11 12:27:36,152][root][INFO] - epoch total correct predictions=57338
[2022-01-11 12:27:36,154][root][INFO] - ***** Epoch 7 *****
[2022-01-11 12:27:36,154][root][INFO] - ***** Epoch 7 *****
[2022-01-11 12:27:36,154][root][INFO] - ***** Epoch 7 *****
[2022-01-11 12:27:36,155][root][INFO] - rank=3; Iteration start
[2022-01-11 12:27:36,155][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:27:36,155][root][INFO] - rank=2; Iteration start
[2022-01-11 12:27:36,155][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:27:36,155][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:27:36,155][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:27:36,155][root][INFO] - rank=1; Iteration start
[2022-01-11 12:27:36,155][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:27:36,155][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:27:36,156][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 12:27:36,156][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 12:27:36,156][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 12:27:40,870][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.6
[2022-01-11 12:27:40,870][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.6
[2022-01-11 12:27:40,870][root][INFO] - Av Loss per epoch=0.071247
[2022-01-11 12:27:40,870][root][INFO] - epoch total correct predictions=57338
[2022-01-11 12:27:40,872][root][INFO] - ***** Epoch 7 *****
[2022-01-11 12:27:40,874][root][INFO] - rank=0; Iteration start
[2022-01-11 12:27:40,874][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:27:40,874][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:27:40,874][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 12:27:41,769][root][INFO] - Epoch: 7: Step: 1/920, loss=0.122080, lr=0.000009
[2022-01-11 12:27:41,769][root][INFO] - Epoch: 7: Step: 1/920, loss=0.122080, lr=0.000009
[2022-01-11 12:27:41,770][root][INFO] - Epoch: 7: Step: 1/920, loss=0.122080, lr=0.000009
[2022-01-11 12:27:41,770][root][INFO] - Epoch: 7: Step: 1/920, loss=0.122080, lr=0.000009
[2022-01-11 12:29:20,663][root][INFO] - Train batch 100
[2022-01-11 12:29:20,663][root][INFO] - Avg. loss per last 100 batches: 0.062843
[2022-01-11 12:29:20,665][root][INFO] - Train batch 100
[2022-01-11 12:29:20,666][root][INFO] - Avg. loss per last 100 batches: 0.062843
[2022-01-11 12:29:20,666][root][INFO] - Train batch 100
[2022-01-11 12:29:20,666][root][INFO] - Avg. loss per last 100 batches: 0.062843
[2022-01-11 12:29:20,666][root][INFO] - Train batch 100
[2022-01-11 12:29:20,667][root][INFO] - Avg. loss per last 100 batches: 0.062843
[2022-01-11 12:29:21,709][root][INFO] - Epoch: 7: Step: 101/920, loss=0.016300, lr=0.000009
[2022-01-11 12:29:21,717][root][INFO] - Epoch: 7: Step: 101/920, loss=0.016300, lr=0.000009
[2022-01-11 12:29:21,718][root][INFO] - Epoch: 7: Step: 101/920, loss=0.016300, lr=0.000009
[2022-01-11 12:29:21,719][root][INFO] - Epoch: 7: Step: 101/920, loss=0.016300, lr=0.000009
[2022-01-11 12:30:59,929][root][INFO] - Train batch 200
[2022-01-11 12:30:59,929][root][INFO] - Train batch 200
[2022-01-11 12:30:59,929][root][INFO] - Avg. loss per last 100 batches: 0.064126
[2022-01-11 12:30:59,929][root][INFO] - Avg. loss per last 100 batches: 0.064126
[2022-01-11 12:30:59,929][root][INFO] - Train batch 200
[2022-01-11 12:30:59,930][root][INFO] - Avg. loss per last 100 batches: 0.064126
[2022-01-11 12:30:59,930][root][INFO] - Train batch 200
[2022-01-11 12:30:59,930][root][INFO] - Avg. loss per last 100 batches: 0.064126
[2022-01-11 12:31:00,943][root][INFO] - Epoch: 7: Step: 201/920, loss=0.071317, lr=0.000009
[2022-01-11 12:31:00,950][root][INFO] - Epoch: 7: Step: 201/920, loss=0.071317, lr=0.000009
[2022-01-11 12:31:00,951][root][INFO] - Epoch: 7: Step: 201/920, loss=0.071317, lr=0.000009
[2022-01-11 12:31:00,952][root][INFO] - Epoch: 7: Step: 201/920, loss=0.071317, lr=0.000009
[2022-01-11 12:32:38,160][root][INFO] - Train batch 300
[2022-01-11 12:32:38,161][root][INFO] - Avg. loss per last 100 batches: 0.062393
[2022-01-11 12:32:38,161][root][INFO] - Train batch 300
[2022-01-11 12:32:38,161][root][INFO] - Avg. loss per last 100 batches: 0.062393
[2022-01-11 12:32:38,162][root][INFO] - Train batch 300
[2022-01-11 12:32:38,162][root][INFO] - Avg. loss per last 100 batches: 0.062393
[2022-01-11 12:32:38,163][root][INFO] - Train batch 300
[2022-01-11 12:32:38,163][root][INFO] - Avg. loss per last 100 batches: 0.062393
[2022-01-11 12:32:39,137][root][INFO] - Epoch: 7: Step: 301/920, loss=0.103950, lr=0.000009
[2022-01-11 12:32:39,138][root][INFO] - Epoch: 7: Step: 301/920, loss=0.103950, lr=0.000009
[2022-01-11 12:32:39,139][root][INFO] - Epoch: 7: Step: 301/920, loss=0.103950, lr=0.000009
[2022-01-11 12:32:39,140][root][INFO] - Epoch: 7: Step: 301/920, loss=0.103950, lr=0.000009
[2022-01-11 12:34:16,752][root][INFO] - Train batch 400
[2022-01-11 12:34:16,752][root][INFO] - Avg. loss per last 100 batches: 0.058378
[2022-01-11 12:34:16,753][root][INFO] - Train batch 400
[2022-01-11 12:34:16,753][root][INFO] - Avg. loss per last 100 batches: 0.058378
[2022-01-11 12:34:16,753][root][INFO] - Train batch 400
[2022-01-11 12:34:16,753][root][INFO] - Avg. loss per last 100 batches: 0.058378
[2022-01-11 12:34:16,753][root][INFO] - Train batch 400
[2022-01-11 12:34:16,754][root][INFO] - Avg. loss per last 100 batches: 0.058378
[2022-01-11 12:34:17,609][root][INFO] - Epoch: 7: Step: 401/920, loss=0.098009, lr=0.000009
[2022-01-11 12:34:17,610][root][INFO] - Epoch: 7: Step: 401/920, loss=0.098009, lr=0.000009
[2022-01-11 12:34:17,610][root][INFO] - Epoch: 7: Step: 401/920, loss=0.098009, lr=0.000009
[2022-01-11 12:34:17,611][root][INFO] - Epoch: 7: Step: 401/920, loss=0.098009, lr=0.000009
[2022-01-11 12:35:56,419][root][INFO] - Train batch 500
[2022-01-11 12:35:56,419][root][INFO] - Train batch 500
[2022-01-11 12:35:56,419][root][INFO] - Avg. loss per last 100 batches: 0.057232
[2022-01-11 12:35:56,419][root][INFO] - Avg. loss per last 100 batches: 0.057232
[2022-01-11 12:35:56,419][root][INFO] - Train batch 500
[2022-01-11 12:35:56,420][root][INFO] - Avg. loss per last 100 batches: 0.057232
[2022-01-11 12:35:56,420][root][INFO] - Train batch 500
[2022-01-11 12:35:56,420][root][INFO] - Avg. loss per last 100 batches: 0.057232
[2022-01-11 12:35:57,366][root][INFO] - Epoch: 7: Step: 501/920, loss=0.027857, lr=0.000009
[2022-01-11 12:35:57,367][root][INFO] - Epoch: 7: Step: 501/920, loss=0.027857, lr=0.000009
[2022-01-11 12:35:57,368][root][INFO] - Epoch: 7: Step: 501/920, loss=0.027857, lr=0.000009
[2022-01-11 12:35:57,368][root][INFO] - Epoch: 7: Step: 501/920, loss=0.027857, lr=0.000009
[2022-01-11 12:37:33,479][root][INFO] - Train batch 600
[2022-01-11 12:37:33,479][root][INFO] - Avg. loss per last 100 batches: 0.062601
[2022-01-11 12:37:33,479][root][INFO] - Train batch 600
[2022-01-11 12:37:33,479][root][INFO] - Avg. loss per last 100 batches: 0.062601
[2022-01-11 12:37:33,480][root][INFO] - Train batch 600
[2022-01-11 12:37:33,480][root][INFO] - Avg. loss per last 100 batches: 0.062601
[2022-01-11 12:37:33,482][root][INFO] - Train batch 600
[2022-01-11 12:37:33,483][root][INFO] - Avg. loss per last 100 batches: 0.062601
[2022-01-11 12:37:34,537][root][INFO] - Epoch: 7: Step: 601/920, loss=0.025783, lr=0.000009
[2022-01-11 12:37:34,540][root][INFO] - Epoch: 7: Step: 601/920, loss=0.025783, lr=0.000009
[2022-01-11 12:37:34,540][root][INFO] - Epoch: 7: Step: 601/920, loss=0.025783, lr=0.000009
[2022-01-11 12:37:34,540][root][INFO] - Epoch: 7: Step: 601/920, loss=0.025783, lr=0.000009
[2022-01-11 12:39:12,889][root][INFO] - Train batch 700
[2022-01-11 12:39:12,889][root][INFO] - Avg. loss per last 100 batches: 0.067034
[2022-01-11 12:39:12,890][root][INFO] - Train batch 700
[2022-01-11 12:39:12,890][root][INFO] - Avg. loss per last 100 batches: 0.067034
[2022-01-11 12:39:12,890][root][INFO] - Train batch 700
[2022-01-11 12:39:12,890][root][INFO] - Avg. loss per last 100 batches: 0.067034
[2022-01-11 12:39:12,891][root][INFO] - Train batch 700
[2022-01-11 12:39:12,891][root][INFO] - Avg. loss per last 100 batches: 0.067034
[2022-01-11 12:39:13,767][root][INFO] - Epoch: 7: Step: 701/920, loss=0.079337, lr=0.000009
[2022-01-11 12:39:13,768][root][INFO] - Epoch: 7: Step: 701/920, loss=0.079337, lr=0.000009
[2022-01-11 12:39:13,769][root][INFO] - Epoch: 7: Step: 701/920, loss=0.079337, lr=0.000009
[2022-01-11 12:39:13,769][root][INFO] - Epoch: 7: Step: 701/920, loss=0.079337, lr=0.000009
[2022-01-11 12:40:52,582][root][INFO] - Train batch 800
[2022-01-11 12:40:52,583][root][INFO] - Avg. loss per last 100 batches: 0.064033
[2022-01-11 12:40:52,583][root][INFO] - Train batch 800
[2022-01-11 12:40:52,583][root][INFO] - Avg. loss per last 100 batches: 0.064033
[2022-01-11 12:40:52,583][root][INFO] - Train batch 800
[2022-01-11 12:40:52,583][root][INFO] - Avg. loss per last 100 batches: 0.064033
[2022-01-11 12:40:52,583][root][INFO] - Train batch 800
[2022-01-11 12:40:52,583][root][INFO] - Avg. loss per last 100 batches: 0.064033
[2022-01-11 12:40:53,522][root][INFO] - Epoch: 7: Step: 801/920, loss=0.090890, lr=0.000009
[2022-01-11 12:40:53,522][root][INFO] - Epoch: 7: Step: 801/920, loss=0.090890, lr=0.000009
[2022-01-11 12:40:53,523][root][INFO] - Epoch: 7: Step: 801/920, loss=0.090890, lr=0.000009
[2022-01-11 12:40:53,524][root][INFO] - Epoch: 7: Step: 801/920, loss=0.090890, lr=0.000009
[2022-01-11 12:42:30,641][root][INFO] - Train batch 900
[2022-01-11 12:42:30,641][root][INFO] - Avg. loss per last 100 batches: 0.064815
[2022-01-11 12:42:30,641][root][INFO] - Train batch 900
[2022-01-11 12:42:30,641][root][INFO] - Avg. loss per last 100 batches: 0.064815
[2022-01-11 12:42:30,643][root][INFO] - Train batch 900
[2022-01-11 12:42:30,643][root][INFO] - Avg. loss per last 100 batches: 0.064815
[2022-01-11 12:42:30,643][root][INFO] - Train batch 900
[2022-01-11 12:42:30,643][root][INFO] - Avg. loss per last 100 batches: 0.064815
[2022-01-11 12:42:31,573][root][INFO] - Epoch: 7: Step: 901/920, loss=0.045368, lr=0.000009
[2022-01-11 12:42:31,574][root][INFO] - Epoch: 7: Step: 901/920, loss=0.045368, lr=0.000009
[2022-01-11 12:42:31,576][root][INFO] - Epoch: 7: Step: 901/920, loss=0.045368, lr=0.000009
[2022-01-11 12:42:31,576][root][INFO] - Epoch: 7: Step: 901/920, loss=0.045368, lr=0.000009
[2022-01-11 12:42:50,282][root][INFO] - rank=2, Validation: Epoch: 7 Step: 920/920
[2022-01-11 12:42:50,282][root][INFO] - NLL validation ...
[2022-01-11 12:42:50,284][root][INFO] - rank=2; Iteration start
[2022-01-11 12:42:50,284][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:42:50,284][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:42:50,284][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 12:42:50,286][root][INFO] - rank=1, Validation: Epoch: 7 Step: 920/920
[2022-01-11 12:42:50,286][root][INFO] - rank=0, Validation: Epoch: 7 Step: 920/920
[2022-01-11 12:42:50,286][root][INFO] - NLL validation ...
[2022-01-11 12:42:50,286][root][INFO] - NLL validation ...
[2022-01-11 12:42:50,287][root][INFO] - rank=1; Iteration start
[2022-01-11 12:42:50,287][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:42:50,287][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:42:50,288][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 12:42:50,287][root][INFO] - rank=0; Iteration start
[2022-01-11 12:42:50,288][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:42:50,288][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:42:50,288][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 12:42:50,288][root][INFO] - rank=3, Validation: Epoch: 7 Step: 920/920
[2022-01-11 12:42:50,288][root][INFO] - NLL validation ...
[2022-01-11 12:42:50,289][root][INFO] - rank=3; Iteration start
[2022-01-11 12:42:50,289][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:42:50,289][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:42:50,289][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 12:42:50,294][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 12:42:50,298][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 12:42:50,298][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 12:42:50,299][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 12:42:51,039][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 12:42:51,040][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 12:42:51,041][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 12:42:51,057][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 12:42:51,794][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 12:42:51,795][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 12:42:51,795][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 12:42:51,796][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 12:42:52,532][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 12:42:52,532][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 12:42:52,533][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 12:42:52,533][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 12:42:53,270][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 12:42:53,271][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 12:42:53,271][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 12:42:53,271][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 12:42:54,014][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 12:42:54,015][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 12:42:54,016][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 12:42:54,985][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 12:42:55,716][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 12:42:55,716][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 12:42:55,716][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 12:42:55,717][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 12:42:56,452][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 12:42:56,453][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 12:42:56,453][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 12:42:56,454][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 12:42:57,192][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 12:42:57,192][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 12:42:57,193][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 12:42:57,193][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 12:42:57,932][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 12:42:57,935][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 12:42:57,935][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 12:42:57,936][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 12:42:58,674][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 12:42:59,594][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 12:42:59,604][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 12:42:59,629][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 12:43:00,367][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 12:43:00,367][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 12:43:00,367][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 12:43:00,368][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 12:43:01,106][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 12:43:01,106][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 12:43:01,106][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 12:43:01,106][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 12:43:01,846][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 12:43:01,847][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 12:43:01,847][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 12:43:01,847][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 12:43:02,584][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 12:43:02,584][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 12:43:02,584][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 12:43:02,584][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 12:43:03,320][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 12:43:03,321][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 12:43:03,321][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 12:43:03,322][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 12:43:04,057][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 12:43:04,057][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 12:43:04,058][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 12:43:04,058][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 12:43:04,798][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 12:43:04,798][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 12:43:04,799][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 12:43:04,799][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 12:43:05,536][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 12:43:05,536][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 12:43:05,537][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 12:43:06,172][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 12:43:06,911][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 12:43:06,912][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 12:43:06,912][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 12:43:06,912][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 12:43:07,650][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 12:43:07,651][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 12:43:07,651][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 12:43:07,651][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 12:43:08,388][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 12:43:08,388][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 12:43:08,388][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 12:43:08,388][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 12:43:09,126][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 12:43:09,126][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 12:43:09,127][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 12:43:09,127][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 12:43:09,871][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 12:43:10,470][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 12:43:10,472][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 12:43:10,499][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 12:43:11,233][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 12:43:11,234][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 12:43:11,234][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 12:43:11,234][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 12:43:11,965][root][INFO] - rank=3; last iteration 25
[2022-01-11 12:43:11,965][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:43:11,965][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 12:43:11,965][root][INFO] - rank=0; last iteration 25
[2022-01-11 12:43:11,965][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:11,965][root][INFO] - rank=1; last iteration 25
[2022-01-11 12:43:11,965][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:43:11,965][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 12:43:11,965][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:43:11,965][root][INFO] - NLL Validation: loss = 0.394209. correct prediction ratio  5617/6400 ~  0.877656
[2022-01-11 12:43:11,965][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 12:43:11,965][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:11,966][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:11,966][root][INFO] - NLL Validation: loss = 0.394209. correct prediction ratio  5617/6400 ~  0.877656
[2022-01-11 12:43:11,966][root][INFO] - NLL Validation: loss = 0.394209. correct prediction ratio  5617/6400 ~  0.877656
[2022-01-11 12:43:11,966][root][INFO] - rank=2; last iteration 25
[2022-01-11 12:43:11,966][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:43:11,966][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 12:43:11,966][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:11,966][root][INFO] - NLL Validation: loss = 0.394209. correct prediction ratio  5617/6400 ~  0.877656
[2022-01-11 12:43:11,968][root][INFO] - rank=3; last iteration 920
[2022-01-11 12:43:11,968][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:43:11,968][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 12:43:11,968][root][INFO] - rank=1; last iteration 920
[2022-01-11 12:43:11,968][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:43:11,968][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 12:43:11,968][root][INFO] - rank=2; last iteration 920
[2022-01-11 12:43:11,968][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:11,969][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:43:11,969][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 12:43:11,969][root][INFO] - Epoch finished on 3
[2022-01-11 12:43:11,969][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:11,969][root][INFO] - NLL validation ...
[2022-01-11 12:43:11,969][root][INFO] - Epoch finished on 1
[2022-01-11 12:43:11,969][root][INFO] - NLL validation ...
[2022-01-11 12:43:11,969][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:11,969][root][INFO] - Epoch finished on 2
[2022-01-11 12:43:11,969][root][INFO] - NLL validation ...
[2022-01-11 12:43:11,970][root][INFO] - rank=3; Iteration start
[2022-01-11 12:43:11,970][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:43:11,970][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:43:11,970][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 12:43:11,970][root][INFO] - rank=1; Iteration start
[2022-01-11 12:43:11,970][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:43:11,970][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:43:11,970][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 12:43:11,970][root][INFO] - rank=2; Iteration start
[2022-01-11 12:43:11,970][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:43:11,971][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:43:11,971][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 12:43:11,978][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 12:43:11,978][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 12:43:11,978][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 12:43:15,830][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.7
[2022-01-11 12:43:15,830][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.7
[2022-01-11 12:43:15,832][root][INFO] - rank=0; last iteration 920
[2022-01-11 12:43:15,832][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:43:15,832][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 12:43:15,832][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:15,832][root][INFO] - Epoch finished on 0
[2022-01-11 12:43:15,832][root][INFO] - NLL validation ...
[2022-01-11 12:43:15,834][root][INFO] - rank=0; Iteration start
[2022-01-11 12:43:15,834][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:43:15,834][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:43:15,834][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 12:43:15,842][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 12:43:16,583][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 12:43:16,584][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 12:43:16,584][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 12:43:16,584][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 12:43:17,317][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 12:43:17,318][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 12:43:17,318][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 12:43:17,318][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 12:43:18,052][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 12:43:18,053][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 12:43:18,054][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 12:43:18,054][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 12:43:18,788][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 12:43:18,789][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 12:43:18,789][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 12:43:18,789][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 12:43:19,527][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 12:43:19,527][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 12:43:19,527][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 12:43:19,530][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 12:43:20,263][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 12:43:20,263][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 12:43:20,265][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 12:43:20,265][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 12:43:21,001][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 12:43:21,001][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 12:43:21,002][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 12:43:21,640][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 12:43:22,373][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 12:43:22,373][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 12:43:22,375][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 12:43:22,378][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 12:43:23,113][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 12:43:23,113][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 12:43:23,114][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 12:43:23,115][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 12:43:23,852][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 12:43:23,852][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 12:43:23,853][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 12:43:23,854][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 12:43:24,594][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 12:43:24,594][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 12:43:24,594][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 12:43:24,596][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 12:43:25,335][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 12:43:25,963][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 12:43:25,967][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 12:43:26,047][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 12:43:26,782][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 12:43:26,782][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 12:43:26,783][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 12:43:26,784][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 12:43:27,520][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 12:43:27,521][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 12:43:27,522][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 12:43:27,523][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 12:43:28,256][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 12:43:28,257][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 12:43:28,257][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 12:43:28,258][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 12:43:28,992][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 12:43:28,993][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 12:43:28,993][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 12:43:28,994][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 12:43:29,731][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 12:43:29,731][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 12:43:29,733][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 12:43:29,736][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 12:43:30,475][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 12:43:30,476][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 12:43:30,477][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 12:43:30,477][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 12:43:31,215][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 12:43:31,216][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 12:43:31,216][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 12:43:31,218][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 12:43:31,952][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 12:43:31,953][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 12:43:31,953][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 12:43:31,955][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 12:43:32,692][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 12:43:32,693][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 12:43:32,693][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 12:43:33,569][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 12:43:34,302][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 12:43:34,303][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 12:43:34,303][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 12:43:34,304][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 12:43:35,042][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 12:43:35,042][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 12:43:35,042][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 12:43:35,044][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 12:43:35,779][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 12:43:35,779][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 12:43:35,780][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 12:43:35,802][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 12:43:36,531][root][INFO] - rank=3; last iteration 25
[2022-01-11 12:43:36,531][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:43:36,531][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 12:43:36,531][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:36,531][root][INFO] - NLL Validation: loss = 0.394209. correct prediction ratio  5617/6400 ~  0.877656
[2022-01-11 12:43:36,532][root][INFO] - rank=1; last iteration 25
[2022-01-11 12:43:36,532][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:43:36,532][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 12:43:36,533][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:36,533][root][INFO] - Av Loss per epoch=0.062503
[2022-01-11 12:43:36,533][root][INFO] - NLL Validation: loss = 0.394209. correct prediction ratio  5617/6400 ~  0.877656
[2022-01-11 12:43:36,533][root][INFO] - epoch total correct predictions=57496
[2022-01-11 12:43:36,534][root][INFO] - rank=0; last iteration 25
[2022-01-11 12:43:36,534][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:43:36,534][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 12:43:36,534][root][INFO] - Av Loss per epoch=0.062503
[2022-01-11 12:43:36,534][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:36,534][root][INFO] - epoch total correct predictions=57496
[2022-01-11 12:43:36,535][root][INFO] - NLL Validation: loss = 0.394209. correct prediction ratio  5617/6400 ~  0.877656
[2022-01-11 12:43:36,534][root][INFO] - ***** Epoch 8 *****
[2022-01-11 12:43:36,536][root][INFO] - rank=3; Iteration start
[2022-01-11 12:43:36,536][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:43:36,536][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:43:36,537][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 12:43:36,536][root][INFO] - ***** Epoch 8 *****
[2022-01-11 12:43:36,538][root][INFO] - rank=1; Iteration start
[2022-01-11 12:43:36,538][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:43:36,538][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:43:36,539][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 12:43:36,544][root][INFO] - rank=2; last iteration 25
[2022-01-11 12:43:36,544][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:43:36,544][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 12:43:36,545][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:43:36,545][root][INFO] - NLL Validation: loss = 0.394209. correct prediction ratio  5617/6400 ~  0.877656
[2022-01-11 12:43:36,546][root][INFO] - Av Loss per epoch=0.062503
[2022-01-11 12:43:36,546][root][INFO] - epoch total correct predictions=57496
[2022-01-11 12:43:36,549][root][INFO] - ***** Epoch 8 *****
[2022-01-11 12:43:36,552][root][INFO] - rank=2; Iteration start
[2022-01-11 12:43:36,552][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:43:36,552][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:43:36,553][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 12:43:41,349][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.7
[2022-01-11 12:43:41,350][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.7
[2022-01-11 12:43:41,350][root][INFO] - Av Loss per epoch=0.062503
[2022-01-11 12:43:41,351][root][INFO] - epoch total correct predictions=57496
[2022-01-11 12:43:41,352][root][INFO] - ***** Epoch 8 *****
[2022-01-11 12:43:41,354][root][INFO] - rank=0; Iteration start
[2022-01-11 12:43:41,355][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:43:41,355][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:43:41,355][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 12:43:42,344][root][INFO] - Epoch: 8: Step: 1/920, loss=0.019431, lr=0.000009
[2022-01-11 12:43:42,345][root][INFO] - Epoch: 8: Step: 1/920, loss=0.019431, lr=0.000009
[2022-01-11 12:43:42,346][root][INFO] - Epoch: 8: Step: 1/920, loss=0.019431, lr=0.000009
[2022-01-11 12:43:42,347][root][INFO] - Epoch: 8: Step: 1/920, loss=0.019431, lr=0.000009
[2022-01-11 12:45:21,483][root][INFO] - Train batch 100
[2022-01-11 12:45:21,483][root][INFO] - Avg. loss per last 100 batches: 0.056276
[2022-01-11 12:45:21,483][root][INFO] - Train batch 100
[2022-01-11 12:45:21,484][root][INFO] - Avg. loss per last 100 batches: 0.056276
[2022-01-11 12:45:21,484][root][INFO] - Train batch 100
[2022-01-11 12:45:21,484][root][INFO] - Avg. loss per last 100 batches: 0.056276
[2022-01-11 12:45:21,487][root][INFO] - Train batch 100
[2022-01-11 12:45:21,487][root][INFO] - Avg. loss per last 100 batches: 0.056276
[2022-01-11 12:45:22,534][root][INFO] - Epoch: 8: Step: 101/920, loss=0.108796, lr=0.000009
[2022-01-11 12:45:22,536][root][INFO] - Epoch: 8: Step: 101/920, loss=0.108796, lr=0.000009
[2022-01-11 12:45:22,537][root][INFO] - Epoch: 8: Step: 101/920, loss=0.108796, lr=0.000009
[2022-01-11 12:45:22,538][root][INFO] - Epoch: 8: Step: 101/920, loss=0.108796, lr=0.000009
[2022-01-11 12:47:01,052][root][INFO] - Train batch 200
[2022-01-11 12:47:01,052][root][INFO] - Avg. loss per last 100 batches: 0.056015
[2022-01-11 12:47:01,055][root][INFO] - Train batch 200
[2022-01-11 12:47:01,055][root][INFO] - Avg. loss per last 100 batches: 0.056015
[2022-01-11 12:47:01,055][root][INFO] - Train batch 200
[2022-01-11 12:47:01,055][root][INFO] - Avg. loss per last 100 batches: 0.056015
[2022-01-11 12:47:01,056][root][INFO] - Train batch 200
[2022-01-11 12:47:01,056][root][INFO] - Avg. loss per last 100 batches: 0.056015
[2022-01-11 12:47:01,897][root][INFO] - Epoch: 8: Step: 201/920, loss=0.038666, lr=0.000009
[2022-01-11 12:47:01,899][root][INFO] - Epoch: 8: Step: 201/920, loss=0.038666, lr=0.000009
[2022-01-11 12:47:01,902][root][INFO] - Epoch: 8: Step: 201/920, loss=0.038666, lr=0.000009
[2022-01-11 12:47:01,903][root][INFO] - Epoch: 8: Step: 201/920, loss=0.038666, lr=0.000009
[2022-01-11 12:48:39,121][root][INFO] - Train batch 300
[2022-01-11 12:48:39,121][root][INFO] - Avg. loss per last 100 batches: 0.057952
[2022-01-11 12:48:39,121][root][INFO] - Train batch 300
[2022-01-11 12:48:39,121][root][INFO] - Avg. loss per last 100 batches: 0.057952
[2022-01-11 12:48:39,122][root][INFO] - Train batch 300
[2022-01-11 12:48:39,122][root][INFO] - Avg. loss per last 100 batches: 0.057952
[2022-01-11 12:48:39,123][root][INFO] - Train batch 300
[2022-01-11 12:48:39,123][root][INFO] - Avg. loss per last 100 batches: 0.057952
[2022-01-11 12:48:40,173][root][INFO] - Epoch: 8: Step: 301/920, loss=0.069747, lr=0.000008
[2022-01-11 12:48:40,175][root][INFO] - Epoch: 8: Step: 301/920, loss=0.069747, lr=0.000008
[2022-01-11 12:48:40,175][root][INFO] - Epoch: 8: Step: 301/920, loss=0.069747, lr=0.000008
[2022-01-11 12:48:40,176][root][INFO] - Epoch: 8: Step: 301/920, loss=0.069747, lr=0.000008
[2022-01-11 12:50:18,668][root][INFO] - Train batch 400
[2022-01-11 12:50:18,668][root][INFO] - Avg. loss per last 100 batches: 0.054634
[2022-01-11 12:50:18,669][root][INFO] - Train batch 400
[2022-01-11 12:50:18,669][root][INFO] - Avg. loss per last 100 batches: 0.054634
[2022-01-11 12:50:18,670][root][INFO] - Train batch 400
[2022-01-11 12:50:18,670][root][INFO] - Avg. loss per last 100 batches: 0.054634
[2022-01-11 12:50:18,671][root][INFO] - Train batch 400
[2022-01-11 12:50:18,672][root][INFO] - Avg. loss per last 100 batches: 0.054634
[2022-01-11 12:50:19,714][root][INFO] - Epoch: 8: Step: 401/920, loss=0.088595, lr=0.000008
[2022-01-11 12:50:19,714][root][INFO] - Epoch: 8: Step: 401/920, loss=0.088595, lr=0.000008
[2022-01-11 12:50:19,714][root][INFO] - Epoch: 8: Step: 401/920, loss=0.088595, lr=0.000008
[2022-01-11 12:50:19,715][root][INFO] - Epoch: 8: Step: 401/920, loss=0.088595, lr=0.000008
[2022-01-11 12:51:57,484][root][INFO] - Train batch 500
[2022-01-11 12:51:57,484][root][INFO] - Avg. loss per last 100 batches: 0.052628
[2022-01-11 12:51:57,485][root][INFO] - Train batch 500
[2022-01-11 12:51:57,485][root][INFO] - Avg. loss per last 100 batches: 0.052628
[2022-01-11 12:51:57,485][root][INFO] - Train batch 500
[2022-01-11 12:51:57,485][root][INFO] - Avg. loss per last 100 batches: 0.052628
[2022-01-11 12:51:57,486][root][INFO] - Train batch 500
[2022-01-11 12:51:57,486][root][INFO] - Avg. loss per last 100 batches: 0.052628
[2022-01-11 12:51:58,376][root][INFO] - Epoch: 8: Step: 501/920, loss=0.117756, lr=0.000008
[2022-01-11 12:51:58,382][root][INFO] - Epoch: 8: Step: 501/920, loss=0.117756, lr=0.000008
[2022-01-11 12:51:58,382][root][INFO] - Epoch: 8: Step: 501/920, loss=0.117756, lr=0.000008
[2022-01-11 12:51:58,383][root][INFO] - Epoch: 8: Step: 501/920, loss=0.117756, lr=0.000008
[2022-01-11 12:53:35,718][root][INFO] - Train batch 600
[2022-01-11 12:53:35,718][root][INFO] - Avg. loss per last 100 batches: 0.062274
[2022-01-11 12:53:35,718][root][INFO] - Train batch 600
[2022-01-11 12:53:35,718][root][INFO] - Avg. loss per last 100 batches: 0.062274
[2022-01-11 12:53:35,719][root][INFO] - Train batch 600
[2022-01-11 12:53:35,719][root][INFO] - Avg. loss per last 100 batches: 0.062274
[2022-01-11 12:53:35,719][root][INFO] - Train batch 600
[2022-01-11 12:53:35,720][root][INFO] - Avg. loss per last 100 batches: 0.062274
[2022-01-11 12:53:36,731][root][INFO] - Epoch: 8: Step: 601/920, loss=0.059554, lr=0.000008
[2022-01-11 12:53:36,733][root][INFO] - Epoch: 8: Step: 601/920, loss=0.059554, lr=0.000008
[2022-01-11 12:53:36,733][root][INFO] - Epoch: 8: Step: 601/920, loss=0.059554, lr=0.000008
[2022-01-11 12:53:36,733][root][INFO] - Epoch: 8: Step: 601/920, loss=0.059554, lr=0.000008
[2022-01-11 12:55:14,175][root][INFO] - Train batch 700
[2022-01-11 12:55:14,175][root][INFO] - Avg. loss per last 100 batches: 0.055237
[2022-01-11 12:55:14,189][root][INFO] - Train batch 700
[2022-01-11 12:55:14,190][root][INFO] - Avg. loss per last 100 batches: 0.055237
[2022-01-11 12:55:14,190][root][INFO] - Train batch 700
[2022-01-11 12:55:14,190][root][INFO] - Avg. loss per last 100 batches: 0.055237
[2022-01-11 12:55:14,193][root][INFO] - Train batch 700
[2022-01-11 12:55:14,193][root][INFO] - Avg. loss per last 100 batches: 0.055237
[2022-01-11 12:55:15,241][root][INFO] - Epoch: 8: Step: 701/920, loss=0.124690, lr=0.000008
[2022-01-11 12:55:15,253][root][INFO] - Epoch: 8: Step: 701/920, loss=0.124690, lr=0.000008
[2022-01-11 12:55:15,253][root][INFO] - Epoch: 8: Step: 701/920, loss=0.124690, lr=0.000008
[2022-01-11 12:55:15,253][root][INFO] - Epoch: 8: Step: 701/920, loss=0.124690, lr=0.000008
[2022-01-11 12:56:53,546][root][INFO] - Train batch 800
[2022-01-11 12:56:53,546][root][INFO] - Avg. loss per last 100 batches: 0.054892
[2022-01-11 12:56:53,547][root][INFO] - Train batch 800
[2022-01-11 12:56:53,548][root][INFO] - Avg. loss per last 100 batches: 0.054892
[2022-01-11 12:56:53,547][root][INFO] - Train batch 800
[2022-01-11 12:56:53,548][root][INFO] - Avg. loss per last 100 batches: 0.054892
[2022-01-11 12:56:53,548][root][INFO] - Train batch 800
[2022-01-11 12:56:53,548][root][INFO] - Avg. loss per last 100 batches: 0.054892
[2022-01-11 12:56:54,520][root][INFO] - Epoch: 8: Step: 801/920, loss=0.021545, lr=0.000008
[2022-01-11 12:56:54,521][root][INFO] - Epoch: 8: Step: 801/920, loss=0.021545, lr=0.000008
[2022-01-11 12:56:54,522][root][INFO] - Epoch: 8: Step: 801/920, loss=0.021545, lr=0.000008
[2022-01-11 12:56:54,522][root][INFO] - Epoch: 8: Step: 801/920, loss=0.021545, lr=0.000008
[2022-01-11 12:58:30,855][root][INFO] - Train batch 900
[2022-01-11 12:58:30,856][root][INFO] - Avg. loss per last 100 batches: 0.063653
[2022-01-11 12:58:30,863][root][INFO] - Train batch 900
[2022-01-11 12:58:30,864][root][INFO] - Avg. loss per last 100 batches: 0.063653
[2022-01-11 12:58:30,864][root][INFO] - Train batch 900
[2022-01-11 12:58:30,864][root][INFO] - Avg. loss per last 100 batches: 0.063653
[2022-01-11 12:58:30,865][root][INFO] - Train batch 900
[2022-01-11 12:58:30,865][root][INFO] - Avg. loss per last 100 batches: 0.063653
[2022-01-11 12:58:31,721][root][INFO] - Epoch: 8: Step: 901/920, loss=0.161651, lr=0.000008
[2022-01-11 12:58:31,721][root][INFO] - Epoch: 8: Step: 901/920, loss=0.161651, lr=0.000008
[2022-01-11 12:58:31,722][root][INFO] - Epoch: 8: Step: 901/920, loss=0.161651, lr=0.000008
[2022-01-11 12:58:31,722][root][INFO] - Epoch: 8: Step: 901/920, loss=0.161651, lr=0.000008
[2022-01-11 12:58:51,426][root][INFO] - rank=1, Validation: Epoch: 8 Step: 920/920
[2022-01-11 12:58:51,426][root][INFO] - NLL validation ...
[2022-01-11 12:58:51,428][root][INFO] - rank=1; Iteration start
[2022-01-11 12:58:51,428][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:58:51,428][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:58:51,428][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 12:58:51,432][root][INFO] - rank=0, Validation: Epoch: 8 Step: 920/920
[2022-01-11 12:58:51,432][root][INFO] - NLL validation ...
[2022-01-11 12:58:51,433][root][INFO] - rank=2, Validation: Epoch: 8 Step: 920/920
[2022-01-11 12:58:51,433][root][INFO] - rank=3, Validation: Epoch: 8 Step: 920/920
[2022-01-11 12:58:51,433][root][INFO] - NLL validation ...
[2022-01-11 12:58:51,433][root][INFO] - NLL validation ...
[2022-01-11 12:58:51,433][root][INFO] - rank=0; Iteration start
[2022-01-11 12:58:51,433][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:58:51,434][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:58:51,434][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 12:58:51,434][root][INFO] - rank=2; Iteration start
[2022-01-11 12:58:51,435][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:58:51,435][root][INFO] - rank=3; Iteration start
[2022-01-11 12:58:51,435][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:58:51,435][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 12:58:51,435][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:58:51,435][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:58:51,435][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 12:58:51,438][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 12:58:51,443][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 12:58:51,445][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 12:58:51,445][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 12:58:52,186][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 12:58:52,188][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 12:58:52,188][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 12:58:52,205][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 12:58:52,939][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 12:58:52,939][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 12:58:52,939][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 12:58:52,939][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 12:58:53,675][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 12:58:53,675][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 12:58:53,675][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 12:58:53,676][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 12:58:54,412][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 12:58:54,412][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 12:58:54,413][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 12:58:54,413][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 12:58:55,157][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 12:58:56,106][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 12:58:56,155][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 12:58:56,171][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 12:58:56,908][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 12:58:56,908][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 12:58:56,909][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 12:58:56,909][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 12:58:57,646][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 12:58:57,647][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 12:58:57,647][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 12:58:57,647][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 12:58:58,387][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 12:58:58,387][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 12:58:58,387][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 12:58:58,388][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 12:58:59,130][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 12:58:59,130][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 12:58:59,130][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 12:58:59,130][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 12:58:59,869][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 12:58:59,869][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 12:58:59,869][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 12:58:59,869][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 12:59:00,608][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 12:59:00,608][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 12:59:00,608][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 12:59:00,608][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 12:59:01,348][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 12:59:01,348][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 12:59:01,349][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 12:59:01,349][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 12:59:02,091][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 12:59:02,092][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 12:59:02,092][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 12:59:02,689][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 12:59:03,422][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 12:59:03,422][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 12:59:03,422][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 12:59:03,423][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 12:59:04,163][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 12:59:04,164][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 12:59:04,164][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 12:59:04,164][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 12:59:04,900][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 12:59:04,900][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 12:59:04,901][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 12:59:04,902][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 12:59:05,640][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 12:59:05,640][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 12:59:05,640][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 12:59:05,641][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 12:59:06,378][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 12:59:06,379][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 12:59:06,379][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 12:59:06,379][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 12:59:07,123][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 12:59:07,746][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 12:59:07,755][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 12:59:07,998][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 12:59:08,736][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 12:59:08,737][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 12:59:08,737][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 12:59:08,737][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 12:59:09,475][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 12:59:09,475][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 12:59:09,476][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 12:59:09,476][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 12:59:10,217][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 12:59:10,217][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 12:59:10,217][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 12:59:10,217][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 12:59:10,959][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 12:59:10,959][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 12:59:10,960][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 12:59:10,960][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 12:59:11,697][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 12:59:11,697][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 12:59:11,697][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 12:59:11,697][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 12:59:12,427][root][INFO] - rank=1; last iteration 25
[2022-01-11 12:59:12,428][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:59:12,428][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 12:59:12,428][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:12,428][root][INFO] - NLL Validation: loss = 0.376173. correct prediction ratio  5657/6400 ~  0.883906
[2022-01-11 12:59:12,428][root][INFO] - rank=0; last iteration 25
[2022-01-11 12:59:12,428][root][INFO] - rank=2; last iteration 25
[2022-01-11 12:59:12,428][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:59:12,428][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:59:12,428][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 12:59:12,428][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 12:59:12,428][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:12,428][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:12,428][root][INFO] - NLL Validation: loss = 0.376173. correct prediction ratio  5657/6400 ~  0.883906
[2022-01-11 12:59:12,428][root][INFO] - NLL Validation: loss = 0.376173. correct prediction ratio  5657/6400 ~  0.883906
[2022-01-11 12:59:12,429][root][INFO] - rank=3; last iteration 25
[2022-01-11 12:59:12,429][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:59:12,429][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 12:59:12,429][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:12,429][root][INFO] - NLL Validation: loss = 0.376173. correct prediction ratio  5657/6400 ~  0.883906
[2022-01-11 12:59:12,430][root][INFO] - rank=1; last iteration 920
[2022-01-11 12:59:12,430][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:59:12,430][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 12:59:12,431][root][INFO] - rank=2; last iteration 920
[2022-01-11 12:59:12,431][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:59:12,431][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 12:59:12,431][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:12,431][root][INFO] - Epoch finished on 1
[2022-01-11 12:59:12,431][root][INFO] - NLL validation ...
[2022-01-11 12:59:12,431][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:12,431][root][INFO] - Epoch finished on 2
[2022-01-11 12:59:12,431][root][INFO] - NLL validation ...
[2022-01-11 12:59:12,432][root][INFO] - rank=3; last iteration 920
[2022-01-11 12:59:12,432][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:59:12,432][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 12:59:12,432][root][INFO] - rank=1; Iteration start
[2022-01-11 12:59:12,432][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:59:12,432][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:59:12,432][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 12:59:12,432][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:12,433][root][INFO] - Epoch finished on 3
[2022-01-11 12:59:12,433][root][INFO] - rank=2; Iteration start
[2022-01-11 12:59:12,433][root][INFO] - NLL validation ...
[2022-01-11 12:59:12,433][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:59:12,433][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:59:12,433][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 12:59:12,434][root][INFO] - rank=3; Iteration start
[2022-01-11 12:59:12,434][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:59:12,434][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:59:12,434][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 12:59:12,440][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 12:59:12,441][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 12:59:12,444][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 12:59:16,536][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.8
[2022-01-11 12:59:16,536][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.8
[2022-01-11 12:59:16,536][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.8
[2022-01-11 12:59:16,538][root][INFO] - rank=0; last iteration 920
[2022-01-11 12:59:16,538][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 12:59:16,538][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 12:59:16,538][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:16,538][root][INFO] - Epoch finished on 0
[2022-01-11 12:59:16,538][root][INFO] - NLL validation ...
[2022-01-11 12:59:16,540][root][INFO] - rank=0; Iteration start
[2022-01-11 12:59:16,540][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:59:16,540][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 12:59:16,540][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 12:59:16,548][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 12:59:17,287][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 12:59:17,288][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 12:59:17,289][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 12:59:17,289][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 12:59:18,027][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 12:59:18,029][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 12:59:18,031][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 12:59:18,646][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 12:59:19,374][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 12:59:19,374][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 12:59:19,374][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 12:59:19,377][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 12:59:20,118][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 12:59:20,119][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 12:59:20,120][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 12:59:20,122][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 12:59:20,862][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 12:59:20,862][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 12:59:20,862][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 12:59:20,865][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 12:59:21,603][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 12:59:21,604][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 12:59:21,604][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 12:59:21,608][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 12:59:22,345][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 12:59:22,345][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 12:59:22,348][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 12:59:22,349][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 12:59:23,095][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 12:59:23,711][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 12:59:23,750][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 12:59:23,834][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 12:59:24,570][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 12:59:24,570][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 12:59:24,572][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 12:59:24,574][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 12:59:25,310][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 12:59:25,311][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 12:59:25,313][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 12:59:25,313][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 12:59:26,055][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 12:59:26,056][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 12:59:26,058][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 12:59:26,059][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 12:59:26,798][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 12:59:26,798][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 12:59:26,800][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 12:59:26,801][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 12:59:27,539][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 12:59:27,539][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 12:59:27,542][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 12:59:27,542][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 12:59:28,279][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 12:59:28,279][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 12:59:28,281][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 12:59:28,282][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 12:59:29,018][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 12:59:29,018][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 12:59:29,020][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 12:59:29,020][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 12:59:29,756][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 12:59:29,756][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 12:59:29,759][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 12:59:30,505][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 12:59:31,237][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 12:59:31,239][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 12:59:31,240][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 12:59:31,241][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 12:59:31,976][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 12:59:31,976][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 12:59:31,979][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 12:59:31,979][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 12:59:32,715][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 12:59:32,715][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 12:59:32,718][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 12:59:32,718][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 12:59:33,456][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 12:59:33,456][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 12:59:33,458][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 12:59:33,458][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 12:59:34,199][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 12:59:34,200][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 12:59:34,202][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 12:59:34,202][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 12:59:34,942][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 12:59:35,556][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 12:59:35,575][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 12:59:35,775][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 12:59:36,513][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 12:59:36,514][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 12:59:36,515][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 12:59:36,515][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 12:59:37,255][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 12:59:37,257][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 12:59:37,258][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 12:59:37,258][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 12:59:37,988][root][INFO] - rank=1; last iteration 25
[2022-01-11 12:59:37,988][root][INFO] - rank=3; last iteration 25
[2022-01-11 12:59:37,988][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:59:37,988][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:59:37,988][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 12:59:37,988][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 12:59:37,988][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:37,988][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:37,988][root][INFO] - NLL Validation: loss = 0.376173. correct prediction ratio  5657/6400 ~  0.883906
[2022-01-11 12:59:37,988][root][INFO] - NLL Validation: loss = 0.376173. correct prediction ratio  5657/6400 ~  0.883906
[2022-01-11 12:59:37,989][root][INFO] - rank=2; last iteration 25
[2022-01-11 12:59:37,989][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:59:37,989][root][INFO] - rank=0; last iteration 25
[2022-01-11 12:59:37,989][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 12:59:37,989][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 12:59:37,989][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:37,989][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 12:59:37,989][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 12:59:37,989][root][INFO] - NLL Validation: loss = 0.376173. correct prediction ratio  5657/6400 ~  0.883906
[2022-01-11 12:59:37,989][root][INFO] - NLL Validation: loss = 0.376173. correct prediction ratio  5657/6400 ~  0.883906
[2022-01-11 12:59:37,990][root][INFO] - Av Loss per epoch=0.057026
[2022-01-11 12:59:37,990][root][INFO] - epoch total correct predictions=57647
[2022-01-11 12:59:37,990][root][INFO] - Av Loss per epoch=0.057026
[2022-01-11 12:59:37,990][root][INFO] - epoch total correct predictions=57647
[2022-01-11 12:59:37,990][root][INFO] - Av Loss per epoch=0.057026
[2022-01-11 12:59:37,990][root][INFO] - epoch total correct predictions=57647
[2022-01-11 12:59:37,991][root][INFO] - ***** Epoch 9 *****
[2022-01-11 12:59:37,991][root][INFO] - ***** Epoch 9 *****
[2022-01-11 12:59:37,992][root][INFO] - ***** Epoch 9 *****
[2022-01-11 12:59:37,993][root][INFO] - rank=3; Iteration start
[2022-01-11 12:59:37,993][root][INFO] - rank=1; Iteration start
[2022-01-11 12:59:37,993][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:59:37,993][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:59:37,993][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:59:37,993][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:59:37,994][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 12:59:37,994][root][INFO] - rank=2; Iteration start
[2022-01-11 12:59:37,994][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 12:59:37,994][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:59:37,994][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:59:37,994][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 12:59:42,852][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.8
[2022-01-11 12:59:42,853][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.8
[2022-01-11 12:59:42,853][root][INFO] - Av Loss per epoch=0.057026
[2022-01-11 12:59:42,853][root][INFO] - epoch total correct predictions=57647
[2022-01-11 12:59:42,856][root][INFO] - ***** Epoch 9 *****
[2022-01-11 12:59:42,859][root][INFO] - rank=0; Iteration start
[2022-01-11 12:59:42,859][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 12:59:42,859][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 12:59:42,860][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 12:59:43,858][root][INFO] - Epoch: 9: Step: 1/920, loss=0.052696, lr=0.000008
[2022-01-11 12:59:43,859][root][INFO] - Epoch: 9: Step: 1/920, loss=0.052696, lr=0.000008
[2022-01-11 12:59:43,859][root][INFO] - Epoch: 9: Step: 1/920, loss=0.052696, lr=0.000008
[2022-01-11 12:59:43,860][root][INFO] - Epoch: 9: Step: 1/920, loss=0.052696, lr=0.000008
[2022-01-11 13:01:21,627][root][INFO] - Train batch 100
[2022-01-11 13:01:21,628][root][INFO] - Avg. loss per last 100 batches: 0.047763
[2022-01-11 13:01:21,628][root][INFO] - Train batch 100
[2022-01-11 13:01:21,628][root][INFO] - Avg. loss per last 100 batches: 0.047763
[2022-01-11 13:01:21,628][root][INFO] - Train batch 100
[2022-01-11 13:01:21,628][root][INFO] - Avg. loss per last 100 batches: 0.047763
[2022-01-11 13:01:21,629][root][INFO] - Train batch 100
[2022-01-11 13:01:21,629][root][INFO] - Avg. loss per last 100 batches: 0.047763
[2022-01-11 13:01:22,595][root][INFO] - Epoch: 9: Step: 101/920, loss=0.104558, lr=0.000008
[2022-01-11 13:01:22,595][root][INFO] - Epoch: 9: Step: 101/920, loss=0.104558, lr=0.000008
[2022-01-11 13:01:22,596][root][INFO] - Epoch: 9: Step: 101/920, loss=0.104558, lr=0.000008
[2022-01-11 13:01:22,597][root][INFO] - Epoch: 9: Step: 101/920, loss=0.104558, lr=0.000008
[2022-01-11 13:02:59,812][root][INFO] - Train batch 200
[2022-01-11 13:02:59,812][root][INFO] - Avg. loss per last 100 batches: 0.051950
[2022-01-11 13:02:59,819][root][INFO] - Train batch 200
[2022-01-11 13:02:59,819][root][INFO] - Avg. loss per last 100 batches: 0.051950
[2022-01-11 13:02:59,820][root][INFO] - Train batch 200
[2022-01-11 13:02:59,821][root][INFO] - Avg. loss per last 100 batches: 0.051950
[2022-01-11 13:02:59,821][root][INFO] - Train batch 200
[2022-01-11 13:02:59,821][root][INFO] - Avg. loss per last 100 batches: 0.051950
[2022-01-11 13:03:00,735][root][INFO] - Epoch: 9: Step: 201/920, loss=0.013457, lr=0.000008
[2022-01-11 13:03:00,735][root][INFO] - Epoch: 9: Step: 201/920, loss=0.013457, lr=0.000008
[2022-01-11 13:03:00,736][root][INFO] - Epoch: 9: Step: 201/920, loss=0.013457, lr=0.000008
[2022-01-11 13:03:00,737][root][INFO] - Epoch: 9: Step: 201/920, loss=0.013457, lr=0.000008
[2022-01-11 13:04:38,957][root][INFO] - Train batch 300
[2022-01-11 13:04:38,957][root][INFO] - Avg. loss per last 100 batches: 0.049486
[2022-01-11 13:04:38,957][root][INFO] - Train batch 300
[2022-01-11 13:04:38,957][root][INFO] - Train batch 300
[2022-01-11 13:04:38,958][root][INFO] - Avg. loss per last 100 batches: 0.049486
[2022-01-11 13:04:38,958][root][INFO] - Avg. loss per last 100 batches: 0.049486
[2022-01-11 13:04:38,958][root][INFO] - Train batch 300
[2022-01-11 13:04:38,958][root][INFO] - Avg. loss per last 100 batches: 0.049486
[2022-01-11 13:04:40,005][root][INFO] - Epoch: 9: Step: 301/920, loss=0.074668, lr=0.000008
[2022-01-11 13:04:40,008][root][INFO] - Epoch: 9: Step: 301/920, loss=0.074668, lr=0.000008
[2022-01-11 13:04:40,009][root][INFO] - Epoch: 9: Step: 301/920, loss=0.074668, lr=0.000008
[2022-01-11 13:04:40,009][root][INFO] - Epoch: 9: Step: 301/920, loss=0.074668, lr=0.000008
[2022-01-11 13:06:19,485][root][INFO] - Train batch 400
[2022-01-11 13:06:19,485][root][INFO] - Avg. loss per last 100 batches: 0.052700
[2022-01-11 13:06:19,499][root][INFO] - Train batch 400
[2022-01-11 13:06:19,499][root][INFO] - Avg. loss per last 100 batches: 0.052700
[2022-01-11 13:06:19,499][root][INFO] - Train batch 400
[2022-01-11 13:06:19,500][root][INFO] - Avg. loss per last 100 batches: 0.052700
[2022-01-11 13:06:19,500][root][INFO] - Train batch 400
[2022-01-11 13:06:19,501][root][INFO] - Avg. loss per last 100 batches: 0.052700
[2022-01-11 13:06:20,547][root][INFO] - Epoch: 9: Step: 401/920, loss=0.015088, lr=0.000008
[2022-01-11 13:06:20,548][root][INFO] - Epoch: 9: Step: 401/920, loss=0.015088, lr=0.000008
[2022-01-11 13:06:20,548][root][INFO] - Epoch: 9: Step: 401/920, loss=0.015088, lr=0.000008
[2022-01-11 13:06:20,548][root][INFO] - Epoch: 9: Step: 401/920, loss=0.015088, lr=0.000008
[2022-01-11 13:07:56,367][root][INFO] - Train batch 500
[2022-01-11 13:07:56,367][root][INFO] - Avg. loss per last 100 batches: 0.059366
[2022-01-11 13:07:56,367][root][INFO] - Train batch 500
[2022-01-11 13:07:56,367][root][INFO] - Avg. loss per last 100 batches: 0.059366
[2022-01-11 13:07:56,368][root][INFO] - Train batch 500
[2022-01-11 13:07:56,368][root][INFO] - Avg. loss per last 100 batches: 0.059366
[2022-01-11 13:07:56,369][root][INFO] - Train batch 500
[2022-01-11 13:07:56,369][root][INFO] - Avg. loss per last 100 batches: 0.059366
[2022-01-11 13:07:57,226][root][INFO] - Epoch: 9: Step: 501/920, loss=0.144650, lr=0.000008
[2022-01-11 13:07:57,226][root][INFO] - Epoch: 9: Step: 501/920, loss=0.144650, lr=0.000008
[2022-01-11 13:07:57,226][root][INFO] - Epoch: 9: Step: 501/920, loss=0.144650, lr=0.000008
[2022-01-11 13:07:57,227][root][INFO] - Epoch: 9: Step: 501/920, loss=0.144650, lr=0.000008
[2022-01-11 13:09:36,136][root][INFO] - Train batch 600
[2022-01-11 13:09:36,136][root][INFO] - Avg. loss per last 100 batches: 0.048183
[2022-01-11 13:09:36,143][root][INFO] - Train batch 600
[2022-01-11 13:09:36,144][root][INFO] - Avg. loss per last 100 batches: 0.048183
[2022-01-11 13:09:36,144][root][INFO] - Train batch 600
[2022-01-11 13:09:36,144][root][INFO] - Train batch 600
[2022-01-11 13:09:36,144][root][INFO] - Avg. loss per last 100 batches: 0.048183
[2022-01-11 13:09:36,144][root][INFO] - Avg. loss per last 100 batches: 0.048183
[2022-01-11 13:09:37,155][root][INFO] - Epoch: 9: Step: 601/920, loss=0.084096, lr=0.000008
[2022-01-11 13:09:37,155][root][INFO] - Epoch: 9: Step: 601/920, loss=0.084096, lr=0.000008
[2022-01-11 13:09:37,155][root][INFO] - Epoch: 9: Step: 601/920, loss=0.084096, lr=0.000008
[2022-01-11 13:09:37,155][root][INFO] - Epoch: 9: Step: 601/920, loss=0.084096, lr=0.000008
[2022-01-11 13:11:15,650][root][INFO] - Train batch 700
[2022-01-11 13:11:15,650][root][INFO] - Avg. loss per last 100 batches: 0.055691
[2022-01-11 13:11:15,650][root][INFO] - Train batch 700
[2022-01-11 13:11:15,650][root][INFO] - Avg. loss per last 100 batches: 0.055691
[2022-01-11 13:11:15,650][root][INFO] - Train batch 700
[2022-01-11 13:11:15,650][root][INFO] - Avg. loss per last 100 batches: 0.055691
[2022-01-11 13:11:15,650][root][INFO] - Train batch 700
[2022-01-11 13:11:15,651][root][INFO] - Avg. loss per last 100 batches: 0.055691
[2022-01-11 13:11:16,523][root][INFO] - Epoch: 9: Step: 701/920, loss=0.057930, lr=0.000008
[2022-01-11 13:11:16,523][root][INFO] - Epoch: 9: Step: 701/920, loss=0.057930, lr=0.000008
[2022-01-11 13:11:16,523][root][INFO] - Epoch: 9: Step: 701/920, loss=0.057930, lr=0.000008
[2022-01-11 13:11:16,523][root][INFO] - Epoch: 9: Step: 701/920, loss=0.057930, lr=0.000008
[2022-01-11 13:12:53,670][root][INFO] - Train batch 800
[2022-01-11 13:12:53,671][root][INFO] - Avg. loss per last 100 batches: 0.050384
[2022-01-11 13:12:53,675][root][INFO] - Train batch 800
[2022-01-11 13:12:53,676][root][INFO] - Avg. loss per last 100 batches: 0.050384
[2022-01-11 13:12:53,677][root][INFO] - Train batch 800
[2022-01-11 13:12:53,677][root][INFO] - Avg. loss per last 100 batches: 0.050384
[2022-01-11 13:12:53,678][root][INFO] - Train batch 800
[2022-01-11 13:12:53,678][root][INFO] - Avg. loss per last 100 batches: 0.050384
[2022-01-11 13:12:54,517][root][INFO] - Epoch: 9: Step: 801/920, loss=0.072341, lr=0.000008
[2022-01-11 13:12:54,533][root][INFO] - Epoch: 9: Step: 801/920, loss=0.072341, lr=0.000008
[2022-01-11 13:12:54,533][root][INFO] - Epoch: 9: Step: 801/920, loss=0.072341, lr=0.000008
[2022-01-11 13:12:54,533][root][INFO] - Epoch: 9: Step: 801/920, loss=0.072341, lr=0.000008
[2022-01-11 13:14:30,922][root][INFO] - Train batch 900
[2022-01-11 13:14:30,923][root][INFO] - Avg. loss per last 100 batches: 0.048547
[2022-01-11 13:14:30,926][root][INFO] - Train batch 900
[2022-01-11 13:14:30,926][root][INFO] - Avg. loss per last 100 batches: 0.048547
[2022-01-11 13:14:30,934][root][INFO] - Train batch 900
[2022-01-11 13:14:30,934][root][INFO] - Avg. loss per last 100 batches: 0.048547
[2022-01-11 13:14:30,934][root][INFO] - Train batch 900
[2022-01-11 13:14:30,934][root][INFO] - Avg. loss per last 100 batches: 0.048547
[2022-01-11 13:14:31,983][root][INFO] - Epoch: 9: Step: 901/920, loss=0.081824, lr=0.000008
[2022-01-11 13:14:31,984][root][INFO] - Epoch: 9: Step: 901/920, loss=0.081824, lr=0.000008
[2022-01-11 13:14:31,985][root][INFO] - Epoch: 9: Step: 901/920, loss=0.081824, lr=0.000008
[2022-01-11 13:14:31,985][root][INFO] - Epoch: 9: Step: 901/920, loss=0.081824, lr=0.000008
[2022-01-11 13:14:50,630][root][INFO] - rank=1, Validation: Epoch: 9 Step: 920/920
[2022-01-11 13:14:50,630][root][INFO] - NLL validation ...
[2022-01-11 13:14:50,632][root][INFO] - rank=3, Validation: Epoch: 9 Step: 920/920
[2022-01-11 13:14:50,632][root][INFO] - rank=1; Iteration start
[2022-01-11 13:14:50,632][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:14:50,632][root][INFO] - NLL validation ...
[2022-01-11 13:14:50,632][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:14:50,632][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 13:14:50,632][root][INFO] - rank=0, Validation: Epoch: 9 Step: 920/920
[2022-01-11 13:14:50,633][root][INFO] - NLL validation ...
[2022-01-11 13:14:50,633][root][INFO] - rank=3; Iteration start
[2022-01-11 13:14:50,633][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:14:50,633][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:14:50,633][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 13:14:50,634][root][INFO] - rank=0; Iteration start
[2022-01-11 13:14:50,634][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:14:50,634][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:14:50,634][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 13:14:50,634][root][INFO] - rank=2, Validation: Epoch: 9 Step: 920/920
[2022-01-11 13:14:50,634][root][INFO] - NLL validation ...
[2022-01-11 13:14:50,635][root][INFO] - rank=2; Iteration start
[2022-01-11 13:14:50,636][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:14:50,636][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:14:50,636][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 13:14:50,642][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 13:14:50,643][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 13:14:50,644][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 13:14:50,646][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 13:14:51,389][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 13:14:52,369][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 13:14:52,376][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 13:14:52,378][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 13:14:53,115][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 13:14:53,116][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 13:14:53,116][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 13:14:53,116][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 13:14:53,852][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 13:14:53,852][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 13:14:53,853][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 13:14:53,853][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 13:14:54,588][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 13:14:54,588][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 13:14:54,588][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 13:14:54,588][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 13:14:55,328][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 13:14:55,329][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 13:14:55,330][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 13:14:55,330][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 13:14:56,067][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 13:14:56,067][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 13:14:56,068][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 13:14:56,880][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 13:14:57,611][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 13:14:57,611][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 13:14:57,613][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 13:14:57,613][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 13:14:58,352][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 13:14:58,354][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 13:14:58,354][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 13:14:58,354][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 13:14:59,090][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 13:14:59,090][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 13:14:59,091][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 13:14:59,092][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 13:14:59,830][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 13:14:59,830][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 13:14:59,830][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 13:14:59,830][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 13:15:00,571][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 13:15:00,571][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 13:15:00,571][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 13:15:00,571][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 13:15:01,312][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 13:15:01,314][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 13:15:01,314][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 13:15:01,315][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 13:15:02,053][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 13:15:02,053][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 13:15:02,054][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 13:15:02,054][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 13:15:02,792][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 13:15:03,413][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 13:15:03,474][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 13:15:03,513][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 13:15:04,249][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 13:15:04,250][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 13:15:04,250][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 13:15:04,250][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 13:15:04,985][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 13:15:04,986][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 13:15:04,986][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 13:15:04,986][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 13:15:05,724][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 13:15:05,724][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 13:15:05,724][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 13:15:05,724][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 13:15:06,459][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 13:15:06,459][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 13:15:06,460][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 13:15:06,460][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 13:15:07,200][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 13:15:07,201][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 13:15:07,201][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 13:15:07,201][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 13:15:07,941][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 13:15:07,942][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 13:15:07,942][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 13:15:08,544][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 13:15:09,275][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 13:15:09,275][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 13:15:09,275][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 13:15:09,275][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 13:15:10,015][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 13:15:10,016][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 13:15:10,016][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 13:15:10,016][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 13:15:10,754][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 13:15:10,755][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 13:15:10,755][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 13:15:10,756][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 13:15:11,491][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 13:15:11,491][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 13:15:11,491][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 13:15:11,491][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 13:15:12,221][root][INFO] - rank=3; last iteration 25
[2022-01-11 13:15:12,221][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:15:12,221][root][INFO] - rank=1; last iteration 25
[2022-01-11 13:15:12,221][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 13:15:12,221][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:15:12,221][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:12,221][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 13:15:12,221][root][INFO] - rank=0; last iteration 25
[2022-01-11 13:15:12,221][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:12,221][root][INFO] - NLL Validation: loss = 0.396057. correct prediction ratio  5684/6400 ~  0.888125
[2022-01-11 13:15:12,221][root][INFO] - rank=2; last iteration 25
[2022-01-11 13:15:12,221][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:15:12,221][root][INFO] - NLL Validation: loss = 0.396057. correct prediction ratio  5684/6400 ~  0.888125
[2022-01-11 13:15:12,221][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 13:15:12,221][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:15:12,221][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 13:15:12,221][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:12,221][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:12,221][root][INFO] - NLL Validation: loss = 0.396057. correct prediction ratio  5684/6400 ~  0.888125
[2022-01-11 13:15:12,221][root][INFO] - NLL Validation: loss = 0.396057. correct prediction ratio  5684/6400 ~  0.888125
[2022-01-11 13:15:12,223][root][INFO] - rank=3; last iteration 920
[2022-01-11 13:15:12,223][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:15:12,223][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 13:15:12,223][root][INFO] - rank=1; last iteration 920
[2022-01-11 13:15:12,224][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:15:12,224][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 13:15:12,224][root][INFO] - rank=2; last iteration 920
[2022-01-11 13:15:12,224][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:15:12,224][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 13:15:12,224][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:12,224][root][INFO] - Epoch finished on 3
[2022-01-11 13:15:12,224][root][INFO] - NLL validation ...
[2022-01-11 13:15:12,224][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:12,224][root][INFO] - Epoch finished on 1
[2022-01-11 13:15:12,224][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:12,224][root][INFO] - NLL validation ...
[2022-01-11 13:15:12,224][root][INFO] - Epoch finished on 2
[2022-01-11 13:15:12,224][root][INFO] - NLL validation ...
[2022-01-11 13:15:12,225][root][INFO] - rank=3; Iteration start
[2022-01-11 13:15:12,225][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:15:12,225][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:15:12,225][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 13:15:12,225][root][INFO] - rank=1; Iteration start
[2022-01-11 13:15:12,226][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:15:12,226][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:15:12,226][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 13:15:12,226][root][INFO] - rank=2; Iteration start
[2022-01-11 13:15:12,226][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:15:12,226][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:15:12,226][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 13:15:12,232][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 13:15:12,234][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 13:15:12,235][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 13:15:16,127][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.9
[2022-01-11 13:15:16,128][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.9
[2022-01-11 13:15:16,129][root][INFO] - rank=0; last iteration 920
[2022-01-11 13:15:16,129][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:15:16,129][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 13:15:16,130][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:16,130][root][INFO] - Epoch finished on 0
[2022-01-11 13:15:16,130][root][INFO] - NLL validation ...
[2022-01-11 13:15:16,131][root][INFO] - rank=0; Iteration start
[2022-01-11 13:15:16,131][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:15:16,132][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:15:16,132][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 13:15:16,140][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 13:15:16,889][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 13:15:16,889][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 13:15:16,891][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 13:15:16,891][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 13:15:17,627][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 13:15:17,628][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 13:15:17,628][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 13:15:17,629][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 13:15:18,363][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 13:15:18,365][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 13:15:18,365][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 13:15:18,365][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 13:15:19,104][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 13:15:19,731][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 13:15:19,937][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 13:15:19,967][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 13:15:20,704][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 13:15:20,704][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 13:15:20,705][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 13:15:20,705][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 13:15:21,439][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 13:15:21,441][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 13:15:21,441][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 13:15:21,442][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 13:15:22,176][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 13:15:22,177][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 13:15:22,177][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 13:15:22,178][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 13:15:22,917][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 13:15:22,917][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 13:15:22,918][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 13:15:23,719][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 13:15:24,451][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 13:15:24,452][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 13:15:24,452][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 13:15:24,453][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 13:15:25,188][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 13:15:25,189][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 13:15:25,189][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 13:15:25,190][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 13:15:25,926][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 13:15:25,926][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 13:15:25,927][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 13:15:25,927][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 13:15:26,664][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 13:15:26,664][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 13:15:26,665][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 13:15:26,666][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 13:15:27,401][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 13:15:27,401][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 13:15:27,402][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 13:15:27,402][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 13:15:28,135][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 13:15:28,135][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 13:15:28,136][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 13:15:28,137][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 13:15:28,874][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 13:15:28,874][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 13:15:28,874][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 13:15:28,876][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 13:15:29,608][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 13:15:29,609][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 13:15:29,610][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 13:15:29,610][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 13:15:30,345][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 13:15:30,346][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 13:15:30,346][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 13:15:30,347][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 13:15:31,081][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 13:15:31,673][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 13:15:31,677][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 13:15:31,958][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 13:15:32,693][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 13:15:32,694][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 13:15:32,694][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 13:15:32,695][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 13:15:33,430][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 13:15:33,430][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 13:15:33,431][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 13:15:33,431][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 13:15:34,166][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 13:15:34,166][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 13:15:34,167][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 13:15:34,168][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 13:15:34,906][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 13:15:34,906][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 13:15:34,907][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 13:15:35,632][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 13:15:36,361][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 13:15:36,361][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 13:15:36,362][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 13:15:36,363][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 13:15:37,097][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 13:15:37,097][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 13:15:37,097][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 13:15:37,098][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 13:15:37,826][root][INFO] - rank=3; last iteration 25
[2022-01-11 13:15:37,826][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:15:37,826][root][INFO] - rank=1; last iteration 25
[2022-01-11 13:15:37,826][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 13:15:37,826][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:15:37,826][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:37,826][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 13:15:37,826][root][INFO] - rank=0; last iteration 25
[2022-01-11 13:15:37,826][root][INFO] - rank=2; last iteration 25
[2022-01-11 13:15:37,826][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:37,826][root][INFO] - NLL Validation: loss = 0.396057. correct prediction ratio  5684/6400 ~  0.888125
[2022-01-11 13:15:37,827][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:15:37,827][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:15:37,827][root][INFO] - NLL Validation: loss = 0.396057. correct prediction ratio  5684/6400 ~  0.888125
[2022-01-11 13:15:37,827][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 13:15:37,827][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 13:15:37,827][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:37,827][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:15:37,827][root][INFO] - NLL Validation: loss = 0.396057. correct prediction ratio  5684/6400 ~  0.888125
[2022-01-11 13:15:37,827][root][INFO] - NLL Validation: loss = 0.396057. correct prediction ratio  5684/6400 ~  0.888125
[2022-01-11 13:15:37,828][root][INFO] - Av Loss per epoch=0.051392
[2022-01-11 13:15:37,828][root][INFO] - epoch total correct predictions=57733
[2022-01-11 13:15:37,828][root][INFO] - Av Loss per epoch=0.051392
[2022-01-11 13:15:37,828][root][INFO] - epoch total correct predictions=57733
[2022-01-11 13:15:37,828][root][INFO] - Av Loss per epoch=0.051392
[2022-01-11 13:15:37,828][root][INFO] - epoch total correct predictions=57733
[2022-01-11 13:15:37,829][root][INFO] - ***** Epoch 10 *****
[2022-01-11 13:15:37,830][root][INFO] - ***** Epoch 10 *****
[2022-01-11 13:15:37,830][root][INFO] - ***** Epoch 10 *****
[2022-01-11 13:15:37,831][root][INFO] - rank=3; Iteration start
[2022-01-11 13:15:37,831][root][INFO] - rank=1; Iteration start
[2022-01-11 13:15:37,831][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:15:37,831][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:15:37,831][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:15:37,831][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:15:37,831][root][INFO] - rank=2; Iteration start
[2022-01-11 13:15:37,831][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:15:37,831][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:15:37,832][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 13:15:37,832][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 13:15:37,832][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 13:15:42,674][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.9
[2022-01-11 13:15:42,675][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.9
[2022-01-11 13:15:42,675][root][INFO] - Av Loss per epoch=0.051392
[2022-01-11 13:15:42,675][root][INFO] - epoch total correct predictions=57733
[2022-01-11 13:15:42,676][root][INFO] - ***** Epoch 10 *****
[2022-01-11 13:15:42,678][root][INFO] - rank=0; Iteration start
[2022-01-11 13:15:42,678][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:15:42,678][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:15:42,678][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 13:15:43,687][root][INFO] - Epoch: 10: Step: 1/920, loss=0.105579, lr=0.000008
[2022-01-11 13:15:43,688][root][INFO] - Epoch: 10: Step: 1/920, loss=0.105579, lr=0.000008
[2022-01-11 13:15:43,690][root][INFO] - Epoch: 10: Step: 1/920, loss=0.105579, lr=0.000008
[2022-01-11 13:15:43,691][root][INFO] - Epoch: 10: Step: 1/920, loss=0.105579, lr=0.000008
[2022-01-11 13:17:21,709][root][INFO] - Train batch 100
[2022-01-11 13:17:21,709][root][INFO] - Avg. loss per last 100 batches: 0.044686
[2022-01-11 13:17:21,709][root][INFO] - Train batch 100
[2022-01-11 13:17:21,710][root][INFO] - Avg. loss per last 100 batches: 0.044686
[2022-01-11 13:17:21,710][root][INFO] - Train batch 100
[2022-01-11 13:17:21,710][root][INFO] - Avg. loss per last 100 batches: 0.044686
[2022-01-11 13:17:21,720][root][INFO] - Train batch 100
[2022-01-11 13:17:21,720][root][INFO] - Avg. loss per last 100 batches: 0.044686
[2022-01-11 13:17:22,776][root][INFO] - Epoch: 10: Step: 101/920, loss=0.087868, lr=0.000008
[2022-01-11 13:17:22,776][root][INFO] - Epoch: 10: Step: 101/920, loss=0.087868, lr=0.000008
[2022-01-11 13:17:22,777][root][INFO] - Epoch: 10: Step: 101/920, loss=0.087868, lr=0.000008
[2022-01-11 13:17:22,778][root][INFO] - Epoch: 10: Step: 101/920, loss=0.087868, lr=0.000008
[2022-01-11 13:18:59,837][root][INFO] - Train batch 200
[2022-01-11 13:18:59,838][root][INFO] - Avg. loss per last 100 batches: 0.043404
[2022-01-11 13:18:59,838][root][INFO] - Train batch 200
[2022-01-11 13:18:59,838][root][INFO] - Train batch 200
[2022-01-11 13:18:59,838][root][INFO] - Avg. loss per last 100 batches: 0.043404
[2022-01-11 13:18:59,838][root][INFO] - Train batch 200
[2022-01-11 13:18:59,838][root][INFO] - Avg. loss per last 100 batches: 0.043404
[2022-01-11 13:18:59,838][root][INFO] - Avg. loss per last 100 batches: 0.043404
[2022-01-11 13:19:00,862][root][INFO] - Epoch: 10: Step: 201/920, loss=0.089882, lr=0.000008
[2022-01-11 13:19:00,862][root][INFO] - Epoch: 10: Step: 201/920, loss=0.089882, lr=0.000008
[2022-01-11 13:19:00,865][root][INFO] - Epoch: 10: Step: 201/920, loss=0.089882, lr=0.000008
[2022-01-11 13:19:00,865][root][INFO] - Epoch: 10: Step: 201/920, loss=0.089882, lr=0.000008
[2022-01-11 13:20:38,937][root][INFO] - Train batch 300
[2022-01-11 13:20:38,937][root][INFO] - Avg. loss per last 100 batches: 0.051948
[2022-01-11 13:20:38,937][root][INFO] - Train batch 300
[2022-01-11 13:20:38,937][root][INFO] - Avg. loss per last 100 batches: 0.051948
[2022-01-11 13:20:38,937][root][INFO] - Train batch 300
[2022-01-11 13:20:38,937][root][INFO] - Avg. loss per last 100 batches: 0.051948
[2022-01-11 13:20:38,950][root][INFO] - Train batch 300
[2022-01-11 13:20:38,950][root][INFO] - Avg. loss per last 100 batches: 0.051948
[2022-01-11 13:20:39,994][root][INFO] - Epoch: 10: Step: 301/920, loss=0.045835, lr=0.000008
[2022-01-11 13:20:39,995][root][INFO] - Epoch: 10: Step: 301/920, loss=0.045835, lr=0.000008
[2022-01-11 13:20:39,996][root][INFO] - Epoch: 10: Step: 301/920, loss=0.045835, lr=0.000008
[2022-01-11 13:20:40,008][root][INFO] - Epoch: 10: Step: 301/920, loss=0.045835, lr=0.000008
[2022-01-11 13:22:19,416][root][INFO] - Train batch 400
[2022-01-11 13:22:19,416][root][INFO] - Avg. loss per last 100 batches: 0.050980
[2022-01-11 13:22:19,417][root][INFO] - Train batch 400
[2022-01-11 13:22:19,417][root][INFO] - Avg. loss per last 100 batches: 0.050980
[2022-01-11 13:22:19,417][root][INFO] - Train batch 400
[2022-01-11 13:22:19,417][root][INFO] - Avg. loss per last 100 batches: 0.050980
[2022-01-11 13:22:19,417][root][INFO] - Train batch 400
[2022-01-11 13:22:19,417][root][INFO] - Avg. loss per last 100 batches: 0.050980
[2022-01-11 13:22:20,303][root][INFO] - Epoch: 10: Step: 401/920, loss=0.050051, lr=0.000008
[2022-01-11 13:22:20,312][root][INFO] - Epoch: 10: Step: 401/920, loss=0.050051, lr=0.000008
[2022-01-11 13:22:20,312][root][INFO] - Epoch: 10: Step: 401/920, loss=0.050051, lr=0.000008
[2022-01-11 13:22:20,312][root][INFO] - Epoch: 10: Step: 401/920, loss=0.050051, lr=0.000008
[2022-01-11 13:23:56,426][root][INFO] - Train batch 500
[2022-01-11 13:23:56,427][root][INFO] - Avg. loss per last 100 batches: 0.043555
[2022-01-11 13:23:56,429][root][INFO] - Train batch 500
[2022-01-11 13:23:56,429][root][INFO] - Avg. loss per last 100 batches: 0.043555
[2022-01-11 13:23:56,429][root][INFO] - Train batch 500
[2022-01-11 13:23:56,429][root][INFO] - Avg. loss per last 100 batches: 0.043555
[2022-01-11 13:23:56,433][root][INFO] - Train batch 500
[2022-01-11 13:23:56,433][root][INFO] - Avg. loss per last 100 batches: 0.043555
[2022-01-11 13:23:57,464][root][INFO] - Epoch: 10: Step: 501/920, loss=0.046960, lr=0.000008
[2022-01-11 13:23:57,475][root][INFO] - Epoch: 10: Step: 501/920, loss=0.046960, lr=0.000008
[2022-01-11 13:23:57,476][root][INFO] - Epoch: 10: Step: 501/920, loss=0.046960, lr=0.000008
[2022-01-11 13:23:57,476][root][INFO] - Epoch: 10: Step: 501/920, loss=0.046960, lr=0.000008
[2022-01-11 13:25:37,034][root][INFO] - Train batch 600
[2022-01-11 13:25:37,034][root][INFO] - Avg. loss per last 100 batches: 0.049672
[2022-01-11 13:25:37,046][root][INFO] - Train batch 600
[2022-01-11 13:25:37,046][root][INFO] - Avg. loss per last 100 batches: 0.049672
[2022-01-11 13:25:37,047][root][INFO] - Train batch 600
[2022-01-11 13:25:37,047][root][INFO] - Avg. loss per last 100 batches: 0.049672
[2022-01-11 13:25:37,061][root][INFO] - Train batch 600
[2022-01-11 13:25:37,061][root][INFO] - Avg. loss per last 100 batches: 0.049672
[2022-01-11 13:25:37,940][root][INFO] - Epoch: 10: Step: 601/920, loss=0.034190, lr=0.000008
[2022-01-11 13:25:37,942][root][INFO] - Epoch: 10: Step: 601/920, loss=0.034190, lr=0.000008
[2022-01-11 13:25:37,943][root][INFO] - Epoch: 10: Step: 601/920, loss=0.034190, lr=0.000008
[2022-01-11 13:25:37,954][root][INFO] - Epoch: 10: Step: 601/920, loss=0.034190, lr=0.000008
[2022-01-11 13:27:15,965][root][INFO] - Train batch 700
[2022-01-11 13:27:15,965][root][INFO] - Avg. loss per last 100 batches: 0.051609
[2022-01-11 13:27:15,968][root][INFO] - Train batch 700
[2022-01-11 13:27:15,968][root][INFO] - Avg. loss per last 100 batches: 0.051609
[2022-01-11 13:27:15,968][root][INFO] - Train batch 700
[2022-01-11 13:27:15,968][root][INFO] - Avg. loss per last 100 batches: 0.051609
[2022-01-11 13:27:15,969][root][INFO] - Train batch 700
[2022-01-11 13:27:15,969][root][INFO] - Avg. loss per last 100 batches: 0.051609
[2022-01-11 13:27:16,826][root][INFO] - Epoch: 10: Step: 701/920, loss=0.090826, lr=0.000008
[2022-01-11 13:27:16,826][root][INFO] - Epoch: 10: Step: 701/920, loss=0.090826, lr=0.000008
[2022-01-11 13:27:16,827][root][INFO] - Epoch: 10: Step: 701/920, loss=0.090826, lr=0.000008
[2022-01-11 13:27:16,827][root][INFO] - Epoch: 10: Step: 701/920, loss=0.090826, lr=0.000008
[2022-01-11 13:28:53,495][root][INFO] - Train batch 800
[2022-01-11 13:28:53,495][root][INFO] - Avg. loss per last 100 batches: 0.050276
[2022-01-11 13:28:53,495][root][INFO] - Train batch 800
[2022-01-11 13:28:53,496][root][INFO] - Avg. loss per last 100 batches: 0.050276
[2022-01-11 13:28:53,498][root][INFO] - Train batch 800
[2022-01-11 13:28:53,498][root][INFO] - Avg. loss per last 100 batches: 0.050276
[2022-01-11 13:28:53,498][root][INFO] - Train batch 800
[2022-01-11 13:28:53,498][root][INFO] - Avg. loss per last 100 batches: 0.050276
[2022-01-11 13:28:54,482][root][INFO] - Epoch: 10: Step: 801/920, loss=0.106902, lr=0.000008
[2022-01-11 13:28:54,486][root][INFO] - Epoch: 10: Step: 801/920, loss=0.106902, lr=0.000008
[2022-01-11 13:28:54,487][root][INFO] - Epoch: 10: Step: 801/920, loss=0.106902, lr=0.000008
[2022-01-11 13:28:54,488][root][INFO] - Epoch: 10: Step: 801/920, loss=0.106902, lr=0.000008
[2022-01-11 13:30:33,829][root][INFO] - Train batch 900
[2022-01-11 13:30:33,829][root][INFO] - Train batch 900
[2022-01-11 13:30:33,829][root][INFO] - Avg. loss per last 100 batches: 0.053918
[2022-01-11 13:30:33,829][root][INFO] - Avg. loss per last 100 batches: 0.053918
[2022-01-11 13:30:33,829][root][INFO] - Train batch 900
[2022-01-11 13:30:33,830][root][INFO] - Avg. loss per last 100 batches: 0.053918
[2022-01-11 13:30:33,830][root][INFO] - Train batch 900
[2022-01-11 13:30:33,830][root][INFO] - Avg. loss per last 100 batches: 0.053918
[2022-01-11 13:30:34,793][root][INFO] - Epoch: 10: Step: 901/920, loss=0.010450, lr=0.000008
[2022-01-11 13:30:34,797][root][INFO] - Epoch: 10: Step: 901/920, loss=0.010450, lr=0.000008
[2022-01-11 13:30:34,797][root][INFO] - Epoch: 10: Step: 901/920, loss=0.010450, lr=0.000008
[2022-01-11 13:30:34,797][root][INFO] - Epoch: 10: Step: 901/920, loss=0.010450, lr=0.000008
[2022-01-11 13:30:54,314][root][INFO] - rank=2, Validation: Epoch: 10 Step: 920/920
[2022-01-11 13:30:54,314][root][INFO] - NLL validation ...
[2022-01-11 13:30:54,315][root][INFO] - rank=2; Iteration start
[2022-01-11 13:30:54,315][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:30:54,315][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:30:54,315][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 13:30:54,326][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 13:30:54,326][root][INFO] - rank=0, Validation: Epoch: 10 Step: 920/920
[2022-01-11 13:30:54,326][root][INFO] - NLL validation ...
[2022-01-11 13:30:54,328][root][INFO] - rank=0; Iteration start
[2022-01-11 13:30:54,328][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:30:54,328][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:30:54,328][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 13:30:54,329][root][INFO] - rank=1, Validation: Epoch: 10 Step: 920/920
[2022-01-11 13:30:54,330][root][INFO] - NLL validation ...
[2022-01-11 13:30:54,330][root][INFO] - rank=3, Validation: Epoch: 10 Step: 920/920
[2022-01-11 13:30:54,330][root][INFO] - NLL validation ...
[2022-01-11 13:30:54,331][root][INFO] - rank=1; Iteration start
[2022-01-11 13:30:54,331][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:30:54,331][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:30:54,331][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 13:30:54,331][root][INFO] - rank=3; Iteration start
[2022-01-11 13:30:54,332][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:30:54,332][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:30:54,332][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 13:30:54,338][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 13:30:54,341][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 13:30:54,342][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 13:30:55,077][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 13:30:55,078][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 13:30:55,078][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 13:30:55,078][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 13:30:55,813][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 13:30:55,813][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 13:30:55,813][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 13:30:55,815][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 13:30:56,555][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 13:30:56,555][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 13:30:56,557][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 13:30:56,557][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 13:30:57,292][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 13:30:57,293][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 13:30:57,294][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 13:30:57,294][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 13:30:58,031][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 13:30:58,032][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 13:30:58,032][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 13:30:58,032][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 13:30:58,769][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 13:30:58,769][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 13:30:58,769][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 13:30:58,769][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 13:30:59,508][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 13:30:59,509][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 13:30:59,509][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 13:30:59,509][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 13:31:00,249][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 13:31:00,250][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 13:31:00,250][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 13:31:00,250][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 13:31:00,985][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 13:31:00,986][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 13:31:00,986][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 13:31:00,986][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 13:31:01,726][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 13:31:02,346][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 13:31:02,674][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 13:31:02,692][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 13:31:03,428][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 13:31:03,428][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 13:31:03,429][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 13:31:03,429][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 13:31:04,165][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 13:31:04,165][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 13:31:04,165][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 13:31:04,166][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 13:31:04,904][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 13:31:04,904][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 13:31:04,906][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 13:31:05,485][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 13:31:06,216][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 13:31:06,216][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 13:31:06,216][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 13:31:06,217][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 13:31:06,951][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 13:31:06,951][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 13:31:06,952][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 13:31:06,952][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 13:31:07,687][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 13:31:07,688][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 13:31:07,688][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 13:31:07,690][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 13:31:08,427][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 13:31:08,428][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 13:31:08,428][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 13:31:08,428][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 13:31:09,163][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 13:31:09,163][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 13:31:09,163][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 13:31:09,163][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 13:31:09,900][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 13:31:09,900][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 13:31:09,900][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 13:31:09,900][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 13:31:10,637][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 13:31:10,637][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 13:31:10,638][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 13:31:10,638][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 13:31:11,376][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 13:31:11,378][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 13:31:11,378][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 13:31:11,378][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 13:31:12,116][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 13:31:12,116][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 13:31:12,117][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 13:31:12,118][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 13:31:12,853][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 13:31:13,440][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 13:31:13,470][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 13:31:13,704][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 13:31:14,444][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 13:31:14,445][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 13:31:14,445][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 13:31:14,445][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 13:31:15,173][root][INFO] - rank=1; last iteration 25
[2022-01-11 13:31:15,173][root][INFO] - rank=3; last iteration 25
[2022-01-11 13:31:15,173][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:31:15,173][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:31:15,173][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 13:31:15,173][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 13:31:15,173][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:15,173][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:15,173][root][INFO] - NLL Validation: loss = 0.388951. correct prediction ratio  5674/6400 ~  0.886563
[2022-01-11 13:31:15,173][root][INFO] - NLL Validation: loss = 0.388951. correct prediction ratio  5674/6400 ~  0.886563
[2022-01-11 13:31:15,173][root][INFO] - rank=0; last iteration 25
[2022-01-11 13:31:15,173][root][INFO] - rank=2; last iteration 25
[2022-01-11 13:31:15,173][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:31:15,173][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:31:15,173][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 13:31:15,173][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 13:31:15,173][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:15,173][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:15,174][root][INFO] - NLL Validation: loss = 0.388951. correct prediction ratio  5674/6400 ~  0.886563
[2022-01-11 13:31:15,174][root][INFO] - NLL Validation: loss = 0.388951. correct prediction ratio  5674/6400 ~  0.886563
[2022-01-11 13:31:15,176][root][INFO] - rank=3; last iteration 920
[2022-01-11 13:31:15,176][root][INFO] - rank=1; last iteration 920
[2022-01-11 13:31:15,176][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:31:15,176][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:31:15,176][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 13:31:15,176][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 13:31:15,176][root][INFO] - rank=2; last iteration 920
[2022-01-11 13:31:15,176][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:31:15,176][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 13:31:15,176][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:15,176][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:15,176][root][INFO] - Epoch finished on 1
[2022-01-11 13:31:15,176][root][INFO] - Epoch finished on 3
[2022-01-11 13:31:15,176][root][INFO] - NLL validation ...
[2022-01-11 13:31:15,177][root][INFO] - NLL validation ...
[2022-01-11 13:31:15,177][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:15,177][root][INFO] - Epoch finished on 2
[2022-01-11 13:31:15,177][root][INFO] - NLL validation ...
[2022-01-11 13:31:15,178][root][INFO] - rank=1; Iteration start
[2022-01-11 13:31:15,178][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:31:15,178][root][INFO] - rank=3; Iteration start
[2022-01-11 13:31:15,178][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:31:15,178][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:31:15,178][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 13:31:15,178][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:31:15,178][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 13:31:15,178][root][INFO] - rank=2; Iteration start
[2022-01-11 13:31:15,178][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:31:15,178][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:31:15,178][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 13:31:15,186][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 13:31:15,186][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 13:31:15,187][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 13:31:19,114][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.10
[2022-01-11 13:31:19,114][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.10
[2022-01-11 13:31:19,116][root][INFO] - rank=0; last iteration 920
[2022-01-11 13:31:19,116][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:31:19,116][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 13:31:19,116][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:19,116][root][INFO] - Epoch finished on 0
[2022-01-11 13:31:19,116][root][INFO] - NLL validation ...
[2022-01-11 13:31:19,118][root][INFO] - rank=0; Iteration start
[2022-01-11 13:31:19,118][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:31:19,118][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:31:19,118][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 13:31:19,125][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 13:31:19,870][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 13:31:19,870][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 13:31:19,870][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 13:31:19,872][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 13:31:20,604][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 13:31:20,604][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 13:31:20,605][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 13:31:21,212][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 13:31:21,939][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 13:31:21,940][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 13:31:21,941][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 13:31:21,941][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 13:31:22,676][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 13:31:22,676][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 13:31:22,676][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 13:31:22,677][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 13:31:23,413][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 13:31:23,413][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 13:31:23,413][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 13:31:23,414][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 13:31:24,152][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 13:31:24,154][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 13:31:24,154][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 13:31:24,155][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 13:31:24,889][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 13:31:24,889][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 13:31:24,889][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 13:31:24,890][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 13:31:25,625][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 13:31:25,625][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 13:31:25,625][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 13:31:25,627][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 13:31:26,360][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 13:31:26,361][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 13:31:26,361][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 13:31:26,361][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 13:31:27,102][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 13:31:27,103][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 13:31:27,104][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 13:31:27,106][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 13:31:27,840][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 13:31:27,840][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 13:31:27,840][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 13:31:27,841][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 13:31:28,578][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 13:31:29,197][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 13:31:29,207][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 13:31:29,278][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 13:31:30,006][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 13:31:30,006][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 13:31:30,006][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 13:31:30,008][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 13:31:30,743][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 13:31:30,743][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 13:31:30,743][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 13:31:30,745][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 13:31:31,478][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 13:31:31,479][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 13:31:31,479][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 13:31:31,481][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 13:31:32,213][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 13:31:32,214][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 13:31:32,215][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 13:31:32,879][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 13:31:33,612][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 13:31:33,612][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 13:31:33,612][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 13:31:33,613][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 13:31:34,349][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 13:31:34,350][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 13:31:34,350][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 13:31:34,352][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 13:31:35,087][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 13:31:35,087][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 13:31:35,088][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 13:31:35,091][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 13:31:35,828][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 13:31:35,829][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 13:31:35,829][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 13:31:35,830][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 13:31:36,565][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 13:31:36,565][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 13:31:36,565][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 13:31:36,566][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 13:31:37,307][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 13:31:37,307][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 13:31:37,309][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 13:31:37,310][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 13:31:38,047][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 13:31:38,047][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 13:31:38,048][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 13:31:38,048][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 13:31:38,782][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 13:31:38,782][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 13:31:38,784][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 13:31:38,784][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 13:31:39,510][root][INFO] - rank=0; last iteration 25
[2022-01-11 13:31:39,510][root][INFO] - rank=2; last iteration 25
[2022-01-11 13:31:39,510][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:31:39,510][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 13:31:39,510][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:31:39,510][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 13:31:39,510][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:39,510][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:39,510][root][INFO] - NLL Validation: loss = 0.388951. correct prediction ratio  5674/6400 ~  0.886563
[2022-01-11 13:31:39,510][root][INFO] - NLL Validation: loss = 0.388951. correct prediction ratio  5674/6400 ~  0.886563
[2022-01-11 13:31:39,510][root][INFO] - rank=1; last iteration 25
[2022-01-11 13:31:39,510][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:31:39,510][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 13:31:39,510][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:39,511][root][INFO] - NLL Validation: loss = 0.388951. correct prediction ratio  5674/6400 ~  0.886563
[2022-01-11 13:31:39,511][root][INFO] - Av Loss per epoch=0.048696
[2022-01-11 13:31:39,511][root][INFO] - epoch total correct predictions=57811
[2022-01-11 13:31:39,512][root][INFO] - Av Loss per epoch=0.048696
[2022-01-11 13:31:39,512][root][INFO] - epoch total correct predictions=57811
[2022-01-11 13:31:39,513][root][INFO] - ***** Epoch 11 *****
[2022-01-11 13:31:39,513][root][INFO] - ***** Epoch 11 *****
[2022-01-11 13:31:39,514][root][INFO] - rank=3; last iteration 25
[2022-01-11 13:31:39,514][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:31:39,514][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 13:31:39,514][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:31:39,514][root][INFO] - NLL Validation: loss = 0.388951. correct prediction ratio  5674/6400 ~  0.886563
[2022-01-11 13:31:39,515][root][INFO] - rank=2; Iteration start
[2022-01-11 13:31:39,515][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:31:39,515][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:31:39,515][root][INFO] - rank=1; Iteration start
[2022-01-11 13:31:39,515][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:31:39,515][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:31:39,515][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 13:31:39,515][root][INFO] - Av Loss per epoch=0.048696
[2022-01-11 13:31:39,515][root][INFO] - epoch total correct predictions=57811
[2022-01-11 13:31:39,516][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 13:31:39,517][root][INFO] - ***** Epoch 11 *****
[2022-01-11 13:31:39,519][root][INFO] - rank=3; Iteration start
[2022-01-11 13:31:39,519][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:31:39,519][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:31:39,519][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 13:31:44,514][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.10
[2022-01-11 13:31:44,515][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.10
[2022-01-11 13:31:44,515][root][INFO] - Av Loss per epoch=0.048696
[2022-01-11 13:31:44,515][root][INFO] - epoch total correct predictions=57811
[2022-01-11 13:31:44,517][root][INFO] - ***** Epoch 11 *****
[2022-01-11 13:31:44,519][root][INFO] - rank=0; Iteration start
[2022-01-11 13:31:44,519][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:31:44,519][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:31:44,519][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 13:31:45,603][root][INFO] - Epoch: 11: Step: 1/920, loss=0.035546, lr=0.000008
[2022-01-11 13:31:45,604][root][INFO] - Epoch: 11: Step: 1/920, loss=0.035546, lr=0.000008
[2022-01-11 13:31:45,605][root][INFO] - Epoch: 11: Step: 1/920, loss=0.035546, lr=0.000008
[2022-01-11 13:31:45,606][root][INFO] - Epoch: 11: Step: 1/920, loss=0.035546, lr=0.000008
[2022-01-11 13:33:20,669][root][INFO] - Train batch 100
[2022-01-11 13:33:20,669][root][INFO] - Avg. loss per last 100 batches: 0.041925
[2022-01-11 13:33:20,669][root][INFO] - Train batch 100
[2022-01-11 13:33:20,669][root][INFO] - Train batch 100
[2022-01-11 13:33:20,669][root][INFO] - Avg. loss per last 100 batches: 0.041925
[2022-01-11 13:33:20,669][root][INFO] - Avg. loss per last 100 batches: 0.041925
[2022-01-11 13:33:20,670][root][INFO] - Train batch 100
[2022-01-11 13:33:20,670][root][INFO] - Avg. loss per last 100 batches: 0.041925
[2022-01-11 13:33:21,680][root][INFO] - Epoch: 11: Step: 101/920, loss=0.044351, lr=0.000008
[2022-01-11 13:33:21,680][root][INFO] - Epoch: 11: Step: 101/920, loss=0.044351, lr=0.000008
[2022-01-11 13:33:21,681][root][INFO] - Epoch: 11: Step: 101/920, loss=0.044351, lr=0.000008
[2022-01-11 13:33:21,681][root][INFO] - Epoch: 11: Step: 101/920, loss=0.044351, lr=0.000008
[2022-01-11 13:35:00,373][root][INFO] - Train batch 200
[2022-01-11 13:35:00,373][root][INFO] - Avg. loss per last 100 batches: 0.040040
[2022-01-11 13:35:00,386][root][INFO] - Train batch 200
[2022-01-11 13:35:00,386][root][INFO] - Avg. loss per last 100 batches: 0.040040
[2022-01-11 13:35:00,386][root][INFO] - Train batch 200
[2022-01-11 13:35:00,387][root][INFO] - Avg. loss per last 100 batches: 0.040040
[2022-01-11 13:35:00,388][root][INFO] - Train batch 200
[2022-01-11 13:35:00,388][root][INFO] - Avg. loss per last 100 batches: 0.040040
[2022-01-11 13:35:01,435][root][INFO] - Epoch: 11: Step: 201/920, loss=0.102167, lr=0.000008
[2022-01-11 13:35:01,435][root][INFO] - Epoch: 11: Step: 201/920, loss=0.102167, lr=0.000008
[2022-01-11 13:35:01,436][root][INFO] - Epoch: 11: Step: 201/920, loss=0.102167, lr=0.000008
[2022-01-11 13:35:01,436][root][INFO] - Epoch: 11: Step: 201/920, loss=0.102167, lr=0.000008
[2022-01-11 13:36:40,960][root][INFO] - Train batch 300
[2022-01-11 13:36:40,960][root][INFO] - Train batch 300
[2022-01-11 13:36:40,961][root][INFO] - Avg. loss per last 100 batches: 0.035645
[2022-01-11 13:36:40,961][root][INFO] - Avg. loss per last 100 batches: 0.035645
[2022-01-11 13:36:40,961][root][INFO] - Train batch 300
[2022-01-11 13:36:40,961][root][INFO] - Avg. loss per last 100 batches: 0.035645
[2022-01-11 13:36:40,961][root][INFO] - Train batch 300
[2022-01-11 13:36:40,961][root][INFO] - Avg. loss per last 100 batches: 0.035645
[2022-01-11 13:36:42,008][root][INFO] - Epoch: 11: Step: 301/920, loss=0.065682, lr=0.000008
[2022-01-11 13:36:42,008][root][INFO] - Epoch: 11: Step: 301/920, loss=0.065682, lr=0.000008
[2022-01-11 13:36:42,009][root][INFO] - Epoch: 11: Step: 301/920, loss=0.065682, lr=0.000008
[2022-01-11 13:36:42,010][root][INFO] - Epoch: 11: Step: 301/920, loss=0.065682, lr=0.000008
[2022-01-11 13:38:18,342][root][INFO] - Train batch 400
[2022-01-11 13:38:18,342][root][INFO] - Avg. loss per last 100 batches: 0.049017
[2022-01-11 13:38:18,346][root][INFO] - Train batch 400
[2022-01-11 13:38:18,346][root][INFO] - Avg. loss per last 100 batches: 0.049017
[2022-01-11 13:38:18,346][root][INFO] - Train batch 400
[2022-01-11 13:38:18,347][root][INFO] - Avg. loss per last 100 batches: 0.049017
[2022-01-11 13:38:18,347][root][INFO] - Train batch 400
[2022-01-11 13:38:18,347][root][INFO] - Avg. loss per last 100 batches: 0.049017
[2022-01-11 13:38:19,398][root][INFO] - Epoch: 11: Step: 401/920, loss=0.027089, lr=0.000008
[2022-01-11 13:38:19,398][root][INFO] - Epoch: 11: Step: 401/920, loss=0.027089, lr=0.000008
[2022-01-11 13:38:19,399][root][INFO] - Epoch: 11: Step: 401/920, loss=0.027089, lr=0.000008
[2022-01-11 13:38:19,399][root][INFO] - Epoch: 11: Step: 401/920, loss=0.027089, lr=0.000008
[2022-01-11 13:39:58,232][root][INFO] - Train batch 500
[2022-01-11 13:39:58,232][root][INFO] - Avg. loss per last 100 batches: 0.046278
[2022-01-11 13:39:58,243][root][INFO] - Train batch 500
[2022-01-11 13:39:58,243][root][INFO] - Avg. loss per last 100 batches: 0.046278
[2022-01-11 13:39:58,243][root][INFO] - Train batch 500
[2022-01-11 13:39:58,243][root][INFO] - Avg. loss per last 100 batches: 0.046278
[2022-01-11 13:39:58,245][root][INFO] - Train batch 500
[2022-01-11 13:39:58,245][root][INFO] - Avg. loss per last 100 batches: 0.046278
[2022-01-11 13:39:59,211][root][INFO] - Epoch: 11: Step: 501/920, loss=0.065975, lr=0.000008
[2022-01-11 13:39:59,211][root][INFO] - Epoch: 11: Step: 501/920, loss=0.065975, lr=0.000008
[2022-01-11 13:39:59,212][root][INFO] - Epoch: 11: Step: 501/920, loss=0.065975, lr=0.000008
[2022-01-11 13:39:59,212][root][INFO] - Epoch: 11: Step: 501/920, loss=0.065975, lr=0.000008
[2022-01-11 13:41:37,870][root][INFO] - Train batch 600
[2022-01-11 13:41:37,870][root][INFO] - Avg. loss per last 100 batches: 0.046931
[2022-01-11 13:41:37,870][root][INFO] - Train batch 600
[2022-01-11 13:41:37,870][root][INFO] - Avg. loss per last 100 batches: 0.046931
[2022-01-11 13:41:37,870][root][INFO] - Train batch 600
[2022-01-11 13:41:37,870][root][INFO] - Avg. loss per last 100 batches: 0.046931
[2022-01-11 13:41:37,870][root][INFO] - Train batch 600
[2022-01-11 13:41:37,871][root][INFO] - Avg. loss per last 100 batches: 0.046931
[2022-01-11 13:41:38,918][root][INFO] - Epoch: 11: Step: 601/920, loss=0.062922, lr=0.000008
[2022-01-11 13:41:38,918][root][INFO] - Epoch: 11: Step: 601/920, loss=0.062922, lr=0.000008
[2022-01-11 13:41:38,919][root][INFO] - Epoch: 11: Step: 601/920, loss=0.062922, lr=0.000008
[2022-01-11 13:41:38,919][root][INFO] - Epoch: 11: Step: 601/920, loss=0.062922, lr=0.000008
[2022-01-11 13:43:15,735][root][INFO] - Train batch 700
[2022-01-11 13:43:15,735][root][INFO] - Avg. loss per last 100 batches: 0.047604
[2022-01-11 13:43:15,735][root][INFO] - Train batch 700
[2022-01-11 13:43:15,735][root][INFO] - Avg. loss per last 100 batches: 0.047604
[2022-01-11 13:43:15,736][root][INFO] - Train batch 700
[2022-01-11 13:43:15,736][root][INFO] - Avg. loss per last 100 batches: 0.047604
[2022-01-11 13:43:15,736][root][INFO] - Train batch 700
[2022-01-11 13:43:15,736][root][INFO] - Avg. loss per last 100 batches: 0.047604
[2022-01-11 13:43:16,723][root][INFO] - Epoch: 11: Step: 701/920, loss=0.033291, lr=0.000008
[2022-01-11 13:43:16,723][root][INFO] - Epoch: 11: Step: 701/920, loss=0.033291, lr=0.000008
[2022-01-11 13:43:16,724][root][INFO] - Epoch: 11: Step: 701/920, loss=0.033291, lr=0.000008
[2022-01-11 13:43:16,724][root][INFO] - Epoch: 11: Step: 701/920, loss=0.033291, lr=0.000008
[2022-01-11 13:44:55,232][root][INFO] - Train batch 800
[2022-01-11 13:44:55,232][root][INFO] - Train batch 800
[2022-01-11 13:44:55,232][root][INFO] - Avg. loss per last 100 batches: 0.042583
[2022-01-11 13:44:55,232][root][INFO] - Avg. loss per last 100 batches: 0.042583
[2022-01-11 13:44:55,233][root][INFO] - Train batch 800
[2022-01-11 13:44:55,233][root][INFO] - Train batch 800
[2022-01-11 13:44:55,233][root][INFO] - Avg. loss per last 100 batches: 0.042583
[2022-01-11 13:44:55,233][root][INFO] - Avg. loss per last 100 batches: 0.042583
[2022-01-11 13:44:56,253][root][INFO] - Epoch: 11: Step: 801/920, loss=0.043116, lr=0.000008
[2022-01-11 13:44:56,254][root][INFO] - Epoch: 11: Step: 801/920, loss=0.043116, lr=0.000008
[2022-01-11 13:44:56,254][root][INFO] - Epoch: 11: Step: 801/920, loss=0.043116, lr=0.000008
[2022-01-11 13:44:56,256][root][INFO] - Epoch: 11: Step: 801/920, loss=0.043116, lr=0.000008
[2022-01-11 13:46:35,005][root][INFO] - Train batch 900
[2022-01-11 13:46:35,006][root][INFO] - Avg. loss per last 100 batches: 0.048120
[2022-01-11 13:46:35,006][root][INFO] - Train batch 900
[2022-01-11 13:46:35,006][root][INFO] - Avg. loss per last 100 batches: 0.048120
[2022-01-11 13:46:35,008][root][INFO] - Train batch 900
[2022-01-11 13:46:35,009][root][INFO] - Avg. loss per last 100 batches: 0.048120
[2022-01-11 13:46:35,009][root][INFO] - Train batch 900
[2022-01-11 13:46:35,009][root][INFO] - Avg. loss per last 100 batches: 0.048120
[2022-01-11 13:46:36,026][root][INFO] - Epoch: 11: Step: 901/920, loss=0.067774, lr=0.000008
[2022-01-11 13:46:36,027][root][INFO] - Epoch: 11: Step: 901/920, loss=0.067774, lr=0.000008
[2022-01-11 13:46:36,029][root][INFO] - Epoch: 11: Step: 901/920, loss=0.067774, lr=0.000008
[2022-01-11 13:46:36,029][root][INFO] - Epoch: 11: Step: 901/920, loss=0.067774, lr=0.000008
[2022-01-11 13:46:54,795][root][INFO] - rank=1, Validation: Epoch: 11 Step: 920/920
[2022-01-11 13:46:54,795][root][INFO] - NLL validation ...
[2022-01-11 13:46:54,796][root][INFO] - rank=1; Iteration start
[2022-01-11 13:46:54,796][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:46:54,796][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:46:54,796][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 13:46:54,797][root][INFO] - rank=0, Validation: Epoch: 11 Step: 920/920
[2022-01-11 13:46:54,797][root][INFO] - rank=3, Validation: Epoch: 11 Step: 920/920
[2022-01-11 13:46:54,797][root][INFO] - NLL validation ...
[2022-01-11 13:46:54,797][root][INFO] - NLL validation ...
[2022-01-11 13:46:54,797][root][INFO] - rank=2, Validation: Epoch: 11 Step: 920/920
[2022-01-11 13:46:54,798][root][INFO] - NLL validation ...
[2022-01-11 13:46:54,798][root][INFO] - rank=0; Iteration start
[2022-01-11 13:46:54,798][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:46:54,798][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:46:54,798][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 13:46:54,798][root][INFO] - rank=3; Iteration start
[2022-01-11 13:46:54,798][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:46:54,798][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:46:54,798][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 13:46:54,799][root][INFO] - rank=2; Iteration start
[2022-01-11 13:46:54,799][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:46:54,799][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:46:54,799][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 13:46:54,807][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 13:46:54,808][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 13:46:54,809][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 13:46:54,809][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 13:46:55,549][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 13:46:55,549][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 13:46:55,550][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 13:46:55,550][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 13:46:56,286][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 13:46:56,287][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 13:46:56,287][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 13:46:56,287][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 13:46:57,023][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 13:46:58,001][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 13:46:58,004][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 13:46:58,015][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 13:46:58,749][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 13:46:58,749][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 13:46:58,749][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 13:46:58,750][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 13:46:59,488][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 13:46:59,488][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 13:46:59,488][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 13:46:59,489][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 13:47:00,227][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 13:47:00,228][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 13:47:00,228][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 13:47:00,228][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 13:47:00,965][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 13:47:00,965][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 13:47:00,966][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 13:47:00,966][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 13:47:01,701][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 13:47:01,701][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 13:47:01,703][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 13:47:02,684][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 13:47:03,419][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 13:47:03,419][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 13:47:03,419][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 13:47:03,420][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 13:47:04,159][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 13:47:04,160][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 13:47:04,160][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 13:47:04,160][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 13:47:04,895][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 13:47:04,896][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 13:47:04,896][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 13:47:04,897][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 13:47:05,634][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 13:47:05,635][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 13:47:05,635][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 13:47:05,636][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 13:47:06,373][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 13:47:06,373][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 13:47:06,374][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 13:47:06,376][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 13:47:07,115][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 13:47:07,115][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 13:47:07,115][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 13:47:07,115][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 13:47:07,850][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 13:47:07,851][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 13:47:07,851][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 13:47:07,851][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 13:47:08,586][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 13:47:08,586][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 13:47:08,586][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 13:47:08,586][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 13:47:09,324][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 13:47:09,936][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 13:47:10,005][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 13:47:10,107][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 13:47:10,838][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 13:47:10,838][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 13:47:10,838][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 13:47:10,839][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 13:47:11,575][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 13:47:11,575][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 13:47:11,576][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 13:47:11,576][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 13:47:12,313][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 13:47:12,313][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 13:47:12,313][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 13:47:12,313][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 13:47:13,052][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 13:47:13,053][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 13:47:13,054][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 13:47:13,054][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 13:47:13,792][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 13:47:13,792][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 13:47:13,792][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 13:47:14,400][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 13:47:15,130][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 13:47:15,130][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 13:47:15,131][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 13:47:15,131][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 13:47:15,869][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 13:47:15,869][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 13:47:15,869][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 13:47:15,869][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 13:47:16,598][root][INFO] - rank=3; last iteration 25
[2022-01-11 13:47:16,598][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:47:16,598][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 13:47:16,598][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:16,598][root][INFO] - rank=0; last iteration 25
[2022-01-11 13:47:16,598][root][INFO] - NLL Validation: loss = 0.386784. correct prediction ratio  5696/6400 ~  0.890000
[2022-01-11 13:47:16,598][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:47:16,598][root][INFO] - rank=1; last iteration 25
[2022-01-11 13:47:16,598][root][INFO] - rank=2; last iteration 25
[2022-01-11 13:47:16,598][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 13:47:16,598][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:47:16,598][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:47:16,598][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:16,598][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 13:47:16,598][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 13:47:16,598][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:16,598][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:16,598][root][INFO] - NLL Validation: loss = 0.386784. correct prediction ratio  5696/6400 ~  0.890000
[2022-01-11 13:47:16,599][root][INFO] - NLL Validation: loss = 0.386784. correct prediction ratio  5696/6400 ~  0.890000
[2022-01-11 13:47:16,599][root][INFO] - NLL Validation: loss = 0.386784. correct prediction ratio  5696/6400 ~  0.890000
[2022-01-11 13:47:16,601][root][INFO] - rank=3; last iteration 920
[2022-01-11 13:47:16,601][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:47:16,601][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 13:47:16,601][root][INFO] - rank=1; last iteration 920
[2022-01-11 13:47:16,601][root][INFO] - rank=2; last iteration 920
[2022-01-11 13:47:16,601][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:47:16,601][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:47:16,601][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 13:47:16,601][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 13:47:16,601][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:16,601][root][INFO] - Epoch finished on 3
[2022-01-11 13:47:16,601][root][INFO] - NLL validation ...
[2022-01-11 13:47:16,601][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:16,601][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:16,602][root][INFO] - Epoch finished on 1
[2022-01-11 13:47:16,602][root][INFO] - Epoch finished on 2
[2022-01-11 13:47:16,602][root][INFO] - NLL validation ...
[2022-01-11 13:47:16,602][root][INFO] - NLL validation ...
[2022-01-11 13:47:16,603][root][INFO] - rank=3; Iteration start
[2022-01-11 13:47:16,603][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:47:16,603][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:47:16,603][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 13:47:16,603][root][INFO] - rank=1; Iteration start
[2022-01-11 13:47:16,603][root][INFO] - rank=2; Iteration start
[2022-01-11 13:47:16,603][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:47:16,603][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:47:16,603][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:47:16,603][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:47:16,603][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 13:47:16,603][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 13:47:16,611][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 13:47:16,611][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 13:47:16,612][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 13:47:20,230][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.11
[2022-01-11 13:47:20,231][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.11
[2022-01-11 13:47:20,232][root][INFO] - rank=0; last iteration 920
[2022-01-11 13:47:20,232][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 13:47:20,232][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 13:47:20,232][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:20,233][root][INFO] - Epoch finished on 0
[2022-01-11 13:47:20,233][root][INFO] - NLL validation ...
[2022-01-11 13:47:20,234][root][INFO] - rank=0; Iteration start
[2022-01-11 13:47:20,234][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:47:20,234][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 13:47:20,234][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 13:47:20,242][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 13:47:20,983][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 13:47:20,984][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 13:47:20,985][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 13:47:20,985][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 13:47:21,718][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 13:47:21,718][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 13:47:21,719][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 13:47:21,719][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 13:47:22,453][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 13:47:22,453][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 13:47:22,453][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 13:47:22,454][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 13:47:23,192][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 13:47:23,193][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 13:47:23,193][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 13:47:23,194][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 13:47:23,933][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 13:47:24,542][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 13:47:24,544][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 13:47:24,793][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 13:47:25,525][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 13:47:25,525][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 13:47:25,527][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 13:47:25,527][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 13:47:26,264][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 13:47:26,264][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 13:47:26,265][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 13:47:26,266][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 13:47:27,006][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 13:47:27,008][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 13:47:27,008][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 13:47:27,009][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 13:47:27,746][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 13:47:27,747][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 13:47:27,747][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 13:47:27,749][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 13:47:28,484][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 13:47:28,485][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 13:47:28,486][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 13:47:29,103][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 13:47:29,835][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 13:47:29,836][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 13:47:29,836][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 13:47:29,840][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 13:47:30,575][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 13:47:30,575][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 13:47:30,575][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 13:47:30,577][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 13:47:31,317][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 13:47:31,317][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 13:47:31,317][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 13:47:31,318][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 13:47:32,053][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 13:47:32,053][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 13:47:32,054][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 13:47:32,055][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 13:47:32,789][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 13:47:32,789][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 13:47:32,790][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 13:47:32,791][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 13:47:33,523][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 13:47:33,524][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 13:47:33,524][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 13:47:33,526][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 13:47:34,267][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 13:47:34,267][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 13:47:34,267][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 13:47:34,269][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 13:47:35,002][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 13:47:35,002][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 13:47:35,003][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 13:47:35,004][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 13:47:35,740][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 13:47:36,338][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 13:47:36,359][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 13:47:36,564][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 13:47:37,300][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 13:47:37,301][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 13:47:37,303][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 13:47:37,304][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 13:47:38,039][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 13:47:38,039][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 13:47:38,040][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 13:47:38,040][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 13:47:38,780][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 13:47:38,782][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 13:47:38,783][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 13:47:38,783][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 13:47:39,519][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 13:47:39,519][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 13:47:39,521][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 13:47:39,521][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 13:47:40,255][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 13:47:40,255][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 13:47:40,257][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 13:47:40,897][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 13:47:41,619][root][INFO] - rank=0; last iteration 25
[2022-01-11 13:47:41,619][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:47:41,619][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 13:47:41,619][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:41,620][root][INFO] - NLL Validation: loss = 0.386784. correct prediction ratio  5696/6400 ~  0.890000
[2022-01-11 13:47:41,620][root][INFO] - rank=2; last iteration 25
[2022-01-11 13:47:41,620][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:47:41,620][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 13:47:41,620][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:41,620][root][INFO] - rank=3; last iteration 25
[2022-01-11 13:47:41,620][root][INFO] - rank=1; last iteration 25
[2022-01-11 13:47:41,620][root][INFO] - NLL Validation: loss = 0.386784. correct prediction ratio  5696/6400 ~  0.890000
[2022-01-11 13:47:41,620][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:47:41,620][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 13:47:41,620][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 13:47:41,620][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 13:47:41,620][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:41,620][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 13:47:41,620][root][INFO] - NLL Validation: loss = 0.386784. correct prediction ratio  5696/6400 ~  0.890000
[2022-01-11 13:47:41,620][root][INFO] - NLL Validation: loss = 0.386784. correct prediction ratio  5696/6400 ~  0.890000
[2022-01-11 13:47:41,621][root][INFO] - Av Loss per epoch=0.044430
[2022-01-11 13:47:41,621][root][INFO] - epoch total correct predictions=57930
[2022-01-11 13:47:41,622][root][INFO] - Av Loss per epoch=0.044430
[2022-01-11 13:47:41,622][root][INFO] - epoch total correct predictions=57930
[2022-01-11 13:47:41,622][root][INFO] - Av Loss per epoch=0.044430
[2022-01-11 13:47:41,622][root][INFO] - epoch total correct predictions=57930
[2022-01-11 13:47:41,623][root][INFO] - ***** Epoch 12 *****
[2022-01-11 13:47:41,623][root][INFO] - ***** Epoch 12 *****
[2022-01-11 13:47:41,624][root][INFO] - ***** Epoch 12 *****
[2022-01-11 13:47:41,625][root][INFO] - rank=2; Iteration start
[2022-01-11 13:47:41,625][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:47:41,625][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:47:41,625][root][INFO] - rank=1; Iteration start
[2022-01-11 13:47:41,625][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:47:41,625][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:47:41,625][root][INFO] - rank=3; Iteration start
[2022-01-11 13:47:41,625][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:47:41,625][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:47:41,625][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 13:47:41,625][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 13:47:41,625][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 13:47:46,445][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.11
[2022-01-11 13:47:46,445][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.11
[2022-01-11 13:47:46,445][root][INFO] - Av Loss per epoch=0.044430
[2022-01-11 13:47:46,446][root][INFO] - epoch total correct predictions=57930
[2022-01-11 13:47:46,447][root][INFO] - ***** Epoch 12 *****
[2022-01-11 13:47:46,449][root][INFO] - rank=0; Iteration start
[2022-01-11 13:47:46,449][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 13:47:46,449][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 13:47:46,450][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 13:47:47,335][root][INFO] - Epoch: 12: Step: 1/920, loss=0.124008, lr=0.000008
[2022-01-11 13:47:47,336][root][INFO] - Epoch: 12: Step: 1/920, loss=0.124008, lr=0.000008
[2022-01-11 13:47:47,336][root][INFO] - Epoch: 12: Step: 1/920, loss=0.124008, lr=0.000008
[2022-01-11 13:47:47,336][root][INFO] - Epoch: 12: Step: 1/920, loss=0.124008, lr=0.000008
[2022-01-11 13:49:24,229][root][INFO] - Train batch 100
[2022-01-11 13:49:24,229][root][INFO] - Avg. loss per last 100 batches: 0.046176
[2022-01-11 13:49:24,236][root][INFO] - Train batch 100
[2022-01-11 13:49:24,236][root][INFO] - Avg. loss per last 100 batches: 0.046176
[2022-01-11 13:49:24,237][root][INFO] - Train batch 100
[2022-01-11 13:49:24,238][root][INFO] - Avg. loss per last 100 batches: 0.046176
[2022-01-11 13:49:24,238][root][INFO] - Train batch 100
[2022-01-11 13:49:24,238][root][INFO] - Avg. loss per last 100 batches: 0.046176
[2022-01-11 13:49:25,278][root][INFO] - Epoch: 12: Step: 101/920, loss=0.047926, lr=0.000007
[2022-01-11 13:49:25,288][root][INFO] - Epoch: 12: Step: 101/920, loss=0.047926, lr=0.000007
[2022-01-11 13:49:25,288][root][INFO] - Epoch: 12: Step: 101/920, loss=0.047926, lr=0.000007
[2022-01-11 13:49:25,289][root][INFO] - Epoch: 12: Step: 101/920, loss=0.047926, lr=0.000007
[2022-01-11 13:51:03,652][root][INFO] - Train batch 200
[2022-01-11 13:51:03,653][root][INFO] - Avg. loss per last 100 batches: 0.040445
[2022-01-11 13:51:03,653][root][INFO] - Train batch 200
[2022-01-11 13:51:03,653][root][INFO] - Avg. loss per last 100 batches: 0.040445
[2022-01-11 13:51:03,654][root][INFO] - Train batch 200
[2022-01-11 13:51:03,654][root][INFO] - Avg. loss per last 100 batches: 0.040445
[2022-01-11 13:51:03,655][root][INFO] - Train batch 200
[2022-01-11 13:51:03,655][root][INFO] - Avg. loss per last 100 batches: 0.040445
[2022-01-11 13:51:04,517][root][INFO] - Epoch: 12: Step: 201/920, loss=0.007177, lr=0.000007
[2022-01-11 13:51:04,517][root][INFO] - Epoch: 12: Step: 201/920, loss=0.007177, lr=0.000007
[2022-01-11 13:51:04,518][root][INFO] - Epoch: 12: Step: 201/920, loss=0.007177, lr=0.000007
[2022-01-11 13:51:04,519][root][INFO] - Epoch: 12: Step: 201/920, loss=0.007177, lr=0.000007
[2022-01-11 13:52:42,046][root][INFO] - Train batch 300
[2022-01-11 13:52:42,046][root][INFO] - Avg. loss per last 100 batches: 0.036236
[2022-01-11 13:52:42,046][root][INFO] - Train batch 300
[2022-01-11 13:52:42,047][root][INFO] - Avg. loss per last 100 batches: 0.036236
[2022-01-11 13:52:42,048][root][INFO] - Train batch 300
[2022-01-11 13:52:42,048][root][INFO] - Avg. loss per last 100 batches: 0.036236
[2022-01-11 13:52:42,048][root][INFO] - Train batch 300
[2022-01-11 13:52:42,048][root][INFO] - Avg. loss per last 100 batches: 0.036236
[2022-01-11 13:52:43,029][root][INFO] - Epoch: 12: Step: 301/920, loss=0.007819, lr=0.000007
[2022-01-11 13:52:43,030][root][INFO] - Epoch: 12: Step: 301/920, loss=0.007819, lr=0.000007
[2022-01-11 13:52:43,031][root][INFO] - Epoch: 12: Step: 301/920, loss=0.007819, lr=0.000007
[2022-01-11 13:52:43,032][root][INFO] - Epoch: 12: Step: 301/920, loss=0.007819, lr=0.000007
[2022-01-11 13:54:20,504][root][INFO] - Train batch 400
[2022-01-11 13:54:20,504][root][INFO] - Avg. loss per last 100 batches: 0.039289
[2022-01-11 13:54:20,512][root][INFO] - Train batch 400
[2022-01-11 13:54:20,512][root][INFO] - Avg. loss per last 100 batches: 0.039289
[2022-01-11 13:54:20,513][root][INFO] - Train batch 400
[2022-01-11 13:54:20,513][root][INFO] - Avg. loss per last 100 batches: 0.039289
[2022-01-11 13:54:20,513][root][INFO] - Train batch 400
[2022-01-11 13:54:20,514][root][INFO] - Avg. loss per last 100 batches: 0.039289
[2022-01-11 13:54:21,443][root][INFO] - Epoch: 12: Step: 401/920, loss=0.036902, lr=0.000007
[2022-01-11 13:54:21,444][root][INFO] - Epoch: 12: Step: 401/920, loss=0.036902, lr=0.000007
[2022-01-11 13:54:21,444][root][INFO] - Epoch: 12: Step: 401/920, loss=0.036902, lr=0.000007
[2022-01-11 13:54:21,445][root][INFO] - Epoch: 12: Step: 401/920, loss=0.036902, lr=0.000007
[2022-01-11 13:55:59,473][root][INFO] - Train batch 500
[2022-01-11 13:55:59,473][root][INFO] - Avg. loss per last 100 batches: 0.038689
[2022-01-11 13:55:59,475][root][INFO] - Train batch 500
[2022-01-11 13:55:59,475][root][INFO] - Avg. loss per last 100 batches: 0.038689
[2022-01-11 13:55:59,476][root][INFO] - Train batch 500
[2022-01-11 13:55:59,476][root][INFO] - Avg. loss per last 100 batches: 0.038689
[2022-01-11 13:55:59,483][root][INFO] - Train batch 500
[2022-01-11 13:55:59,483][root][INFO] - Avg. loss per last 100 batches: 0.038689
[2022-01-11 13:56:00,381][root][INFO] - Epoch: 12: Step: 501/920, loss=0.022293, lr=0.000007
[2022-01-11 13:56:00,382][root][INFO] - Epoch: 12: Step: 501/920, loss=0.022293, lr=0.000007
[2022-01-11 13:56:00,382][root][INFO] - Epoch: 12: Step: 501/920, loss=0.022293, lr=0.000007
[2022-01-11 13:56:00,383][root][INFO] - Epoch: 12: Step: 501/920, loss=0.022293, lr=0.000007
[2022-01-11 13:57:38,598][root][INFO] - Train batch 600
[2022-01-11 13:57:38,599][root][INFO] - Avg. loss per last 100 batches: 0.040327
[2022-01-11 13:57:38,600][root][INFO] - Train batch 600
[2022-01-11 13:57:38,600][root][INFO] - Avg. loss per last 100 batches: 0.040327
[2022-01-11 13:57:38,601][root][INFO] - Train batch 600
[2022-01-11 13:57:38,601][root][INFO] - Avg. loss per last 100 batches: 0.040327
[2022-01-11 13:57:38,602][root][INFO] - Train batch 600
[2022-01-11 13:57:38,602][root][INFO] - Avg. loss per last 100 batches: 0.040327
[2022-01-11 13:57:39,654][root][INFO] - Epoch: 12: Step: 601/920, loss=0.011348, lr=0.000007
[2022-01-11 13:57:39,654][root][INFO] - Epoch: 12: Step: 601/920, loss=0.011348, lr=0.000007
[2022-01-11 13:57:39,655][root][INFO] - Epoch: 12: Step: 601/920, loss=0.011348, lr=0.000007
[2022-01-11 13:57:39,655][root][INFO] - Epoch: 12: Step: 601/920, loss=0.011348, lr=0.000007
[2022-01-11 13:59:16,807][root][INFO] - Train batch 700
[2022-01-11 13:59:16,808][root][INFO] - Avg. loss per last 100 batches: 0.038960
[2022-01-11 13:59:16,808][root][INFO] - Train batch 700
[2022-01-11 13:59:16,808][root][INFO] - Avg. loss per last 100 batches: 0.038960
[2022-01-11 13:59:16,809][root][INFO] - Train batch 700
[2022-01-11 13:59:16,809][root][INFO] - Avg. loss per last 100 batches: 0.038960
[2022-01-11 13:59:16,810][root][INFO] - Train batch 700
[2022-01-11 13:59:16,810][root][INFO] - Avg. loss per last 100 batches: 0.038960
[2022-01-11 13:59:17,863][root][INFO] - Epoch: 12: Step: 701/920, loss=0.028220, lr=0.000007
[2022-01-11 13:59:17,863][root][INFO] - Epoch: 12: Step: 701/920, loss=0.028220, lr=0.000007
[2022-01-11 13:59:17,863][root][INFO] - Epoch: 12: Step: 701/920, loss=0.028220, lr=0.000007
[2022-01-11 13:59:17,863][root][INFO] - Epoch: 12: Step: 701/920, loss=0.028220, lr=0.000007
[2022-01-11 14:00:55,957][root][INFO] - Train batch 800
[2022-01-11 14:00:55,957][root][INFO] - Avg. loss per last 100 batches: 0.044716
[2022-01-11 14:00:55,957][root][INFO] - Train batch 800
[2022-01-11 14:00:55,957][root][INFO] - Avg. loss per last 100 batches: 0.044716
[2022-01-11 14:00:55,958][root][INFO] - Train batch 800
[2022-01-11 14:00:55,958][root][INFO] - Train batch 800
[2022-01-11 14:00:55,958][root][INFO] - Avg. loss per last 100 batches: 0.044716
[2022-01-11 14:00:55,958][root][INFO] - Avg. loss per last 100 batches: 0.044716
[2022-01-11 14:00:56,809][root][INFO] - Epoch: 12: Step: 801/920, loss=0.096165, lr=0.000007
[2022-01-11 14:00:56,809][root][INFO] - Epoch: 12: Step: 801/920, loss=0.096165, lr=0.000007
[2022-01-11 14:00:56,809][root][INFO] - Epoch: 12: Step: 801/920, loss=0.096165, lr=0.000007
[2022-01-11 14:00:56,810][root][INFO] - Epoch: 12: Step: 801/920, loss=0.096165, lr=0.000007
[2022-01-11 14:02:37,479][root][INFO] - Train batch 900
[2022-01-11 14:02:37,479][root][INFO] - Avg. loss per last 100 batches: 0.043530
[2022-01-11 14:02:37,479][root][INFO] - Train batch 900
[2022-01-11 14:02:37,480][root][INFO] - Avg. loss per last 100 batches: 0.043530
[2022-01-11 14:02:37,479][root][INFO] - Train batch 900
[2022-01-11 14:02:37,480][root][INFO] - Avg. loss per last 100 batches: 0.043530
[2022-01-11 14:02:37,491][root][INFO] - Train batch 900
[2022-01-11 14:02:37,491][root][INFO] - Avg. loss per last 100 batches: 0.043530
[2022-01-11 14:02:38,516][root][INFO] - Epoch: 12: Step: 901/920, loss=0.039147, lr=0.000007
[2022-01-11 14:02:38,517][root][INFO] - Epoch: 12: Step: 901/920, loss=0.039147, lr=0.000007
[2022-01-11 14:02:38,517][root][INFO] - Epoch: 12: Step: 901/920, loss=0.039147, lr=0.000007
[2022-01-11 14:02:38,529][root][INFO] - Epoch: 12: Step: 901/920, loss=0.039147, lr=0.000007
[2022-01-11 14:02:57,278][root][INFO] - rank=1, Validation: Epoch: 12 Step: 920/920
[2022-01-11 14:02:57,278][root][INFO] - NLL validation ...
[2022-01-11 14:02:57,279][root][INFO] - rank=0, Validation: Epoch: 12 Step: 920/920
[2022-01-11 14:02:57,279][root][INFO] - NLL validation ...
[2022-01-11 14:02:57,279][root][INFO] - rank=2, Validation: Epoch: 12 Step: 920/920
[2022-01-11 14:02:57,279][root][INFO] - rank=3, Validation: Epoch: 12 Step: 920/920
[2022-01-11 14:02:57,279][root][INFO] - NLL validation ...
[2022-01-11 14:02:57,279][root][INFO] - rank=1; Iteration start
[2022-01-11 14:02:57,279][root][INFO] - NLL validation ...
[2022-01-11 14:02:57,279][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:02:57,279][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:02:57,279][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 14:02:57,280][root][INFO] - rank=0; Iteration start
[2022-01-11 14:02:57,280][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:02:57,280][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:02:57,280][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 14:02:57,280][root][INFO] - rank=2; Iteration start
[2022-01-11 14:02:57,280][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:02:57,281][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:02:57,281][root][INFO] - rank=3; Iteration start
[2022-01-11 14:02:57,281][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 14:02:57,281][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:02:57,281][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:02:57,281][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 14:02:57,289][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 14:02:57,290][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 14:02:57,290][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 14:02:57,290][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 14:02:58,025][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 14:02:58,025][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 14:02:58,026][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 14:02:58,026][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 14:02:58,759][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 14:02:58,759][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 14:02:58,760][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 14:02:58,760][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 14:02:59,496][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 14:02:59,496][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 14:02:59,496][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 14:03:00,483][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 14:03:01,215][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 14:03:01,215][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 14:03:01,216][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 14:03:01,216][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 14:03:01,954][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 14:03:01,954][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 14:03:01,954][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 14:03:01,954][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 14:03:02,691][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 14:03:02,691][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 14:03:02,691][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 14:03:02,692][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 14:03:03,428][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 14:03:03,428][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 14:03:03,428][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 14:03:03,428][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 14:03:04,166][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 14:03:04,166][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 14:03:04,166][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 14:03:04,166][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 14:03:04,902][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 14:03:04,902][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 14:03:04,902][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 14:03:04,902][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 14:03:05,641][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 14:03:06,259][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 14:03:06,265][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 14:03:06,590][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 14:03:07,325][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 14:03:07,325][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 14:03:07,326][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 14:03:07,327][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 14:03:08,070][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 14:03:08,071][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 14:03:08,071][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 14:03:08,073][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 14:03:08,815][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 14:03:08,815][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 14:03:08,815][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 14:03:08,815][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 14:03:09,553][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 14:03:09,554][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 14:03:09,555][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 14:03:09,555][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 14:03:10,291][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 14:03:10,291][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 14:03:10,294][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 14:03:10,294][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 14:03:11,038][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 14:03:11,038][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 14:03:11,038][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 14:03:11,038][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 14:03:11,776][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 14:03:11,777][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 14:03:11,778][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 14:03:12,386][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 14:03:13,119][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 14:03:13,120][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 14:03:13,120][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 14:03:13,120][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 14:03:13,857][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 14:03:13,858][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 14:03:13,858][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 14:03:13,859][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 14:03:14,597][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 14:03:14,599][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 14:03:14,600][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 14:03:14,601][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 14:03:15,337][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 14:03:15,337][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 14:03:15,337][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 14:03:15,337][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 14:03:16,074][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 14:03:16,074][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 14:03:16,075][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 14:03:16,075][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 14:03:16,812][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 14:03:16,813][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 14:03:16,813][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 14:03:16,814][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 14:03:17,554][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 14:03:18,177][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 14:03:18,180][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 14:03:18,393][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 14:03:19,120][root][INFO] - rank=2; last iteration 25
[2022-01-11 14:03:19,120][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:03:19,120][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 14:03:19,120][root][INFO] - rank=3; last iteration 25
[2022-01-11 14:03:19,120][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:19,120][root][INFO] - rank=1; last iteration 25
[2022-01-11 14:03:19,120][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:03:19,121][root][INFO] - NLL Validation: loss = 0.388213. correct prediction ratio  5683/6400 ~  0.887969
[2022-01-11 14:03:19,121][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 14:03:19,121][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:03:19,121][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 14:03:19,121][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:19,121][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:19,121][root][INFO] - NLL Validation: loss = 0.388213. correct prediction ratio  5683/6400 ~  0.887969
[2022-01-11 14:03:19,121][root][INFO] - rank=0; last iteration 25
[2022-01-11 14:03:19,121][root][INFO] - NLL Validation: loss = 0.388213. correct prediction ratio  5683/6400 ~  0.887969
[2022-01-11 14:03:19,121][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:03:19,121][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 14:03:19,121][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:19,121][root][INFO] - NLL Validation: loss = 0.388213. correct prediction ratio  5683/6400 ~  0.887969
[2022-01-11 14:03:19,123][root][INFO] - rank=2; last iteration 920
[2022-01-11 14:03:19,123][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:03:19,123][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 14:03:19,123][root][INFO] - rank=3; last iteration 920
[2022-01-11 14:03:19,123][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:03:19,123][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 14:03:19,123][root][INFO] - rank=1; last iteration 920
[2022-01-11 14:03:19,123][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:03:19,123][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 14:03:19,123][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:19,124][root][INFO] - Epoch finished on 2
[2022-01-11 14:03:19,124][root][INFO] - NLL validation ...
[2022-01-11 14:03:19,124][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:19,124][root][INFO] - Epoch finished on 3
[2022-01-11 14:03:19,124][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:19,124][root][INFO] - Epoch finished on 1
[2022-01-11 14:03:19,124][root][INFO] - NLL validation ...
[2022-01-11 14:03:19,124][root][INFO] - NLL validation ...
[2022-01-11 14:03:19,125][root][INFO] - rank=2; Iteration start
[2022-01-11 14:03:19,125][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:03:19,125][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:03:19,125][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 14:03:19,125][root][INFO] - rank=3; Iteration start
[2022-01-11 14:03:19,125][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:03:19,125][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:03:19,125][root][INFO] - rank=1; Iteration start
[2022-01-11 14:03:19,125][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 14:03:19,125][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:03:19,125][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:03:19,125][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 14:03:19,132][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 14:03:19,133][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 14:03:19,134][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 14:03:23,095][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.12
[2022-01-11 14:03:23,096][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.12
[2022-01-11 14:03:23,097][root][INFO] - rank=0; last iteration 920
[2022-01-11 14:03:23,097][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:03:23,097][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 14:03:23,098][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:23,098][root][INFO] - Epoch finished on 0
[2022-01-11 14:03:23,098][root][INFO] - NLL validation ...
[2022-01-11 14:03:23,099][root][INFO] - rank=0; Iteration start
[2022-01-11 14:03:23,099][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:03:23,099][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:03:23,099][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 14:03:23,106][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 14:03:23,843][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 14:03:23,844][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 14:03:23,845][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 14:03:23,847][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 14:03:24,584][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 14:03:24,586][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 14:03:24,587][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 14:03:24,590][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 14:03:25,322][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 14:03:25,323][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 14:03:25,324][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 14:03:25,324][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 14:03:26,059][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 14:03:26,059][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 14:03:26,061][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 14:03:26,062][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 14:03:26,796][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 14:03:26,797][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 14:03:26,798][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 14:03:26,799][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 14:03:27,538][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 14:03:27,540][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 14:03:27,541][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 14:03:27,542][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 14:03:28,276][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 14:03:28,278][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 14:03:28,278][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 14:03:28,894][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 14:03:29,628][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 14:03:29,629][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 14:03:29,629][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 14:03:29,630][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 14:03:30,364][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 14:03:30,365][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 14:03:30,367][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 14:03:30,368][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 14:03:31,101][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 14:03:31,102][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 14:03:31,103][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 14:03:31,105][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 14:03:31,838][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 14:03:31,838][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 14:03:31,840][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 14:03:31,840][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 14:03:32,575][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 14:03:32,576][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 14:03:32,577][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 14:03:32,578][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 14:03:33,318][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 14:03:33,961][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 14:03:33,986][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 14:03:34,155][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 14:03:34,886][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 14:03:34,887][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 14:03:34,887][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 14:03:34,888][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 14:03:35,621][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 14:03:35,622][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 14:03:35,623][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 14:03:35,623][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 14:03:36,358][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 14:03:36,358][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 14:03:36,360][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 14:03:36,362][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 14:03:37,096][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 14:03:37,098][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 14:03:37,098][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 14:03:37,099][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 14:03:37,833][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 14:03:37,833][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 14:03:37,834][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 14:03:37,834][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 14:03:38,574][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 14:03:38,575][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 14:03:38,576][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 14:03:38,577][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 14:03:39,312][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 14:03:39,313][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 14:03:39,314][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 14:03:40,123][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 14:03:40,853][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 14:03:40,855][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 14:03:40,855][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 14:03:40,855][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 14:03:41,594][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 14:03:41,595][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 14:03:41,595][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 14:03:41,595][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 14:03:42,332][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 14:03:42,333][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 14:03:42,333][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 14:03:42,334][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 14:03:43,066][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 14:03:43,067][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 14:03:43,067][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 14:03:43,067][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 14:03:43,793][root][INFO] - rank=1; last iteration 25
[2022-01-11 14:03:43,793][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:03:43,793][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 14:03:43,793][root][INFO] - rank=2; last iteration 25
[2022-01-11 14:03:43,793][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:43,793][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:03:43,793][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 14:03:43,793][root][INFO] - NLL Validation: loss = 0.388213. correct prediction ratio  5683/6400 ~  0.887969
[2022-01-11 14:03:43,793][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:43,793][root][INFO] - rank=0; last iteration 25
[2022-01-11 14:03:43,793][root][INFO] - NLL Validation: loss = 0.388213. correct prediction ratio  5683/6400 ~  0.887969
[2022-01-11 14:03:43,793][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:03:43,793][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 14:03:43,793][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:43,794][root][INFO] - NLL Validation: loss = 0.388213. correct prediction ratio  5683/6400 ~  0.887969
[2022-01-11 14:03:43,794][root][INFO] - rank=3; last iteration 25
[2022-01-11 14:03:43,794][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:03:43,795][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 14:03:43,795][root][INFO] - Av Loss per epoch=0.040823
[2022-01-11 14:03:43,795][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:03:43,795][root][INFO] - epoch total correct predictions=57965
[2022-01-11 14:03:43,795][root][INFO] - Av Loss per epoch=0.040823
[2022-01-11 14:03:43,795][root][INFO] - NLL Validation: loss = 0.388213. correct prediction ratio  5683/6400 ~  0.887969
[2022-01-11 14:03:43,795][root][INFO] - epoch total correct predictions=57965
[2022-01-11 14:03:43,796][root][INFO] - Av Loss per epoch=0.040823
[2022-01-11 14:03:43,796][root][INFO] - epoch total correct predictions=57965
[2022-01-11 14:03:43,796][root][INFO] - ***** Epoch 13 *****
[2022-01-11 14:03:43,797][root][INFO] - ***** Epoch 13 *****
[2022-01-11 14:03:43,798][root][INFO] - rank=1; Iteration start
[2022-01-11 14:03:43,798][root][INFO] - rank=2; Iteration start
[2022-01-11 14:03:43,798][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:03:43,798][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:03:43,798][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:03:43,798][root][INFO] - ***** Epoch 13 *****
[2022-01-11 14:03:43,798][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:03:43,799][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 14:03:43,799][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 14:03:43,799][root][INFO] - rank=3; Iteration start
[2022-01-11 14:03:43,800][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:03:43,800][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:03:43,800][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 14:03:48,914][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.12
[2022-01-11 14:03:48,915][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.12
[2022-01-11 14:03:48,915][root][INFO] - Av Loss per epoch=0.040823
[2022-01-11 14:03:48,915][root][INFO] - epoch total correct predictions=57965
[2022-01-11 14:03:48,917][root][INFO] - ***** Epoch 13 *****
[2022-01-11 14:03:48,920][root][INFO] - rank=0; Iteration start
[2022-01-11 14:03:48,920][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:03:48,920][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:03:48,920][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 14:03:49,999][root][INFO] - Epoch: 13: Step: 1/920, loss=0.024803, lr=0.000007
[2022-01-11 14:03:50,001][root][INFO] - Epoch: 13: Step: 1/920, loss=0.024803, lr=0.000007
[2022-01-11 14:03:50,001][root][INFO] - Epoch: 13: Step: 1/920, loss=0.024803, lr=0.000007
[2022-01-11 14:03:50,002][root][INFO] - Epoch: 13: Step: 1/920, loss=0.024803, lr=0.000007
[2022-01-11 14:05:27,643][root][INFO] - Train batch 100
[2022-01-11 14:05:27,643][root][INFO] - Avg. loss per last 100 batches: 0.035261
[2022-01-11 14:05:27,643][root][INFO] - Train batch 100
[2022-01-11 14:05:27,643][root][INFO] - Avg. loss per last 100 batches: 0.035261
[2022-01-11 14:05:27,645][root][INFO] - Train batch 100
[2022-01-11 14:05:27,645][root][INFO] - Avg. loss per last 100 batches: 0.035261
[2022-01-11 14:05:27,646][root][INFO] - Train batch 100
[2022-01-11 14:05:27,646][root][INFO] - Avg. loss per last 100 batches: 0.035261
[2022-01-11 14:05:28,633][root][INFO] - Epoch: 13: Step: 101/920, loss=0.005679, lr=0.000007
[2022-01-11 14:05:28,634][root][INFO] - Epoch: 13: Step: 101/920, loss=0.005679, lr=0.000007
[2022-01-11 14:05:28,634][root][INFO] - Epoch: 13: Step: 101/920, loss=0.005679, lr=0.000007
[2022-01-11 14:05:28,635][root][INFO] - Epoch: 13: Step: 101/920, loss=0.005679, lr=0.000007
[2022-01-11 14:07:07,869][root][INFO] - Train batch 200
[2022-01-11 14:07:07,869][root][INFO] - Avg. loss per last 100 batches: 0.041267
[2022-01-11 14:07:07,869][root][INFO] - Train batch 200
[2022-01-11 14:07:07,870][root][INFO] - Avg. loss per last 100 batches: 0.041267
[2022-01-11 14:07:07,870][root][INFO] - Train batch 200
[2022-01-11 14:07:07,870][root][INFO] - Avg. loss per last 100 batches: 0.041267
[2022-01-11 14:07:07,870][root][INFO] - Train batch 200
[2022-01-11 14:07:07,870][root][INFO] - Avg. loss per last 100 batches: 0.041267
[2022-01-11 14:07:08,922][root][INFO] - Epoch: 13: Step: 201/920, loss=0.032244, lr=0.000007
[2022-01-11 14:07:08,928][root][INFO] - Epoch: 13: Step: 201/920, loss=0.032244, lr=0.000007
[2022-01-11 14:07:08,928][root][INFO] - Epoch: 13: Step: 201/920, loss=0.032244, lr=0.000007
[2022-01-11 14:07:08,929][root][INFO] - Epoch: 13: Step: 201/920, loss=0.032244, lr=0.000007
[2022-01-11 14:08:44,884][root][INFO] - Train batch 300
[2022-01-11 14:08:44,884][root][INFO] - Avg. loss per last 100 batches: 0.036826
[2022-01-11 14:08:44,884][root][INFO] - Train batch 300
[2022-01-11 14:08:44,884][root][INFO] - Avg. loss per last 100 batches: 0.036826
[2022-01-11 14:08:44,884][root][INFO] - Train batch 300
[2022-01-11 14:08:44,885][root][INFO] - Avg. loss per last 100 batches: 0.036826
[2022-01-11 14:08:44,884][root][INFO] - Train batch 300
[2022-01-11 14:08:44,885][root][INFO] - Avg. loss per last 100 batches: 0.036826
[2022-01-11 14:08:45,739][root][INFO] - Epoch: 13: Step: 301/920, loss=0.027475, lr=0.000007
[2022-01-11 14:08:45,741][root][INFO] - Epoch: 13: Step: 301/920, loss=0.027475, lr=0.000007
[2022-01-11 14:08:45,743][root][INFO] - Epoch: 13: Step: 301/920, loss=0.027475, lr=0.000007
[2022-01-11 14:08:45,744][root][INFO] - Epoch: 13: Step: 301/920, loss=0.027475, lr=0.000007
[2022-01-11 14:10:25,281][root][INFO] - Train batch 400
[2022-01-11 14:10:25,281][root][INFO] - Avg. loss per last 100 batches: 0.038246
[2022-01-11 14:10:25,281][root][INFO] - Train batch 400
[2022-01-11 14:10:25,281][root][INFO] - Avg. loss per last 100 batches: 0.038246
[2022-01-11 14:10:25,283][root][INFO] - Train batch 400
[2022-01-11 14:10:25,283][root][INFO] - Avg. loss per last 100 batches: 0.038246
[2022-01-11 14:10:25,295][root][INFO] - Train batch 400
[2022-01-11 14:10:25,295][root][INFO] - Avg. loss per last 100 batches: 0.038246
[2022-01-11 14:10:26,344][root][INFO] - Epoch: 13: Step: 401/920, loss=0.049099, lr=0.000007
[2022-01-11 14:10:26,344][root][INFO] - Epoch: 13: Step: 401/920, loss=0.049099, lr=0.000007
[2022-01-11 14:10:26,346][root][INFO] - Epoch: 13: Step: 401/920, loss=0.049099, lr=0.000007
[2022-01-11 14:10:26,347][root][INFO] - Epoch: 13: Step: 401/920, loss=0.049099, lr=0.000007
[2022-01-11 14:12:03,536][root][INFO] - Train batch 500
[2022-01-11 14:12:03,536][root][INFO] - Avg. loss per last 100 batches: 0.040223
[2022-01-11 14:12:03,536][root][INFO] - Train batch 500
[2022-01-11 14:12:03,537][root][INFO] - Avg. loss per last 100 batches: 0.040223
[2022-01-11 14:12:03,537][root][INFO] - Train batch 500
[2022-01-11 14:12:03,537][root][INFO] - Avg. loss per last 100 batches: 0.040223
[2022-01-11 14:12:03,539][root][INFO] - Train batch 500
[2022-01-11 14:12:03,539][root][INFO] - Avg. loss per last 100 batches: 0.040223
[2022-01-11 14:12:04,587][root][INFO] - Epoch: 13: Step: 501/920, loss=0.025211, lr=0.000007
[2022-01-11 14:12:04,588][root][INFO] - Epoch: 13: Step: 501/920, loss=0.025211, lr=0.000007
[2022-01-11 14:12:04,589][root][INFO] - Epoch: 13: Step: 501/920, loss=0.025211, lr=0.000007
[2022-01-11 14:12:04,591][root][INFO] - Epoch: 13: Step: 501/920, loss=0.025211, lr=0.000007
[2022-01-11 14:13:40,709][root][INFO] - Train batch 600
[2022-01-11 14:13:40,709][root][INFO] - Avg. loss per last 100 batches: 0.039419
[2022-01-11 14:13:40,709][root][INFO] - Train batch 600
[2022-01-11 14:13:40,709][root][INFO] - Avg. loss per last 100 batches: 0.039419
[2022-01-11 14:13:40,711][root][INFO] - Train batch 600
[2022-01-11 14:13:40,711][root][INFO] - Avg. loss per last 100 batches: 0.039419
[2022-01-11 14:13:40,711][root][INFO] - Train batch 600
[2022-01-11 14:13:40,711][root][INFO] - Avg. loss per last 100 batches: 0.039419
[2022-01-11 14:13:41,719][root][INFO] - Epoch: 13: Step: 601/920, loss=0.026226, lr=0.000007
[2022-01-11 14:13:41,719][root][INFO] - Epoch: 13: Step: 601/920, loss=0.026226, lr=0.000007
[2022-01-11 14:13:41,720][root][INFO] - Epoch: 13: Step: 601/920, loss=0.026226, lr=0.000007
[2022-01-11 14:13:41,720][root][INFO] - Epoch: 13: Step: 601/920, loss=0.026226, lr=0.000007
[2022-01-11 14:15:20,895][root][INFO] - Train batch 700
[2022-01-11 14:15:20,895][root][INFO] - Avg. loss per last 100 batches: 0.039320
[2022-01-11 14:15:20,899][root][INFO] - Train batch 700
[2022-01-11 14:15:20,899][root][INFO] - Avg. loss per last 100 batches: 0.039320
[2022-01-11 14:15:20,899][root][INFO] - Train batch 700
[2022-01-11 14:15:20,900][root][INFO] - Avg. loss per last 100 batches: 0.039320
[2022-01-11 14:15:20,900][root][INFO] - Train batch 700
[2022-01-11 14:15:20,901][root][INFO] - Avg. loss per last 100 batches: 0.039320
[2022-01-11 14:15:21,795][root][INFO] - Epoch: 13: Step: 701/920, loss=0.010595, lr=0.000007
[2022-01-11 14:15:21,796][root][INFO] - Epoch: 13: Step: 701/920, loss=0.010595, lr=0.000007
[2022-01-11 14:15:21,797][root][INFO] - Epoch: 13: Step: 701/920, loss=0.010595, lr=0.000007
[2022-01-11 14:15:21,797][root][INFO] - Epoch: 13: Step: 701/920, loss=0.010595, lr=0.000007
[2022-01-11 14:17:00,850][root][INFO] - Train batch 800
[2022-01-11 14:17:00,850][root][INFO] - Avg. loss per last 100 batches: 0.042068
[2022-01-11 14:17:00,853][root][INFO] - Train batch 800
[2022-01-11 14:17:00,853][root][INFO] - Avg. loss per last 100 batches: 0.042068
[2022-01-11 14:17:00,861][root][INFO] - Train batch 800
[2022-01-11 14:17:00,861][root][INFO] - Avg. loss per last 100 batches: 0.042068
[2022-01-11 14:17:00,876][root][INFO] - Train batch 800
[2022-01-11 14:17:00,876][root][INFO] - Avg. loss per last 100 batches: 0.042068
[2022-01-11 14:17:01,746][root][INFO] - Epoch: 13: Step: 801/920, loss=0.073822, lr=0.000007
[2022-01-11 14:17:01,750][root][INFO] - Epoch: 13: Step: 801/920, loss=0.073822, lr=0.000007
[2022-01-11 14:17:01,751][root][INFO] - Epoch: 13: Step: 801/920, loss=0.073822, lr=0.000007
[2022-01-11 14:17:01,764][root][INFO] - Epoch: 13: Step: 801/920, loss=0.073822, lr=0.000007
[2022-01-11 14:18:38,311][root][INFO] - Train batch 900
[2022-01-11 14:18:38,311][root][INFO] - Avg. loss per last 100 batches: 0.042339
[2022-01-11 14:18:38,312][root][INFO] - Train batch 900
[2022-01-11 14:18:38,312][root][INFO] - Avg. loss per last 100 batches: 0.042339
[2022-01-11 14:18:38,313][root][INFO] - Train batch 900
[2022-01-11 14:18:38,313][root][INFO] - Avg. loss per last 100 batches: 0.042339
[2022-01-11 14:18:38,315][root][INFO] - Train batch 900
[2022-01-11 14:18:38,315][root][INFO] - Avg. loss per last 100 batches: 0.042339
[2022-01-11 14:18:39,366][root][INFO] - Epoch: 13: Step: 901/920, loss=0.031827, lr=0.000007
[2022-01-11 14:18:39,367][root][INFO] - Epoch: 13: Step: 901/920, loss=0.031827, lr=0.000007
[2022-01-11 14:18:39,367][root][INFO] - Epoch: 13: Step: 901/920, loss=0.031827, lr=0.000007
[2022-01-11 14:18:39,369][root][INFO] - Epoch: 13: Step: 901/920, loss=0.031827, lr=0.000007
[2022-01-11 14:18:58,066][root][INFO] - rank=0, Validation: Epoch: 13 Step: 920/920
[2022-01-11 14:18:58,066][root][INFO] - NLL validation ...
[2022-01-11 14:18:58,067][root][INFO] - rank=2, Validation: Epoch: 13 Step: 920/920
[2022-01-11 14:18:58,067][root][INFO] - NLL validation ...
[2022-01-11 14:18:58,067][root][INFO] - rank=1, Validation: Epoch: 13 Step: 920/920
[2022-01-11 14:18:58,068][root][INFO] - rank=0; Iteration start
[2022-01-11 14:18:58,068][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:18:58,068][root][INFO] - NLL validation ...
[2022-01-11 14:18:58,068][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:18:58,068][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 14:18:58,068][root][INFO] - rank=2; Iteration start
[2022-01-11 14:18:58,068][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:18:58,068][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:18:58,068][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 14:18:58,069][root][INFO] - rank=1; Iteration start
[2022-01-11 14:18:58,069][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:18:58,069][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:18:58,069][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 14:18:58,071][root][INFO] - rank=3, Validation: Epoch: 13 Step: 920/920
[2022-01-11 14:18:58,071][root][INFO] - NLL validation ...
[2022-01-11 14:18:58,073][root][INFO] - rank=3; Iteration start
[2022-01-11 14:18:58,073][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:18:58,073][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:18:58,073][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 14:18:58,078][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 14:18:58,078][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 14:18:58,079][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 14:18:58,083][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 14:18:58,820][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 14:18:58,821][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 14:18:58,821][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 14:18:58,821][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 14:18:59,560][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 14:18:59,560][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 14:18:59,561][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 14:19:00,529][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 14:19:01,260][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 14:19:01,260][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 14:19:01,260][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 14:19:01,260][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 14:19:01,998][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 14:19:01,998][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 14:19:01,998][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 14:19:01,999][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 14:19:02,739][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 14:19:02,740][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 14:19:02,740][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 14:19:02,740][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 14:19:03,479][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 14:19:03,479][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 14:19:03,479][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 14:19:03,480][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 14:19:04,215][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 14:19:05,163][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 14:19:05,193][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 14:19:05,232][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 14:19:05,969][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 14:19:05,969][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 14:19:05,969][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 14:19:05,972][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 14:19:06,710][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 14:19:06,711][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 14:19:06,711][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 14:19:06,711][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 14:19:07,448][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 14:19:07,448][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 14:19:07,448][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 14:19:07,449][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 14:19:08,187][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 14:19:08,187][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 14:19:08,187][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 14:19:08,187][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 14:19:08,925][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 14:19:08,925][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 14:19:08,925][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 14:19:08,925][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 14:19:09,667][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 14:19:09,669][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 14:19:09,669][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 14:19:09,669][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 14:19:10,406][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 14:19:10,406][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 14:19:10,406][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 14:19:10,406][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 14:19:11,143][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 14:19:11,143][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 14:19:11,143][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 14:19:11,746][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 14:19:12,480][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 14:19:12,480][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 14:19:12,480][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 14:19:12,480][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 14:19:13,219][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 14:19:13,219][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 14:19:13,219][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 14:19:13,219][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 14:19:13,955][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 14:19:13,955][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 14:19:13,955][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 14:19:13,955][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 14:19:14,695][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 14:19:14,697][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 14:19:14,698][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 14:19:14,698][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 14:19:15,434][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 14:19:15,434][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 14:19:15,434][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 14:19:15,436][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 14:19:16,173][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 14:19:16,757][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 14:19:16,785][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 14:19:16,996][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 14:19:17,738][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 14:19:17,740][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 14:19:17,740][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 14:19:17,741][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 14:19:18,479][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 14:19:18,479][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 14:19:18,480][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 14:19:18,480][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 14:19:19,216][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 14:19:19,217][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 14:19:19,217][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 14:19:19,217][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 14:19:19,943][root][INFO] - rank=1; last iteration 25
[2022-01-11 14:19:19,943][root][INFO] - rank=0; last iteration 25
[2022-01-11 14:19:19,943][root][INFO] - rank=3; last iteration 25
[2022-01-11 14:19:19,943][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:19:19,943][root][INFO] - rank=2; last iteration 25
[2022-01-11 14:19:19,943][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:19:19,943][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 14:19:19,943][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:19:19,943][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:19:19,943][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 14:19:19,943][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 14:19:19,943][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:19,943][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 14:19:19,943][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:19,943][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:19,943][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:19,943][root][INFO] - NLL Validation: loss = 0.384897. correct prediction ratio  5706/6400 ~  0.891563
[2022-01-11 14:19:19,944][root][INFO] - NLL Validation: loss = 0.384897. correct prediction ratio  5706/6400 ~  0.891563
[2022-01-11 14:19:19,944][root][INFO] - NLL Validation: loss = 0.384897. correct prediction ratio  5706/6400 ~  0.891563
[2022-01-11 14:19:19,944][root][INFO] - NLL Validation: loss = 0.384897. correct prediction ratio  5706/6400 ~  0.891563
[2022-01-11 14:19:19,946][root][INFO] - rank=1; last iteration 920
[2022-01-11 14:19:19,946][root][INFO] - rank=3; last iteration 920
[2022-01-11 14:19:19,946][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:19:19,946][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:19:19,946][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 14:19:19,946][root][INFO] - rank=2; last iteration 920
[2022-01-11 14:19:19,946][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 14:19:19,946][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:19:19,946][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 14:19:19,946][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:19,947][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:19,947][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:19,947][root][INFO] - Epoch finished on 1
[2022-01-11 14:19:19,947][root][INFO] - Epoch finished on 3
[2022-01-11 14:19:19,947][root][INFO] - Epoch finished on 2
[2022-01-11 14:19:19,947][root][INFO] - NLL validation ...
[2022-01-11 14:19:19,947][root][INFO] - NLL validation ...
[2022-01-11 14:19:19,947][root][INFO] - NLL validation ...
[2022-01-11 14:19:19,948][root][INFO] - rank=1; Iteration start
[2022-01-11 14:19:19,948][root][INFO] - rank=3; Iteration start
[2022-01-11 14:19:19,948][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:19:19,948][root][INFO] - rank=2; Iteration start
[2022-01-11 14:19:19,948][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:19:19,948][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:19:19,948][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:19:19,948][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:19:19,948][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 14:19:19,948][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:19:19,948][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 14:19:19,948][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 14:19:19,955][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 14:19:19,956][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 14:19:19,956][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 14:19:23,649][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.13
[2022-01-11 14:19:23,649][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.13
[2022-01-11 14:19:23,650][root][INFO] - rank=0; last iteration 920
[2022-01-11 14:19:23,651][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:19:23,651][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 14:19:23,651][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:23,651][root][INFO] - Epoch finished on 0
[2022-01-11 14:19:23,651][root][INFO] - NLL validation ...
[2022-01-11 14:19:23,652][root][INFO] - rank=0; Iteration start
[2022-01-11 14:19:23,653][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:19:23,653][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:19:23,653][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 14:19:23,661][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 14:19:24,405][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 14:19:24,405][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 14:19:24,405][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 14:19:24,406][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 14:19:25,140][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 14:19:25,140][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 14:19:25,141][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 14:19:25,144][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 14:19:25,875][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 14:19:25,875][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 14:19:25,875][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 14:19:25,876][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 14:19:26,613][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 14:19:26,615][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 14:19:26,615][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 14:19:27,274][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 14:19:28,003][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 14:19:28,003][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 14:19:28,003][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 14:19:28,003][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 14:19:28,739][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 14:19:28,740][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 14:19:28,740][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 14:19:28,741][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 14:19:29,478][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 14:19:29,479][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 14:19:29,479][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 14:19:29,481][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 14:19:30,216][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 14:19:30,216][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 14:19:30,216][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 14:19:30,217][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 14:19:30,951][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 14:19:31,566][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 14:19:31,574][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 14:19:31,577][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 14:19:32,308][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 14:19:32,308][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 14:19:32,308][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 14:19:32,310][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 14:19:33,043][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 14:19:33,044][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 14:19:33,044][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 14:19:33,045][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 14:19:33,779][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 14:19:33,780][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 14:19:33,780][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 14:19:33,781][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 14:19:34,520][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 14:19:34,521][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 14:19:34,522][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 14:19:34,523][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 14:19:35,258][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 14:19:35,258][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 14:19:35,258][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 14:19:35,260][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 14:19:35,993][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 14:19:35,993][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 14:19:35,995][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 14:19:35,996][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 14:19:36,727][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 14:19:36,728][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 14:19:36,729][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 14:19:36,729][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 14:19:37,467][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 14:19:37,468][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 14:19:37,469][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 14:19:37,470][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 14:19:38,203][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 14:19:38,204][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 14:19:38,205][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 14:19:39,048][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 14:19:39,780][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 14:19:39,780][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 14:19:39,781][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 14:19:39,782][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 14:19:40,518][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 14:19:40,518][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 14:19:40,518][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 14:19:40,520][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 14:19:41,254][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 14:19:41,255][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 14:19:41,256][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 14:19:41,257][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 14:19:41,991][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 14:19:41,992][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 14:19:41,992][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 14:19:41,993][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 14:19:42,732][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 14:19:43,343][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 14:19:43,350][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 14:19:43,462][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 14:19:44,194][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 14:19:44,195][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 14:19:44,196][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 14:19:44,197][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 14:19:44,925][root][INFO] - rank=1; last iteration 25
[2022-01-11 14:19:44,925][root][INFO] - rank=3; last iteration 25
[2022-01-11 14:19:44,925][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:19:44,925][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:19:44,925][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 14:19:44,925][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 14:19:44,925][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:44,925][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:44,925][root][INFO] - NLL Validation: loss = 0.384897. correct prediction ratio  5706/6400 ~  0.891563
[2022-01-11 14:19:44,925][root][INFO] - NLL Validation: loss = 0.384897. correct prediction ratio  5706/6400 ~  0.891563
[2022-01-11 14:19:44,925][root][INFO] - rank=2; last iteration 25
[2022-01-11 14:19:44,925][root][INFO] - rank=0; last iteration 25
[2022-01-11 14:19:44,925][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:19:44,925][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 14:19:44,925][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:19:44,926][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 14:19:44,926][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:44,926][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:19:44,926][root][INFO] - NLL Validation: loss = 0.384897. correct prediction ratio  5706/6400 ~  0.891563
[2022-01-11 14:19:44,926][root][INFO] - NLL Validation: loss = 0.384897. correct prediction ratio  5706/6400 ~  0.891563
[2022-01-11 14:19:44,926][root][INFO] - Av Loss per epoch=0.039319
[2022-01-11 14:19:44,926][root][INFO] - Av Loss per epoch=0.039319
[2022-01-11 14:19:44,927][root][INFO] - epoch total correct predictions=58011
[2022-01-11 14:19:44,927][root][INFO] - epoch total correct predictions=58011
[2022-01-11 14:19:44,927][root][INFO] - Av Loss per epoch=0.039319
[2022-01-11 14:19:44,927][root][INFO] - epoch total correct predictions=58011
[2022-01-11 14:19:44,928][root][INFO] - ***** Epoch 14 *****
[2022-01-11 14:19:44,928][root][INFO] - ***** Epoch 14 *****
[2022-01-11 14:19:44,929][root][INFO] - ***** Epoch 14 *****
[2022-01-11 14:19:44,930][root][INFO] - rank=3; Iteration start
[2022-01-11 14:19:44,930][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:19:44,930][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:19:44,930][root][INFO] - rank=1; Iteration start
[2022-01-11 14:19:44,930][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:19:44,930][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:19:44,930][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 14:19:44,930][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 14:19:44,930][root][INFO] - rank=2; Iteration start
[2022-01-11 14:19:44,930][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:19:44,931][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:19:44,931][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 14:19:49,760][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.13
[2022-01-11 14:19:49,761][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.13
[2022-01-11 14:19:49,761][root][INFO] - Av Loss per epoch=0.039319
[2022-01-11 14:19:49,761][root][INFO] - epoch total correct predictions=58011
[2022-01-11 14:19:49,763][root][INFO] - ***** Epoch 14 *****
[2022-01-11 14:19:49,766][root][INFO] - rank=0; Iteration start
[2022-01-11 14:19:49,766][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:19:49,766][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:19:49,766][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 14:19:50,750][root][INFO] - Epoch: 14: Step: 1/920, loss=0.024780, lr=0.000007
[2022-01-11 14:19:50,752][root][INFO] - Epoch: 14: Step: 1/920, loss=0.024780, lr=0.000007
[2022-01-11 14:19:50,752][root][INFO] - Epoch: 14: Step: 1/920, loss=0.024780, lr=0.000007
[2022-01-11 14:19:50,753][root][INFO] - Epoch: 14: Step: 1/920, loss=0.024780, lr=0.000007
[2022-01-11 14:21:28,767][root][INFO] - Train batch 100
[2022-01-11 14:21:28,767][root][INFO] - Avg. loss per last 100 batches: 0.035473
[2022-01-11 14:21:28,780][root][INFO] - Train batch 100
[2022-01-11 14:21:28,780][root][INFO] - Avg. loss per last 100 batches: 0.035473
[2022-01-11 14:21:28,781][root][INFO] - Train batch 100
[2022-01-11 14:21:28,781][root][INFO] - Avg. loss per last 100 batches: 0.035473
[2022-01-11 14:21:28,781][root][INFO] - Train batch 100
[2022-01-11 14:21:28,782][root][INFO] - Avg. loss per last 100 batches: 0.035473
[2022-01-11 14:21:29,823][root][INFO] - Epoch: 14: Step: 101/920, loss=0.048850, lr=0.000007
[2022-01-11 14:21:29,836][root][INFO] - Epoch: 14: Step: 101/920, loss=0.048850, lr=0.000007
[2022-01-11 14:21:29,838][root][INFO] - Epoch: 14: Step: 101/920, loss=0.048850, lr=0.000007
[2022-01-11 14:21:29,838][root][INFO] - Epoch: 14: Step: 101/920, loss=0.048850, lr=0.000007
[2022-01-11 14:23:07,673][root][INFO] - Train batch 200
[2022-01-11 14:23:07,673][root][INFO] - Avg. loss per last 100 batches: 0.036159
[2022-01-11 14:23:07,677][root][INFO] - Train batch 200
[2022-01-11 14:23:07,677][root][INFO] - Avg. loss per last 100 batches: 0.036159
[2022-01-11 14:23:07,678][root][INFO] - Train batch 200
[2022-01-11 14:23:07,678][root][INFO] - Avg. loss per last 100 batches: 0.036159
[2022-01-11 14:23:07,678][root][INFO] - Train batch 200
[2022-01-11 14:23:07,678][root][INFO] - Avg. loss per last 100 batches: 0.036159
[2022-01-11 14:23:08,528][root][INFO] - Epoch: 14: Step: 201/920, loss=0.178060, lr=0.000007
[2022-01-11 14:23:08,528][root][INFO] - Epoch: 14: Step: 201/920, loss=0.178060, lr=0.000007
[2022-01-11 14:23:08,529][root][INFO] - Epoch: 14: Step: 201/920, loss=0.178060, lr=0.000007
[2022-01-11 14:23:08,529][root][INFO] - Epoch: 14: Step: 201/920, loss=0.178060, lr=0.000007
[2022-01-11 14:24:46,181][root][INFO] - Train batch 300
[2022-01-11 14:24:46,181][root][INFO] - Avg. loss per last 100 batches: 0.038149
[2022-01-11 14:24:46,183][root][INFO] - Train batch 300
[2022-01-11 14:24:46,183][root][INFO] - Avg. loss per last 100 batches: 0.038149
[2022-01-11 14:24:46,183][root][INFO] - Train batch 300
[2022-01-11 14:24:46,183][root][INFO] - Avg. loss per last 100 batches: 0.038149
[2022-01-11 14:24:46,195][root][INFO] - Train batch 300
[2022-01-11 14:24:46,195][root][INFO] - Avg. loss per last 100 batches: 0.038149
[2022-01-11 14:24:47,238][root][INFO] - Epoch: 14: Step: 301/920, loss=0.156118, lr=0.000007
[2022-01-11 14:24:47,239][root][INFO] - Epoch: 14: Step: 301/920, loss=0.156118, lr=0.000007
[2022-01-11 14:24:47,240][root][INFO] - Epoch: 14: Step: 301/920, loss=0.156118, lr=0.000007
[2022-01-11 14:24:47,254][root][INFO] - Epoch: 14: Step: 301/920, loss=0.156118, lr=0.000007
[2022-01-11 14:26:26,462][root][INFO] - Train batch 400
[2022-01-11 14:26:26,462][root][INFO] - Avg. loss per last 100 batches: 0.035801
[2022-01-11 14:26:26,463][root][INFO] - Train batch 400
[2022-01-11 14:26:26,463][root][INFO] - Avg. loss per last 100 batches: 0.035801
[2022-01-11 14:26:26,463][root][INFO] - Train batch 400
[2022-01-11 14:26:26,463][root][INFO] - Avg. loss per last 100 batches: 0.035801
[2022-01-11 14:26:26,464][root][INFO] - Train batch 400
[2022-01-11 14:26:26,464][root][INFO] - Avg. loss per last 100 batches: 0.035801
[2022-01-11 14:26:27,513][root][INFO] - Epoch: 14: Step: 401/920, loss=0.011294, lr=0.000007
[2022-01-11 14:26:27,514][root][INFO] - Epoch: 14: Step: 401/920, loss=0.011294, lr=0.000007
[2022-01-11 14:26:27,515][root][INFO] - Epoch: 14: Step: 401/920, loss=0.011294, lr=0.000007
[2022-01-11 14:26:27,516][root][INFO] - Epoch: 14: Step: 401/920, loss=0.011294, lr=0.000007
[2022-01-11 14:28:06,324][root][INFO] - Train batch 500
[2022-01-11 14:28:06,324][root][INFO] - Avg. loss per last 100 batches: 0.039335
[2022-01-11 14:28:06,337][root][INFO] - Train batch 500
[2022-01-11 14:28:06,338][root][INFO] - Avg. loss per last 100 batches: 0.039335
[2022-01-11 14:28:06,338][root][INFO] - Train batch 500
[2022-01-11 14:28:06,338][root][INFO] - Avg. loss per last 100 batches: 0.039335
[2022-01-11 14:28:06,340][root][INFO] - Train batch 500
[2022-01-11 14:28:06,340][root][INFO] - Avg. loss per last 100 batches: 0.039335
[2022-01-11 14:28:07,392][root][INFO] - Epoch: 14: Step: 501/920, loss=0.022735, lr=0.000007
[2022-01-11 14:28:07,392][root][INFO] - Epoch: 14: Step: 501/920, loss=0.022735, lr=0.000007
[2022-01-11 14:28:07,394][root][INFO] - Epoch: 14: Step: 501/920, loss=0.022735, lr=0.000007
[2022-01-11 14:28:07,395][root][INFO] - Epoch: 14: Step: 501/920, loss=0.022735, lr=0.000007
[2022-01-11 14:29:43,126][root][INFO] - Train batch 600
[2022-01-11 14:29:43,127][root][INFO] - Avg. loss per last 100 batches: 0.034245
[2022-01-11 14:29:43,140][root][INFO] - Train batch 600
[2022-01-11 14:29:43,140][root][INFO] - Avg. loss per last 100 batches: 0.034245
[2022-01-11 14:29:43,141][root][INFO] - Train batch 600
[2022-01-11 14:29:43,141][root][INFO] - Avg. loss per last 100 batches: 0.034245
[2022-01-11 14:29:43,143][root][INFO] - Train batch 600
[2022-01-11 14:29:43,143][root][INFO] - Avg. loss per last 100 batches: 0.034245
[2022-01-11 14:29:44,199][root][INFO] - Epoch: 14: Step: 601/920, loss=0.164380, lr=0.000007
[2022-01-11 14:29:44,200][root][INFO] - Epoch: 14: Step: 601/920, loss=0.164380, lr=0.000007
[2022-01-11 14:29:44,200][root][INFO] - Epoch: 14: Step: 601/920, loss=0.164380, lr=0.000007
[2022-01-11 14:29:44,200][root][INFO] - Epoch: 14: Step: 601/920, loss=0.164380, lr=0.000007
[2022-01-11 14:31:22,976][root][INFO] - Train batch 700
[2022-01-11 14:31:22,976][root][INFO] - Avg. loss per last 100 batches: 0.040300
[2022-01-11 14:31:22,981][root][INFO] - Train batch 700
[2022-01-11 14:31:22,981][root][INFO] - Avg. loss per last 100 batches: 0.040300
[2022-01-11 14:31:22,984][root][INFO] - Train batch 700
[2022-01-11 14:31:22,984][root][INFO] - Avg. loss per last 100 batches: 0.040300
[2022-01-11 14:31:22,985][root][INFO] - Train batch 700
[2022-01-11 14:31:22,985][root][INFO] - Avg. loss per last 100 batches: 0.040300
[2022-01-11 14:31:23,832][root][INFO] - Epoch: 14: Step: 701/920, loss=0.049149, lr=0.000007
[2022-01-11 14:31:23,833][root][INFO] - Epoch: 14: Step: 701/920, loss=0.049149, lr=0.000007
[2022-01-11 14:31:23,833][root][INFO] - Epoch: 14: Step: 701/920, loss=0.049149, lr=0.000007
[2022-01-11 14:31:23,834][root][INFO] - Epoch: 14: Step: 701/920, loss=0.049149, lr=0.000007
[2022-01-11 14:33:00,839][root][INFO] - Train batch 800
[2022-01-11 14:33:00,839][root][INFO] - Avg. loss per last 100 batches: 0.037084
[2022-01-11 14:33:00,839][root][INFO] - Train batch 800
[2022-01-11 14:33:00,839][root][INFO] - Avg. loss per last 100 batches: 0.037084
[2022-01-11 14:33:00,839][root][INFO] - Train batch 800
[2022-01-11 14:33:00,840][root][INFO] - Avg. loss per last 100 batches: 0.037084
[2022-01-11 14:33:00,839][root][INFO] - Train batch 800
[2022-01-11 14:33:00,840][root][INFO] - Avg. loss per last 100 batches: 0.037084
[2022-01-11 14:33:01,887][root][INFO] - Epoch: 14: Step: 801/920, loss=0.070007, lr=0.000007
[2022-01-11 14:33:01,889][root][INFO] - Epoch: 14: Step: 801/920, loss=0.070007, lr=0.000007
[2022-01-11 14:33:01,889][root][INFO] - Epoch: 14: Step: 801/920, loss=0.070007, lr=0.000007
[2022-01-11 14:33:01,889][root][INFO] - Epoch: 14: Step: 801/920, loss=0.070007, lr=0.000007
[2022-01-11 14:34:37,730][root][INFO] - Train batch 900
[2022-01-11 14:34:37,730][root][INFO] - Avg. loss per last 100 batches: 0.037802
[2022-01-11 14:34:37,730][root][INFO] - Train batch 900
[2022-01-11 14:34:37,730][root][INFO] - Avg. loss per last 100 batches: 0.037802
[2022-01-11 14:34:37,731][root][INFO] - Train batch 900
[2022-01-11 14:34:37,732][root][INFO] - Avg. loss per last 100 batches: 0.037802
[2022-01-11 14:34:37,732][root][INFO] - Train batch 900
[2022-01-11 14:34:37,732][root][INFO] - Avg. loss per last 100 batches: 0.037802
[2022-01-11 14:34:38,629][root][INFO] - Epoch: 14: Step: 901/920, loss=0.012359, lr=0.000007
[2022-01-11 14:34:38,630][root][INFO] - Epoch: 14: Step: 901/920, loss=0.012359, lr=0.000007
[2022-01-11 14:34:38,631][root][INFO] - Epoch: 14: Step: 901/920, loss=0.012359, lr=0.000007
[2022-01-11 14:34:38,632][root][INFO] - Epoch: 14: Step: 901/920, loss=0.012359, lr=0.000007
[2022-01-11 14:34:58,456][root][INFO] - rank=3, Validation: Epoch: 14 Step: 920/920
[2022-01-11 14:34:58,456][root][INFO] - NLL validation ...
[2022-01-11 14:34:58,457][root][INFO] - rank=0, Validation: Epoch: 14 Step: 920/920
[2022-01-11 14:34:58,457][root][INFO] - rank=3; Iteration start
[2022-01-11 14:34:58,457][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:34:58,457][root][INFO] - NLL validation ...
[2022-01-11 14:34:58,457][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:34:58,457][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 14:34:58,457][root][INFO] - rank=1, Validation: Epoch: 14 Step: 920/920
[2022-01-11 14:34:58,457][root][INFO] - rank=2, Validation: Epoch: 14 Step: 920/920
[2022-01-11 14:34:58,457][root][INFO] - NLL validation ...
[2022-01-11 14:34:58,458][root][INFO] - NLL validation ...
[2022-01-11 14:34:58,458][root][INFO] - rank=0; Iteration start
[2022-01-11 14:34:58,458][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:34:58,458][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:34:58,458][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 14:34:58,459][root][INFO] - rank=1; Iteration start
[2022-01-11 14:34:58,459][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:34:58,459][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:34:58,459][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 14:34:58,459][root][INFO] - rank=2; Iteration start
[2022-01-11 14:34:58,459][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:34:58,459][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:34:58,459][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 14:34:58,467][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 14:34:58,468][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 14:34:58,469][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 14:34:58,469][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 14:34:59,206][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 14:34:59,207][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 14:34:59,207][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 14:34:59,208][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 14:34:59,943][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 14:34:59,944][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 14:34:59,944][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 14:34:59,944][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 14:35:00,680][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 14:35:00,682][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 14:35:00,682][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 14:35:00,683][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 14:35:01,420][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 14:35:02,396][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 14:35:02,396][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 14:35:02,408][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 14:35:03,142][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 14:35:03,143][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 14:35:03,143][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 14:35:03,144][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 14:35:03,881][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 14:35:03,882][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 14:35:03,882][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 14:35:03,883][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 14:35:04,624][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 14:35:04,626][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 14:35:04,626][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 14:35:04,627][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 14:35:05,363][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 14:35:05,363][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 14:35:05,364][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 14:35:05,364][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 14:35:06,100][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 14:35:06,100][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 14:35:06,100][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 14:35:06,100][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 14:35:06,839][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 14:35:06,839][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 14:35:06,840][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 14:35:06,840][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 14:35:07,579][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 14:35:07,580][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 14:35:07,580][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 14:35:08,200][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 14:35:08,932][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 14:35:08,933][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 14:35:08,933][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 14:35:08,936][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 14:35:09,676][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 14:35:09,676][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 14:35:09,676][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 14:35:09,677][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 14:35:10,412][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 14:35:10,412][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 14:35:10,412][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 14:35:10,413][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 14:35:11,146][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 14:35:11,146][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 14:35:11,147][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 14:35:11,147][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 14:35:11,882][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 14:35:11,883][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 14:35:11,883][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 14:35:11,883][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 14:35:12,622][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 14:35:13,232][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 14:35:13,238][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 14:35:13,327][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 14:35:14,065][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 14:35:14,065][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 14:35:14,066][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 14:35:14,066][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 14:35:14,802][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 14:35:14,802][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 14:35:14,803][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 14:35:14,803][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 14:35:15,540][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 14:35:15,540][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 14:35:15,541][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 14:35:15,541][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 14:35:16,279][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 14:35:16,280][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 14:35:16,280][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 14:35:16,280][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 14:35:17,017][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 14:35:17,017][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 14:35:17,017][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 14:35:17,017][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 14:35:17,755][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 14:35:17,755][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 14:35:17,755][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 14:35:17,755][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 14:35:18,494][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 14:35:18,496][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 14:35:18,496][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 14:35:18,496][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 14:35:19,224][root][INFO] - rank=1; last iteration 25
[2022-01-11 14:35:19,224][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:35:19,224][root][INFO] - rank=3; last iteration 25
[2022-01-11 14:35:19,224][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 14:35:19,224][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:35:19,224][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:19,224][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 14:35:19,224][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:19,224][root][INFO] - NLL Validation: loss = 0.392881. correct prediction ratio  5708/6400 ~  0.891875
[2022-01-11 14:35:19,224][root][INFO] - NLL Validation: loss = 0.392881. correct prediction ratio  5708/6400 ~  0.891875
[2022-01-11 14:35:19,224][root][INFO] - rank=2; last iteration 25
[2022-01-11 14:35:19,224][root][INFO] - rank=0; last iteration 25
[2022-01-11 14:35:19,225][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:35:19,225][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 14:35:19,225][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:35:19,225][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 14:35:19,225][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:19,225][root][INFO] - NLL Validation: loss = 0.392881. correct prediction ratio  5708/6400 ~  0.891875
[2022-01-11 14:35:19,225][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:19,225][root][INFO] - NLL Validation: loss = 0.392881. correct prediction ratio  5708/6400 ~  0.891875
[2022-01-11 14:35:19,227][root][INFO] - rank=1; last iteration 920
[2022-01-11 14:35:19,227][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:35:19,227][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 14:35:19,227][root][INFO] - rank=3; last iteration 920
[2022-01-11 14:35:19,227][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:35:19,227][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 14:35:19,227][root][INFO] - rank=2; last iteration 920
[2022-01-11 14:35:19,227][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:35:19,227][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 14:35:19,227][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:19,227][root][INFO] - Epoch finished on 1
[2022-01-11 14:35:19,227][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:19,228][root][INFO] - NLL validation ...
[2022-01-11 14:35:19,228][root][INFO] - Epoch finished on 3
[2022-01-11 14:35:19,228][root][INFO] - NLL validation ...
[2022-01-11 14:35:19,228][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:19,228][root][INFO] - Epoch finished on 2
[2022-01-11 14:35:19,228][root][INFO] - NLL validation ...
[2022-01-11 14:35:19,229][root][INFO] - rank=1; Iteration start
[2022-01-11 14:35:19,229][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:35:19,229][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:35:19,229][root][INFO] - rank=3; Iteration start
[2022-01-11 14:35:19,229][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 14:35:19,229][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:35:19,229][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:35:19,229][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 14:35:19,229][root][INFO] - rank=2; Iteration start
[2022-01-11 14:35:19,229][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:35:19,229][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:35:19,229][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 14:35:19,237][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 14:35:19,237][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 14:35:19,238][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 14:35:23,297][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.14
[2022-01-11 14:35:23,297][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.14
[2022-01-11 14:35:23,299][root][INFO] - rank=0; last iteration 920
[2022-01-11 14:35:23,299][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:35:23,299][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 14:35:23,300][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:23,300][root][INFO] - Epoch finished on 0
[2022-01-11 14:35:23,300][root][INFO] - NLL validation ...
[2022-01-11 14:35:23,301][root][INFO] - rank=0; Iteration start
[2022-01-11 14:35:23,301][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:35:23,301][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:35:23,301][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 14:35:24,058][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 14:35:24,798][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 14:35:24,800][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 14:35:24,801][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 14:35:24,801][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 14:35:25,537][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 14:35:25,537][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 14:35:25,538][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 14:35:25,538][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 14:35:26,272][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 14:35:26,273][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 14:35:26,273][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 14:35:26,276][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 14:35:27,009][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 14:35:27,010][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 14:35:27,010][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 14:35:27,011][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 14:35:27,747][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 14:35:27,747][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 14:35:27,748][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 14:35:27,748][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 14:35:28,493][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 14:35:29,116][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 14:35:29,167][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 14:35:29,340][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 14:35:30,071][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 14:35:30,072][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 14:35:30,073][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 14:35:30,073][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 14:35:30,812][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 14:35:30,812][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 14:35:30,812][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 14:35:30,813][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 14:35:31,552][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 14:35:31,555][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 14:35:31,555][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 14:35:31,557][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 14:35:32,296][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 14:35:32,296][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 14:35:32,296][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 14:35:32,296][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 14:35:33,035][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 14:35:33,036][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 14:35:33,036][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 14:35:33,037][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 14:35:33,773][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 14:35:33,775][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 14:35:33,776][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 14:35:33,776][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 14:35:34,514][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 14:35:34,518][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 14:35:34,518][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 14:35:34,518][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 14:35:35,254][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 14:35:35,255][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 14:35:35,256][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 14:35:36,056][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 14:35:36,788][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 14:35:36,788][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 14:35:36,789][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 14:35:36,789][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 14:35:37,524][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 14:35:37,525][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 14:35:37,525][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 14:35:37,526][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 14:35:38,264][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 14:35:38,265][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 14:35:38,265][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 14:35:38,266][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 14:35:39,000][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 14:35:39,002][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 14:35:39,002][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 14:35:39,002][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 14:35:39,739][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 14:35:39,740][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 14:35:39,741][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 14:35:39,741][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 14:35:40,483][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 14:35:41,086][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 14:35:41,342][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 14:35:41,345][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 14:35:42,078][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 14:35:42,078][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 14:35:42,079][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 14:35:42,081][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 14:35:42,815][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 14:35:42,815][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 14:35:42,816][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 14:35:42,816][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 14:35:43,553][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 14:35:43,553][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 14:35:43,554][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 14:35:43,554][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 14:35:44,290][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 14:35:44,292][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 14:35:44,293][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 14:35:44,293][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 14:35:45,019][root][INFO] - rank=0; last iteration 25
[2022-01-11 14:35:45,019][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:35:45,019][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 14:35:45,019][root][INFO] - rank=2; last iteration 25
[2022-01-11 14:35:45,019][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:45,020][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:35:45,020][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 14:35:45,020][root][INFO] - NLL Validation: loss = 0.392881. correct prediction ratio  5708/6400 ~  0.891875
[2022-01-11 14:35:45,020][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:45,020][root][INFO] - rank=3; last iteration 25
[2022-01-11 14:35:45,020][root][INFO] - rank=1; last iteration 25
[2022-01-11 14:35:45,020][root][INFO] - NLL Validation: loss = 0.392881. correct prediction ratio  5708/6400 ~  0.891875
[2022-01-11 14:35:45,020][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:35:45,020][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:35:45,020][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 14:35:45,020][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 14:35:45,020][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:45,020][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:35:45,020][root][INFO] - NLL Validation: loss = 0.392881. correct prediction ratio  5708/6400 ~  0.891875
[2022-01-11 14:35:45,020][root][INFO] - NLL Validation: loss = 0.392881. correct prediction ratio  5708/6400 ~  0.891875
[2022-01-11 14:35:45,021][root][INFO] - Av Loss per epoch=0.037120
[2022-01-11 14:35:45,021][root][INFO] - epoch total correct predictions=58039
[2022-01-11 14:35:45,021][root][INFO] - Av Loss per epoch=0.037120
[2022-01-11 14:35:45,021][root][INFO] - epoch total correct predictions=58039
[2022-01-11 14:35:45,021][root][INFO] - Av Loss per epoch=0.037120
[2022-01-11 14:35:45,021][root][INFO] - epoch total correct predictions=58039
[2022-01-11 14:35:45,023][root][INFO] - ***** Epoch 15 *****
[2022-01-11 14:35:45,023][root][INFO] - ***** Epoch 15 *****
[2022-01-11 14:35:45,023][root][INFO] - ***** Epoch 15 *****
[2022-01-11 14:35:45,024][root][INFO] - rank=2; Iteration start
[2022-01-11 14:35:45,025][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:35:45,025][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:35:45,025][root][INFO] - rank=1; Iteration start
[2022-01-11 14:35:45,025][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:35:45,025][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:35:45,025][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 14:35:45,025][root][INFO] - rank=3; Iteration start
[2022-01-11 14:35:45,025][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:35:45,025][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:35:45,025][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 14:35:45,026][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 14:35:50,145][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.14
[2022-01-11 14:35:50,145][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.14
[2022-01-11 14:35:50,145][root][INFO] - Av Loss per epoch=0.037120
[2022-01-11 14:35:50,145][root][INFO] - epoch total correct predictions=58039
[2022-01-11 14:35:50,147][root][INFO] - ***** Epoch 15 *****
[2022-01-11 14:35:50,149][root][INFO] - rank=0; Iteration start
[2022-01-11 14:35:50,149][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:35:50,149][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:35:50,150][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 14:35:51,066][root][INFO] - Epoch: 15: Step: 1/920, loss=0.015565, lr=0.000007
[2022-01-11 14:35:51,067][root][INFO] - Epoch: 15: Step: 1/920, loss=0.015565, lr=0.000007
[2022-01-11 14:35:51,067][root][INFO] - Epoch: 15: Step: 1/920, loss=0.015565, lr=0.000007
[2022-01-11 14:35:51,068][root][INFO] - Epoch: 15: Step: 1/920, loss=0.015565, lr=0.000007
[2022-01-11 14:37:28,465][root][INFO] - Train batch 100
[2022-01-11 14:37:28,465][root][INFO] - Avg. loss per last 100 batches: 0.037073
[2022-01-11 14:37:28,466][root][INFO] - Train batch 100
[2022-01-11 14:37:28,466][root][INFO] - Avg. loss per last 100 batches: 0.037073
[2022-01-11 14:37:28,466][root][INFO] - Train batch 100
[2022-01-11 14:37:28,466][root][INFO] - Avg. loss per last 100 batches: 0.037073
[2022-01-11 14:37:28,467][root][INFO] - Train batch 100
[2022-01-11 14:37:28,467][root][INFO] - Avg. loss per last 100 batches: 0.037073
[2022-01-11 14:37:29,511][root][INFO] - Epoch: 15: Step: 101/920, loss=0.016796, lr=0.000007
[2022-01-11 14:37:29,513][root][INFO] - Epoch: 15: Step: 101/920, loss=0.016796, lr=0.000007
[2022-01-11 14:37:29,513][root][INFO] - Epoch: 15: Step: 101/920, loss=0.016796, lr=0.000007
[2022-01-11 14:37:29,514][root][INFO] - Epoch: 15: Step: 101/920, loss=0.016796, lr=0.000007
[2022-01-11 14:39:06,661][root][INFO] - Train batch 200
[2022-01-11 14:39:06,661][root][INFO] - Avg. loss per last 100 batches: 0.033610
[2022-01-11 14:39:06,661][root][INFO] - Train batch 200
[2022-01-11 14:39:06,662][root][INFO] - Avg. loss per last 100 batches: 0.033610
[2022-01-11 14:39:06,663][root][INFO] - Train batch 200
[2022-01-11 14:39:06,663][root][INFO] - Avg. loss per last 100 batches: 0.033610
[2022-01-11 14:39:06,664][root][INFO] - Train batch 200
[2022-01-11 14:39:06,664][root][INFO] - Avg. loss per last 100 batches: 0.033610
[2022-01-11 14:39:07,691][root][INFO] - Epoch: 15: Step: 201/920, loss=0.090088, lr=0.000007
[2022-01-11 14:39:07,691][root][INFO] - Epoch: 15: Step: 201/920, loss=0.090088, lr=0.000007
[2022-01-11 14:39:07,691][root][INFO] - Epoch: 15: Step: 201/920, loss=0.090088, lr=0.000007
[2022-01-11 14:39:07,692][root][INFO] - Epoch: 15: Step: 201/920, loss=0.090088, lr=0.000007
[2022-01-11 14:40:47,368][root][INFO] - Train batch 300
[2022-01-11 14:40:47,368][root][INFO] - Avg. loss per last 100 batches: 0.036534
[2022-01-11 14:40:47,368][root][INFO] - Train batch 300
[2022-01-11 14:40:47,368][root][INFO] - Avg. loss per last 100 batches: 0.036534
[2022-01-11 14:40:47,368][root][INFO] - Train batch 300
[2022-01-11 14:40:47,368][root][INFO] - Avg. loss per last 100 batches: 0.036534
[2022-01-11 14:40:47,370][root][INFO] - Train batch 300
[2022-01-11 14:40:47,370][root][INFO] - Avg. loss per last 100 batches: 0.036534
[2022-01-11 14:40:48,423][root][INFO] - Epoch: 15: Step: 301/920, loss=0.010427, lr=0.000007
[2022-01-11 14:40:48,424][root][INFO] - Epoch: 15: Step: 301/920, loss=0.010427, lr=0.000007
[2022-01-11 14:40:48,425][root][INFO] - Epoch: 15: Step: 301/920, loss=0.010427, lr=0.000007
[2022-01-11 14:40:48,426][root][INFO] - Epoch: 15: Step: 301/920, loss=0.010427, lr=0.000007
[2022-01-11 14:42:27,023][root][INFO] - Train batch 400
[2022-01-11 14:42:27,023][root][INFO] - Avg. loss per last 100 batches: 0.036750
[2022-01-11 14:42:27,034][root][INFO] - Train batch 400
[2022-01-11 14:42:27,034][root][INFO] - Avg. loss per last 100 batches: 0.036750
[2022-01-11 14:42:27,036][root][INFO] - Train batch 400
[2022-01-11 14:42:27,036][root][INFO] - Avg. loss per last 100 batches: 0.036750
[2022-01-11 14:42:27,049][root][INFO] - Train batch 400
[2022-01-11 14:42:27,050][root][INFO] - Avg. loss per last 100 batches: 0.036750
[2022-01-11 14:42:28,060][root][INFO] - Epoch: 15: Step: 401/920, loss=0.015616, lr=0.000007
[2022-01-11 14:42:28,060][root][INFO] - Epoch: 15: Step: 401/920, loss=0.015616, lr=0.000007
[2022-01-11 14:42:28,061][root][INFO] - Epoch: 15: Step: 401/920, loss=0.015616, lr=0.000007
[2022-01-11 14:42:28,072][root][INFO] - Epoch: 15: Step: 401/920, loss=0.015616, lr=0.000007
[2022-01-11 14:44:04,045][root][INFO] - Train batch 500
[2022-01-11 14:44:04,045][root][INFO] - Avg. loss per last 100 batches: 0.030921
[2022-01-11 14:44:04,045][root][INFO] - Train batch 500
[2022-01-11 14:44:04,045][root][INFO] - Avg. loss per last 100 batches: 0.030921
[2022-01-11 14:44:04,046][root][INFO] - Train batch 500
[2022-01-11 14:44:04,047][root][INFO] - Avg. loss per last 100 batches: 0.030921
[2022-01-11 14:44:04,047][root][INFO] - Train batch 500
[2022-01-11 14:44:04,047][root][INFO] - Avg. loss per last 100 batches: 0.030921
[2022-01-11 14:44:05,088][root][INFO] - Epoch: 15: Step: 501/920, loss=0.056692, lr=0.000007
[2022-01-11 14:44:05,092][root][INFO] - Epoch: 15: Step: 501/920, loss=0.056692, lr=0.000007
[2022-01-11 14:44:05,092][root][INFO] - Epoch: 15: Step: 501/920, loss=0.056692, lr=0.000007
[2022-01-11 14:44:05,093][root][INFO] - Epoch: 15: Step: 501/920, loss=0.056692, lr=0.000007
[2022-01-11 14:45:44,127][root][INFO] - Train batch 600
[2022-01-11 14:45:44,127][root][INFO] - Avg. loss per last 100 batches: 0.038837
[2022-01-11 14:45:44,139][root][INFO] - Train batch 600
[2022-01-11 14:45:44,139][root][INFO] - Avg. loss per last 100 batches: 0.038837
[2022-01-11 14:45:44,139][root][INFO] - Train batch 600
[2022-01-11 14:45:44,140][root][INFO] - Avg. loss per last 100 batches: 0.038837
[2022-01-11 14:45:44,139][root][INFO] - Train batch 600
[2022-01-11 14:45:44,140][root][INFO] - Avg. loss per last 100 batches: 0.038837
[2022-01-11 14:45:45,106][root][INFO] - Epoch: 15: Step: 601/920, loss=0.008111, lr=0.000007
[2022-01-11 14:45:45,107][root][INFO] - Epoch: 15: Step: 601/920, loss=0.008111, lr=0.000007
[2022-01-11 14:45:45,107][root][INFO] - Epoch: 15: Step: 601/920, loss=0.008111, lr=0.000007
[2022-01-11 14:45:45,108][root][INFO] - Epoch: 15: Step: 601/920, loss=0.008111, lr=0.000007
[2022-01-11 14:47:24,587][root][INFO] - Train batch 700
[2022-01-11 14:47:24,587][root][INFO] - Avg. loss per last 100 batches: 0.036752
[2022-01-11 14:47:24,587][root][INFO] - Train batch 700
[2022-01-11 14:47:24,587][root][INFO] - Avg. loss per last 100 batches: 0.036752
[2022-01-11 14:47:24,587][root][INFO] - Train batch 700
[2022-01-11 14:47:24,587][root][INFO] - Train batch 700
[2022-01-11 14:47:24,587][root][INFO] - Avg. loss per last 100 batches: 0.036752
[2022-01-11 14:47:24,587][root][INFO] - Avg. loss per last 100 batches: 0.036752
[2022-01-11 14:47:25,645][root][INFO] - Epoch: 15: Step: 701/920, loss=0.003135, lr=0.000006
[2022-01-11 14:47:25,646][root][INFO] - Epoch: 15: Step: 701/920, loss=0.003135, lr=0.000006
[2022-01-11 14:47:25,647][root][INFO] - Epoch: 15: Step: 701/920, loss=0.003135, lr=0.000006
[2022-01-11 14:47:25,647][root][INFO] - Epoch: 15: Step: 701/920, loss=0.003135, lr=0.000006
[2022-01-11 14:49:02,195][root][INFO] - Train batch 800
[2022-01-11 14:49:02,196][root][INFO] - Avg. loss per last 100 batches: 0.039815
[2022-01-11 14:49:02,196][root][INFO] - Train batch 800
[2022-01-11 14:49:02,196][root][INFO] - Avg. loss per last 100 batches: 0.039815
[2022-01-11 14:49:02,196][root][INFO] - Train batch 800
[2022-01-11 14:49:02,197][root][INFO] - Avg. loss per last 100 batches: 0.039815
[2022-01-11 14:49:02,210][root][INFO] - Train batch 800
[2022-01-11 14:49:02,210][root][INFO] - Avg. loss per last 100 batches: 0.039815
[2022-01-11 14:49:03,085][root][INFO] - Epoch: 15: Step: 801/920, loss=0.057908, lr=0.000006
[2022-01-11 14:49:03,094][root][INFO] - Epoch: 15: Step: 801/920, loss=0.057908, lr=0.000006
[2022-01-11 14:49:03,094][root][INFO] - Epoch: 15: Step: 801/920, loss=0.057908, lr=0.000006
[2022-01-11 14:49:03,094][root][INFO] - Epoch: 15: Step: 801/920, loss=0.057908, lr=0.000006
[2022-01-11 14:50:41,691][root][INFO] - Train batch 900
[2022-01-11 14:50:41,691][root][INFO] - Avg. loss per last 100 batches: 0.039755
[2022-01-11 14:50:41,699][root][INFO] - Train batch 900
[2022-01-11 14:50:41,699][root][INFO] - Avg. loss per last 100 batches: 0.039755
[2022-01-11 14:50:41,700][root][INFO] - Train batch 900
[2022-01-11 14:50:41,700][root][INFO] - Train batch 900
[2022-01-11 14:50:41,700][root][INFO] - Avg. loss per last 100 batches: 0.039755
[2022-01-11 14:50:41,700][root][INFO] - Avg. loss per last 100 batches: 0.039755
[2022-01-11 14:50:42,748][root][INFO] - Epoch: 15: Step: 901/920, loss=0.245953, lr=0.000006
[2022-01-11 14:50:42,751][root][INFO] - Epoch: 15: Step: 901/920, loss=0.245953, lr=0.000006
[2022-01-11 14:50:42,754][root][INFO] - Epoch: 15: Step: 901/920, loss=0.245953, lr=0.000006
[2022-01-11 14:50:42,755][root][INFO] - Epoch: 15: Step: 901/920, loss=0.245953, lr=0.000006
[2022-01-11 14:51:00,139][root][INFO] - rank=0, Validation: Epoch: 15 Step: 920/920
[2022-01-11 14:51:00,139][root][INFO] - rank=1, Validation: Epoch: 15 Step: 920/920
[2022-01-11 14:51:00,139][root][INFO] - rank=3, Validation: Epoch: 15 Step: 920/920
[2022-01-11 14:51:00,139][root][INFO] - NLL validation ...
[2022-01-11 14:51:00,139][root][INFO] - NLL validation ...
[2022-01-11 14:51:00,139][root][INFO] - NLL validation ...
[2022-01-11 14:51:00,139][root][INFO] - rank=2, Validation: Epoch: 15 Step: 920/920
[2022-01-11 14:51:00,140][root][INFO] - NLL validation ...
[2022-01-11 14:51:00,141][root][INFO] - rank=0; Iteration start
[2022-01-11 14:51:00,141][root][INFO] - rank=1; Iteration start
[2022-01-11 14:51:00,141][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:00,141][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:00,141][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:51:00,141][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:51:00,141][root][INFO] - rank=3; Iteration start
[2022-01-11 14:51:00,141][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 14:51:00,141][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 14:51:00,141][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:00,141][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:51:00,141][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 14:51:00,141][root][INFO] - rank=2; Iteration start
[2022-01-11 14:51:00,141][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:00,141][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:51:00,141][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 14:51:00,151][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 14:51:01,123][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 14:51:01,134][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 14:51:01,136][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 14:51:01,878][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 14:51:01,879][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 14:51:01,879][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 14:51:01,880][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 14:51:02,615][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 14:51:02,615][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 14:51:02,616][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 14:51:02,616][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 14:51:03,352][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 14:51:03,352][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 14:51:03,352][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 14:51:03,352][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 14:51:04,087][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 14:51:04,087][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 14:51:04,088][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 14:51:04,088][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 14:51:04,827][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 14:51:04,827][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 14:51:04,828][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 14:51:04,828][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 14:51:05,585][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 14:51:05,587][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 14:51:05,591][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 14:51:06,489][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 14:51:07,220][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 14:51:07,220][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 14:51:07,220][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 14:51:07,220][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 14:51:07,958][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 14:51:07,959][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 14:51:07,959][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 14:51:07,959][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 14:51:08,695][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 14:51:08,695][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 14:51:08,696][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 14:51:08,696][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 14:51:09,436][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 14:51:09,437][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 14:51:09,437][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 14:51:09,437][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 14:51:10,176][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 14:51:10,177][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 14:51:10,178][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 14:51:10,179][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 14:51:10,920][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 14:51:10,920][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 14:51:10,921][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 14:51:10,921][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 14:51:11,659][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 14:51:11,660][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 14:51:11,660][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 14:51:11,661][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 14:51:12,406][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 14:51:13,012][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 14:51:13,051][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 14:51:13,070][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 14:51:13,809][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 14:51:13,809][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 14:51:13,809][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 14:51:13,811][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 14:51:14,544][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 14:51:14,544][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 14:51:14,545][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 14:51:14,545][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 14:51:15,285][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 14:51:15,287][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 14:51:15,287][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 14:51:15,288][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 14:51:16,024][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 14:51:16,024][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 14:51:16,025][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 14:51:16,025][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 14:51:16,764][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 14:51:16,764][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 14:51:16,764][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 14:51:16,764][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 14:51:17,502][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 14:51:17,502][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 14:51:17,502][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 14:51:18,288][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 14:51:19,020][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 14:51:19,020][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 14:51:19,020][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 14:51:19,020][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 14:51:19,759][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 14:51:19,759][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 14:51:19,759][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 14:51:19,759][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 14:51:20,499][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 14:51:20,499][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 14:51:20,499][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 14:51:20,499][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 14:51:21,236][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 14:51:21,237][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 14:51:21,238][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 14:51:21,240][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 14:51:21,964][root][INFO] - rank=2; last iteration 25
[2022-01-11 14:51:21,964][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:51:21,964][root][INFO] - rank=0; last iteration 25
[2022-01-11 14:51:21,964][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 14:51:21,964][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:51:21,964][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:21,964][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 14:51:21,964][root][INFO] - rank=3; last iteration 25
[2022-01-11 14:51:21,964][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:21,964][root][INFO] - NLL Validation: loss = 0.387431. correct prediction ratio  5677/6400 ~  0.887031
[2022-01-11 14:51:21,964][root][INFO] - rank=1; last iteration 25
[2022-01-11 14:51:21,964][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:51:21,965][root][INFO] - NLL Validation: loss = 0.387431. correct prediction ratio  5677/6400 ~  0.887031
[2022-01-11 14:51:21,965][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 14:51:21,965][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:51:21,965][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 14:51:21,965][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:21,965][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:21,965][root][INFO] - NLL Validation: loss = 0.387431. correct prediction ratio  5677/6400 ~  0.887031
[2022-01-11 14:51:21,965][root][INFO] - NLL Validation: loss = 0.387431. correct prediction ratio  5677/6400 ~  0.887031
[2022-01-11 14:51:21,967][root][INFO] - rank=2; last iteration 920
[2022-01-11 14:51:21,967][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:51:21,967][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 14:51:21,967][root][INFO] - rank=3; last iteration 920
[2022-01-11 14:51:21,967][root][INFO] - rank=1; last iteration 920
[2022-01-11 14:51:21,967][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:51:21,967][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:51:21,967][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 14:51:21,967][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 14:51:21,967][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:21,968][root][INFO] - Epoch finished on 2
[2022-01-11 14:51:21,968][root][INFO] - NLL validation ...
[2022-01-11 14:51:21,968][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:21,968][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:21,968][root][INFO] - Epoch finished on 3
[2022-01-11 14:51:21,968][root][INFO] - Epoch finished on 1
[2022-01-11 14:51:21,968][root][INFO] - NLL validation ...
[2022-01-11 14:51:21,968][root][INFO] - NLL validation ...
[2022-01-11 14:51:21,969][root][INFO] - rank=2; Iteration start
[2022-01-11 14:51:21,969][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:21,969][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:51:21,969][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 14:51:21,969][root][INFO] - rank=1; Iteration start
[2022-01-11 14:51:21,969][root][INFO] - rank=3; Iteration start
[2022-01-11 14:51:21,969][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:21,969][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:21,969][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:51:21,969][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:51:21,969][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 14:51:21,969][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 14:51:21,977][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 14:51:21,979][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 14:51:21,979][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 14:51:25,752][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.15
[2022-01-11 14:51:25,752][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.15
[2022-01-11 14:51:25,753][root][INFO] - rank=0; last iteration 920
[2022-01-11 14:51:25,753][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 14:51:25,753][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 14:51:25,754][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:25,754][root][INFO] - Epoch finished on 0
[2022-01-11 14:51:25,754][root][INFO] - NLL validation ...
[2022-01-11 14:51:25,755][root][INFO] - rank=0; Iteration start
[2022-01-11 14:51:25,755][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:25,755][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 14:51:25,755][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 14:51:25,764][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 14:51:26,506][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 14:51:26,506][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 14:51:26,508][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 14:51:26,509][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 14:51:27,243][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 14:51:27,244][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 14:51:27,246][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 14:51:27,247][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 14:51:27,980][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 14:51:28,608][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 14:51:28,882][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 14:51:28,882][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 14:51:29,616][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 14:51:29,616][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 14:51:29,617][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 14:51:29,618][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 14:51:30,353][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 14:51:30,353][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 14:51:30,354][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 14:51:30,355][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 14:51:31,091][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 14:51:31,091][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 14:51:31,092][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 14:51:31,093][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 14:51:31,828][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 14:51:31,830][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 14:51:31,830][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 14:51:31,830][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 14:51:32,566][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 14:51:32,567][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 14:51:32,568][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 14:51:32,568][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 14:51:33,304][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 14:51:33,305][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 14:51:33,305][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 14:51:33,305][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 14:51:34,043][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 14:51:34,043][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 14:51:34,044][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 14:51:34,641][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 14:51:35,370][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 14:51:35,372][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 14:51:35,372][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 14:51:35,372][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 14:51:36,113][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 14:51:36,115][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 14:51:36,115][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 14:51:36,115][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 14:51:36,852][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 14:51:36,852][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 14:51:36,852][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 14:51:36,852][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 14:51:37,587][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 14:51:37,587][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 14:51:37,587][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 14:51:37,588][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 14:51:38,322][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 14:51:38,322][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 14:51:38,322][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 14:51:38,325][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 14:51:39,062][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 14:51:39,062][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 14:51:39,062][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 14:51:39,063][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 14:51:39,798][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 14:51:40,406][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 14:51:40,408][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 14:51:40,472][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 14:51:41,211][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 14:51:41,211][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 14:51:41,211][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 14:51:41,212][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 14:51:41,947][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 14:51:41,947][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 14:51:41,947][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 14:51:41,948][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 14:51:42,683][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 14:51:42,684][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 14:51:42,684][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 14:51:42,684][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 14:51:43,420][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 14:51:43,421][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 14:51:43,421][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 14:51:43,421][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 14:51:44,160][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 14:51:44,160][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 14:51:44,160][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 14:51:44,161][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 14:51:44,900][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 14:51:44,900][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 14:51:44,900][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 14:51:44,900][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 14:51:45,636][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 14:51:45,636][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 14:51:45,637][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 14:51:46,250][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 14:51:46,971][root][INFO] - rank=3; last iteration 25
[2022-01-11 14:51:46,971][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:51:46,971][root][INFO] - rank=0; last iteration 25
[2022-01-11 14:51:46,971][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 14:51:46,971][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:51:46,971][root][INFO] - rank=2; last iteration 25
[2022-01-11 14:51:46,971][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:46,971][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 14:51:46,971][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:51:46,971][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:46,971][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 14:51:46,971][root][INFO] - NLL Validation: loss = 0.387431. correct prediction ratio  5677/6400 ~  0.887031
[2022-01-11 14:51:46,971][root][INFO] - rank=1; last iteration 25
[2022-01-11 14:51:46,971][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:46,971][root][INFO] - NLL Validation: loss = 0.387431. correct prediction ratio  5677/6400 ~  0.887031
[2022-01-11 14:51:46,971][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 14:51:46,971][root][INFO] - NLL Validation: loss = 0.387431. correct prediction ratio  5677/6400 ~  0.887031
[2022-01-11 14:51:46,971][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 14:51:46,971][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 14:51:46,971][root][INFO] - NLL Validation: loss = 0.387431. correct prediction ratio  5677/6400 ~  0.887031
[2022-01-11 14:51:46,972][root][INFO] - Av Loss per epoch=0.036932
[2022-01-11 14:51:46,972][root][INFO] - epoch total correct predictions=58065
[2022-01-11 14:51:46,973][root][INFO] - Av Loss per epoch=0.036932
[2022-01-11 14:51:46,973][root][INFO] - epoch total correct predictions=58065
[2022-01-11 14:51:46,973][root][INFO] - Av Loss per epoch=0.036932
[2022-01-11 14:51:46,973][root][INFO] - epoch total correct predictions=58065
[2022-01-11 14:51:46,974][root][INFO] - ***** Epoch 16 *****
[2022-01-11 14:51:46,975][root][INFO] - ***** Epoch 16 *****
[2022-01-11 14:51:46,975][root][INFO] - ***** Epoch 16 *****
[2022-01-11 14:51:46,976][root][INFO] - rank=3; Iteration start
[2022-01-11 14:51:46,976][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:46,976][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:51:46,976][root][INFO] - rank=2; Iteration start
[2022-01-11 14:51:46,976][root][INFO] - rank=1; Iteration start
[2022-01-11 14:51:46,976][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:46,976][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:46,976][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:51:46,976][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:51:46,976][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 14:51:46,977][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 14:51:46,977][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 14:51:51,869][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.15
[2022-01-11 14:51:51,870][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.15
[2022-01-11 14:51:51,870][root][INFO] - Av Loss per epoch=0.036932
[2022-01-11 14:51:51,870][root][INFO] - epoch total correct predictions=58065
[2022-01-11 14:51:51,872][root][INFO] - ***** Epoch 16 *****
[2022-01-11 14:51:51,874][root][INFO] - rank=0; Iteration start
[2022-01-11 14:51:51,874][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 14:51:51,874][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 14:51:51,874][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 14:51:52,864][root][INFO] - Epoch: 16: Step: 1/920, loss=0.082242, lr=0.000006
[2022-01-11 14:51:52,865][root][INFO] - Epoch: 16: Step: 1/920, loss=0.082242, lr=0.000006
[2022-01-11 14:51:52,866][root][INFO] - Epoch: 16: Step: 1/920, loss=0.082242, lr=0.000006
[2022-01-11 14:51:52,866][root][INFO] - Epoch: 16: Step: 1/920, loss=0.082242, lr=0.000006
[2022-01-11 14:53:30,588][root][INFO] - Train batch 100
[2022-01-11 14:53:30,589][root][INFO] - Avg. loss per last 100 batches: 0.033695
[2022-01-11 14:53:30,589][root][INFO] - Train batch 100
[2022-01-11 14:53:30,589][root][INFO] - Avg. loss per last 100 batches: 0.033695
[2022-01-11 14:53:30,590][root][INFO] - Train batch 100
[2022-01-11 14:53:30,590][root][INFO] - Avg. loss per last 100 batches: 0.033695
[2022-01-11 14:53:30,590][root][INFO] - Train batch 100
[2022-01-11 14:53:30,590][root][INFO] - Avg. loss per last 100 batches: 0.033695
[2022-01-11 14:53:31,435][root][INFO] - Epoch: 16: Step: 101/920, loss=0.053641, lr=0.000006
[2022-01-11 14:53:31,443][root][INFO] - Epoch: 16: Step: 101/920, loss=0.053641, lr=0.000006
[2022-01-11 14:53:31,443][root][INFO] - Epoch: 16: Step: 101/920, loss=0.053641, lr=0.000006
[2022-01-11 14:53:31,444][root][INFO] - Epoch: 16: Step: 101/920, loss=0.053641, lr=0.000006
[2022-01-11 14:55:08,675][root][INFO] - Train batch 200
[2022-01-11 14:55:08,675][root][INFO] - Avg. loss per last 100 batches: 0.031838
[2022-01-11 14:55:08,675][root][INFO] - Train batch 200
[2022-01-11 14:55:08,676][root][INFO] - Avg. loss per last 100 batches: 0.031838
[2022-01-11 14:55:08,677][root][INFO] - Train batch 200
[2022-01-11 14:55:08,677][root][INFO] - Avg. loss per last 100 batches: 0.031838
[2022-01-11 14:55:08,678][root][INFO] - Train batch 200
[2022-01-11 14:55:08,678][root][INFO] - Avg. loss per last 100 batches: 0.031838
[2022-01-11 14:55:09,528][root][INFO] - Epoch: 16: Step: 201/920, loss=0.040200, lr=0.000006
[2022-01-11 14:55:09,531][root][INFO] - Epoch: 16: Step: 201/920, loss=0.040200, lr=0.000006
[2022-01-11 14:55:09,532][root][INFO] - Epoch: 16: Step: 201/920, loss=0.040200, lr=0.000006
[2022-01-11 14:55:09,533][root][INFO] - Epoch: 16: Step: 201/920, loss=0.040200, lr=0.000006
[2022-01-11 14:56:48,793][root][INFO] - Train batch 300
[2022-01-11 14:56:48,793][root][INFO] - Avg. loss per last 100 batches: 0.030860
[2022-01-11 14:56:48,793][root][INFO] - Train batch 300
[2022-01-11 14:56:48,793][root][INFO] - Avg. loss per last 100 batches: 0.030860
[2022-01-11 14:56:48,793][root][INFO] - Train batch 300
[2022-01-11 14:56:48,794][root][INFO] - Avg. loss per last 100 batches: 0.030860
[2022-01-11 14:56:48,795][root][INFO] - Train batch 300
[2022-01-11 14:56:48,795][root][INFO] - Avg. loss per last 100 batches: 0.030860
[2022-01-11 14:56:49,810][root][INFO] - Epoch: 16: Step: 301/920, loss=0.016800, lr=0.000006
[2022-01-11 14:56:49,811][root][INFO] - Epoch: 16: Step: 301/920, loss=0.016800, lr=0.000006
[2022-01-11 14:56:49,812][root][INFO] - Epoch: 16: Step: 301/920, loss=0.016800, lr=0.000006
[2022-01-11 14:56:49,812][root][INFO] - Epoch: 16: Step: 301/920, loss=0.016800, lr=0.000006
[2022-01-11 14:58:28,516][root][INFO] - Train batch 400
[2022-01-11 14:58:28,516][root][INFO] - Avg. loss per last 100 batches: 0.030106
[2022-01-11 14:58:28,520][root][INFO] - Train batch 400
[2022-01-11 14:58:28,520][root][INFO] - Avg. loss per last 100 batches: 0.030106
[2022-01-11 14:58:28,520][root][INFO] - Train batch 400
[2022-01-11 14:58:28,520][root][INFO] - Avg. loss per last 100 batches: 0.030106
[2022-01-11 14:58:28,527][root][INFO] - Train batch 400
[2022-01-11 14:58:28,527][root][INFO] - Avg. loss per last 100 batches: 0.030106
[2022-01-11 14:58:30,341][root][INFO] - Epoch: 16: Step: 401/920, loss=0.079802, lr=0.000006
[2022-01-11 14:58:30,341][root][INFO] - Epoch: 16: Step: 401/920, loss=0.079802, lr=0.000006
[2022-01-11 14:58:30,344][root][INFO] - Epoch: 16: Step: 401/920, loss=0.079802, lr=0.000006
[2022-01-11 14:58:30,357][root][INFO] - Epoch: 16: Step: 401/920, loss=0.079802, lr=0.000006
[2022-01-11 15:00:07,102][root][INFO] - Train batch 500
[2022-01-11 15:00:07,102][root][INFO] - Avg. loss per last 100 batches: 0.031486
[2022-01-11 15:00:07,103][root][INFO] - Train batch 500
[2022-01-11 15:00:07,103][root][INFO] - Avg. loss per last 100 batches: 0.031486
[2022-01-11 15:00:07,103][root][INFO] - Train batch 500
[2022-01-11 15:00:07,103][root][INFO] - Avg. loss per last 100 batches: 0.031486
[2022-01-11 15:00:07,104][root][INFO] - Train batch 500
[2022-01-11 15:00:07,104][root][INFO] - Avg. loss per last 100 batches: 0.031486
[2022-01-11 15:00:08,029][root][INFO] - Epoch: 16: Step: 501/920, loss=0.036884, lr=0.000006
[2022-01-11 15:00:08,030][root][INFO] - Epoch: 16: Step: 501/920, loss=0.036884, lr=0.000006
[2022-01-11 15:00:08,030][root][INFO] - Epoch: 16: Step: 501/920, loss=0.036884, lr=0.000006
[2022-01-11 15:00:08,030][root][INFO] - Epoch: 16: Step: 501/920, loss=0.036884, lr=0.000006
[2022-01-11 15:01:45,752][root][INFO] - Train batch 600
[2022-01-11 15:01:45,752][root][INFO] - Avg. loss per last 100 batches: 0.027338
[2022-01-11 15:01:45,752][root][INFO] - Train batch 600
[2022-01-11 15:01:45,753][root][INFO] - Avg. loss per last 100 batches: 0.027338
[2022-01-11 15:01:45,753][root][INFO] - Train batch 600
[2022-01-11 15:01:45,753][root][INFO] - Avg. loss per last 100 batches: 0.027338
[2022-01-11 15:01:45,753][root][INFO] - Train batch 600
[2022-01-11 15:01:45,753][root][INFO] - Avg. loss per last 100 batches: 0.027338
[2022-01-11 15:01:46,677][root][INFO] - Epoch: 16: Step: 601/920, loss=0.004956, lr=0.000006
[2022-01-11 15:01:46,678][root][INFO] - Epoch: 16: Step: 601/920, loss=0.004956, lr=0.000006
[2022-01-11 15:01:46,678][root][INFO] - Epoch: 16: Step: 601/920, loss=0.004956, lr=0.000006
[2022-01-11 15:01:46,679][root][INFO] - Epoch: 16: Step: 601/920, loss=0.004956, lr=0.000006
[2022-01-11 15:03:26,427][root][INFO] - Train batch 700
[2022-01-11 15:03:26,427][root][INFO] - Avg. loss per last 100 batches: 0.035706
[2022-01-11 15:03:26,429][root][INFO] - Train batch 700
[2022-01-11 15:03:26,429][root][INFO] - Avg. loss per last 100 batches: 0.035706
[2022-01-11 15:03:26,429][root][INFO] - Train batch 700
[2022-01-11 15:03:26,429][root][INFO] - Avg. loss per last 100 batches: 0.035706
[2022-01-11 15:03:26,429][root][INFO] - Train batch 700
[2022-01-11 15:03:26,430][root][INFO] - Avg. loss per last 100 batches: 0.035706
[2022-01-11 15:03:27,598][root][INFO] - Epoch: 16: Step: 701/920, loss=0.026896, lr=0.000006
[2022-01-11 15:03:27,598][root][INFO] - Epoch: 16: Step: 701/920, loss=0.026896, lr=0.000006
[2022-01-11 15:03:27,598][root][INFO] - Epoch: 16: Step: 701/920, loss=0.026896, lr=0.000006
[2022-01-11 15:03:27,598][root][INFO] - Epoch: 16: Step: 701/920, loss=0.026896, lr=0.000006
[2022-01-11 15:05:03,689][root][INFO] - Train batch 800
[2022-01-11 15:05:03,689][root][INFO] - Avg. loss per last 100 batches: 0.032166
[2022-01-11 15:05:03,689][root][INFO] - Train batch 800
[2022-01-11 15:05:03,689][root][INFO] - Avg. loss per last 100 batches: 0.032166
[2022-01-11 15:05:03,690][root][INFO] - Train batch 800
[2022-01-11 15:05:03,690][root][INFO] - Avg. loss per last 100 batches: 0.032166
[2022-01-11 15:05:03,690][root][INFO] - Train batch 800
[2022-01-11 15:05:03,690][root][INFO] - Avg. loss per last 100 batches: 0.032166
[2022-01-11 15:05:04,733][root][INFO] - Epoch: 16: Step: 801/920, loss=0.012492, lr=0.000006
[2022-01-11 15:05:04,736][root][INFO] - Epoch: 16: Step: 801/920, loss=0.012492, lr=0.000006
[2022-01-11 15:05:04,736][root][INFO] - Epoch: 16: Step: 801/920, loss=0.012492, lr=0.000006
[2022-01-11 15:05:04,737][root][INFO] - Epoch: 16: Step: 801/920, loss=0.012492, lr=0.000006
[2022-01-11 15:06:44,015][root][INFO] - Train batch 900
[2022-01-11 15:06:44,015][root][INFO] - Avg. loss per last 100 batches: 0.035415
[2022-01-11 15:06:44,016][root][INFO] - Train batch 900
[2022-01-11 15:06:44,016][root][INFO] - Avg. loss per last 100 batches: 0.035415
[2022-01-11 15:06:44,016][root][INFO] - Train batch 900
[2022-01-11 15:06:44,016][root][INFO] - Train batch 900
[2022-01-11 15:06:44,016][root][INFO] - Avg. loss per last 100 batches: 0.035415
[2022-01-11 15:06:44,017][root][INFO] - Avg. loss per last 100 batches: 0.035415
[2022-01-11 15:06:45,067][root][INFO] - Epoch: 16: Step: 901/920, loss=0.020403, lr=0.000006
[2022-01-11 15:06:45,069][root][INFO] - Epoch: 16: Step: 901/920, loss=0.020403, lr=0.000006
[2022-01-11 15:06:45,070][root][INFO] - Epoch: 16: Step: 901/920, loss=0.020403, lr=0.000006
[2022-01-11 15:06:45,071][root][INFO] - Epoch: 16: Step: 901/920, loss=0.020403, lr=0.000006
[2022-01-11 15:07:03,926][root][INFO] - rank=3, Validation: Epoch: 16 Step: 920/920
[2022-01-11 15:07:03,927][root][INFO] - NLL validation ...
[2022-01-11 15:07:03,928][root][INFO] - rank=3; Iteration start
[2022-01-11 15:07:03,928][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:03,928][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:07:03,928][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 15:07:03,929][root][INFO] - rank=0, Validation: Epoch: 16 Step: 920/920
[2022-01-11 15:07:03,930][root][INFO] - NLL validation ...
[2022-01-11 15:07:03,930][root][INFO] - rank=2, Validation: Epoch: 16 Step: 920/920
[2022-01-11 15:07:03,930][root][INFO] - NLL validation ...
[2022-01-11 15:07:03,930][root][INFO] - rank=1, Validation: Epoch: 16 Step: 920/920
[2022-01-11 15:07:03,930][root][INFO] - NLL validation ...
[2022-01-11 15:07:03,931][root][INFO] - rank=0; Iteration start
[2022-01-11 15:07:03,931][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:03,931][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:07:03,931][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 15:07:03,931][root][INFO] - rank=2; Iteration start
[2022-01-11 15:07:03,931][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:03,931][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:07:03,931][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 15:07:03,931][root][INFO] - rank=1; Iteration start
[2022-01-11 15:07:03,932][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:03,932][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:07:03,932][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 15:07:03,938][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 15:07:03,941][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 15:07:03,941][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 15:07:03,942][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 15:07:04,678][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 15:07:04,679][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 15:07:04,679][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 15:07:04,679][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 15:07:05,413][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 15:07:05,414][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 15:07:05,414][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 15:07:06,067][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 15:07:06,797][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 15:07:06,797][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 15:07:06,797][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 15:07:06,797][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 15:07:07,533][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 15:07:07,534][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 15:07:07,534][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 15:07:07,534][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 15:07:08,271][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 15:07:08,272][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 15:07:08,272][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 15:07:08,273][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 15:07:09,014][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 15:07:09,014][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 15:07:09,014][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 15:07:09,014][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 15:07:09,751][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 15:07:09,752][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 15:07:09,752][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 15:07:09,753][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 15:07:10,491][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 15:07:10,491][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 15:07:10,492][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 15:07:10,493][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 15:07:11,227][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 15:07:11,227][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 15:07:11,228][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 15:07:11,228][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 15:07:11,969][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 15:07:12,688][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 15:07:12,911][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 15:07:12,929][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 15:07:13,665][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 15:07:13,665][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 15:07:13,666][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 15:07:13,666][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 15:07:14,404][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 15:07:14,404][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 15:07:14,404][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 15:07:14,405][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 15:07:15,145][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 15:07:15,147][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 15:07:15,147][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 15:07:15,147][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 15:07:15,883][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 15:07:15,884][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 15:07:15,884][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 15:07:15,885][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 15:07:16,619][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 15:07:16,619][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 15:07:16,620][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 15:07:16,622][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 15:07:17,355][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 15:07:17,355][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 15:07:17,356][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 15:07:18,230][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 15:07:18,963][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 15:07:18,963][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 15:07:18,964][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 15:07:18,964][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 15:07:19,699][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 15:07:19,699][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 15:07:19,699][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 15:07:19,700][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 15:07:20,436][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 15:07:20,437][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 15:07:20,437][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 15:07:20,437][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 15:07:21,177][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 15:07:21,178][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 15:07:21,178][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 15:07:21,178][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 15:07:21,916][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 15:07:21,916][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 15:07:21,917][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 15:07:21,917][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 15:07:22,653][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 15:07:22,653][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 15:07:22,654][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 15:07:22,654][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 15:07:23,391][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 15:07:23,391][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 15:07:23,391][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 15:07:23,392][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 15:07:24,130][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 15:07:24,727][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 15:07:24,737][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 15:07:24,970][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 15:07:25,693][root][INFO] - rank=3; last iteration 25
[2022-01-11 15:07:25,693][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:07:25,693][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 15:07:25,693][root][INFO] - rank=1; last iteration 25
[2022-01-11 15:07:25,693][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:25,693][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:07:25,693][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 15:07:25,693][root][INFO] - NLL Validation: loss = 0.413148. correct prediction ratio  5705/6400 ~  0.891406
[2022-01-11 15:07:25,693][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:25,694][root][INFO] - NLL Validation: loss = 0.413148. correct prediction ratio  5705/6400 ~  0.891406
[2022-01-11 15:07:25,694][root][INFO] - rank=2; last iteration 25
[2022-01-11 15:07:25,694][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:07:25,694][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 15:07:25,694][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:25,694][root][INFO] - rank=0; last iteration 25
[2022-01-11 15:07:25,694][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:07:25,694][root][INFO] - NLL Validation: loss = 0.413148. correct prediction ratio  5705/6400 ~  0.891406
[2022-01-11 15:07:25,694][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 15:07:25,694][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:25,694][root][INFO] - NLL Validation: loss = 0.413148. correct prediction ratio  5705/6400 ~  0.891406
[2022-01-11 15:07:25,696][root][INFO] - rank=1; last iteration 920
[2022-01-11 15:07:25,696][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:07:25,696][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 15:07:25,696][root][INFO] - rank=3; last iteration 920
[2022-01-11 15:07:25,696][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:07:25,696][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 15:07:25,697][root][INFO] - rank=2; last iteration 920
[2022-01-11 15:07:25,697][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:25,697][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:07:25,697][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 15:07:25,697][root][INFO] - Epoch finished on 1
[2022-01-11 15:07:25,697][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:25,697][root][INFO] - NLL validation ...
[2022-01-11 15:07:25,697][root][INFO] - Epoch finished on 3
[2022-01-11 15:07:25,697][root][INFO] - NLL validation ...
[2022-01-11 15:07:25,697][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:25,697][root][INFO] - Epoch finished on 2
[2022-01-11 15:07:25,697][root][INFO] - NLL validation ...
[2022-01-11 15:07:25,698][root][INFO] - rank=1; Iteration start
[2022-01-11 15:07:25,698][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:25,698][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:07:25,698][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 15:07:25,698][root][INFO] - rank=3; Iteration start
[2022-01-11 15:07:25,698][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:25,698][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:07:25,698][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 15:07:25,699][root][INFO] - rank=2; Iteration start
[2022-01-11 15:07:25,699][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:25,699][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:07:25,699][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 15:07:25,705][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 15:07:25,706][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 15:07:25,707][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 15:07:29,888][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.16
[2022-01-11 15:07:29,889][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.16
[2022-01-11 15:07:29,890][root][INFO] - rank=0; last iteration 920
[2022-01-11 15:07:29,890][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:07:29,890][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 15:07:29,891][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:29,891][root][INFO] - Epoch finished on 0
[2022-01-11 15:07:29,891][root][INFO] - NLL validation ...
[2022-01-11 15:07:29,892][root][INFO] - rank=0; Iteration start
[2022-01-11 15:07:29,892][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:29,892][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:07:29,892][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 15:07:29,900][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 15:07:30,641][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 15:07:30,641][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 15:07:30,641][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 15:07:30,642][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 15:07:31,377][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 15:07:31,378][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 15:07:31,378][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 15:07:31,380][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 15:07:32,115][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 15:07:32,115][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 15:07:32,115][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 15:07:32,116][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 15:07:32,849][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 15:07:32,849][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 15:07:32,850][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 15:07:32,850][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 15:07:33,586][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 15:07:33,586][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 15:07:33,587][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 15:07:33,587][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 15:07:34,326][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 15:07:34,326][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 15:07:34,327][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 15:07:35,022][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 15:07:35,753][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 15:07:35,754][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 15:07:35,754][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 15:07:35,754][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 15:07:36,490][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 15:07:36,490][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 15:07:36,490][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 15:07:36,490][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 15:07:37,227][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 15:07:37,228][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 15:07:37,229][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 15:07:37,229][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 15:07:37,964][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 15:07:37,964][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 15:07:37,965][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 15:07:37,965][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 15:07:38,700][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 15:07:38,701][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 15:07:38,701][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 15:07:38,701][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 15:07:39,439][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 15:07:39,439][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 15:07:39,440][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 15:07:39,440][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 15:07:40,179][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 15:07:40,804][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 15:07:40,807][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 15:07:40,811][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 15:07:41,543][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 15:07:41,543][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 15:07:41,543][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 15:07:41,544][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 15:07:42,282][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 15:07:42,284][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 15:07:42,284][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 15:07:42,284][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 15:07:43,018][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 15:07:43,018][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 15:07:43,018][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 15:07:43,018][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 15:07:43,756][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 15:07:43,756][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 15:07:43,757][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 15:07:43,757][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 15:07:44,492][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 15:07:44,492][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 15:07:44,493][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 15:07:44,493][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 15:07:45,229][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 15:07:45,229][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 15:07:45,229][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 15:07:45,229][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 15:07:45,963][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 15:07:45,964][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 15:07:45,964][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 15:07:46,589][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 15:07:47,318][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 15:07:47,318][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 15:07:47,319][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 15:07:47,319][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 15:07:48,054][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 15:07:48,054][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 15:07:48,055][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 15:07:48,055][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 15:07:48,790][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 15:07:48,791][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 15:07:48,792][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 15:07:48,793][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 15:07:49,532][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 15:07:49,533][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 15:07:49,533][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 15:07:49,534][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 15:07:50,261][root][INFO] - rank=3; last iteration 25
[2022-01-11 15:07:50,261][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:07:50,261][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 15:07:50,261][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:50,261][root][INFO] - NLL Validation: loss = 0.413148. correct prediction ratio  5705/6400 ~  0.891406
[2022-01-11 15:07:50,262][root][INFO] - rank=2; last iteration 25
[2022-01-11 15:07:50,262][root][INFO] - rank=0; last iteration 25
[2022-01-11 15:07:50,262][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:07:50,262][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:07:50,262][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 15:07:50,262][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 15:07:50,262][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:50,262][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:50,262][root][INFO] - NLL Validation: loss = 0.413148. correct prediction ratio  5705/6400 ~  0.891406
[2022-01-11 15:07:50,262][root][INFO] - NLL Validation: loss = 0.413148. correct prediction ratio  5705/6400 ~  0.891406
[2022-01-11 15:07:50,263][root][INFO] - Av Loss per epoch=0.032167
[2022-01-11 15:07:50,263][root][INFO] - epoch total correct predictions=58151
[2022-01-11 15:07:50,263][root][INFO] - rank=1; last iteration 25
[2022-01-11 15:07:50,263][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:07:50,263][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 15:07:50,263][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:07:50,263][root][INFO] - NLL Validation: loss = 0.413148. correct prediction ratio  5705/6400 ~  0.891406
[2022-01-11 15:07:50,263][root][INFO] - Av Loss per epoch=0.032167
[2022-01-11 15:07:50,263][root][INFO] - epoch total correct predictions=58151
[2022-01-11 15:07:50,264][root][INFO] - Av Loss per epoch=0.032167
[2022-01-11 15:07:50,265][root][INFO] - epoch total correct predictions=58151
[2022-01-11 15:07:50,264][root][INFO] - ***** Epoch 17 *****
[2022-01-11 15:07:50,265][root][INFO] - ***** Epoch 17 *****
[2022-01-11 15:07:50,266][root][INFO] - rank=3; Iteration start
[2022-01-11 15:07:50,266][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:50,266][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:07:50,266][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 15:07:50,266][root][INFO] - ***** Epoch 17 *****
[2022-01-11 15:07:50,267][root][INFO] - rank=2; Iteration start
[2022-01-11 15:07:50,267][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:50,267][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:07:50,267][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 15:07:50,268][root][INFO] - rank=1; Iteration start
[2022-01-11 15:07:50,268][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:50,268][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:07:50,268][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 15:07:55,438][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.16
[2022-01-11 15:07:55,439][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.16
[2022-01-11 15:07:55,439][root][INFO] - Av Loss per epoch=0.032167
[2022-01-11 15:07:55,439][root][INFO] - epoch total correct predictions=58151
[2022-01-11 15:07:55,441][root][INFO] - ***** Epoch 17 *****
[2022-01-11 15:07:55,442][root][INFO] - rank=0; Iteration start
[2022-01-11 15:07:55,443][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:07:55,443][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:07:55,443][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 15:07:56,371][root][INFO] - Epoch: 17: Step: 1/920, loss=0.040624, lr=0.000006
[2022-01-11 15:07:56,372][root][INFO] - Epoch: 17: Step: 1/920, loss=0.040624, lr=0.000006
[2022-01-11 15:07:56,372][root][INFO] - Epoch: 17: Step: 1/920, loss=0.040624, lr=0.000006
[2022-01-11 15:07:56,373][root][INFO] - Epoch: 17: Step: 1/920, loss=0.040624, lr=0.000006
[2022-01-11 15:09:33,530][root][INFO] - Train batch 100
[2022-01-11 15:09:33,530][root][INFO] - Avg. loss per last 100 batches: 0.031612
[2022-01-11 15:09:33,545][root][INFO] - Train batch 100
[2022-01-11 15:09:33,545][root][INFO] - Avg. loss per last 100 batches: 0.031612
[2022-01-11 15:09:33,545][root][INFO] - Train batch 100
[2022-01-11 15:09:33,545][root][INFO] - Avg. loss per last 100 batches: 0.031612
[2022-01-11 15:09:33,546][root][INFO] - Train batch 100
[2022-01-11 15:09:33,546][root][INFO] - Avg. loss per last 100 batches: 0.031612
[2022-01-11 15:09:34,597][root][INFO] - Epoch: 17: Step: 101/920, loss=0.042282, lr=0.000006
[2022-01-11 15:09:34,597][root][INFO] - Epoch: 17: Step: 101/920, loss=0.042282, lr=0.000006
[2022-01-11 15:09:34,598][root][INFO] - Epoch: 17: Step: 101/920, loss=0.042282, lr=0.000006
[2022-01-11 15:09:34,598][root][INFO] - Epoch: 17: Step: 101/920, loss=0.042282, lr=0.000006
[2022-01-11 15:11:11,283][root][INFO] - Train batch 200
[2022-01-11 15:11:11,284][root][INFO] - Avg. loss per last 100 batches: 0.031135
[2022-01-11 15:11:11,284][root][INFO] - Train batch 200
[2022-01-11 15:11:11,285][root][INFO] - Avg. loss per last 100 batches: 0.031135
[2022-01-11 15:11:11,286][root][INFO] - Train batch 200
[2022-01-11 15:11:11,286][root][INFO] - Avg. loss per last 100 batches: 0.031135
[2022-01-11 15:11:11,287][root][INFO] - Train batch 200
[2022-01-11 15:11:11,287][root][INFO] - Avg. loss per last 100 batches: 0.031135
[2022-01-11 15:11:12,341][root][INFO] - Epoch: 17: Step: 201/920, loss=0.005500, lr=0.000006
[2022-01-11 15:11:12,341][root][INFO] - Epoch: 17: Step: 201/920, loss=0.005500, lr=0.000006
[2022-01-11 15:11:12,343][root][INFO] - Epoch: 17: Step: 201/920, loss=0.005500, lr=0.000006
[2022-01-11 15:11:12,343][root][INFO] - Epoch: 17: Step: 201/920, loss=0.005500, lr=0.000006
[2022-01-11 15:12:52,268][root][INFO] - Train batch 300
[2022-01-11 15:12:52,268][root][INFO] - Avg. loss per last 100 batches: 0.031724
[2022-01-11 15:12:52,271][root][INFO] - Train batch 300
[2022-01-11 15:12:52,271][root][INFO] - Avg. loss per last 100 batches: 0.031724
[2022-01-11 15:12:52,272][root][INFO] - Train batch 300
[2022-01-11 15:12:52,272][root][INFO] - Avg. loss per last 100 batches: 0.031724
[2022-01-11 15:12:52,272][root][INFO] - Train batch 300
[2022-01-11 15:12:52,272][root][INFO] - Avg. loss per last 100 batches: 0.031724
[2022-01-11 15:12:53,312][root][INFO] - Epoch: 17: Step: 301/920, loss=0.023309, lr=0.000006
[2022-01-11 15:12:53,312][root][INFO] - Epoch: 17: Step: 301/920, loss=0.023309, lr=0.000006
[2022-01-11 15:12:53,313][root][INFO] - Epoch: 17: Step: 301/920, loss=0.023309, lr=0.000006
[2022-01-11 15:12:53,313][root][INFO] - Epoch: 17: Step: 301/920, loss=0.023309, lr=0.000006
[2022-01-11 15:14:28,478][root][INFO] - Train batch 400
[2022-01-11 15:14:28,478][root][INFO] - Avg. loss per last 100 batches: 0.038067
[2022-01-11 15:14:28,479][root][INFO] - Train batch 400
[2022-01-11 15:14:28,479][root][INFO] - Avg. loss per last 100 batches: 0.038067
[2022-01-11 15:14:28,479][root][INFO] - Train batch 400
[2022-01-11 15:14:28,479][root][INFO] - Avg. loss per last 100 batches: 0.038067
[2022-01-11 15:14:28,480][root][INFO] - Train batch 400
[2022-01-11 15:14:28,480][root][INFO] - Avg. loss per last 100 batches: 0.038067
[2022-01-11 15:14:29,434][root][INFO] - Epoch: 17: Step: 401/920, loss=0.045185, lr=0.000006
[2022-01-11 15:14:29,434][root][INFO] - Epoch: 17: Step: 401/920, loss=0.045185, lr=0.000006
[2022-01-11 15:14:29,435][root][INFO] - Epoch: 17: Step: 401/920, loss=0.045185, lr=0.000006
[2022-01-11 15:14:29,437][root][INFO] - Epoch: 17: Step: 401/920, loss=0.045185, lr=0.000006
[2022-01-11 15:16:08,761][root][INFO] - Train batch 500
[2022-01-11 15:16:08,761][root][INFO] - Avg. loss per last 100 batches: 0.034300
[2022-01-11 15:16:08,761][root][INFO] - Train batch 500
[2022-01-11 15:16:08,761][root][INFO] - Train batch 500
[2022-01-11 15:16:08,761][root][INFO] - Avg. loss per last 100 batches: 0.034300
[2022-01-11 15:16:08,761][root][INFO] - Avg. loss per last 100 batches: 0.034300
[2022-01-11 15:16:08,762][root][INFO] - Train batch 500
[2022-01-11 15:16:08,762][root][INFO] - Avg. loss per last 100 batches: 0.034300
[2022-01-11 15:16:09,820][root][INFO] - Epoch: 17: Step: 501/920, loss=0.041316, lr=0.000006
[2022-01-11 15:16:09,821][root][INFO] - Epoch: 17: Step: 501/920, loss=0.041316, lr=0.000006
[2022-01-11 15:16:09,822][root][INFO] - Epoch: 17: Step: 501/920, loss=0.041316, lr=0.000006
[2022-01-11 15:16:09,822][root][INFO] - Epoch: 17: Step: 501/920, loss=0.041316, lr=0.000006
[2022-01-11 15:17:48,018][root][INFO] - Train batch 600
[2022-01-11 15:17:48,018][root][INFO] - Avg. loss per last 100 batches: 0.034360
[2022-01-11 15:17:48,018][root][INFO] - Train batch 600
[2022-01-11 15:17:48,018][root][INFO] - Avg. loss per last 100 batches: 0.034360
[2022-01-11 15:17:48,020][root][INFO] - Train batch 600
[2022-01-11 15:17:48,020][root][INFO] - Avg. loss per last 100 batches: 0.034360
[2022-01-11 15:17:48,020][root][INFO] - Train batch 600
[2022-01-11 15:17:48,021][root][INFO] - Avg. loss per last 100 batches: 0.034360
[2022-01-11 15:17:48,968][root][INFO] - Epoch: 17: Step: 601/920, loss=0.023927, lr=0.000006
[2022-01-11 15:17:48,972][root][INFO] - Epoch: 17: Step: 601/920, loss=0.023927, lr=0.000006
[2022-01-11 15:17:48,972][root][INFO] - Epoch: 17: Step: 601/920, loss=0.023927, lr=0.000006
[2022-01-11 15:17:48,973][root][INFO] - Epoch: 17: Step: 601/920, loss=0.023927, lr=0.000006
[2022-01-11 15:19:26,167][root][INFO] - Train batch 700
[2022-01-11 15:19:26,168][root][INFO] - Avg. loss per last 100 batches: 0.026006
[2022-01-11 15:19:26,168][root][INFO] - Train batch 700
[2022-01-11 15:19:26,168][root][INFO] - Avg. loss per last 100 batches: 0.026006
[2022-01-11 15:19:26,169][root][INFO] - Train batch 700
[2022-01-11 15:19:26,169][root][INFO] - Avg. loss per last 100 batches: 0.026006
[2022-01-11 15:19:26,170][root][INFO] - Train batch 700
[2022-01-11 15:19:26,170][root][INFO] - Avg. loss per last 100 batches: 0.026006
[2022-01-11 15:19:27,193][root][INFO] - Epoch: 17: Step: 701/920, loss=0.005984, lr=0.000006
[2022-01-11 15:19:27,194][root][INFO] - Epoch: 17: Step: 701/920, loss=0.005984, lr=0.000006
[2022-01-11 15:19:27,194][root][INFO] - Epoch: 17: Step: 701/920, loss=0.005984, lr=0.000006
[2022-01-11 15:19:27,195][root][INFO] - Epoch: 17: Step: 701/920, loss=0.005984, lr=0.000006
[2022-01-11 15:21:05,407][root][INFO] - Train batch 800
[2022-01-11 15:21:05,407][root][INFO] - Avg. loss per last 100 batches: 0.032069
[2022-01-11 15:21:05,407][root][INFO] - Train batch 800
[2022-01-11 15:21:05,407][root][INFO] - Avg. loss per last 100 batches: 0.032069
[2022-01-11 15:21:05,407][root][INFO] - Train batch 800
[2022-01-11 15:21:05,407][root][INFO] - Avg. loss per last 100 batches: 0.032069
[2022-01-11 15:21:05,408][root][INFO] - Train batch 800
[2022-01-11 15:21:05,408][root][INFO] - Avg. loss per last 100 batches: 0.032069
[2022-01-11 15:21:06,456][root][INFO] - Epoch: 17: Step: 801/920, loss=0.030413, lr=0.000006
[2022-01-11 15:21:06,456][root][INFO] - Epoch: 17: Step: 801/920, loss=0.030413, lr=0.000006
[2022-01-11 15:21:06,457][root][INFO] - Epoch: 17: Step: 801/920, loss=0.030413, lr=0.000006
[2022-01-11 15:21:06,458][root][INFO] - Epoch: 17: Step: 801/920, loss=0.030413, lr=0.000006
[2022-01-11 15:22:44,605][root][INFO] - Train batch 900
[2022-01-11 15:22:44,605][root][INFO] - Avg. loss per last 100 batches: 0.032935
[2022-01-11 15:22:44,613][root][INFO] - Train batch 900
[2022-01-11 15:22:44,613][root][INFO] - Train batch 900
[2022-01-11 15:22:44,613][root][INFO] - Avg. loss per last 100 batches: 0.032935
[2022-01-11 15:22:44,613][root][INFO] - Avg. loss per last 100 batches: 0.032935
[2022-01-11 15:22:44,614][root][INFO] - Train batch 900
[2022-01-11 15:22:44,614][root][INFO] - Avg. loss per last 100 batches: 0.032935
[2022-01-11 15:22:45,661][root][INFO] - Epoch: 17: Step: 901/920, loss=0.002898, lr=0.000006
[2022-01-11 15:22:45,668][root][INFO] - Epoch: 17: Step: 901/920, loss=0.002898, lr=0.000006
[2022-01-11 15:22:45,669][root][INFO] - Epoch: 17: Step: 901/920, loss=0.002898, lr=0.000006
[2022-01-11 15:22:45,670][root][INFO] - Epoch: 17: Step: 901/920, loss=0.002898, lr=0.000006
[2022-01-11 15:23:05,117][root][INFO] - rank=0, Validation: Epoch: 17 Step: 920/920
[2022-01-11 15:23:05,117][root][INFO] - NLL validation ...
[2022-01-11 15:23:05,117][root][INFO] - rank=2, Validation: Epoch: 17 Step: 920/920
[2022-01-11 15:23:05,117][root][INFO] - NLL validation ...
[2022-01-11 15:23:05,118][root][INFO] - rank=1, Validation: Epoch: 17 Step: 920/920
[2022-01-11 15:23:05,118][root][INFO] - rank=0; Iteration start
[2022-01-11 15:23:05,118][root][INFO] - NLL validation ...
[2022-01-11 15:23:05,118][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:05,118][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:23:05,118][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 15:23:05,118][root][INFO] - rank=3, Validation: Epoch: 17 Step: 920/920
[2022-01-11 15:23:05,119][root][INFO] - NLL validation ...
[2022-01-11 15:23:05,119][root][INFO] - rank=2; Iteration start
[2022-01-11 15:23:05,119][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:05,119][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:23:05,119][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 15:23:05,119][root][INFO] - rank=1; Iteration start
[2022-01-11 15:23:05,120][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:05,120][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:23:05,120][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 15:23:05,120][root][INFO] - rank=3; Iteration start
[2022-01-11 15:23:05,120][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:05,120][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:23:05,120][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 15:23:05,128][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 15:23:05,129][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 15:23:05,129][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 15:23:05,130][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 15:23:05,865][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 15:23:05,866][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 15:23:05,866][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 15:23:05,866][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 15:23:06,602][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 15:23:06,603][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 15:23:06,604][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 15:23:06,604][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 15:23:07,339][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 15:23:07,339][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 15:23:07,340][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 15:23:07,340][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 15:23:08,075][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 15:23:08,075][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 15:23:08,076][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 15:23:08,076][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 15:23:08,814][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 15:23:08,814][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 15:23:08,814][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 15:23:08,814][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 15:23:09,554][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 15:23:09,555][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 15:23:09,555][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 15:23:09,555][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 15:23:10,291][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 15:23:11,128][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 15:23:11,254][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 15:23:11,271][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 15:23:12,006][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 15:23:12,006][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 15:23:12,006][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 15:23:12,006][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 15:23:12,740][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 15:23:12,741][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 15:23:12,741][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 15:23:12,741][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 15:23:13,482][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 15:23:13,482][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 15:23:13,482][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 15:23:13,484][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 15:23:14,220][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 15:23:14,220][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 15:23:14,220][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 15:23:14,847][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 15:23:15,578][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 15:23:15,578][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 15:23:15,579][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 15:23:15,580][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 15:23:16,323][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 15:23:16,323][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 15:23:16,324][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 15:23:16,324][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 15:23:17,059][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 15:23:17,059][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 15:23:17,059][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 15:23:17,060][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 15:23:17,796][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 15:23:17,797][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 15:23:17,797][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 15:23:17,797][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 15:23:18,531][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 15:23:18,532][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 15:23:18,534][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 15:23:18,534][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 15:23:19,275][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 15:23:19,276][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 15:23:19,276][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 15:23:19,276][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 15:23:20,011][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 15:23:20,012][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 15:23:20,012][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 15:23:20,013][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 15:23:20,749][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 15:23:20,749][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 15:23:20,749][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 15:23:20,750][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 15:23:21,490][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 15:23:21,491][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 15:23:21,491][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 15:23:21,491][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 15:23:22,228][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 15:23:22,829][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 15:23:22,937][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 15:23:22,975][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 15:23:23,716][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 15:23:23,716][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 15:23:23,717][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 15:23:23,717][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 15:23:24,459][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 15:23:24,461][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 15:23:24,461][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 15:23:24,462][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 15:23:25,199][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 15:23:25,199][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 15:23:25,200][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 15:23:25,200][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 15:23:25,927][root][INFO] - rank=0; last iteration 25
[2022-01-11 15:23:25,927][root][INFO] - rank=2; last iteration 25
[2022-01-11 15:23:25,928][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:23:25,928][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:23:25,928][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 15:23:25,928][root][INFO] - rank=3; last iteration 25
[2022-01-11 15:23:25,928][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 15:23:25,928][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:25,928][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:23:25,928][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:25,928][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 15:23:25,928][root][INFO] - NLL Validation: loss = 0.392033. correct prediction ratio  5699/6400 ~  0.890469
[2022-01-11 15:23:25,928][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:25,928][root][INFO] - NLL Validation: loss = 0.392033. correct prediction ratio  5699/6400 ~  0.890469
[2022-01-11 15:23:25,928][root][INFO] - NLL Validation: loss = 0.392033. correct prediction ratio  5699/6400 ~  0.890469
[2022-01-11 15:23:25,930][root][INFO] - rank=1; last iteration 25
[2022-01-11 15:23:25,930][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:23:25,930][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 15:23:25,930][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:25,930][root][INFO] - NLL Validation: loss = 0.392033. correct prediction ratio  5699/6400 ~  0.890469
[2022-01-11 15:23:25,930][root][INFO] - rank=2; last iteration 920
[2022-01-11 15:23:25,930][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:23:25,930][root][INFO] - rank=3; last iteration 920
[2022-01-11 15:23:25,930][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 15:23:25,930][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:23:25,930][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 15:23:25,931][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:25,931][root][INFO] - Epoch finished on 3
[2022-01-11 15:23:25,931][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:25,931][root][INFO] - NLL validation ...
[2022-01-11 15:23:25,931][root][INFO] - Epoch finished on 2
[2022-01-11 15:23:25,931][root][INFO] - NLL validation ...
[2022-01-11 15:23:25,932][root][INFO] - rank=3; Iteration start
[2022-01-11 15:23:25,932][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:25,932][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:23:25,932][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 15:23:25,932][root][INFO] - rank=1; last iteration 920
[2022-01-11 15:23:25,932][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:23:25,932][root][INFO] - rank=2; Iteration start
[2022-01-11 15:23:25,933][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 15:23:25,933][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:25,933][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:23:25,933][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 15:23:25,933][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:25,933][root][INFO] - Epoch finished on 1
[2022-01-11 15:23:25,933][root][INFO] - NLL validation ...
[2022-01-11 15:23:25,934][root][INFO] - rank=1; Iteration start
[2022-01-11 15:23:25,934][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:25,934][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:23:25,935][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 15:23:25,941][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 15:23:25,942][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 15:23:25,944][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 15:23:29,893][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.17
[2022-01-11 15:23:29,893][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.17
[2022-01-11 15:23:29,895][root][INFO] - rank=0; last iteration 920
[2022-01-11 15:23:29,895][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:23:29,895][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 15:23:29,896][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:29,896][root][INFO] - Epoch finished on 0
[2022-01-11 15:23:29,896][root][INFO] - NLL validation ...
[2022-01-11 15:23:29,897][root][INFO] - rank=0; Iteration start
[2022-01-11 15:23:29,897][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:29,897][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:23:29,897][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 15:23:30,830][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 15:23:31,571][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 15:23:31,571][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 15:23:31,571][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 15:23:31,571][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 15:23:32,308][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 15:23:32,309][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 15:23:32,309][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 15:23:32,309][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 15:23:33,043][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 15:23:33,043][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 15:23:33,044][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 15:23:33,044][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 15:23:33,781][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 15:23:33,781][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 15:23:33,781][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 15:23:33,782][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 15:23:34,521][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 15:23:34,521][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 15:23:34,522][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 15:23:34,522][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 15:23:35,263][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 15:23:35,264][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 15:23:35,264][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 15:23:35,266][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 15:23:36,002][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 15:23:36,004][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 15:23:36,004][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 15:23:36,004][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 15:23:36,738][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 15:23:36,739][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 15:23:36,739][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 15:23:36,740][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 15:23:37,476][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 15:23:38,274][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 15:23:38,329][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 15:23:38,376][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 15:23:39,114][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 15:23:39,114][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 15:23:39,115][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 15:23:39,115][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 15:23:39,852][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 15:23:39,852][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 15:23:39,853][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 15:23:39,853][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 15:23:40,590][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 15:23:40,590][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 15:23:40,591][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 15:23:40,592][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 15:23:41,326][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 15:23:41,327][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 15:23:41,327][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 15:23:41,328][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 15:23:42,061][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 15:23:42,062][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 15:23:42,062][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 15:23:42,698][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 15:23:43,428][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 15:23:43,429][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 15:23:43,429][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 15:23:43,430][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 15:23:44,164][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 15:23:44,164][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 15:23:44,164][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 15:23:44,165][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 15:23:44,902][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 15:23:44,902][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 15:23:44,902][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 15:23:44,903][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 15:23:45,637][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 15:23:45,637][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 15:23:45,638][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 15:23:45,639][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 15:23:46,379][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 15:23:46,380][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 15:23:46,381][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 15:23:46,381][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 15:23:47,118][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 15:23:47,118][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 15:23:47,119][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 15:23:47,120][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 15:23:47,856][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 15:23:47,857][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 15:23:47,858][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 15:23:47,858][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 15:23:48,599][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 15:23:48,599][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 15:23:48,600][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 15:23:48,600][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 15:23:49,338][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 15:23:49,935][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 15:23:49,938][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 15:23:49,978][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 15:23:50,711][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 15:23:50,711][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 15:23:50,711][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 15:23:50,712][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 15:23:51,439][root][INFO] - rank=3; last iteration 25
[2022-01-11 15:23:51,439][root][INFO] - rank=1; last iteration 25
[2022-01-11 15:23:51,439][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:23:51,439][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:23:51,439][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 15:23:51,439][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 15:23:51,439][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:51,439][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:51,439][root][INFO] - rank=0; last iteration 25
[2022-01-11 15:23:51,439][root][INFO] - NLL Validation: loss = 0.392033. correct prediction ratio  5699/6400 ~  0.890469
[2022-01-11 15:23:51,439][root][INFO] - rank=2; last iteration 25
[2022-01-11 15:23:51,439][root][INFO] - NLL Validation: loss = 0.392033. correct prediction ratio  5699/6400 ~  0.890469
[2022-01-11 15:23:51,439][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:23:51,439][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 15:23:51,439][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:23:51,439][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 15:23:51,439][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:51,439][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:23:51,439][root][INFO] - NLL Validation: loss = 0.392033. correct prediction ratio  5699/6400 ~  0.890469
[2022-01-11 15:23:51,439][root][INFO] - NLL Validation: loss = 0.392033. correct prediction ratio  5699/6400 ~  0.890469
[2022-01-11 15:23:51,440][root][INFO] - Av Loss per epoch=0.032365
[2022-01-11 15:23:51,440][root][INFO] - epoch total correct predictions=58176
[2022-01-11 15:23:51,440][root][INFO] - Av Loss per epoch=0.032365
[2022-01-11 15:23:51,440][root][INFO] - epoch total correct predictions=58176
[2022-01-11 15:23:51,441][root][INFO] - Av Loss per epoch=0.032365
[2022-01-11 15:23:51,441][root][INFO] - epoch total correct predictions=58176
[2022-01-11 15:23:51,442][root][INFO] - ***** Epoch 18 *****
[2022-01-11 15:23:51,442][root][INFO] - ***** Epoch 18 *****
[2022-01-11 15:23:51,442][root][INFO] - ***** Epoch 18 *****
[2022-01-11 15:23:51,444][root][INFO] - rank=3; Iteration start
[2022-01-11 15:23:51,444][root][INFO] - rank=1; Iteration start
[2022-01-11 15:23:51,444][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:51,444][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:51,444][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:23:51,444][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:23:51,444][root][INFO] - rank=2; Iteration start
[2022-01-11 15:23:51,444][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:51,444][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:23:51,444][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 15:23:51,444][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 15:23:51,444][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 15:23:56,406][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.17
[2022-01-11 15:23:56,407][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.17
[2022-01-11 15:23:56,407][root][INFO] - Av Loss per epoch=0.032365
[2022-01-11 15:23:56,407][root][INFO] - epoch total correct predictions=58176
[2022-01-11 15:23:56,409][root][INFO] - ***** Epoch 18 *****
[2022-01-11 15:23:56,411][root][INFO] - rank=0; Iteration start
[2022-01-11 15:23:56,412][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:23:56,412][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:23:56,412][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 15:23:57,480][root][INFO] - Epoch: 18: Step: 1/920, loss=0.006766, lr=0.000006
[2022-01-11 15:23:57,494][root][INFO] - Epoch: 18: Step: 1/920, loss=0.006766, lr=0.000006
[2022-01-11 15:23:57,495][root][INFO] - Epoch: 18: Step: 1/920, loss=0.006766, lr=0.000006
[2022-01-11 15:23:57,495][root][INFO] - Epoch: 18: Step: 1/920, loss=0.006766, lr=0.000006
[2022-01-11 15:25:35,119][root][INFO] - Train batch 100
[2022-01-11 15:25:35,119][root][INFO] - Avg. loss per last 100 batches: 0.028989
[2022-01-11 15:25:35,131][root][INFO] - Train batch 100
[2022-01-11 15:25:35,131][root][INFO] - Avg. loss per last 100 batches: 0.028989
[2022-01-11 15:25:35,132][root][INFO] - Train batch 100
[2022-01-11 15:25:35,133][root][INFO] - Avg. loss per last 100 batches: 0.028989
[2022-01-11 15:25:35,136][root][INFO] - Train batch 100
[2022-01-11 15:25:35,136][root][INFO] - Avg. loss per last 100 batches: 0.028989
[2022-01-11 15:25:36,182][root][INFO] - Epoch: 18: Step: 101/920, loss=0.002337, lr=0.000006
[2022-01-11 15:25:36,192][root][INFO] - Epoch: 18: Step: 101/920, loss=0.002337, lr=0.000006
[2022-01-11 15:25:36,197][root][INFO] - Epoch: 18: Step: 101/920, loss=0.002337, lr=0.000006
[2022-01-11 15:25:36,198][root][INFO] - Epoch: 18: Step: 101/920, loss=0.002337, lr=0.000006
[2022-01-11 15:27:15,512][root][INFO] - Train batch 200
[2022-01-11 15:27:15,512][root][INFO] - Avg. loss per last 100 batches: 0.033237
[2022-01-11 15:27:15,512][root][INFO] - Train batch 200
[2022-01-11 15:27:15,512][root][INFO] - Avg. loss per last 100 batches: 0.033237
[2022-01-11 15:27:15,513][root][INFO] - Train batch 200
[2022-01-11 15:27:15,513][root][INFO] - Avg. loss per last 100 batches: 0.033237
[2022-01-11 15:27:15,513][root][INFO] - Train batch 200
[2022-01-11 15:27:15,513][root][INFO] - Avg. loss per last 100 batches: 0.033237
[2022-01-11 15:27:16,565][root][INFO] - Epoch: 18: Step: 201/920, loss=0.053588, lr=0.000006
[2022-01-11 15:27:16,565][root][INFO] - Epoch: 18: Step: 201/920, loss=0.053588, lr=0.000006
[2022-01-11 15:27:16,566][root][INFO] - Epoch: 18: Step: 201/920, loss=0.053588, lr=0.000006
[2022-01-11 15:27:16,567][root][INFO] - Epoch: 18: Step: 201/920, loss=0.053588, lr=0.000006
[2022-01-11 15:28:52,960][root][INFO] - Train batch 300
[2022-01-11 15:28:52,961][root][INFO] - Avg. loss per last 100 batches: 0.030914
[2022-01-11 15:28:52,961][root][INFO] - Train batch 300
[2022-01-11 15:28:52,961][root][INFO] - Avg. loss per last 100 batches: 0.030914
[2022-01-11 15:28:52,961][root][INFO] - Train batch 300
[2022-01-11 15:28:52,962][root][INFO] - Avg. loss per last 100 batches: 0.030914
[2022-01-11 15:28:52,962][root][INFO] - Train batch 300
[2022-01-11 15:28:52,962][root][INFO] - Avg. loss per last 100 batches: 0.030914
[2022-01-11 15:28:53,951][root][INFO] - Epoch: 18: Step: 301/920, loss=0.048782, lr=0.000006
[2022-01-11 15:28:53,951][root][INFO] - Epoch: 18: Step: 301/920, loss=0.048782, lr=0.000006
[2022-01-11 15:28:53,951][root][INFO] - Epoch: 18: Step: 301/920, loss=0.048782, lr=0.000006
[2022-01-11 15:28:53,952][root][INFO] - Epoch: 18: Step: 301/920, loss=0.048782, lr=0.000006
[2022-01-11 15:30:30,375][root][INFO] - Train batch 400
[2022-01-11 15:30:30,375][root][INFO] - Avg. loss per last 100 batches: 0.027981
[2022-01-11 15:30:30,376][root][INFO] - Train batch 400
[2022-01-11 15:30:30,376][root][INFO] - Avg. loss per last 100 batches: 0.027981
[2022-01-11 15:30:30,377][root][INFO] - Train batch 400
[2022-01-11 15:30:30,377][root][INFO] - Avg. loss per last 100 batches: 0.027981
[2022-01-11 15:30:30,377][root][INFO] - Train batch 400
[2022-01-11 15:30:30,377][root][INFO] - Avg. loss per last 100 batches: 0.027981
[2022-01-11 15:30:31,335][root][INFO] - Epoch: 18: Step: 401/920, loss=0.024797, lr=0.000006
[2022-01-11 15:30:31,339][root][INFO] - Epoch: 18: Step: 401/920, loss=0.024797, lr=0.000006
[2022-01-11 15:30:31,339][root][INFO] - Epoch: 18: Step: 401/920, loss=0.024797, lr=0.000006
[2022-01-11 15:30:31,339][root][INFO] - Epoch: 18: Step: 401/920, loss=0.024797, lr=0.000006
[2022-01-11 15:32:10,294][root][INFO] - Train batch 500
[2022-01-11 15:32:10,294][root][INFO] - Avg. loss per last 100 batches: 0.028291
[2022-01-11 15:32:10,294][root][INFO] - Train batch 500
[2022-01-11 15:32:10,294][root][INFO] - Avg. loss per last 100 batches: 0.028291
[2022-01-11 15:32:10,294][root][INFO] - Train batch 500
[2022-01-11 15:32:10,294][root][INFO] - Avg. loss per last 100 batches: 0.028291
[2022-01-11 15:32:10,294][root][INFO] - Train batch 500
[2022-01-11 15:32:10,295][root][INFO] - Avg. loss per last 100 batches: 0.028291
[2022-01-11 15:32:11,296][root][INFO] - Epoch: 18: Step: 501/920, loss=0.100469, lr=0.000006
[2022-01-11 15:32:11,296][root][INFO] - Epoch: 18: Step: 501/920, loss=0.100469, lr=0.000006
[2022-01-11 15:32:11,296][root][INFO] - Epoch: 18: Step: 501/920, loss=0.100469, lr=0.000006
[2022-01-11 15:32:11,296][root][INFO] - Epoch: 18: Step: 501/920, loss=0.100469, lr=0.000006
[2022-01-11 15:33:50,579][root][INFO] - Train batch 600
[2022-01-11 15:33:50,579][root][INFO] - Avg. loss per last 100 batches: 0.034501
[2022-01-11 15:33:50,579][root][INFO] - Train batch 600
[2022-01-11 15:33:50,580][root][INFO] - Avg. loss per last 100 batches: 0.034501
[2022-01-11 15:33:50,580][root][INFO] - Train batch 600
[2022-01-11 15:33:50,580][root][INFO] - Avg. loss per last 100 batches: 0.034501
[2022-01-11 15:33:50,582][root][INFO] - Train batch 600
[2022-01-11 15:33:50,582][root][INFO] - Avg. loss per last 100 batches: 0.034501
[2022-01-11 15:33:51,424][root][INFO] - Epoch: 18: Step: 601/920, loss=0.055628, lr=0.000006
[2022-01-11 15:33:51,432][root][INFO] - Epoch: 18: Step: 601/920, loss=0.055628, lr=0.000006
[2022-01-11 15:33:51,432][root][INFO] - Epoch: 18: Step: 601/920, loss=0.055628, lr=0.000006
[2022-01-11 15:33:51,432][root][INFO] - Epoch: 18: Step: 601/920, loss=0.055628, lr=0.000006
[2022-01-11 15:35:28,321][root][INFO] - Train batch 700
[2022-01-11 15:35:28,321][root][INFO] - Avg. loss per last 100 batches: 0.030780
[2022-01-11 15:35:28,321][root][INFO] - Train batch 700
[2022-01-11 15:35:28,322][root][INFO] - Avg. loss per last 100 batches: 0.030780
[2022-01-11 15:35:28,322][root][INFO] - Train batch 700
[2022-01-11 15:35:28,322][root][INFO] - Avg. loss per last 100 batches: 0.030780
[2022-01-11 15:35:28,322][root][INFO] - Train batch 700
[2022-01-11 15:35:28,322][root][INFO] - Avg. loss per last 100 batches: 0.030780
[2022-01-11 15:35:29,301][root][INFO] - Epoch: 18: Step: 701/920, loss=0.031063, lr=0.000006
[2022-01-11 15:35:29,304][root][INFO] - Epoch: 18: Step: 701/920, loss=0.031063, lr=0.000006
[2022-01-11 15:35:29,305][root][INFO] - Epoch: 18: Step: 701/920, loss=0.031063, lr=0.000006
[2022-01-11 15:35:29,305][root][INFO] - Epoch: 18: Step: 701/920, loss=0.031063, lr=0.000006
[2022-01-11 15:37:07,282][root][INFO] - Train batch 800
[2022-01-11 15:37:07,282][root][INFO] - Avg. loss per last 100 batches: 0.031037
[2022-01-11 15:37:07,282][root][INFO] - Train batch 800
[2022-01-11 15:37:07,283][root][INFO] - Avg. loss per last 100 batches: 0.031037
[2022-01-11 15:37:07,285][root][INFO] - Train batch 800
[2022-01-11 15:37:07,285][root][INFO] - Train batch 800
[2022-01-11 15:37:07,286][root][INFO] - Avg. loss per last 100 batches: 0.031037
[2022-01-11 15:37:07,286][root][INFO] - Avg. loss per last 100 batches: 0.031037
[2022-01-11 15:37:08,255][root][INFO] - Epoch: 18: Step: 801/920, loss=0.005838, lr=0.000006
[2022-01-11 15:37:08,256][root][INFO] - Epoch: 18: Step: 801/920, loss=0.005838, lr=0.000006
[2022-01-11 15:37:08,256][root][INFO] - Epoch: 18: Step: 801/920, loss=0.005838, lr=0.000006
[2022-01-11 15:37:08,256][root][INFO] - Epoch: 18: Step: 801/920, loss=0.005838, lr=0.000006
[2022-01-11 15:38:47,686][root][INFO] - Train batch 900
[2022-01-11 15:38:47,686][root][INFO] - Avg. loss per last 100 batches: 0.026325
[2022-01-11 15:38:47,687][root][INFO] - Train batch 900
[2022-01-11 15:38:47,687][root][INFO] - Avg. loss per last 100 batches: 0.026325
[2022-01-11 15:38:47,687][root][INFO] - Train batch 900
[2022-01-11 15:38:47,687][root][INFO] - Avg. loss per last 100 batches: 0.026325
[2022-01-11 15:38:47,688][root][INFO] - Train batch 900
[2022-01-11 15:38:47,688][root][INFO] - Avg. loss per last 100 batches: 0.026325
[2022-01-11 15:38:48,625][root][INFO] - Epoch: 18: Step: 901/920, loss=0.053174, lr=0.000006
[2022-01-11 15:38:48,627][root][INFO] - Epoch: 18: Step: 901/920, loss=0.053174, lr=0.000006
[2022-01-11 15:38:48,628][root][INFO] - Epoch: 18: Step: 901/920, loss=0.053174, lr=0.000006
[2022-01-11 15:38:48,629][root][INFO] - Epoch: 18: Step: 901/920, loss=0.053174, lr=0.000006
[2022-01-11 15:39:05,163][root][INFO] - rank=0, Validation: Epoch: 18 Step: 920/920
[2022-01-11 15:39:05,164][root][INFO] - NLL validation ...
[2022-01-11 15:39:05,164][root][INFO] - rank=2, Validation: Epoch: 18 Step: 920/920
[2022-01-11 15:39:05,164][root][INFO] - NLL validation ...
[2022-01-11 15:39:05,165][root][INFO] - rank=0; Iteration start
[2022-01-11 15:39:05,165][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:05,165][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:39:05,165][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 15:39:05,165][root][INFO] - rank=2; Iteration start
[2022-01-11 15:39:05,165][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:05,165][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:39:05,165][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 15:39:05,165][root][INFO] - rank=3, Validation: Epoch: 18 Step: 920/920
[2022-01-11 15:39:05,166][root][INFO] - NLL validation ...
[2022-01-11 15:39:05,166][root][INFO] - rank=1, Validation: Epoch: 18 Step: 920/920
[2022-01-11 15:39:05,166][root][INFO] - NLL validation ...
[2022-01-11 15:39:05,167][root][INFO] - rank=3; Iteration start
[2022-01-11 15:39:05,167][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:05,167][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:39:05,167][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 15:39:05,167][root][INFO] - rank=1; Iteration start
[2022-01-11 15:39:05,167][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:05,167][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:39:05,167][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 15:39:05,175][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 15:39:05,176][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 15:39:05,177][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 15:39:05,178][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 15:39:05,915][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 15:39:05,915][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 15:39:05,916][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 15:39:05,916][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 15:39:06,650][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 15:39:07,626][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 15:39:07,634][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 15:39:07,644][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 15:39:08,375][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 15:39:08,375][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 15:39:08,375][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 15:39:08,375][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 15:39:09,109][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 15:39:09,110][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 15:39:09,110][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 15:39:10,055][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 15:39:10,790][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 15:39:10,792][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 15:39:10,792][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 15:39:10,793][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 15:39:11,531][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 15:39:11,531][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 15:39:11,532][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 15:39:11,532][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 15:39:12,268][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 15:39:12,268][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 15:39:12,268][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 15:39:12,268][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 15:39:13,008][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 15:39:13,009][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 15:39:13,009][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 15:39:13,009][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 15:39:13,745][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 15:39:13,745][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 15:39:13,745][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 15:39:13,746][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 15:39:14,482][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 15:39:14,482][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 15:39:14,482][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 15:39:14,482][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 15:39:15,219][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 15:39:15,219][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 15:39:15,219][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 15:39:15,219][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 15:39:15,962][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 15:39:15,963][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 15:39:15,963][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 15:39:15,963][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 15:39:16,700][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 15:39:16,700][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 15:39:16,700][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 15:39:16,700][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 15:39:17,434][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 15:39:17,435][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 15:39:17,435][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 15:39:17,435][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 15:39:18,169][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 15:39:18,169][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 15:39:18,170][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 15:39:18,170][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 15:39:18,910][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 15:39:19,514][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 15:39:19,515][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 15:39:19,532][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 15:39:20,263][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 15:39:20,263][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 15:39:20,263][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 15:39:20,263][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 15:39:21,001][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 15:39:21,001][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 15:39:21,002][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 15:39:21,597][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 15:39:22,332][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 15:39:22,332][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 15:39:22,333][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 15:39:22,333][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 15:39:23,069][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 15:39:23,069][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 15:39:23,069][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 15:39:23,070][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 15:39:23,807][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 15:39:23,808][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 15:39:23,808][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 15:39:23,809][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 15:39:24,545][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 15:39:24,545][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 15:39:24,546][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 15:39:24,546][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 15:39:25,283][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 15:39:25,284][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 15:39:25,284][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 15:39:25,284][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 15:39:26,021][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 15:39:26,021][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 15:39:26,021][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 15:39:26,022][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 15:39:26,754][root][INFO] - rank=0; last iteration 25
[2022-01-11 15:39:26,754][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:39:26,754][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 15:39:26,754][root][INFO] - rank=3; last iteration 25
[2022-01-11 15:39:26,754][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:26,754][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:39:26,755][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 15:39:26,755][root][INFO] - NLL Validation: loss = 0.405164. correct prediction ratio  5714/6400 ~  0.892813
[2022-01-11 15:39:26,755][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:26,755][root][INFO] - NLL Validation: loss = 0.405164. correct prediction ratio  5714/6400 ~  0.892813
[2022-01-11 15:39:26,755][root][INFO] - rank=2; last iteration 25
[2022-01-11 15:39:26,755][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:39:26,755][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 15:39:26,755][root][INFO] - rank=1; last iteration 25
[2022-01-11 15:39:26,755][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:26,755][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:39:26,755][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 15:39:26,755][root][INFO] - NLL Validation: loss = 0.405164. correct prediction ratio  5714/6400 ~  0.892813
[2022-01-11 15:39:26,755][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:26,755][root][INFO] - NLL Validation: loss = 0.405164. correct prediction ratio  5714/6400 ~  0.892813
[2022-01-11 15:39:26,757][root][INFO] - rank=3; last iteration 920
[2022-01-11 15:39:26,757][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:39:26,757][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 15:39:26,757][root][INFO] - rank=2; last iteration 920
[2022-01-11 15:39:26,757][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:39:26,757][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 15:39:26,758][root][INFO] - rank=1; last iteration 920
[2022-01-11 15:39:26,758][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:26,758][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:39:26,758][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 15:39:26,758][root][INFO] - Epoch finished on 3
[2022-01-11 15:39:26,758][root][INFO] - NLL validation ...
[2022-01-11 15:39:26,758][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:26,758][root][INFO] - Epoch finished on 2
[2022-01-11 15:39:26,758][root][INFO] - NLL validation ...
[2022-01-11 15:39:26,758][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:26,758][root][INFO] - Epoch finished on 1
[2022-01-11 15:39:26,758][root][INFO] - NLL validation ...
[2022-01-11 15:39:26,759][root][INFO] - rank=3; Iteration start
[2022-01-11 15:39:26,759][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:26,759][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:39:26,759][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 15:39:26,759][root][INFO] - rank=2; Iteration start
[2022-01-11 15:39:26,759][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:26,759][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:39:26,759][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 15:39:26,760][root][INFO] - rank=1; Iteration start
[2022-01-11 15:39:26,760][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:26,760][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:39:26,760][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 15:39:26,767][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 15:39:26,767][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 15:39:26,768][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 15:39:30,718][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.18
[2022-01-11 15:39:30,718][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.18
[2022-01-11 15:39:30,720][root][INFO] - rank=0; last iteration 920
[2022-01-11 15:39:30,720][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:39:30,720][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 15:39:30,720][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:30,720][root][INFO] - Epoch finished on 0
[2022-01-11 15:39:30,720][root][INFO] - NLL validation ...
[2022-01-11 15:39:30,722][root][INFO] - rank=0; Iteration start
[2022-01-11 15:39:30,722][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:30,722][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:39:30,722][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 15:39:30,729][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 15:39:31,470][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 15:39:31,471][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 15:39:31,471][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 15:39:31,476][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 15:39:32,206][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 15:39:32,206][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 15:39:32,206][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 15:39:32,208][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 15:39:32,939][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 15:39:32,939][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 15:39:32,939][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 15:39:32,941][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 15:39:33,676][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 15:39:34,291][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 15:39:34,302][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 15:39:34,401][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 15:39:35,132][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 15:39:35,132][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 15:39:35,132][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 15:39:35,134][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 15:39:35,868][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 15:39:35,868][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 15:39:35,872][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 15:39:36,468][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 15:39:37,198][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 15:39:37,198][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 15:39:37,199][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 15:39:37,200][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 15:39:37,933][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 15:39:37,933][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 15:39:37,934][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 15:39:37,935][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 15:39:38,668][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 15:39:38,671][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 15:39:38,672][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 15:39:38,673][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 15:39:39,410][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 15:39:39,411][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 15:39:39,412][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 15:39:39,412][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 15:39:40,147][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 15:39:40,149][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 15:39:40,149][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 15:39:40,151][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 15:39:40,886][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 15:39:40,888][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 15:39:40,888][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 15:39:40,889][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 15:39:41,629][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 15:39:41,630][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 15:39:41,630][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 15:39:41,630][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 15:39:42,366][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 15:39:42,367][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 15:39:42,367][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 15:39:42,368][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 15:39:43,101][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 15:39:43,103][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 15:39:43,103][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 15:39:43,103][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 15:39:43,837][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 15:39:43,838][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 15:39:43,838][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 15:39:43,839][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 15:39:44,583][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 15:39:44,586][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 15:39:44,586][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 15:39:44,587][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 15:39:45,322][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 15:39:45,935][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 15:39:46,078][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 15:39:46,140][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 15:39:46,872][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 15:39:46,873][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 15:39:46,873][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 15:39:46,873][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 15:39:47,608][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 15:39:47,610][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 15:39:47,610][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 15:39:48,415][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 15:39:49,144][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 15:39:49,145][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 15:39:49,145][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 15:39:49,147][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 15:39:49,885][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 15:39:49,885][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 15:39:49,885][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 15:39:49,885][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 15:39:50,623][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 15:39:50,624][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 15:39:50,624][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 15:39:50,625][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 15:39:51,360][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 15:39:51,360][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 15:39:51,360][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 15:39:51,360][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 15:39:52,089][root][INFO] - rank=0; last iteration 25
[2022-01-11 15:39:52,089][root][INFO] - rank=2; last iteration 25
[2022-01-11 15:39:52,089][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:39:52,089][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:39:52,089][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 15:39:52,089][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 15:39:52,089][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:52,089][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:52,089][root][INFO] - rank=1; last iteration 25
[2022-01-11 15:39:52,090][root][INFO] - NLL Validation: loss = 0.405164. correct prediction ratio  5714/6400 ~  0.892813
[2022-01-11 15:39:52,090][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:39:52,090][root][INFO] - NLL Validation: loss = 0.405164. correct prediction ratio  5714/6400 ~  0.892813
[2022-01-11 15:39:52,090][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 15:39:52,090][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:52,090][root][INFO] - NLL Validation: loss = 0.405164. correct prediction ratio  5714/6400 ~  0.892813
[2022-01-11 15:39:52,091][root][INFO] - rank=3; last iteration 25
[2022-01-11 15:39:52,091][root][INFO] - Av Loss per epoch=0.030111
[2022-01-11 15:39:52,091][root][INFO] - epoch total correct predictions=58197
[2022-01-11 15:39:52,091][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:39:52,091][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 15:39:52,091][root][INFO] - Av Loss per epoch=0.030111
[2022-01-11 15:39:52,091][root][INFO] - epoch total correct predictions=58197
[2022-01-11 15:39:52,091][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:39:52,091][root][INFO] - NLL Validation: loss = 0.405164. correct prediction ratio  5714/6400 ~  0.892813
[2022-01-11 15:39:52,093][root][INFO] - Av Loss per epoch=0.030111
[2022-01-11 15:39:52,093][root][INFO] - epoch total correct predictions=58197
[2022-01-11 15:39:52,093][root][INFO] - ***** Epoch 19 *****
[2022-01-11 15:39:52,093][root][INFO] - ***** Epoch 19 *****
[2022-01-11 15:39:52,094][root][INFO] - rank=2; Iteration start
[2022-01-11 15:39:52,094][root][INFO] - rank=1; Iteration start
[2022-01-11 15:39:52,094][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:52,094][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:52,094][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:39:52,094][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:39:52,094][root][INFO] - ***** Epoch 19 *****
[2022-01-11 15:39:52,095][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 15:39:52,095][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 15:39:52,096][root][INFO] - rank=3; Iteration start
[2022-01-11 15:39:52,096][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:52,096][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:39:52,096][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 15:39:57,090][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.18
[2022-01-11 15:39:57,091][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.18
[2022-01-11 15:39:57,091][root][INFO] - Av Loss per epoch=0.030111
[2022-01-11 15:39:57,092][root][INFO] - epoch total correct predictions=58197
[2022-01-11 15:39:57,094][root][INFO] - ***** Epoch 19 *****
[2022-01-11 15:39:57,098][root][INFO] - rank=0; Iteration start
[2022-01-11 15:39:57,098][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:39:57,098][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:39:57,099][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 15:39:57,996][root][INFO] - Epoch: 19: Step: 1/920, loss=0.020527, lr=0.000006
[2022-01-11 15:39:58,001][root][INFO] - Epoch: 19: Step: 1/920, loss=0.020527, lr=0.000006
[2022-01-11 15:39:58,002][root][INFO] - Epoch: 19: Step: 1/920, loss=0.020527, lr=0.000006
[2022-01-11 15:39:58,004][root][INFO] - Epoch: 19: Step: 1/920, loss=0.020527, lr=0.000006
[2022-01-11 15:41:37,557][root][INFO] - Train batch 100
[2022-01-11 15:41:37,557][root][INFO] - Avg. loss per last 100 batches: 0.026159
[2022-01-11 15:41:37,559][root][INFO] - Train batch 100
[2022-01-11 15:41:37,560][root][INFO] - Avg. loss per last 100 batches: 0.026159
[2022-01-11 15:41:37,561][root][INFO] - Train batch 100
[2022-01-11 15:41:37,561][root][INFO] - Train batch 100
[2022-01-11 15:41:37,561][root][INFO] - Avg. loss per last 100 batches: 0.026159
[2022-01-11 15:41:37,561][root][INFO] - Avg. loss per last 100 batches: 0.026159
[2022-01-11 15:41:38,602][root][INFO] - Epoch: 19: Step: 101/920, loss=0.024533, lr=0.000006
[2022-01-11 15:41:38,609][root][INFO] - Epoch: 19: Step: 101/920, loss=0.024533, lr=0.000006
[2022-01-11 15:41:38,609][root][INFO] - Epoch: 19: Step: 101/920, loss=0.024533, lr=0.000006
[2022-01-11 15:41:38,612][root][INFO] - Epoch: 19: Step: 101/920, loss=0.024533, lr=0.000006
[2022-01-11 15:43:17,211][root][INFO] - Train batch 200
[2022-01-11 15:43:17,211][root][INFO] - Avg. loss per last 100 batches: 0.028406
[2022-01-11 15:43:17,216][root][INFO] - Train batch 200
[2022-01-11 15:43:17,216][root][INFO] - Avg. loss per last 100 batches: 0.028406
[2022-01-11 15:43:17,217][root][INFO] - Train batch 200
[2022-01-11 15:43:17,217][root][INFO] - Avg. loss per last 100 batches: 0.028406
[2022-01-11 15:43:17,217][root][INFO] - Train batch 200
[2022-01-11 15:43:17,218][root][INFO] - Avg. loss per last 100 batches: 0.028406
[2022-01-11 15:43:18,159][root][INFO] - Epoch: 19: Step: 201/920, loss=0.013494, lr=0.000006
[2022-01-11 15:43:18,160][root][INFO] - Epoch: 19: Step: 201/920, loss=0.013494, lr=0.000006
[2022-01-11 15:43:18,160][root][INFO] - Epoch: 19: Step: 201/920, loss=0.013494, lr=0.000006
[2022-01-11 15:43:18,161][root][INFO] - Epoch: 19: Step: 201/920, loss=0.013494, lr=0.000006
[2022-01-11 15:44:54,307][root][INFO] - Train batch 300
[2022-01-11 15:44:54,307][root][INFO] - Avg. loss per last 100 batches: 0.026912
[2022-01-11 15:44:54,307][root][INFO] - Train batch 300
[2022-01-11 15:44:54,307][root][INFO] - Avg. loss per last 100 batches: 0.026912
[2022-01-11 15:44:54,308][root][INFO] - Train batch 300
[2022-01-11 15:44:54,308][root][INFO] - Avg. loss per last 100 batches: 0.026912
[2022-01-11 15:44:54,308][root][INFO] - Train batch 300
[2022-01-11 15:44:54,308][root][INFO] - Avg. loss per last 100 batches: 0.026912
[2022-01-11 15:44:55,187][root][INFO] - Epoch: 19: Step: 301/920, loss=0.023969, lr=0.000006
[2022-01-11 15:44:55,187][root][INFO] - Epoch: 19: Step: 301/920, loss=0.023969, lr=0.000006
[2022-01-11 15:44:55,187][root][INFO] - Epoch: 19: Step: 301/920, loss=0.023969, lr=0.000006
[2022-01-11 15:44:55,187][root][INFO] - Epoch: 19: Step: 301/920, loss=0.023969, lr=0.000006
[2022-01-11 15:46:34,093][root][INFO] - Train batch 400
[2022-01-11 15:46:34,093][root][INFO] - Avg. loss per last 100 batches: 0.030144
[2022-01-11 15:46:34,095][root][INFO] - Train batch 400
[2022-01-11 15:46:34,095][root][INFO] - Avg. loss per last 100 batches: 0.030144
[2022-01-11 15:46:34,095][root][INFO] - Train batch 400
[2022-01-11 15:46:34,095][root][INFO] - Avg. loss per last 100 batches: 0.030144
[2022-01-11 15:46:34,095][root][INFO] - Train batch 400
[2022-01-11 15:46:34,095][root][INFO] - Avg. loss per last 100 batches: 0.030144
[2022-01-11 15:46:35,147][root][INFO] - Epoch: 19: Step: 401/920, loss=0.037930, lr=0.000006
[2022-01-11 15:46:35,149][root][INFO] - Epoch: 19: Step: 401/920, loss=0.037930, lr=0.000006
[2022-01-11 15:46:35,151][root][INFO] - Epoch: 19: Step: 401/920, loss=0.037930, lr=0.000006
[2022-01-11 15:46:35,152][root][INFO] - Epoch: 19: Step: 401/920, loss=0.037930, lr=0.000006
[2022-01-11 15:48:14,545][root][INFO] - Train batch 500
[2022-01-11 15:48:14,545][root][INFO] - Avg. loss per last 100 batches: 0.028183
[2022-01-11 15:48:14,548][root][INFO] - Train batch 500
[2022-01-11 15:48:14,548][root][INFO] - Avg. loss per last 100 batches: 0.028183
[2022-01-11 15:48:14,549][root][INFO] - Train batch 500
[2022-01-11 15:48:14,549][root][INFO] - Avg. loss per last 100 batches: 0.028183
[2022-01-11 15:48:14,549][root][INFO] - Train batch 500
[2022-01-11 15:48:14,550][root][INFO] - Avg. loss per last 100 batches: 0.028183
[2022-01-11 15:48:15,578][root][INFO] - Epoch: 19: Step: 501/920, loss=0.048888, lr=0.000005
[2022-01-11 15:48:15,578][root][INFO] - Epoch: 19: Step: 501/920, loss=0.048888, lr=0.000005
[2022-01-11 15:48:15,579][root][INFO] - Epoch: 19: Step: 501/920, loss=0.048888, lr=0.000005
[2022-01-11 15:48:15,579][root][INFO] - Epoch: 19: Step: 501/920, loss=0.048888, lr=0.000005
[2022-01-11 15:49:50,261][root][INFO] - Train batch 600
[2022-01-11 15:49:50,261][root][INFO] - Avg. loss per last 100 batches: 0.028283
[2022-01-11 15:49:50,262][root][INFO] - Train batch 600
[2022-01-11 15:49:50,262][root][INFO] - Avg. loss per last 100 batches: 0.028283
[2022-01-11 15:49:50,263][root][INFO] - Train batch 600
[2022-01-11 15:49:50,263][root][INFO] - Avg. loss per last 100 batches: 0.028283
[2022-01-11 15:49:50,264][root][INFO] - Train batch 600
[2022-01-11 15:49:50,264][root][INFO] - Avg. loss per last 100 batches: 0.028283
[2022-01-11 15:49:51,223][root][INFO] - Epoch: 19: Step: 601/920, loss=0.045496, lr=0.000005
[2022-01-11 15:49:51,225][root][INFO] - Epoch: 19: Step: 601/920, loss=0.045496, lr=0.000005
[2022-01-11 15:49:51,225][root][INFO] - Epoch: 19: Step: 601/920, loss=0.045496, lr=0.000005
[2022-01-11 15:49:51,225][root][INFO] - Epoch: 19: Step: 601/920, loss=0.045496, lr=0.000005
[2022-01-11 15:51:29,398][root][INFO] - Train batch 700
[2022-01-11 15:51:29,398][root][INFO] - Avg. loss per last 100 batches: 0.023195
[2022-01-11 15:51:29,398][root][INFO] - Train batch 700
[2022-01-11 15:51:29,398][root][INFO] - Avg. loss per last 100 batches: 0.023195
[2022-01-11 15:51:29,399][root][INFO] - Train batch 700
[2022-01-11 15:51:29,399][root][INFO] - Avg. loss per last 100 batches: 0.023195
[2022-01-11 15:51:29,400][root][INFO] - Train batch 700
[2022-01-11 15:51:29,400][root][INFO] - Avg. loss per last 100 batches: 0.023195
[2022-01-11 15:51:30,450][root][INFO] - Epoch: 19: Step: 701/920, loss=0.015523, lr=0.000005
[2022-01-11 15:51:30,450][root][INFO] - Epoch: 19: Step: 701/920, loss=0.015523, lr=0.000005
[2022-01-11 15:51:30,451][root][INFO] - Epoch: 19: Step: 701/920, loss=0.015523, lr=0.000005
[2022-01-11 15:51:30,451][root][INFO] - Epoch: 19: Step: 701/920, loss=0.015523, lr=0.000005
[2022-01-11 15:53:10,012][root][INFO] - Train batch 800
[2022-01-11 15:53:10,012][root][INFO] - Avg. loss per last 100 batches: 0.027811
[2022-01-11 15:53:10,018][root][INFO] - Train batch 800
[2022-01-11 15:53:10,018][root][INFO] - Avg. loss per last 100 batches: 0.027811
[2022-01-11 15:53:10,018][root][INFO] - Train batch 800
[2022-01-11 15:53:10,019][root][INFO] - Avg. loss per last 100 batches: 0.027811
[2022-01-11 15:53:10,019][root][INFO] - Train batch 800
[2022-01-11 15:53:10,019][root][INFO] - Avg. loss per last 100 batches: 0.027811
[2022-01-11 15:53:10,998][root][INFO] - Epoch: 19: Step: 801/920, loss=0.005692, lr=0.000005
[2022-01-11 15:53:10,999][root][INFO] - Epoch: 19: Step: 801/920, loss=0.005692, lr=0.000005
[2022-01-11 15:53:11,000][root][INFO] - Epoch: 19: Step: 801/920, loss=0.005692, lr=0.000005
[2022-01-11 15:53:11,000][root][INFO] - Epoch: 19: Step: 801/920, loss=0.005692, lr=0.000005
[2022-01-11 15:54:48,241][root][INFO] - Train batch 900
[2022-01-11 15:54:48,242][root][INFO] - Avg. loss per last 100 batches: 0.036367
[2022-01-11 15:54:48,243][root][INFO] - Train batch 900
[2022-01-11 15:54:48,243][root][INFO] - Avg. loss per last 100 batches: 0.036367
[2022-01-11 15:54:48,245][root][INFO] - Train batch 900
[2022-01-11 15:54:48,245][root][INFO] - Avg. loss per last 100 batches: 0.036367
[2022-01-11 15:54:48,246][root][INFO] - Train batch 900
[2022-01-11 15:54:48,246][root][INFO] - Avg. loss per last 100 batches: 0.036367
[2022-01-11 15:54:49,097][root][INFO] - Epoch: 19: Step: 901/920, loss=0.115560, lr=0.000005
[2022-01-11 15:54:49,098][root][INFO] - Epoch: 19: Step: 901/920, loss=0.115560, lr=0.000005
[2022-01-11 15:54:49,103][root][INFO] - Epoch: 19: Step: 901/920, loss=0.115560, lr=0.000005
[2022-01-11 15:54:49,104][root][INFO] - Epoch: 19: Step: 901/920, loss=0.115560, lr=0.000005
[2022-01-11 15:55:07,922][root][INFO] - rank=0, Validation: Epoch: 19 Step: 920/920
[2022-01-11 15:55:07,922][root][INFO] - rank=2, Validation: Epoch: 19 Step: 920/920
[2022-01-11 15:55:07,923][root][INFO] - NLL validation ...
[2022-01-11 15:55:07,923][root][INFO] - NLL validation ...
[2022-01-11 15:55:07,924][root][INFO] - rank=3, Validation: Epoch: 19 Step: 920/920
[2022-01-11 15:55:07,924][root][INFO] - rank=2; Iteration start
[2022-01-11 15:55:07,924][root][INFO] - NLL validation ...
[2022-01-11 15:55:07,924][root][INFO] - rank=0; Iteration start
[2022-01-11 15:55:07,924][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:07,924][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:55:07,924][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:07,924][root][INFO] - rank=1, Validation: Epoch: 19 Step: 920/920
[2022-01-11 15:55:07,924][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 15:55:07,924][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:55:07,924][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 15:55:07,924][root][INFO] - NLL validation ...
[2022-01-11 15:55:07,925][root][INFO] - rank=3; Iteration start
[2022-01-11 15:55:07,925][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:07,925][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:55:07,925][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 15:55:07,925][root][INFO] - rank=1; Iteration start
[2022-01-11 15:55:07,925][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:07,925][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:55:07,925][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 15:55:07,933][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 15:55:07,933][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 15:55:07,934][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 15:55:07,935][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 15:55:08,670][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 15:55:08,670][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 15:55:08,670][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 15:55:08,671][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 15:55:09,406][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 15:55:09,407][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 15:55:09,407][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 15:55:09,407][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 15:55:10,143][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 15:55:10,143][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 15:55:10,144][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 15:55:10,144][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 15:55:10,881][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 15:55:10,881][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 15:55:10,881][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 15:55:10,882][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 15:55:11,618][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 15:55:11,618][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 15:55:11,618][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 15:55:11,619][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 15:55:12,357][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 15:55:12,358][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 15:55:12,358][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 15:55:12,359][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 15:55:13,097][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 15:55:13,098][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 15:55:13,099][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 15:55:13,099][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 15:55:13,835][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 15:55:13,836][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 15:55:13,836][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 15:55:13,836][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 15:55:14,571][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 15:55:14,571][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 15:55:14,571][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 15:55:14,571][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 15:55:15,309][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 15:55:15,940][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 15:55:15,946][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 15:55:16,206][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 15:55:16,938][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 15:55:16,938][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 15:55:16,941][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 15:55:17,778][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 15:55:18,509][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 15:55:18,509][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 15:55:18,509][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 15:55:18,509][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 15:55:19,248][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 15:55:19,249][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 15:55:19,249][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 15:55:19,249][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 15:55:19,988][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 15:55:19,988][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 15:55:19,989][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 15:55:19,989][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 15:55:20,724][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 15:55:20,724][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 15:55:20,724][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 15:55:20,726][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 15:55:21,460][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 15:55:21,460][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 15:55:21,460][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 15:55:21,461][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 15:55:22,202][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 15:55:22,202][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 15:55:22,202][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 15:55:22,203][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 15:55:22,939][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 15:55:22,939][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 15:55:22,939][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 15:55:22,942][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 15:55:23,679][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 15:55:23,679][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 15:55:23,679][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 15:55:23,679][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 15:55:24,419][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 15:55:24,419][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 15:55:24,419][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 15:55:24,419][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 15:55:25,156][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 15:55:25,157][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 15:55:25,157][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 15:55:25,157][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 15:55:25,896][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 15:55:25,896][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 15:55:25,897][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 15:55:25,897][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 15:55:26,634][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 15:55:26,634][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 15:55:26,634][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 15:55:26,635][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 15:55:27,373][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 15:55:28,033][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 15:55:28,125][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 15:55:28,236][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 15:55:28,961][root][INFO] - rank=3; last iteration 25
[2022-01-11 15:55:28,961][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:55:28,961][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 15:55:28,961][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:28,961][root][INFO] - NLL Validation: loss = 0.409196. correct prediction ratio  5690/6400 ~  0.889062
[2022-01-11 15:55:28,962][root][INFO] - rank=2; last iteration 25
[2022-01-11 15:55:28,962][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:55:28,962][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 15:55:28,962][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:28,962][root][INFO] - NLL Validation: loss = 0.409196. correct prediction ratio  5690/6400 ~  0.889062
[2022-01-11 15:55:28,962][root][INFO] - rank=1; last iteration 25
[2022-01-11 15:55:28,962][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:55:28,962][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 15:55:28,962][root][INFO] - rank=0; last iteration 25
[2022-01-11 15:55:28,962][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:28,962][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:55:28,962][root][INFO] - NLL Validation: loss = 0.409196. correct prediction ratio  5690/6400 ~  0.889062
[2022-01-11 15:55:28,962][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 15:55:28,962][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:28,962][root][INFO] - NLL Validation: loss = 0.409196. correct prediction ratio  5690/6400 ~  0.889062
[2022-01-11 15:55:28,964][root][INFO] - rank=3; last iteration 920
[2022-01-11 15:55:28,964][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:55:28,964][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 15:55:28,964][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:28,964][root][INFO] - rank=2; last iteration 920
[2022-01-11 15:55:28,964][root][INFO] - Epoch finished on 3
[2022-01-11 15:55:28,964][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:55:28,964][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 15:55:28,965][root][INFO] - NLL validation ...
[2022-01-11 15:55:28,965][root][INFO] - rank=1; last iteration 920
[2022-01-11 15:55:28,965][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:55:28,965][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 15:55:28,965][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:28,965][root][INFO] - Epoch finished on 2
[2022-01-11 15:55:28,965][root][INFO] - NLL validation ...
[2022-01-11 15:55:28,965][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:28,965][root][INFO] - Epoch finished on 1
[2022-01-11 15:55:28,965][root][INFO] - NLL validation ...
[2022-01-11 15:55:28,966][root][INFO] - rank=3; Iteration start
[2022-01-11 15:55:28,966][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:28,966][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:55:28,966][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 15:55:28,966][root][INFO] - rank=2; Iteration start
[2022-01-11 15:55:28,966][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:28,966][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:55:28,966][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 15:55:28,967][root][INFO] - rank=1; Iteration start
[2022-01-11 15:55:28,967][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:28,967][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:55:28,967][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 15:55:28,975][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 15:55:28,975][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 15:55:28,976][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 15:55:33,080][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.19
[2022-01-11 15:55:33,080][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.19
[2022-01-11 15:55:33,081][root][INFO] - rank=0; last iteration 920
[2022-01-11 15:55:33,081][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 15:55:33,081][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 15:55:33,082][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:33,082][root][INFO] - Epoch finished on 0
[2022-01-11 15:55:33,082][root][INFO] - NLL validation ...
[2022-01-11 15:55:33,083][root][INFO] - rank=0; Iteration start
[2022-01-11 15:55:33,083][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:33,083][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 15:55:33,083][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 15:55:33,091][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 15:55:33,834][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 15:55:33,835][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 15:55:33,835][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 15:55:34,442][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 15:55:35,171][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 15:55:35,171][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 15:55:35,172][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 15:55:35,173][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 15:55:35,906][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 15:55:35,907][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 15:55:35,907][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 15:55:35,908][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 15:55:36,644][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 15:55:36,644][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 15:55:36,645][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 15:55:36,645][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 15:55:37,381][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 15:55:37,382][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 15:55:37,382][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 15:55:37,383][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 15:55:38,120][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 15:55:38,120][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 15:55:38,121][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 15:55:38,121][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 15:55:38,857][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 15:55:38,857][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 15:55:38,858][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 15:55:38,859][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 15:55:39,594][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 15:55:39,594][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 15:55:39,595][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 15:55:39,595][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 15:55:40,328][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 15:55:40,328][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 15:55:40,329][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 15:55:40,330][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 15:55:41,070][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 15:55:41,071][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 15:55:41,071][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 15:55:41,072][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 15:55:41,807][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 15:55:41,807][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 15:55:41,807][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 15:55:41,809][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 15:55:42,546][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 15:55:42,546][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 15:55:42,547][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 15:55:42,548][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 15:55:43,284][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 15:55:43,900][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 15:55:43,957][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 15:55:44,065][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 15:55:44,799][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 15:55:44,800][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 15:55:44,800][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 15:55:45,396][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 15:55:46,127][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 15:55:46,128][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 15:55:46,128][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 15:55:46,130][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 15:55:46,860][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 15:55:46,860][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 15:55:46,860][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 15:55:46,862][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 15:55:47,597][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 15:55:47,597][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 15:55:47,598][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 15:55:47,599][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 15:55:48,337][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 15:55:48,337][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 15:55:48,337][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 15:55:48,337][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 15:55:49,073][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 15:55:49,073][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 15:55:49,073][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 15:55:49,076][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 15:55:49,809][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 15:55:49,809][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 15:55:49,809][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 15:55:49,812][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 15:55:50,545][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 15:55:50,545][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 15:55:50,546][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 15:55:50,547][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 15:55:51,284][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 15:55:51,284][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 15:55:51,285][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 15:55:51,286][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 15:55:52,020][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 15:55:52,020][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 15:55:52,021][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 15:55:52,022][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 15:55:52,756][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 15:55:52,757][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 15:55:52,757][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 15:55:52,757][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 15:55:53,484][root][INFO] - rank=0; last iteration 25
[2022-01-11 15:55:53,484][root][INFO] - rank=2; last iteration 25
[2022-01-11 15:55:53,484][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:55:53,484][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:55:53,484][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 15:55:53,484][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 15:55:53,485][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:53,484][root][INFO] - rank=3; last iteration 25
[2022-01-11 15:55:53,485][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:53,485][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:55:53,485][root][INFO] - NLL Validation: loss = 0.409196. correct prediction ratio  5690/6400 ~  0.889062
[2022-01-11 15:55:53,485][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 15:55:53,485][root][INFO] - NLL Validation: loss = 0.409196. correct prediction ratio  5690/6400 ~  0.889062
[2022-01-11 15:55:53,485][root][INFO] - rank=1; last iteration 25
[2022-01-11 15:55:53,485][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:53,485][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 15:55:53,485][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 15:55:53,485][root][INFO] - NLL Validation: loss = 0.409196. correct prediction ratio  5690/6400 ~  0.889062
[2022-01-11 15:55:53,485][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 15:55:53,485][root][INFO] - NLL Validation: loss = 0.409196. correct prediction ratio  5690/6400 ~  0.889062
[2022-01-11 15:55:53,486][root][INFO] - Av Loss per epoch=0.028482
[2022-01-11 15:55:53,486][root][INFO] - epoch total correct predictions=58238
[2022-01-11 15:55:53,486][root][INFO] - Av Loss per epoch=0.028482
[2022-01-11 15:55:53,486][root][INFO] - epoch total correct predictions=58238
[2022-01-11 15:55:53,486][root][INFO] - Av Loss per epoch=0.028482
[2022-01-11 15:55:53,486][root][INFO] - epoch total correct predictions=58238
[2022-01-11 15:55:53,488][root][INFO] - ***** Epoch 20 *****
[2022-01-11 15:55:53,488][root][INFO] - ***** Epoch 20 *****
[2022-01-11 15:55:53,488][root][INFO] - ***** Epoch 20 *****
[2022-01-11 15:55:53,489][root][INFO] - rank=2; Iteration start
[2022-01-11 15:55:53,489][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:53,489][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:55:53,489][root][INFO] - rank=1; Iteration start
[2022-01-11 15:55:53,489][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:53,489][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:55:53,489][root][INFO] - rank=3; Iteration start
[2022-01-11 15:55:53,490][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:53,490][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:55:53,490][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 15:55:53,490][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 15:55:53,490][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 15:55:58,616][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.19
[2022-01-11 15:55:58,616][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.19
[2022-01-11 15:55:58,616][root][INFO] - Av Loss per epoch=0.028482
[2022-01-11 15:55:58,616][root][INFO] - epoch total correct predictions=58238
[2022-01-11 15:55:58,618][root][INFO] - ***** Epoch 20 *****
[2022-01-11 15:55:58,620][root][INFO] - rank=0; Iteration start
[2022-01-11 15:55:58,620][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 15:55:58,620][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 15:55:58,621][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 15:55:59,646][root][INFO] - Epoch: 20: Step: 1/920, loss=0.003965, lr=0.000005
[2022-01-11 15:55:59,648][root][INFO] - Epoch: 20: Step: 1/920, loss=0.003965, lr=0.000005
[2022-01-11 15:55:59,652][root][INFO] - Epoch: 20: Step: 1/920, loss=0.003965, lr=0.000005
[2022-01-11 15:55:59,654][root][INFO] - Epoch: 20: Step: 1/920, loss=0.003965, lr=0.000005
[2022-01-11 15:57:38,229][root][INFO] - Train batch 100
[2022-01-11 15:57:38,229][root][INFO] - Avg. loss per last 100 batches: 0.025694
[2022-01-11 15:57:38,234][root][INFO] - Train batch 100
[2022-01-11 15:57:38,234][root][INFO] - Avg. loss per last 100 batches: 0.025694
[2022-01-11 15:57:38,234][root][INFO] - Train batch 100
[2022-01-11 15:57:38,235][root][INFO] - Avg. loss per last 100 batches: 0.025694
[2022-01-11 15:57:38,235][root][INFO] - Train batch 100
[2022-01-11 15:57:38,235][root][INFO] - Avg. loss per last 100 batches: 0.025694
[2022-01-11 15:57:39,280][root][INFO] - Epoch: 20: Step: 101/920, loss=0.014031, lr=0.000005
[2022-01-11 15:57:39,284][root][INFO] - Epoch: 20: Step: 101/920, loss=0.014031, lr=0.000005
[2022-01-11 15:57:39,285][root][INFO] - Epoch: 20: Step: 101/920, loss=0.014031, lr=0.000005
[2022-01-11 15:57:39,285][root][INFO] - Epoch: 20: Step: 101/920, loss=0.014031, lr=0.000005
[2022-01-11 15:59:15,454][root][INFO] - Train batch 200
[2022-01-11 15:59:15,454][root][INFO] - Avg. loss per last 100 batches: 0.025998
[2022-01-11 15:59:15,454][root][INFO] - Train batch 200
[2022-01-11 15:59:15,454][root][INFO] - Train batch 200
[2022-01-11 15:59:15,454][root][INFO] - Avg. loss per last 100 batches: 0.025998
[2022-01-11 15:59:15,454][root][INFO] - Avg. loss per last 100 batches: 0.025998
[2022-01-11 15:59:15,454][root][INFO] - Train batch 200
[2022-01-11 15:59:15,454][root][INFO] - Avg. loss per last 100 batches: 0.025998
[2022-01-11 15:59:17,422][root][INFO] - Epoch: 20: Step: 201/920, loss=0.001262, lr=0.000005
[2022-01-11 15:59:17,423][root][INFO] - Epoch: 20: Step: 201/920, loss=0.001262, lr=0.000005
[2022-01-11 15:59:17,423][root][INFO] - Epoch: 20: Step: 201/920, loss=0.001262, lr=0.000005
[2022-01-11 15:59:17,423][root][INFO] - Epoch: 20: Step: 201/920, loss=0.001262, lr=0.000005
[2022-01-11 16:00:54,765][root][INFO] - Train batch 300
[2022-01-11 16:00:54,765][root][INFO] - Avg. loss per last 100 batches: 0.025504
[2022-01-11 16:00:54,772][root][INFO] - Train batch 300
[2022-01-11 16:00:54,772][root][INFO] - Avg. loss per last 100 batches: 0.025504
[2022-01-11 16:00:54,772][root][INFO] - Train batch 300
[2022-01-11 16:00:54,772][root][INFO] - Train batch 300
[2022-01-11 16:00:54,772][root][INFO] - Avg. loss per last 100 batches: 0.025504
[2022-01-11 16:00:54,772][root][INFO] - Avg. loss per last 100 batches: 0.025504
[2022-01-11 16:00:56,723][root][INFO] - Epoch: 20: Step: 301/920, loss=0.019649, lr=0.000005
[2022-01-11 16:00:56,723][root][INFO] - Epoch: 20: Step: 301/920, loss=0.019649, lr=0.000005
[2022-01-11 16:00:56,723][root][INFO] - Epoch: 20: Step: 301/920, loss=0.019649, lr=0.000005
[2022-01-11 16:00:56,723][root][INFO] - Epoch: 20: Step: 301/920, loss=0.019649, lr=0.000005
[2022-01-11 16:02:35,495][root][INFO] - Train batch 400
[2022-01-11 16:02:35,495][root][INFO] - Avg. loss per last 100 batches: 0.024087
[2022-01-11 16:02:35,495][root][INFO] - Train batch 400
[2022-01-11 16:02:35,495][root][INFO] - Avg. loss per last 100 batches: 0.024087
[2022-01-11 16:02:35,495][root][INFO] - Train batch 400
[2022-01-11 16:02:35,495][root][INFO] - Avg. loss per last 100 batches: 0.024087
[2022-01-11 16:02:35,506][root][INFO] - Train batch 400
[2022-01-11 16:02:35,506][root][INFO] - Avg. loss per last 100 batches: 0.024087
[2022-01-11 16:02:36,361][root][INFO] - Epoch: 20: Step: 401/920, loss=0.004659, lr=0.000005
[2022-01-11 16:02:36,361][root][INFO] - Epoch: 20: Step: 401/920, loss=0.004659, lr=0.000005
[2022-01-11 16:02:36,361][root][INFO] - Epoch: 20: Step: 401/920, loss=0.004659, lr=0.000005
[2022-01-11 16:02:36,361][root][INFO] - Epoch: 20: Step: 401/920, loss=0.004659, lr=0.000005
[2022-01-11 16:04:13,948][root][INFO] - Train batch 500
[2022-01-11 16:04:13,948][root][INFO] - Avg. loss per last 100 batches: 0.025001
[2022-01-11 16:04:13,950][root][INFO] - Train batch 500
[2022-01-11 16:04:13,950][root][INFO] - Avg. loss per last 100 batches: 0.025001
[2022-01-11 16:04:13,951][root][INFO] - Train batch 500
[2022-01-11 16:04:13,951][root][INFO] - Avg. loss per last 100 batches: 0.025001
[2022-01-11 16:04:13,961][root][INFO] - Train batch 500
[2022-01-11 16:04:13,961][root][INFO] - Avg. loss per last 100 batches: 0.025001
[2022-01-11 16:04:14,867][root][INFO] - Epoch: 20: Step: 501/920, loss=0.070466, lr=0.000005
[2022-01-11 16:04:14,869][root][INFO] - Epoch: 20: Step: 501/920, loss=0.070466, lr=0.000005
[2022-01-11 16:04:14,869][root][INFO] - Epoch: 20: Step: 501/920, loss=0.070466, lr=0.000005
[2022-01-11 16:04:14,881][root][INFO] - Epoch: 20: Step: 501/920, loss=0.070466, lr=0.000005
[2022-01-11 16:05:53,387][root][INFO] - Train batch 600
[2022-01-11 16:05:53,387][root][INFO] - Avg. loss per last 100 batches: 0.025109
[2022-01-11 16:05:53,396][root][INFO] - Train batch 600
[2022-01-11 16:05:53,396][root][INFO] - Avg. loss per last 100 batches: 0.025109
[2022-01-11 16:05:53,397][root][INFO] - Train batch 600
[2022-01-11 16:05:53,397][root][INFO] - Avg. loss per last 100 batches: 0.025109
[2022-01-11 16:05:53,409][root][INFO] - Train batch 600
[2022-01-11 16:05:53,409][root][INFO] - Avg. loss per last 100 batches: 0.025109
[2022-01-11 16:05:54,463][root][INFO] - Epoch: 20: Step: 601/920, loss=0.004530, lr=0.000005
[2022-01-11 16:05:54,466][root][INFO] - Epoch: 20: Step: 601/920, loss=0.004530, lr=0.000005
[2022-01-11 16:05:54,470][root][INFO] - Epoch: 20: Step: 601/920, loss=0.004530, lr=0.000005
[2022-01-11 16:05:54,479][root][INFO] - Epoch: 20: Step: 601/920, loss=0.004530, lr=0.000005
[2022-01-11 16:07:32,618][root][INFO] - Train batch 700
[2022-01-11 16:07:32,618][root][INFO] - Avg. loss per last 100 batches: 0.026932
[2022-01-11 16:07:32,618][root][INFO] - Train batch 700
[2022-01-11 16:07:32,618][root][INFO] - Avg. loss per last 100 batches: 0.026932
[2022-01-11 16:07:32,619][root][INFO] - Train batch 700
[2022-01-11 16:07:32,619][root][INFO] - Avg. loss per last 100 batches: 0.026932
[2022-01-11 16:07:32,619][root][INFO] - Train batch 700
[2022-01-11 16:07:32,620][root][INFO] - Avg. loss per last 100 batches: 0.026932
[2022-01-11 16:07:33,652][root][INFO] - Epoch: 20: Step: 701/920, loss=0.009716, lr=0.000005
[2022-01-11 16:07:33,665][root][INFO] - Epoch: 20: Step: 701/920, loss=0.009716, lr=0.000005
[2022-01-11 16:07:33,666][root][INFO] - Epoch: 20: Step: 701/920, loss=0.009716, lr=0.000005
[2022-01-11 16:07:33,666][root][INFO] - Epoch: 20: Step: 701/920, loss=0.009716, lr=0.000005
[2022-01-11 16:09:10,949][root][INFO] - Train batch 800
[2022-01-11 16:09:10,949][root][INFO] - Avg. loss per last 100 batches: 0.024793
[2022-01-11 16:09:10,963][root][INFO] - Train batch 800
[2022-01-11 16:09:10,963][root][INFO] - Avg. loss per last 100 batches: 0.024793
[2022-01-11 16:09:10,964][root][INFO] - Train batch 800
[2022-01-11 16:09:10,964][root][INFO] - Avg. loss per last 100 batches: 0.024793
[2022-01-11 16:09:10,964][root][INFO] - Train batch 800
[2022-01-11 16:09:10,965][root][INFO] - Avg. loss per last 100 batches: 0.024793
[2022-01-11 16:09:11,882][root][INFO] - Epoch: 20: Step: 801/920, loss=0.010998, lr=0.000005
[2022-01-11 16:09:11,882][root][INFO] - Epoch: 20: Step: 801/920, loss=0.010998, lr=0.000005
[2022-01-11 16:09:11,884][root][INFO] - Epoch: 20: Step: 801/920, loss=0.010998, lr=0.000005
[2022-01-11 16:09:11,884][root][INFO] - Epoch: 20: Step: 801/920, loss=0.010998, lr=0.000005
[2022-01-11 16:10:49,142][root][INFO] - Train batch 900
[2022-01-11 16:10:49,142][root][INFO] - Train batch 900
[2022-01-11 16:10:49,142][root][INFO] - Avg. loss per last 100 batches: 0.026229
[2022-01-11 16:10:49,142][root][INFO] - Avg. loss per last 100 batches: 0.026229
[2022-01-11 16:10:49,142][root][INFO] - Train batch 900
[2022-01-11 16:10:49,143][root][INFO] - Avg. loss per last 100 batches: 0.026229
[2022-01-11 16:10:49,143][root][INFO] - Train batch 900
[2022-01-11 16:10:49,143][root][INFO] - Avg. loss per last 100 batches: 0.026229
[2022-01-11 16:10:50,083][root][INFO] - Epoch: 20: Step: 901/920, loss=0.051869, lr=0.000005
[2022-01-11 16:10:50,084][root][INFO] - Epoch: 20: Step: 901/920, loss=0.051869, lr=0.000005
[2022-01-11 16:10:50,084][root][INFO] - Epoch: 20: Step: 901/920, loss=0.051869, lr=0.000005
[2022-01-11 16:10:50,085][root][INFO] - Epoch: 20: Step: 901/920, loss=0.051869, lr=0.000005
[2022-01-11 16:11:08,763][root][INFO] - rank=1, Validation: Epoch: 20 Step: 920/920
[2022-01-11 16:11:08,763][root][INFO] - NLL validation ...
[2022-01-11 16:11:08,763][root][INFO] - rank=3, Validation: Epoch: 20 Step: 920/920
[2022-01-11 16:11:08,763][root][INFO] - NLL validation ...
[2022-01-11 16:11:08,764][root][INFO] - rank=1; Iteration start
[2022-01-11 16:11:08,764][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:08,764][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:11:08,764][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 16:11:08,765][root][INFO] - rank=3; Iteration start
[2022-01-11 16:11:08,765][root][INFO] - rank=0, Validation: Epoch: 20 Step: 920/920
[2022-01-11 16:11:08,765][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:08,765][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:11:08,765][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 16:11:08,765][root][INFO] - NLL validation ...
[2022-01-11 16:11:08,765][root][INFO] - rank=2, Validation: Epoch: 20 Step: 920/920
[2022-01-11 16:11:08,766][root][INFO] - NLL validation ...
[2022-01-11 16:11:08,766][root][INFO] - rank=0; Iteration start
[2022-01-11 16:11:08,766][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:08,766][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:11:08,766][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 16:11:08,767][root][INFO] - rank=2; Iteration start
[2022-01-11 16:11:08,767][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:08,767][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:11:08,767][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 16:11:08,774][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 16:11:08,775][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 16:11:08,776][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 16:11:08,777][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 16:11:09,518][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 16:11:09,518][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 16:11:09,518][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 16:11:09,518][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 16:11:10,259][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 16:11:10,259][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 16:11:10,259][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 16:11:10,260][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 16:11:10,996][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 16:11:10,996][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 16:11:10,997][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 16:11:10,998][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 16:11:11,733][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 16:11:12,707][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 16:11:12,724][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 16:11:12,736][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 16:11:13,476][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 16:11:13,476][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 16:11:13,476][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 16:11:13,477][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 16:11:14,220][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 16:11:14,222][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 16:11:14,223][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 16:11:14,223][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 16:11:14,960][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 16:11:14,960][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 16:11:14,961][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 16:11:14,961][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 16:11:15,698][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 16:11:15,698][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 16:11:15,699][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 16:11:16,463][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 16:11:17,198][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 16:11:17,199][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 16:11:17,199][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 16:11:17,200][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 16:11:17,939][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 16:11:17,940][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 16:11:17,940][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 16:11:17,941][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 16:11:18,677][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 16:11:18,678][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 16:11:18,678][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 16:11:18,678][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 16:11:19,417][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 16:11:19,417][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 16:11:19,418][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 16:11:19,418][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 16:11:20,157][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 16:11:20,158][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 16:11:20,159][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 16:11:20,160][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 16:11:20,897][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 16:11:20,898][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 16:11:20,898][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 16:11:20,899][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 16:11:21,634][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 16:11:21,635][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 16:11:21,635][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 16:11:21,636][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 16:11:22,371][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 16:11:22,372][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 16:11:22,372][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 16:11:22,372][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 16:11:23,115][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 16:11:23,116][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 16:11:23,116][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 16:11:23,117][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 16:11:23,854][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 16:11:24,469][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 16:11:24,477][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 16:11:24,632][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 16:11:25,369][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 16:11:25,370][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 16:11:25,370][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 16:11:25,370][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 16:11:26,109][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 16:11:26,111][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 16:11:26,112][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 16:11:26,112][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 16:11:26,849][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 16:11:26,849][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 16:11:26,850][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 16:11:27,688][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 16:11:28,421][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 16:11:28,421][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 16:11:28,421][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 16:11:28,422][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 16:11:29,162][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 16:11:29,164][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 16:11:29,164][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 16:11:29,165][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 16:11:29,900][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 16:11:29,901][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 16:11:29,901][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 16:11:29,901][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 16:11:30,629][root][INFO] - rank=1; last iteration 25
[2022-01-11 16:11:30,629][root][INFO] - rank=3; last iteration 25
[2022-01-11 16:11:30,629][root][INFO] - rank=0; last iteration 25
[2022-01-11 16:11:30,629][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:11:30,629][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:11:30,629][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:11:30,629][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 16:11:30,629][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 16:11:30,629][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 16:11:30,629][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:30,629][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:30,629][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:30,629][root][INFO] - NLL Validation: loss = 0.402633. correct prediction ratio  5724/6400 ~  0.894375
[2022-01-11 16:11:30,629][root][INFO] - NLL Validation: loss = 0.402633. correct prediction ratio  5724/6400 ~  0.894375
[2022-01-11 16:11:30,629][root][INFO] - NLL Validation: loss = 0.402633. correct prediction ratio  5724/6400 ~  0.894375
[2022-01-11 16:11:30,629][root][INFO] - rank=2; last iteration 25
[2022-01-11 16:11:30,630][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:11:30,630][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 16:11:30,630][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:30,630][root][INFO] - NLL Validation: loss = 0.402633. correct prediction ratio  5724/6400 ~  0.894375
[2022-01-11 16:11:30,632][root][INFO] - rank=1; last iteration 920
[2022-01-11 16:11:30,632][root][INFO] - rank=3; last iteration 920
[2022-01-11 16:11:30,632][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:11:30,632][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:11:30,632][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 16:11:30,632][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 16:11:30,632][root][INFO] - rank=2; last iteration 920
[2022-01-11 16:11:30,632][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:30,632][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:11:30,632][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:30,632][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 16:11:30,632][root][INFO] - Epoch finished on 1
[2022-01-11 16:11:30,632][root][INFO] - Epoch finished on 3
[2022-01-11 16:11:30,632][root][INFO] - NLL validation ...
[2022-01-11 16:11:30,632][root][INFO] - NLL validation ...
[2022-01-11 16:11:30,633][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:30,633][root][INFO] - Epoch finished on 2
[2022-01-11 16:11:30,633][root][INFO] - NLL validation ...
[2022-01-11 16:11:30,634][root][INFO] - rank=1; Iteration start
[2022-01-11 16:11:30,634][root][INFO] - rank=3; Iteration start
[2022-01-11 16:11:30,634][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:30,634][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:30,634][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:11:30,634][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:11:30,634][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 16:11:30,634][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 16:11:30,634][root][INFO] - rank=2; Iteration start
[2022-01-11 16:11:30,634][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:30,634][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:11:30,634][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 16:11:30,641][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 16:11:30,641][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 16:11:30,642][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 16:11:34,619][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.20
[2022-01-11 16:11:34,619][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.20
[2022-01-11 16:11:34,621][root][INFO] - rank=0; last iteration 920
[2022-01-11 16:11:34,621][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:11:34,621][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 16:11:34,621][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:34,621][root][INFO] - Epoch finished on 0
[2022-01-11 16:11:34,621][root][INFO] - NLL validation ...
[2022-01-11 16:11:34,623][root][INFO] - rank=0; Iteration start
[2022-01-11 16:11:34,623][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:34,623][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:11:34,623][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 16:11:34,631][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 16:11:35,373][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 16:11:35,374][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 16:11:35,374][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 16:11:35,374][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 16:11:36,110][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 16:11:36,110][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 16:11:36,110][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 16:11:36,111][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 16:11:36,845][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 16:11:36,845][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 16:11:36,845][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 16:11:36,848][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 16:11:37,580][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 16:11:37,581][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 16:11:37,581][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 16:11:37,581][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 16:11:38,318][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 16:11:38,318][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 16:11:38,318][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 16:11:38,320][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 16:11:39,058][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 16:11:39,059][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 16:11:39,060][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 16:11:39,061][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 16:11:39,795][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 16:11:39,796][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 16:11:39,797][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 16:11:39,798][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 16:11:40,535][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 16:11:41,139][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 16:11:41,166][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 16:11:41,222][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 16:11:41,955][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 16:11:41,956][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 16:11:41,957][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 16:11:41,958][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 16:11:42,692][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 16:11:42,693][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 16:11:42,694][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 16:11:43,314][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 16:11:44,044][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 16:11:44,044][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 16:11:44,045][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 16:11:44,047][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 16:11:44,781][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 16:11:44,781][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 16:11:44,782][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 16:11:44,785][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 16:11:45,517][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 16:11:45,518][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 16:11:45,518][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 16:11:45,519][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 16:11:46,254][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 16:11:46,254][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 16:11:46,254][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 16:11:46,255][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 16:11:46,993][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 16:11:46,994][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 16:11:46,994][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 16:11:46,996][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 16:11:47,728][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 16:11:47,728][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 16:11:47,728][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 16:11:47,729][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 16:11:48,465][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 16:11:48,465][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 16:11:48,465][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 16:11:48,466][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 16:11:49,201][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 16:11:49,201][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 16:11:49,201][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 16:11:49,203][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 16:11:49,941][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 16:11:49,942][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 16:11:49,943][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 16:11:49,944][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 16:11:50,681][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 16:11:50,681][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 16:11:50,682][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 16:11:50,683][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 16:11:51,418][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 16:11:52,028][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 16:11:52,035][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 16:11:52,260][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 16:11:52,993][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 16:11:52,994][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 16:11:52,994][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 16:11:52,995][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 16:11:53,730][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 16:11:53,731][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 16:11:53,731][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 16:11:53,734][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 16:11:54,468][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 16:11:54,469][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 16:11:54,469][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 16:11:55,087][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 16:11:55,807][root][INFO] - rank=0; last iteration 25
[2022-01-11 16:11:55,807][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:11:55,807][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 16:11:55,807][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:55,807][root][INFO] - NLL Validation: loss = 0.402633. correct prediction ratio  5724/6400 ~  0.894375
[2022-01-11 16:11:55,808][root][INFO] - rank=3; last iteration 25
[2022-01-11 16:11:55,808][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:11:55,808][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 16:11:55,808][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:55,808][root][INFO] - rank=2; last iteration 25
[2022-01-11 16:11:55,808][root][INFO] - NLL Validation: loss = 0.402633. correct prediction ratio  5724/6400 ~  0.894375
[2022-01-11 16:11:55,808][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:11:55,808][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 16:11:55,808][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:55,808][root][INFO] - NLL Validation: loss = 0.402633. correct prediction ratio  5724/6400 ~  0.894375
[2022-01-11 16:11:55,808][root][INFO] - rank=1; last iteration 25
[2022-01-11 16:11:55,809][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:11:55,809][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 16:11:55,809][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:11:55,809][root][INFO] - NLL Validation: loss = 0.402633. correct prediction ratio  5724/6400 ~  0.894375
[2022-01-11 16:11:55,809][root][INFO] - Av Loss per epoch=0.025597
[2022-01-11 16:11:55,810][root][INFO] - epoch total correct predictions=58298
[2022-01-11 16:11:55,810][root][INFO] - Av Loss per epoch=0.025597
[2022-01-11 16:11:55,810][root][INFO] - epoch total correct predictions=58298
[2022-01-11 16:11:55,810][root][INFO] - Av Loss per epoch=0.025597
[2022-01-11 16:11:55,810][root][INFO] - epoch total correct predictions=58298
[2022-01-11 16:11:55,811][root][INFO] - ***** Epoch 21 *****
[2022-01-11 16:11:55,811][root][INFO] - ***** Epoch 21 *****
[2022-01-11 16:11:55,812][root][INFO] - ***** Epoch 21 *****
[2022-01-11 16:11:55,813][root][INFO] - rank=3; Iteration start
[2022-01-11 16:11:55,813][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:55,813][root][INFO] - rank=2; Iteration start
[2022-01-11 16:11:55,813][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:11:55,813][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:55,813][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:11:55,813][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 16:11:55,813][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 16:11:55,814][root][INFO] - rank=1; Iteration start
[2022-01-11 16:11:55,814][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:11:55,814][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:11:55,814][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 16:12:00,843][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.20
[2022-01-11 16:12:00,843][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.20
[2022-01-11 16:12:00,844][root][INFO] - Av Loss per epoch=0.025597
[2022-01-11 16:12:00,844][root][INFO] - epoch total correct predictions=58298
[2022-01-11 16:12:00,845][root][INFO] - ***** Epoch 21 *****
[2022-01-11 16:12:00,847][root][INFO] - rank=0; Iteration start
[2022-01-11 16:12:00,847][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:12:00,847][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:12:00,847][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 16:12:01,796][root][INFO] - Epoch: 21: Step: 1/920, loss=0.015948, lr=0.000005
[2022-01-11 16:12:01,797][root][INFO] - Epoch: 21: Step: 1/920, loss=0.015948, lr=0.000005
[2022-01-11 16:12:01,798][root][INFO] - Epoch: 21: Step: 1/920, loss=0.015948, lr=0.000005
[2022-01-11 16:12:01,799][root][INFO] - Epoch: 21: Step: 1/920, loss=0.015948, lr=0.000005
[2022-01-11 16:13:40,017][root][INFO] - Train batch 100
[2022-01-11 16:13:40,017][root][INFO] - Avg. loss per last 100 batches: 0.029230
[2022-01-11 16:13:40,017][root][INFO] - Train batch 100
[2022-01-11 16:13:40,017][root][INFO] - Avg. loss per last 100 batches: 0.029230
[2022-01-11 16:13:40,018][root][INFO] - Train batch 100
[2022-01-11 16:13:40,018][root][INFO] - Avg. loss per last 100 batches: 0.029230
[2022-01-11 16:13:40,019][root][INFO] - Train batch 100
[2022-01-11 16:13:40,019][root][INFO] - Avg. loss per last 100 batches: 0.029230
[2022-01-11 16:13:41,069][root][INFO] - Epoch: 21: Step: 101/920, loss=0.010254, lr=0.000005
[2022-01-11 16:13:41,069][root][INFO] - Epoch: 21: Step: 101/920, loss=0.010254, lr=0.000005
[2022-01-11 16:13:41,070][root][INFO] - Epoch: 21: Step: 101/920, loss=0.010254, lr=0.000005
[2022-01-11 16:13:41,071][root][INFO] - Epoch: 21: Step: 101/920, loss=0.010254, lr=0.000005
[2022-01-11 16:15:16,844][root][INFO] - Train batch 200
[2022-01-11 16:15:16,845][root][INFO] - Avg. loss per last 100 batches: 0.023295
[2022-01-11 16:15:16,845][root][INFO] - Train batch 200
[2022-01-11 16:15:16,845][root][INFO] - Avg. loss per last 100 batches: 0.023295
[2022-01-11 16:15:16,846][root][INFO] - Train batch 200
[2022-01-11 16:15:16,846][root][INFO] - Avg. loss per last 100 batches: 0.023295
[2022-01-11 16:15:16,846][root][INFO] - Train batch 200
[2022-01-11 16:15:16,846][root][INFO] - Avg. loss per last 100 batches: 0.023295
[2022-01-11 16:15:17,836][root][INFO] - Epoch: 21: Step: 201/920, loss=0.005256, lr=0.000005
[2022-01-11 16:15:17,837][root][INFO] - Epoch: 21: Step: 201/920, loss=0.005256, lr=0.000005
[2022-01-11 16:15:17,837][root][INFO] - Epoch: 21: Step: 201/920, loss=0.005256, lr=0.000005
[2022-01-11 16:15:17,837][root][INFO] - Epoch: 21: Step: 201/920, loss=0.005256, lr=0.000005
[2022-01-11 16:16:56,929][root][INFO] - Train batch 300
[2022-01-11 16:16:56,929][root][INFO] - Avg. loss per last 100 batches: 0.026880
[2022-01-11 16:16:56,931][root][INFO] - Train batch 300
[2022-01-11 16:16:56,931][root][INFO] - Avg. loss per last 100 batches: 0.026880
[2022-01-11 16:16:56,932][root][INFO] - Train batch 300
[2022-01-11 16:16:56,932][root][INFO] - Avg. loss per last 100 batches: 0.026880
[2022-01-11 16:16:56,932][root][INFO] - Train batch 300
[2022-01-11 16:16:56,932][root][INFO] - Avg. loss per last 100 batches: 0.026880
[2022-01-11 16:16:57,974][root][INFO] - Epoch: 21: Step: 301/920, loss=0.016525, lr=0.000005
[2022-01-11 16:16:57,975][root][INFO] - Epoch: 21: Step: 301/920, loss=0.016525, lr=0.000005
[2022-01-11 16:16:57,975][root][INFO] - Epoch: 21: Step: 301/920, loss=0.016525, lr=0.000005
[2022-01-11 16:16:57,976][root][INFO] - Epoch: 21: Step: 301/920, loss=0.016525, lr=0.000005
[2022-01-11 16:18:36,603][root][INFO] - Train batch 400
[2022-01-11 16:18:36,604][root][INFO] - Avg. loss per last 100 batches: 0.022250
[2022-01-11 16:18:36,604][root][INFO] - Train batch 400
[2022-01-11 16:18:36,604][root][INFO] - Avg. loss per last 100 batches: 0.022250
[2022-01-11 16:18:36,605][root][INFO] - Train batch 400
[2022-01-11 16:18:36,605][root][INFO] - Avg. loss per last 100 batches: 0.022250
[2022-01-11 16:18:36,605][root][INFO] - Train batch 400
[2022-01-11 16:18:36,605][root][INFO] - Avg. loss per last 100 batches: 0.022250
[2022-01-11 16:18:37,654][root][INFO] - Epoch: 21: Step: 401/920, loss=0.003103, lr=0.000005
[2022-01-11 16:18:37,654][root][INFO] - Epoch: 21: Step: 401/920, loss=0.003103, lr=0.000005
[2022-01-11 16:18:37,655][root][INFO] - Epoch: 21: Step: 401/920, loss=0.003103, lr=0.000005
[2022-01-11 16:18:37,656][root][INFO] - Epoch: 21: Step: 401/920, loss=0.003103, lr=0.000005
[2022-01-11 16:20:14,038][root][INFO] - Train batch 500
[2022-01-11 16:20:14,039][root][INFO] - Avg. loss per last 100 batches: 0.028906
[2022-01-11 16:20:14,049][root][INFO] - Train batch 500
[2022-01-11 16:20:14,049][root][INFO] - Avg. loss per last 100 batches: 0.028906
[2022-01-11 16:20:14,049][root][INFO] - Train batch 500
[2022-01-11 16:20:14,049][root][INFO] - Avg. loss per last 100 batches: 0.028906
[2022-01-11 16:20:14,050][root][INFO] - Train batch 500
[2022-01-11 16:20:14,050][root][INFO] - Avg. loss per last 100 batches: 0.028906
[2022-01-11 16:20:15,099][root][INFO] - Epoch: 21: Step: 501/920, loss=0.021015, lr=0.000005
[2022-01-11 16:20:15,100][root][INFO] - Epoch: 21: Step: 501/920, loss=0.021015, lr=0.000005
[2022-01-11 16:20:15,100][root][INFO] - Epoch: 21: Step: 501/920, loss=0.021015, lr=0.000005
[2022-01-11 16:20:15,101][root][INFO] - Epoch: 21: Step: 501/920, loss=0.021015, lr=0.000005
[2022-01-11 16:21:54,066][root][INFO] - Train batch 600
[2022-01-11 16:21:54,067][root][INFO] - Avg. loss per last 100 batches: 0.027987
[2022-01-11 16:21:54,073][root][INFO] - Train batch 600
[2022-01-11 16:21:54,074][root][INFO] - Avg. loss per last 100 batches: 0.027987
[2022-01-11 16:21:54,075][root][INFO] - Train batch 600
[2022-01-11 16:21:54,075][root][INFO] - Avg. loss per last 100 batches: 0.027987
[2022-01-11 16:21:54,075][root][INFO] - Train batch 600
[2022-01-11 16:21:54,076][root][INFO] - Avg. loss per last 100 batches: 0.027987
[2022-01-11 16:21:55,127][root][INFO] - Epoch: 21: Step: 601/920, loss=0.036056, lr=0.000005
[2022-01-11 16:21:55,127][root][INFO] - Epoch: 21: Step: 601/920, loss=0.036056, lr=0.000005
[2022-01-11 16:21:55,128][root][INFO] - Epoch: 21: Step: 601/920, loss=0.036056, lr=0.000005
[2022-01-11 16:21:55,128][root][INFO] - Epoch: 21: Step: 601/920, loss=0.036056, lr=0.000005
[2022-01-11 16:23:33,732][root][INFO] - Train batch 700
[2022-01-11 16:23:33,732][root][INFO] - Train batch 700
[2022-01-11 16:23:33,732][root][INFO] - Avg. loss per last 100 batches: 0.024407
[2022-01-11 16:23:33,732][root][INFO] - Avg. loss per last 100 batches: 0.024407
[2022-01-11 16:23:33,732][root][INFO] - Train batch 700
[2022-01-11 16:23:33,733][root][INFO] - Avg. loss per last 100 batches: 0.024407
[2022-01-11 16:23:33,733][root][INFO] - Train batch 700
[2022-01-11 16:23:33,733][root][INFO] - Avg. loss per last 100 batches: 0.024407
[2022-01-11 16:23:34,593][root][INFO] - Epoch: 21: Step: 701/920, loss=0.023604, lr=0.000005
[2022-01-11 16:23:34,593][root][INFO] - Epoch: 21: Step: 701/920, loss=0.023604, lr=0.000005
[2022-01-11 16:23:34,593][root][INFO] - Epoch: 21: Step: 701/920, loss=0.023604, lr=0.000005
[2022-01-11 16:23:34,593][root][INFO] - Epoch: 21: Step: 701/920, loss=0.023604, lr=0.000005
[2022-01-11 16:25:11,102][root][INFO] - Train batch 800
[2022-01-11 16:25:11,102][root][INFO] - Avg. loss per last 100 batches: 0.025022
[2022-01-11 16:25:11,103][root][INFO] - Train batch 800
[2022-01-11 16:25:11,103][root][INFO] - Avg. loss per last 100 batches: 0.025022
[2022-01-11 16:25:11,103][root][INFO] - Train batch 800
[2022-01-11 16:25:11,104][root][INFO] - Avg. loss per last 100 batches: 0.025022
[2022-01-11 16:25:11,105][root][INFO] - Train batch 800
[2022-01-11 16:25:11,105][root][INFO] - Avg. loss per last 100 batches: 0.025022
[2022-01-11 16:25:12,147][root][INFO] - Epoch: 21: Step: 801/920, loss=0.030899, lr=0.000005
[2022-01-11 16:25:12,147][root][INFO] - Epoch: 21: Step: 801/920, loss=0.030899, lr=0.000005
[2022-01-11 16:25:12,148][root][INFO] - Epoch: 21: Step: 801/920, loss=0.030899, lr=0.000005
[2022-01-11 16:25:12,149][root][INFO] - Epoch: 21: Step: 801/920, loss=0.030899, lr=0.000005
[2022-01-11 16:26:50,437][root][INFO] - Train batch 900
[2022-01-11 16:26:50,437][root][INFO] - Avg. loss per last 100 batches: 0.028352
[2022-01-11 16:26:50,437][root][INFO] - Train batch 900
[2022-01-11 16:26:50,437][root][INFO] - Avg. loss per last 100 batches: 0.028352
[2022-01-11 16:26:50,437][root][INFO] - Train batch 900
[2022-01-11 16:26:50,437][root][INFO] - Train batch 900
[2022-01-11 16:26:50,437][root][INFO] - Avg. loss per last 100 batches: 0.028352
[2022-01-11 16:26:50,437][root][INFO] - Avg. loss per last 100 batches: 0.028352
[2022-01-11 16:26:51,468][root][INFO] - Epoch: 21: Step: 901/920, loss=0.029825, lr=0.000005
[2022-01-11 16:26:51,468][root][INFO] - Epoch: 21: Step: 901/920, loss=0.029825, lr=0.000005
[2022-01-11 16:26:51,470][root][INFO] - Epoch: 21: Step: 901/920, loss=0.029825, lr=0.000005
[2022-01-11 16:26:51,470][root][INFO] - Epoch: 21: Step: 901/920, loss=0.029825, lr=0.000005
[2022-01-11 16:27:11,209][root][INFO] - rank=0, Validation: Epoch: 21 Step: 920/920
[2022-01-11 16:27:11,209][root][INFO] - NLL validation ...
[2022-01-11 16:27:11,210][root][INFO] - rank=1, Validation: Epoch: 21 Step: 920/920
[2022-01-11 16:27:11,210][root][INFO] - NLL validation ...
[2022-01-11 16:27:11,210][root][INFO] - rank=2, Validation: Epoch: 21 Step: 920/920
[2022-01-11 16:27:11,210][root][INFO] - NLL validation ...
[2022-01-11 16:27:11,210][root][INFO] - rank=3, Validation: Epoch: 21 Step: 920/920
[2022-01-11 16:27:11,210][root][INFO] - NLL validation ...
[2022-01-11 16:27:11,210][root][INFO] - rank=0; Iteration start
[2022-01-11 16:27:11,210][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:11,211][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:27:11,211][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 16:27:11,211][root][INFO] - rank=1; Iteration start
[2022-01-11 16:27:11,211][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:11,211][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:27:11,211][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 16:27:11,211][root][INFO] - rank=2; Iteration start
[2022-01-11 16:27:11,211][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:11,211][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:27:11,212][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 16:27:11,212][root][INFO] - rank=3; Iteration start
[2022-01-11 16:27:11,212][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:11,212][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:27:11,212][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 16:27:11,221][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 16:27:11,221][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 16:27:11,221][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 16:27:11,222][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 16:27:11,961][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 16:27:11,962][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 16:27:11,964][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 16:27:11,990][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 16:27:12,726][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 16:27:12,726][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 16:27:12,726][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 16:27:12,727][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 16:27:13,461][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 16:27:13,462][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 16:27:13,462][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 16:27:13,462][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 16:27:14,202][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 16:27:14,204][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 16:27:14,204][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 16:27:15,178][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 16:27:15,906][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 16:27:15,907][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 16:27:15,907][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 16:27:15,907][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 16:27:16,645][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 16:27:16,645][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 16:27:16,645][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 16:27:16,645][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 16:27:17,381][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 16:27:17,381][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 16:27:17,381][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 16:27:17,382][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 16:27:18,120][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 16:27:18,122][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 16:27:18,122][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 16:27:18,124][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 16:27:18,857][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 16:27:18,857][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 16:27:18,857][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 16:27:18,858][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 16:27:19,598][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 16:27:19,598][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 16:27:19,598][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 16:27:19,598][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 16:27:20,335][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 16:27:20,335][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 16:27:20,336][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 16:27:20,336][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 16:27:21,077][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 16:27:21,677][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 16:27:21,701][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 16:27:21,886][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 16:27:22,616][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 16:27:22,617][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 16:27:22,617][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 16:27:22,618][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 16:27:23,352][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 16:27:23,352][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 16:27:23,353][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 16:27:23,355][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 16:27:24,093][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 16:27:24,094][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 16:27:24,094][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 16:27:24,095][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 16:27:24,831][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 16:27:24,831][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 16:27:24,832][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 16:27:24,833][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 16:27:25,570][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 16:27:25,570][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 16:27:25,570][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 16:27:25,571][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 16:27:26,307][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 16:27:26,307][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 16:27:26,307][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 16:27:27,043][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 16:27:27,780][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 16:27:27,781][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 16:27:27,781][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 16:27:27,781][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 16:27:28,518][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 16:27:28,518][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 16:27:28,519][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 16:27:28,519][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 16:27:29,254][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 16:27:29,255][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 16:27:29,255][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 16:27:29,255][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 16:27:29,996][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 16:27:29,997][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 16:27:29,997][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 16:27:30,000][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 16:27:30,735][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 16:27:30,735][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 16:27:30,735][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 16:27:30,736][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 16:27:31,473][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 16:27:31,473][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 16:27:31,473][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 16:27:31,474][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 16:27:32,201][root][INFO] - rank=1; last iteration 25
[2022-01-11 16:27:32,201][root][INFO] - rank=3; last iteration 25
[2022-01-11 16:27:32,201][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:27:32,201][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:27:32,201][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 16:27:32,201][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 16:27:32,201][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:32,201][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:32,201][root][INFO] - NLL Validation: loss = 0.397341. correct prediction ratio  5725/6400 ~  0.894531
[2022-01-11 16:27:32,201][root][INFO] - NLL Validation: loss = 0.397341. correct prediction ratio  5725/6400 ~  0.894531
[2022-01-11 16:27:32,201][root][INFO] - rank=2; last iteration 25
[2022-01-11 16:27:32,202][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:27:32,202][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 16:27:32,202][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:32,202][root][INFO] - rank=0; last iteration 25
[2022-01-11 16:27:32,202][root][INFO] - NLL Validation: loss = 0.397341. correct prediction ratio  5725/6400 ~  0.894531
[2022-01-11 16:27:32,202][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:27:32,202][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 16:27:32,202][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:32,202][root][INFO] - NLL Validation: loss = 0.397341. correct prediction ratio  5725/6400 ~  0.894531
[2022-01-11 16:27:32,204][root][INFO] - rank=1; last iteration 920
[2022-01-11 16:27:32,204][root][INFO] - rank=3; last iteration 920
[2022-01-11 16:27:32,204][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:27:32,204][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:27:32,204][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 16:27:32,204][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 16:27:32,204][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:32,204][root][INFO] - rank=2; last iteration 920
[2022-01-11 16:27:32,204][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:27:32,204][root][INFO] - Epoch finished on 1
[2022-01-11 16:27:32,204][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 16:27:32,204][root][INFO] - NLL validation ...
[2022-01-11 16:27:32,205][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:32,205][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:32,205][root][INFO] - Epoch finished on 3
[2022-01-11 16:27:32,205][root][INFO] - Epoch finished on 2
[2022-01-11 16:27:32,205][root][INFO] - NLL validation ...
[2022-01-11 16:27:32,205][root][INFO] - NLL validation ...
[2022-01-11 16:27:32,206][root][INFO] - rank=1; Iteration start
[2022-01-11 16:27:32,206][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:32,206][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:27:32,206][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 16:27:32,206][root][INFO] - rank=3; Iteration start
[2022-01-11 16:27:32,206][root][INFO] - rank=2; Iteration start
[2022-01-11 16:27:32,206][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:32,206][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:32,206][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:27:32,206][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:27:32,206][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 16:27:32,206][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 16:27:32,213][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 16:27:32,214][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 16:27:32,216][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 16:27:36,139][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.21
[2022-01-11 16:27:36,139][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.21
[2022-01-11 16:27:36,141][root][INFO] - rank=0; last iteration 920
[2022-01-11 16:27:36,141][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:27:36,141][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 16:27:36,141][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:36,141][root][INFO] - Epoch finished on 0
[2022-01-11 16:27:36,141][root][INFO] - NLL validation ...
[2022-01-11 16:27:36,143][root][INFO] - rank=0; Iteration start
[2022-01-11 16:27:36,143][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:36,143][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:27:36,143][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 16:27:36,152][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 16:27:36,891][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 16:27:37,499][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 16:27:37,511][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 16:27:37,790][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 16:27:38,524][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 16:27:38,524][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 16:27:38,524][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 16:27:38,526][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 16:27:39,260][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 16:27:39,261][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 16:27:39,263][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 16:27:39,264][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 16:27:40,003][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 16:27:40,004][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 16:27:40,004][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 16:27:40,006][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 16:27:40,744][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 16:27:40,745][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 16:27:40,746][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 16:27:40,746][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 16:27:41,481][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 16:27:41,481][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 16:27:41,482][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 16:27:41,483][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 16:27:42,216][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 16:27:42,216][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 16:27:42,217][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 16:27:43,022][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 16:27:43,753][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 16:27:43,754][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 16:27:43,755][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 16:27:43,756][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 16:27:44,490][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 16:27:44,491][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 16:27:44,492][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 16:27:44,492][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 16:27:45,229][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 16:27:45,230][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 16:27:45,232][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 16:27:45,235][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 16:27:45,974][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 16:27:45,975][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 16:27:45,976][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 16:27:45,977][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 16:27:46,715][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 16:27:46,716][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 16:27:46,716][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 16:27:46,717][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 16:27:47,453][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 16:27:47,453][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 16:27:47,454][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 16:27:47,455][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 16:27:48,190][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 16:27:48,190][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 16:27:48,190][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 16:27:48,192][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 16:27:48,930][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 16:27:49,544][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 16:27:49,572][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 16:27:49,643][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 16:27:50,381][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 16:27:50,381][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 16:27:50,381][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 16:27:50,382][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 16:27:51,120][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 16:27:51,121][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 16:27:51,121][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 16:27:51,122][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 16:27:51,861][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 16:27:51,862][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 16:27:51,862][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 16:27:51,863][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 16:27:52,598][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 16:27:52,598][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 16:27:52,599][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 16:27:52,600][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 16:27:53,336][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 16:27:53,336][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 16:27:53,336][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 16:27:53,337][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 16:27:54,073][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 16:27:54,073][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 16:27:54,074][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 16:27:54,667][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 16:27:55,398][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 16:27:55,398][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 16:27:55,399][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 16:27:55,400][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 16:27:56,139][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 16:27:56,139][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 16:27:56,139][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 16:27:56,140][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 16:27:56,878][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 16:27:56,878][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 16:27:56,879][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 16:27:56,880][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 16:27:57,609][root][INFO] - rank=2; last iteration 25
[2022-01-11 16:27:57,609][root][INFO] - rank=1; last iteration 25
[2022-01-11 16:27:57,610][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:27:57,610][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:27:57,610][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 16:27:57,610][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 16:27:57,610][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:57,610][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:57,610][root][INFO] - rank=3; last iteration 25
[2022-01-11 16:27:57,610][root][INFO] - rank=0; last iteration 25
[2022-01-11 16:27:57,610][root][INFO] - NLL Validation: loss = 0.397341. correct prediction ratio  5725/6400 ~  0.894531
[2022-01-11 16:27:57,610][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:27:57,610][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:27:57,610][root][INFO] - NLL Validation: loss = 0.397341. correct prediction ratio  5725/6400 ~  0.894531
[2022-01-11 16:27:57,610][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 16:27:57,610][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 16:27:57,610][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:57,610][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:27:57,610][root][INFO] - NLL Validation: loss = 0.397341. correct prediction ratio  5725/6400 ~  0.894531
[2022-01-11 16:27:57,610][root][INFO] - NLL Validation: loss = 0.397341. correct prediction ratio  5725/6400 ~  0.894531
[2022-01-11 16:27:57,611][root][INFO] - Av Loss per epoch=0.026220
[2022-01-11 16:27:57,611][root][INFO] - epoch total correct predictions=58298
[2022-01-11 16:27:57,611][root][INFO] - Av Loss per epoch=0.026220
[2022-01-11 16:27:57,611][root][INFO] - epoch total correct predictions=58298
[2022-01-11 16:27:57,611][root][INFO] - Av Loss per epoch=0.026220
[2022-01-11 16:27:57,612][root][INFO] - epoch total correct predictions=58298
[2022-01-11 16:27:57,613][root][INFO] - ***** Epoch 22 *****
[2022-01-11 16:27:57,613][root][INFO] - ***** Epoch 22 *****
[2022-01-11 16:27:57,613][root][INFO] - ***** Epoch 22 *****
[2022-01-11 16:27:57,615][root][INFO] - rank=2; Iteration start
[2022-01-11 16:27:57,615][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:57,615][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:27:57,615][root][INFO] - rank=3; Iteration start
[2022-01-11 16:27:57,615][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:57,615][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:27:57,615][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 16:27:57,615][root][INFO] - rank=1; Iteration start
[2022-01-11 16:27:57,615][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:27:57,615][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:27:57,615][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 16:27:57,616][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 16:28:02,337][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.21
[2022-01-11 16:28:02,337][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.21
[2022-01-11 16:28:02,337][root][INFO] - Av Loss per epoch=0.026220
[2022-01-11 16:28:02,338][root][INFO] - epoch total correct predictions=58298
[2022-01-11 16:28:02,339][root][INFO] - ***** Epoch 22 *****
[2022-01-11 16:28:02,341][root][INFO] - rank=0; Iteration start
[2022-01-11 16:28:02,341][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:28:02,341][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:28:02,342][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 16:28:03,253][root][INFO] - Epoch: 22: Step: 1/920, loss=0.051078, lr=0.000005
[2022-01-11 16:28:03,253][root][INFO] - Epoch: 22: Step: 1/920, loss=0.051078, lr=0.000005
[2022-01-11 16:28:03,254][root][INFO] - Epoch: 22: Step: 1/920, loss=0.051078, lr=0.000005
[2022-01-11 16:28:03,255][root][INFO] - Epoch: 22: Step: 1/920, loss=0.051078, lr=0.000005
[2022-01-11 16:29:38,061][root][INFO] - Train batch 100
[2022-01-11 16:29:38,062][root][INFO] - Avg. loss per last 100 batches: 0.020365
[2022-01-11 16:29:38,064][root][INFO] - Train batch 100
[2022-01-11 16:29:38,064][root][INFO] - Avg. loss per last 100 batches: 0.020365
[2022-01-11 16:29:38,065][root][INFO] - Train batch 100
[2022-01-11 16:29:38,065][root][INFO] - Avg. loss per last 100 batches: 0.020365
[2022-01-11 16:29:38,073][root][INFO] - Train batch 100
[2022-01-11 16:29:38,074][root][INFO] - Avg. loss per last 100 batches: 0.020365
[2022-01-11 16:29:38,965][root][INFO] - Epoch: 22: Step: 101/920, loss=0.012051, lr=0.000005
[2022-01-11 16:29:38,967][root][INFO] - Epoch: 22: Step: 101/920, loss=0.012051, lr=0.000005
[2022-01-11 16:29:38,967][root][INFO] - Epoch: 22: Step: 101/920, loss=0.012051, lr=0.000005
[2022-01-11 16:29:38,969][root][INFO] - Epoch: 22: Step: 101/920, loss=0.012051, lr=0.000005
[2022-01-11 16:31:18,394][root][INFO] - Train batch 200
[2022-01-11 16:31:18,394][root][INFO] - Avg. loss per last 100 batches: 0.026319
[2022-01-11 16:31:18,395][root][INFO] - Train batch 200
[2022-01-11 16:31:18,395][root][INFO] - Avg. loss per last 100 batches: 0.026319
[2022-01-11 16:31:18,396][root][INFO] - Train batch 200
[2022-01-11 16:31:18,396][root][INFO] - Avg. loss per last 100 batches: 0.026319
[2022-01-11 16:31:18,396][root][INFO] - Train batch 200
[2022-01-11 16:31:18,396][root][INFO] - Avg. loss per last 100 batches: 0.026319
[2022-01-11 16:31:19,434][root][INFO] - Epoch: 22: Step: 201/920, loss=0.036602, lr=0.000005
[2022-01-11 16:31:19,438][root][INFO] - Epoch: 22: Step: 201/920, loss=0.036602, lr=0.000005
[2022-01-11 16:31:19,439][root][INFO] - Epoch: 22: Step: 201/920, loss=0.036602, lr=0.000005
[2022-01-11 16:31:19,439][root][INFO] - Epoch: 22: Step: 201/920, loss=0.036602, lr=0.000005
[2022-01-11 16:32:57,447][root][INFO] - Train batch 300
[2022-01-11 16:32:57,448][root][INFO] - Avg. loss per last 100 batches: 0.020580
[2022-01-11 16:32:57,450][root][INFO] - Train batch 300
[2022-01-11 16:32:57,450][root][INFO] - Avg. loss per last 100 batches: 0.020580
[2022-01-11 16:32:57,450][root][INFO] - Train batch 300
[2022-01-11 16:32:57,451][root][INFO] - Avg. loss per last 100 batches: 0.020580
[2022-01-11 16:32:57,451][root][INFO] - Train batch 300
[2022-01-11 16:32:57,451][root][INFO] - Avg. loss per last 100 batches: 0.020580
[2022-01-11 16:32:58,390][root][INFO] - Epoch: 22: Step: 301/920, loss=0.017860, lr=0.000005
[2022-01-11 16:32:58,393][root][INFO] - Epoch: 22: Step: 301/920, loss=0.017860, lr=0.000005
[2022-01-11 16:32:58,393][root][INFO] - Epoch: 22: Step: 301/920, loss=0.017860, lr=0.000005
[2022-01-11 16:32:58,394][root][INFO] - Epoch: 22: Step: 301/920, loss=0.017860, lr=0.000005
[2022-01-11 16:34:35,353][root][INFO] - Train batch 400
[2022-01-11 16:34:35,353][root][INFO] - Train batch 400
[2022-01-11 16:34:35,353][root][INFO] - Avg. loss per last 100 batches: 0.026341
[2022-01-11 16:34:35,353][root][INFO] - Avg. loss per last 100 batches: 0.026341
[2022-01-11 16:34:35,356][root][INFO] - Train batch 400
[2022-01-11 16:34:35,356][root][INFO] - Avg. loss per last 100 batches: 0.026341
[2022-01-11 16:34:35,357][root][INFO] - Train batch 400
[2022-01-11 16:34:35,357][root][INFO] - Avg. loss per last 100 batches: 0.026341
[2022-01-11 16:34:36,413][root][INFO] - Epoch: 22: Step: 401/920, loss=0.006771, lr=0.000005
[2022-01-11 16:34:36,413][root][INFO] - Epoch: 22: Step: 401/920, loss=0.006771, lr=0.000005
[2022-01-11 16:34:36,414][root][INFO] - Epoch: 22: Step: 401/920, loss=0.006771, lr=0.000005
[2022-01-11 16:34:36,414][root][INFO] - Epoch: 22: Step: 401/920, loss=0.006771, lr=0.000005
[2022-01-11 16:36:14,284][root][INFO] - Train batch 500
[2022-01-11 16:36:14,284][root][INFO] - Avg. loss per last 100 batches: 0.026051
[2022-01-11 16:36:14,285][root][INFO] - Train batch 500
[2022-01-11 16:36:14,285][root][INFO] - Avg. loss per last 100 batches: 0.026051
[2022-01-11 16:36:14,286][root][INFO] - Train batch 500
[2022-01-11 16:36:14,286][root][INFO] - Avg. loss per last 100 batches: 0.026051
[2022-01-11 16:36:14,287][root][INFO] - Train batch 500
[2022-01-11 16:36:14,287][root][INFO] - Avg. loss per last 100 batches: 0.026051
[2022-01-11 16:36:15,146][root][INFO] - Epoch: 22: Step: 501/920, loss=0.051153, lr=0.000005
[2022-01-11 16:36:15,154][root][INFO] - Epoch: 22: Step: 501/920, loss=0.051153, lr=0.000005
[2022-01-11 16:36:15,155][root][INFO] - Epoch: 22: Step: 501/920, loss=0.051153, lr=0.000005
[2022-01-11 16:36:15,156][root][INFO] - Epoch: 22: Step: 501/920, loss=0.051153, lr=0.000005
[2022-01-11 16:37:53,483][root][INFO] - Train batch 600
[2022-01-11 16:37:53,483][root][INFO] - Avg. loss per last 100 batches: 0.021588
[2022-01-11 16:37:53,484][root][INFO] - Train batch 600
[2022-01-11 16:37:53,484][root][INFO] - Avg. loss per last 100 batches: 0.021588
[2022-01-11 16:37:53,484][root][INFO] - Train batch 600
[2022-01-11 16:37:53,484][root][INFO] - Avg. loss per last 100 batches: 0.021588
[2022-01-11 16:37:53,485][root][INFO] - Train batch 600
[2022-01-11 16:37:53,485][root][INFO] - Avg. loss per last 100 batches: 0.021588
[2022-01-11 16:37:54,325][root][INFO] - Epoch: 22: Step: 601/920, loss=0.033299, lr=0.000005
[2022-01-11 16:37:54,340][root][INFO] - Epoch: 22: Step: 601/920, loss=0.033299, lr=0.000005
[2022-01-11 16:37:54,340][root][INFO] - Epoch: 22: Step: 601/920, loss=0.033299, lr=0.000005
[2022-01-11 16:37:54,341][root][INFO] - Epoch: 22: Step: 601/920, loss=0.033299, lr=0.000005
[2022-01-11 16:39:31,478][root][INFO] - Train batch 700
[2022-01-11 16:39:31,478][root][INFO] - Avg. loss per last 100 batches: 0.029523
[2022-01-11 16:39:31,478][root][INFO] - Train batch 700
[2022-01-11 16:39:31,478][root][INFO] - Avg. loss per last 100 batches: 0.029523
[2022-01-11 16:39:31,478][root][INFO] - Train batch 700
[2022-01-11 16:39:31,479][root][INFO] - Avg. loss per last 100 batches: 0.029523
[2022-01-11 16:39:31,479][root][INFO] - Train batch 700
[2022-01-11 16:39:31,479][root][INFO] - Avg. loss per last 100 batches: 0.029523
[2022-01-11 16:39:32,324][root][INFO] - Epoch: 22: Step: 701/920, loss=0.094448, lr=0.000005
[2022-01-11 16:39:32,326][root][INFO] - Epoch: 22: Step: 701/920, loss=0.094448, lr=0.000005
[2022-01-11 16:39:32,327][root][INFO] - Epoch: 22: Step: 701/920, loss=0.094448, lr=0.000005
[2022-01-11 16:39:32,328][root][INFO] - Epoch: 22: Step: 701/920, loss=0.094448, lr=0.000005
[2022-01-11 16:41:11,414][root][INFO] - Train batch 800
[2022-01-11 16:41:11,414][root][INFO] - Avg. loss per last 100 batches: 0.022192
[2022-01-11 16:41:11,416][root][INFO] - Train batch 800
[2022-01-11 16:41:11,416][root][INFO] - Avg. loss per last 100 batches: 0.022192
[2022-01-11 16:41:11,416][root][INFO] - Train batch 800
[2022-01-11 16:41:11,416][root][INFO] - Avg. loss per last 100 batches: 0.022192
[2022-01-11 16:41:11,423][root][INFO] - Train batch 800
[2022-01-11 16:41:11,423][root][INFO] - Avg. loss per last 100 batches: 0.022192
[2022-01-11 16:41:12,357][root][INFO] - Epoch: 22: Step: 801/920, loss=0.011375, lr=0.000005
[2022-01-11 16:41:12,358][root][INFO] - Epoch: 22: Step: 801/920, loss=0.011375, lr=0.000005
[2022-01-11 16:41:12,360][root][INFO] - Epoch: 22: Step: 801/920, loss=0.011375, lr=0.000005
[2022-01-11 16:41:12,370][root][INFO] - Epoch: 22: Step: 801/920, loss=0.011375, lr=0.000005
[2022-01-11 16:42:51,313][root][INFO] - Train batch 900
[2022-01-11 16:42:51,313][root][INFO] - Train batch 900
[2022-01-11 16:42:51,313][root][INFO] - Avg. loss per last 100 batches: 0.026774
[2022-01-11 16:42:51,313][root][INFO] - Avg. loss per last 100 batches: 0.026774
[2022-01-11 16:42:51,313][root][INFO] - Train batch 900
[2022-01-11 16:42:51,313][root][INFO] - Avg. loss per last 100 batches: 0.026774
[2022-01-11 16:42:51,325][root][INFO] - Train batch 900
[2022-01-11 16:42:51,325][root][INFO] - Avg. loss per last 100 batches: 0.026774
[2022-01-11 16:42:52,270][root][INFO] - Epoch: 22: Step: 901/920, loss=0.035067, lr=0.000005
[2022-01-11 16:42:52,271][root][INFO] - Epoch: 22: Step: 901/920, loss=0.035067, lr=0.000005
[2022-01-11 16:42:52,272][root][INFO] - Epoch: 22: Step: 901/920, loss=0.035067, lr=0.000005
[2022-01-11 16:42:52,283][root][INFO] - Epoch: 22: Step: 901/920, loss=0.035067, lr=0.000005
[2022-01-11 16:43:11,290][root][INFO] - rank=0, Validation: Epoch: 22 Step: 920/920
[2022-01-11 16:43:11,290][root][INFO] - rank=3, Validation: Epoch: 22 Step: 920/920
[2022-01-11 16:43:11,290][root][INFO] - NLL validation ...
[2022-01-11 16:43:11,290][root][INFO] - NLL validation ...
[2022-01-11 16:43:11,290][root][INFO] - rank=2, Validation: Epoch: 22 Step: 920/920
[2022-01-11 16:43:11,291][root][INFO] - NLL validation ...
[2022-01-11 16:43:11,291][root][INFO] - rank=3; Iteration start
[2022-01-11 16:43:11,291][root][INFO] - rank=0; Iteration start
[2022-01-11 16:43:11,291][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:11,291][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:43:11,291][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:11,291][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 16:43:11,291][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:43:11,291][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 16:43:11,292][root][INFO] - rank=2; Iteration start
[2022-01-11 16:43:11,292][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:11,292][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:43:11,292][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 16:43:11,302][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 16:43:11,302][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 16:43:11,302][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 16:43:11,303][root][INFO] - rank=1, Validation: Epoch: 22 Step: 920/920
[2022-01-11 16:43:11,303][root][INFO] - NLL validation ...
[2022-01-11 16:43:11,304][root][INFO] - rank=1; Iteration start
[2022-01-11 16:43:11,304][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:11,304][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:43:11,304][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 16:43:11,315][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 16:43:12,047][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 16:43:12,049][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 16:43:12,069][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 16:43:13,021][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 16:43:13,751][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 16:43:13,752][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 16:43:13,753][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 16:43:13,753][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 16:43:14,487][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 16:43:14,488][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 16:43:14,488][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 16:43:14,489][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 16:43:15,226][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 16:43:15,226][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 16:43:15,226][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 16:43:15,227][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 16:43:15,969][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 16:43:15,969][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 16:43:15,971][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 16:43:15,971][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 16:43:16,711][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 16:43:16,712][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 16:43:16,712][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 16:43:16,712][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 16:43:17,450][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 16:43:18,406][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 16:43:18,439][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 16:43:18,455][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 16:43:19,191][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 16:43:19,192][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 16:43:19,192][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 16:43:19,192][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 16:43:19,931][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 16:43:19,933][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 16:43:19,933][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 16:43:19,933][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 16:43:20,671][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 16:43:20,672][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 16:43:20,672][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 16:43:20,673][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 16:43:21,412][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 16:43:21,412][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 16:43:21,413][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 16:43:21,413][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 16:43:22,150][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 16:43:22,151][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 16:43:22,151][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 16:43:22,152][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 16:43:22,892][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 16:43:22,894][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 16:43:22,895][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 16:43:22,895][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 16:43:23,633][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 16:43:23,633][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 16:43:23,633][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 16:43:23,634][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 16:43:24,370][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 16:43:24,371][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 16:43:24,372][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 16:43:24,979][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 16:43:25,710][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 16:43:25,711][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 16:43:25,711][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 16:43:25,712][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 16:43:26,454][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 16:43:26,454][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 16:43:26,455][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 16:43:26,455][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 16:43:27,190][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 16:43:27,190][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 16:43:27,190][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 16:43:27,191][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 16:43:27,931][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 16:43:27,933][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 16:43:27,933][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 16:43:27,933][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 16:43:28,670][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 16:43:28,671][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 16:43:28,671][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 16:43:28,671][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 16:43:29,408][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 16:43:30,026][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 16:43:30,036][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 16:43:30,167][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 16:43:30,903][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 16:43:30,903][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 16:43:30,904][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 16:43:30,904][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 16:43:31,643][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 16:43:31,644][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 16:43:31,644][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 16:43:31,644][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 16:43:32,380][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 16:43:32,380][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 16:43:32,380][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 16:43:32,381][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 16:43:33,108][root][INFO] - rank=3; last iteration 25
[2022-01-11 16:43:33,108][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:43:33,108][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 16:43:33,108][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:33,108][root][INFO] - NLL Validation: loss = 0.405451. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:43:33,108][root][INFO] - rank=1; last iteration 25
[2022-01-11 16:43:33,109][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:43:33,109][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 16:43:33,109][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:33,109][root][INFO] - rank=2; last iteration 25
[2022-01-11 16:43:33,109][root][INFO] - NLL Validation: loss = 0.405451. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:43:33,109][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:43:33,109][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 16:43:33,109][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:33,109][root][INFO] - NLL Validation: loss = 0.405451. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:43:33,111][root][INFO] - rank=3; last iteration 920
[2022-01-11 16:43:33,111][root][INFO] - rank=0; last iteration 25
[2022-01-11 16:43:33,111][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:43:33,111][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:43:33,111][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 16:43:33,111][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 16:43:33,111][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:33,111][root][INFO] - NLL Validation: loss = 0.405451. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:43:33,111][root][INFO] - rank=1; last iteration 920
[2022-01-11 16:43:33,111][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:43:33,111][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 16:43:33,111][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:33,111][root][INFO] - rank=2; last iteration 920
[2022-01-11 16:43:33,111][root][INFO] - Epoch finished on 3
[2022-01-11 16:43:33,111][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:43:33,112][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 16:43:33,112][root][INFO] - NLL validation ...
[2022-01-11 16:43:33,112][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:33,112][root][INFO] - Epoch finished on 1
[2022-01-11 16:43:33,112][root][INFO] - NLL validation ...
[2022-01-11 16:43:33,112][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:33,112][root][INFO] - Epoch finished on 2
[2022-01-11 16:43:33,112][root][INFO] - NLL validation ...
[2022-01-11 16:43:33,113][root][INFO] - rank=3; Iteration start
[2022-01-11 16:43:33,113][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:33,113][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:43:33,113][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 16:43:33,113][root][INFO] - rank=1; Iteration start
[2022-01-11 16:43:33,113][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:33,113][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:43:33,113][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 16:43:33,113][root][INFO] - rank=2; Iteration start
[2022-01-11 16:43:33,113][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:33,114][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:43:33,114][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 16:43:33,121][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 16:43:33,121][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 16:43:33,123][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 16:43:37,032][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.22
[2022-01-11 16:43:37,032][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.22
[2022-01-11 16:43:37,034][root][INFO] - rank=0; last iteration 920
[2022-01-11 16:43:37,034][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:43:37,034][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 16:43:37,035][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:37,035][root][INFO] - Epoch finished on 0
[2022-01-11 16:43:37,035][root][INFO] - NLL validation ...
[2022-01-11 16:43:37,036][root][INFO] - rank=0; Iteration start
[2022-01-11 16:43:37,036][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:37,036][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:43:37,036][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 16:43:37,046][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 16:43:37,793][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 16:43:37,794][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 16:43:37,794][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 16:43:37,794][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 16:43:38,530][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 16:43:38,530][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 16:43:38,532][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 16:43:38,532][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 16:43:39,267][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 16:43:39,267][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 16:43:39,269][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 16:43:39,269][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 16:43:40,003][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 16:43:40,003][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 16:43:40,005][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 16:43:40,762][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 16:43:41,493][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 16:43:41,493][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 16:43:41,494][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 16:43:41,495][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 16:43:42,231][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 16:43:42,232][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 16:43:42,232][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 16:43:42,232][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 16:43:42,967][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 16:43:42,967][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 16:43:42,969][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 16:43:42,969][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 16:43:43,706][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 16:43:43,706][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 16:43:43,707][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 16:43:43,707][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 16:43:44,441][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 16:43:44,442][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 16:43:44,443][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 16:43:44,443][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 16:43:45,182][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 16:43:45,815][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 16:43:45,826][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 16:43:45,967][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 16:43:46,706][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 16:43:46,707][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 16:43:46,707][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 16:43:46,708][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 16:43:47,443][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 16:43:47,444][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 16:43:47,444][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 16:43:47,445][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 16:43:48,179][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 16:43:48,180][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 16:43:48,180][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 16:43:48,181][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 16:43:48,915][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 16:43:48,916][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 16:43:48,916][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 16:43:48,917][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 16:43:49,650][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 16:43:49,651][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 16:43:49,651][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 16:43:49,652][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 16:43:50,384][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 16:43:50,385][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 16:43:50,385][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 16:43:50,386][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 16:43:51,122][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 16:43:51,123][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 16:43:51,123][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 16:43:51,124][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 16:43:51,858][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 16:43:51,858][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 16:43:51,858][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 16:43:52,642][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 16:43:53,376][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 16:43:53,379][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 16:43:53,379][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 16:43:53,379][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 16:43:54,116][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 16:43:54,117][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 16:43:54,118][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 16:43:54,120][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 16:43:54,853][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 16:43:54,853][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 16:43:54,854][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 16:43:54,855][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 16:43:55,593][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 16:43:55,593][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 16:43:55,594][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 16:43:55,594][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 16:43:56,331][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 16:43:56,332][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 16:43:56,332][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 16:43:56,332][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 16:43:57,067][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 16:43:57,667][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 16:43:57,691][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 16:43:57,789][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 16:43:58,516][root][INFO] - rank=3; last iteration 25
[2022-01-11 16:43:58,516][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:43:58,516][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 16:43:58,516][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:58,516][root][INFO] - NLL Validation: loss = 0.405451. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:43:58,516][root][INFO] - rank=2; last iteration 25
[2022-01-11 16:43:58,517][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:43:58,517][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 16:43:58,517][root][INFO] - rank=0; last iteration 25
[2022-01-11 16:43:58,517][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:58,517][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:43:58,517][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 16:43:58,517][root][INFO] - NLL Validation: loss = 0.405451. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:43:58,517][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:58,517][root][INFO] - NLL Validation: loss = 0.405451. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:43:58,517][root][INFO] - Av Loss per epoch=0.024427
[2022-01-11 16:43:58,517][root][INFO] - epoch total correct predictions=58312
[2022-01-11 16:43:58,518][root][INFO] - Av Loss per epoch=0.024427
[2022-01-11 16:43:58,518][root][INFO] - epoch total correct predictions=58312
[2022-01-11 16:43:58,519][root][INFO] - ***** Epoch 23 *****
[2022-01-11 16:43:58,520][root][INFO] - rank=1; last iteration 25
[2022-01-11 16:43:58,520][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:43:58,520][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 16:43:58,520][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:43:58,520][root][INFO] - NLL Validation: loss = 0.405451. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:43:58,520][root][INFO] - ***** Epoch 23 *****
[2022-01-11 16:43:58,521][root][INFO] - rank=3; Iteration start
[2022-01-11 16:43:58,521][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:58,521][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:43:58,521][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 16:43:58,521][root][INFO] - rank=2; Iteration start
[2022-01-11 16:43:58,521][root][INFO] - Av Loss per epoch=0.024427
[2022-01-11 16:43:58,521][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:58,521][root][INFO] - epoch total correct predictions=58312
[2022-01-11 16:43:58,521][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:43:58,522][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 16:43:58,523][root][INFO] - ***** Epoch 23 *****
[2022-01-11 16:43:58,525][root][INFO] - rank=1; Iteration start
[2022-01-11 16:43:58,525][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:43:58,525][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:43:58,526][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 16:44:03,498][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.22
[2022-01-11 16:44:03,498][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.22
[2022-01-11 16:44:03,498][root][INFO] - Av Loss per epoch=0.024427
[2022-01-11 16:44:03,498][root][INFO] - epoch total correct predictions=58312
[2022-01-11 16:44:03,500][root][INFO] - ***** Epoch 23 *****
[2022-01-11 16:44:03,502][root][INFO] - rank=0; Iteration start
[2022-01-11 16:44:03,502][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:44:03,502][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:44:03,503][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 16:44:04,503][root][INFO] - Epoch: 23: Step: 1/920, loss=0.034155, lr=0.000005
[2022-01-11 16:44:04,505][root][INFO] - Epoch: 23: Step: 1/920, loss=0.034155, lr=0.000005
[2022-01-11 16:44:04,507][root][INFO] - Epoch: 23: Step: 1/920, loss=0.034155, lr=0.000005
[2022-01-11 16:44:04,517][root][INFO] - Epoch: 23: Step: 1/920, loss=0.034155, lr=0.000005
[2022-01-11 16:45:40,103][root][INFO] - Train batch 100
[2022-01-11 16:45:40,103][root][INFO] - Avg. loss per last 100 batches: 0.027249
[2022-01-11 16:45:40,109][root][INFO] - Train batch 100
[2022-01-11 16:45:40,110][root][INFO] - Avg. loss per last 100 batches: 0.027249
[2022-01-11 16:45:40,110][root][INFO] - Train batch 100
[2022-01-11 16:45:40,110][root][INFO] - Avg. loss per last 100 batches: 0.027249
[2022-01-11 16:45:40,120][root][INFO] - Train batch 100
[2022-01-11 16:45:40,121][root][INFO] - Avg. loss per last 100 batches: 0.027249
[2022-01-11 16:45:41,156][root][INFO] - Epoch: 23: Step: 101/920, loss=0.002487, lr=0.000005
[2022-01-11 16:45:41,156][root][INFO] - Epoch: 23: Step: 101/920, loss=0.002487, lr=0.000005
[2022-01-11 16:45:41,167][root][INFO] - Epoch: 23: Step: 101/920, loss=0.002487, lr=0.000005
[2022-01-11 16:45:41,169][root][INFO] - Epoch: 23: Step: 101/920, loss=0.002487, lr=0.000005
[2022-01-11 16:47:19,285][root][INFO] - Train batch 200
[2022-01-11 16:47:19,285][root][INFO] - Avg. loss per last 100 batches: 0.026925
[2022-01-11 16:47:19,285][root][INFO] - Train batch 200
[2022-01-11 16:47:19,286][root][INFO] - Avg. loss per last 100 batches: 0.026925
[2022-01-11 16:47:19,286][root][INFO] - Train batch 200
[2022-01-11 16:47:19,286][root][INFO] - Avg. loss per last 100 batches: 0.026925
[2022-01-11 16:47:19,287][root][INFO] - Train batch 200
[2022-01-11 16:47:19,287][root][INFO] - Avg. loss per last 100 batches: 0.026925
[2022-01-11 16:47:20,342][root][INFO] - Epoch: 23: Step: 201/920, loss=0.029310, lr=0.000004
[2022-01-11 16:47:20,342][root][INFO] - Epoch: 23: Step: 201/920, loss=0.029310, lr=0.000004
[2022-01-11 16:47:20,343][root][INFO] - Epoch: 23: Step: 201/920, loss=0.029310, lr=0.000004
[2022-01-11 16:47:20,344][root][INFO] - Epoch: 23: Step: 201/920, loss=0.029310, lr=0.000004
[2022-01-11 16:48:57,881][root][INFO] - Train batch 300
[2022-01-11 16:48:57,881][root][INFO] - Avg. loss per last 100 batches: 0.024961
[2022-01-11 16:48:57,882][root][INFO] - Train batch 300
[2022-01-11 16:48:57,882][root][INFO] - Avg. loss per last 100 batches: 0.024961
[2022-01-11 16:48:57,882][root][INFO] - Train batch 300
[2022-01-11 16:48:57,883][root][INFO] - Avg. loss per last 100 batches: 0.024961
[2022-01-11 16:48:57,883][root][INFO] - Train batch 300
[2022-01-11 16:48:57,883][root][INFO] - Avg. loss per last 100 batches: 0.024961
[2022-01-11 16:48:58,916][root][INFO] - Epoch: 23: Step: 301/920, loss=0.002574, lr=0.000004
[2022-01-11 16:48:58,917][root][INFO] - Epoch: 23: Step: 301/920, loss=0.002574, lr=0.000004
[2022-01-11 16:48:58,917][root][INFO] - Epoch: 23: Step: 301/920, loss=0.002574, lr=0.000004
[2022-01-11 16:48:58,918][root][INFO] - Epoch: 23: Step: 301/920, loss=0.002574, lr=0.000004
[2022-01-11 16:50:35,247][root][INFO] - Train batch 400
[2022-01-11 16:50:35,248][root][INFO] - Avg. loss per last 100 batches: 0.024236
[2022-01-11 16:50:35,248][root][INFO] - Train batch 400
[2022-01-11 16:50:35,248][root][INFO] - Avg. loss per last 100 batches: 0.024236
[2022-01-11 16:50:35,249][root][INFO] - Train batch 400
[2022-01-11 16:50:35,250][root][INFO] - Avg. loss per last 100 batches: 0.024236
[2022-01-11 16:50:35,250][root][INFO] - Train batch 400
[2022-01-11 16:50:35,250][root][INFO] - Avg. loss per last 100 batches: 0.024236
[2022-01-11 16:50:37,287][root][INFO] - Epoch: 23: Step: 401/920, loss=0.024354, lr=0.000004
[2022-01-11 16:50:37,287][root][INFO] - Epoch: 23: Step: 401/920, loss=0.024354, lr=0.000004
[2022-01-11 16:50:37,289][root][INFO] - Epoch: 23: Step: 401/920, loss=0.024354, lr=0.000004
[2022-01-11 16:50:37,289][root][INFO] - Epoch: 23: Step: 401/920, loss=0.024354, lr=0.000004
[2022-01-11 16:52:16,255][root][INFO] - Train batch 500
[2022-01-11 16:52:16,255][root][INFO] - Avg. loss per last 100 batches: 0.023189
[2022-01-11 16:52:16,256][root][INFO] - Train batch 500
[2022-01-11 16:52:16,256][root][INFO] - Avg. loss per last 100 batches: 0.023189
[2022-01-11 16:52:16,257][root][INFO] - Train batch 500
[2022-01-11 16:52:16,257][root][INFO] - Avg. loss per last 100 batches: 0.023189
[2022-01-11 16:52:16,257][root][INFO] - Train batch 500
[2022-01-11 16:52:16,257][root][INFO] - Avg. loss per last 100 batches: 0.023189
[2022-01-11 16:52:17,169][root][INFO] - Epoch: 23: Step: 501/920, loss=0.008014, lr=0.000004
[2022-01-11 16:52:17,169][root][INFO] - Epoch: 23: Step: 501/920, loss=0.008014, lr=0.000004
[2022-01-11 16:52:17,169][root][INFO] - Epoch: 23: Step: 501/920, loss=0.008014, lr=0.000004
[2022-01-11 16:52:17,169][root][INFO] - Epoch: 23: Step: 501/920, loss=0.008014, lr=0.000004
[2022-01-11 16:53:55,352][root][INFO] - Train batch 600
[2022-01-11 16:53:55,352][root][INFO] - Avg. loss per last 100 batches: 0.026574
[2022-01-11 16:53:55,354][root][INFO] - Train batch 600
[2022-01-11 16:53:55,354][root][INFO] - Avg. loss per last 100 batches: 0.026574
[2022-01-11 16:53:55,355][root][INFO] - Train batch 600
[2022-01-11 16:53:55,355][root][INFO] - Avg. loss per last 100 batches: 0.026574
[2022-01-11 16:53:55,356][root][INFO] - Train batch 600
[2022-01-11 16:53:55,356][root][INFO] - Avg. loss per last 100 batches: 0.026574
[2022-01-11 16:53:56,345][root][INFO] - Epoch: 23: Step: 601/920, loss=0.007037, lr=0.000004
[2022-01-11 16:53:56,346][root][INFO] - Epoch: 23: Step: 601/920, loss=0.007037, lr=0.000004
[2022-01-11 16:53:56,346][root][INFO] - Epoch: 23: Step: 601/920, loss=0.007037, lr=0.000004
[2022-01-11 16:53:56,347][root][INFO] - Epoch: 23: Step: 601/920, loss=0.007037, lr=0.000004
[2022-01-11 16:55:33,597][root][INFO] - Train batch 700
[2022-01-11 16:55:33,597][root][INFO] - Avg. loss per last 100 batches: 0.022310
[2022-01-11 16:55:33,597][root][INFO] - Train batch 700
[2022-01-11 16:55:33,597][root][INFO] - Train batch 700
[2022-01-11 16:55:33,597][root][INFO] - Avg. loss per last 100 batches: 0.022310
[2022-01-11 16:55:33,597][root][INFO] - Avg. loss per last 100 batches: 0.022310
[2022-01-11 16:55:33,598][root][INFO] - Train batch 700
[2022-01-11 16:55:33,598][root][INFO] - Avg. loss per last 100 batches: 0.022310
[2022-01-11 16:55:34,548][root][INFO] - Epoch: 23: Step: 701/920, loss=0.029969, lr=0.000004
[2022-01-11 16:55:34,548][root][INFO] - Epoch: 23: Step: 701/920, loss=0.029969, lr=0.000004
[2022-01-11 16:55:34,560][root][INFO] - Epoch: 23: Step: 701/920, loss=0.029969, lr=0.000004
[2022-01-11 16:55:34,560][root][INFO] - Epoch: 23: Step: 701/920, loss=0.029969, lr=0.000004
[2022-01-11 16:57:12,710][root][INFO] - Train batch 800
[2022-01-11 16:57:12,710][root][INFO] - Avg. loss per last 100 batches: 0.022600
[2022-01-11 16:57:12,722][root][INFO] - Train batch 800
[2022-01-11 16:57:12,723][root][INFO] - Avg. loss per last 100 batches: 0.022600
[2022-01-11 16:57:12,723][root][INFO] - Train batch 800
[2022-01-11 16:57:12,723][root][INFO] - Avg. loss per last 100 batches: 0.022600
[2022-01-11 16:57:12,724][root][INFO] - Train batch 800
[2022-01-11 16:57:12,724][root][INFO] - Avg. loss per last 100 batches: 0.022600
[2022-01-11 16:57:13,762][root][INFO] - Epoch: 23: Step: 801/920, loss=0.036565, lr=0.000004
[2022-01-11 16:57:13,775][root][INFO] - Epoch: 23: Step: 801/920, loss=0.036565, lr=0.000004
[2022-01-11 16:57:13,775][root][INFO] - Epoch: 23: Step: 801/920, loss=0.036565, lr=0.000004
[2022-01-11 16:57:13,776][root][INFO] - Epoch: 23: Step: 801/920, loss=0.036565, lr=0.000004
[2022-01-11 16:58:52,833][root][INFO] - Train batch 900
[2022-01-11 16:58:52,833][root][INFO] - Avg. loss per last 100 batches: 0.023822
[2022-01-11 16:58:52,833][root][INFO] - Train batch 900
[2022-01-11 16:58:52,834][root][INFO] - Avg. loss per last 100 batches: 0.023822
[2022-01-11 16:58:52,836][root][INFO] - Train batch 900
[2022-01-11 16:58:52,836][root][INFO] - Avg. loss per last 100 batches: 0.023822
[2022-01-11 16:58:52,836][root][INFO] - Train batch 900
[2022-01-11 16:58:52,837][root][INFO] - Avg. loss per last 100 batches: 0.023822
[2022-01-11 16:58:53,899][root][INFO] - Epoch: 23: Step: 901/920, loss=0.018481, lr=0.000004
[2022-01-11 16:58:53,899][root][INFO] - Epoch: 23: Step: 901/920, loss=0.018481, lr=0.000004
[2022-01-11 16:58:53,901][root][INFO] - Epoch: 23: Step: 901/920, loss=0.018481, lr=0.000004
[2022-01-11 16:58:53,901][root][INFO] - Epoch: 23: Step: 901/920, loss=0.018481, lr=0.000004
[2022-01-11 16:59:12,636][root][INFO] - rank=1, Validation: Epoch: 23 Step: 920/920
[2022-01-11 16:59:12,636][root][INFO] - NLL validation ...
[2022-01-11 16:59:12,637][root][INFO] - rank=3, Validation: Epoch: 23 Step: 920/920
[2022-01-11 16:59:12,637][root][INFO] - NLL validation ...
[2022-01-11 16:59:12,638][root][INFO] - rank=1; Iteration start
[2022-01-11 16:59:12,638][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:12,638][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:59:12,638][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 16:59:12,638][root][INFO] - rank=0, Validation: Epoch: 23 Step: 920/920
[2022-01-11 16:59:12,638][root][INFO] - NLL validation ...
[2022-01-11 16:59:12,638][root][INFO] - rank=3; Iteration start
[2022-01-11 16:59:12,638][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:12,638][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:59:12,638][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 16:59:12,638][root][INFO] - rank=2, Validation: Epoch: 23 Step: 920/920
[2022-01-11 16:59:12,639][root][INFO] - NLL validation ...
[2022-01-11 16:59:12,639][root][INFO] - rank=0; Iteration start
[2022-01-11 16:59:12,639][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:12,639][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:59:12,639][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 16:59:12,640][root][INFO] - rank=2; Iteration start
[2022-01-11 16:59:12,640][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:12,640][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:59:12,640][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 16:59:12,648][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 16:59:12,648][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 16:59:12,649][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 16:59:12,650][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 16:59:13,391][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 16:59:13,392][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 16:59:13,392][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 16:59:13,410][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 16:59:14,150][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 16:59:14,151][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 16:59:14,151][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 16:59:14,153][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 16:59:14,887][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 16:59:14,888][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 16:59:14,888][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 16:59:14,888][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 16:59:15,625][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 16:59:16,555][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 16:59:16,610][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 16:59:16,623][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 16:59:17,364][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 16:59:17,366][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 16:59:17,366][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 16:59:17,367][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 16:59:18,103][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 16:59:18,104][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 16:59:18,104][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 16:59:18,104][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 16:59:18,842][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 16:59:18,842][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 16:59:18,842][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 16:59:18,843][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 16:59:19,579][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 16:59:19,579][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 16:59:19,580][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 16:59:19,580][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 16:59:20,316][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 16:59:20,316][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 16:59:20,316][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 16:59:20,316][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 16:59:21,055][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 16:59:21,056][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 16:59:21,057][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 16:59:21,672][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 16:59:22,404][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 16:59:22,404][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 16:59:22,404][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 16:59:22,407][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 16:59:23,145][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 16:59:23,147][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 16:59:23,147][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 16:59:23,147][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 16:59:23,885][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 16:59:23,886][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 16:59:23,886][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 16:59:23,886][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 16:59:24,624][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 16:59:24,624][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 16:59:24,624][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 16:59:24,625][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 16:59:25,359][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 16:59:25,360][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 16:59:25,360][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 16:59:25,360][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 16:59:26,098][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 16:59:26,099][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 16:59:26,099][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 16:59:26,099][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 16:59:26,836][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 16:59:26,836][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 16:59:26,837][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 16:59:26,837][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 16:59:27,573][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 16:59:28,239][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 16:59:28,274][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 16:59:28,317][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 16:59:29,054][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 16:59:29,056][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 16:59:29,056][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 16:59:29,057][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 16:59:29,793][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 16:59:29,794][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 16:59:29,794][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 16:59:29,794][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 16:59:30,534][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 16:59:30,536][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 16:59:30,536][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 16:59:30,536][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 16:59:31,273][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 16:59:31,273][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 16:59:31,274][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 16:59:31,274][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 16:59:32,009][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 16:59:32,009][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 16:59:32,009][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 16:59:32,010][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 16:59:32,748][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 16:59:32,748][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 16:59:32,749][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 16:59:33,369][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 16:59:34,089][root][INFO] - rank=3; last iteration 25
[2022-01-11 16:59:34,089][root][INFO] - rank=1; last iteration 25
[2022-01-11 16:59:34,089][root][INFO] - rank=0; last iteration 25
[2022-01-11 16:59:34,089][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:59:34,089][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:59:34,089][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:59:34,089][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 16:59:34,089][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 16:59:34,089][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 16:59:34,089][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:34,089][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:34,089][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:34,089][root][INFO] - NLL Validation: loss = 0.408259. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:59:34,089][root][INFO] - NLL Validation: loss = 0.408259. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:59:34,089][root][INFO] - NLL Validation: loss = 0.408259. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:59:34,089][root][INFO] - rank=2; last iteration 25
[2022-01-11 16:59:34,089][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:59:34,089][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 16:59:34,089][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:34,089][root][INFO] - NLL Validation: loss = 0.408259. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:59:34,092][root][INFO] - rank=3; last iteration 920
[2022-01-11 16:59:34,092][root][INFO] - rank=1; last iteration 920
[2022-01-11 16:59:34,092][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:59:34,092][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:59:34,092][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 16:59:34,092][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 16:59:34,092][root][INFO] - rank=2; last iteration 920
[2022-01-11 16:59:34,092][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:59:34,092][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 16:59:34,092][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:34,092][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:34,092][root][INFO] - Epoch finished on 1
[2022-01-11 16:59:34,092][root][INFO] - Epoch finished on 3
[2022-01-11 16:59:34,092][root][INFO] - NLL validation ...
[2022-01-11 16:59:34,092][root][INFO] - NLL validation ...
[2022-01-11 16:59:34,092][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:34,093][root][INFO] - Epoch finished on 2
[2022-01-11 16:59:34,093][root][INFO] - NLL validation ...
[2022-01-11 16:59:34,094][root][INFO] - rank=1; Iteration start
[2022-01-11 16:59:34,094][root][INFO] - rank=3; Iteration start
[2022-01-11 16:59:34,094][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:34,094][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:34,094][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:59:34,094][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:59:34,094][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 16:59:34,094][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 16:59:34,094][root][INFO] - rank=2; Iteration start
[2022-01-11 16:59:34,094][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:34,094][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:59:34,094][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 16:59:34,101][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 16:59:34,101][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 16:59:34,102][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 16:59:37,660][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.23
[2022-01-11 16:59:37,661][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.23
[2022-01-11 16:59:37,662][root][INFO] - rank=0; last iteration 920
[2022-01-11 16:59:37,662][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 16:59:37,662][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 16:59:37,662][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:37,662][root][INFO] - Epoch finished on 0
[2022-01-11 16:59:37,663][root][INFO] - NLL validation ...
[2022-01-11 16:59:37,664][root][INFO] - rank=0; Iteration start
[2022-01-11 16:59:37,664][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:37,664][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 16:59:37,664][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 16:59:37,674][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 16:59:38,414][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 16:59:38,414][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 16:59:38,415][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 16:59:38,416][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 16:59:39,152][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 16:59:39,152][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 16:59:39,153][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 16:59:39,154][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 16:59:39,887][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 16:59:39,887][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 16:59:39,888][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 16:59:39,889][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 16:59:40,627][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 16:59:40,628][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 16:59:40,629][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 16:59:40,630][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 16:59:41,372][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 16:59:41,373][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 16:59:41,373][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 16:59:41,375][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 16:59:42,111][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 16:59:42,111][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 16:59:42,112][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 16:59:42,113][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 16:59:42,851][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 16:59:43,461][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 16:59:43,472][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 16:59:43,661][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 16:59:44,397][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 16:59:44,398][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 16:59:44,398][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 16:59:44,399][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 16:59:45,133][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 16:59:45,133][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 16:59:45,134][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 16:59:45,137][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 16:59:45,869][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 16:59:45,869][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 16:59:45,870][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 16:59:45,871][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 16:59:46,605][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 16:59:46,605][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 16:59:46,606][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 16:59:46,607][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 16:59:47,342][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 16:59:47,342][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 16:59:47,343][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 16:59:47,344][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 16:59:48,080][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 16:59:48,081][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 16:59:48,081][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 16:59:48,932][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 16:59:49,661][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 16:59:49,661][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 16:59:49,662][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 16:59:49,662][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 16:59:50,396][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 16:59:50,396][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 16:59:50,397][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 16:59:50,398][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 16:59:51,130][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 16:59:51,130][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 16:59:51,130][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 16:59:51,132][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 16:59:51,870][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 16:59:51,872][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 16:59:51,872][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 16:59:51,873][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 16:59:52,607][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 16:59:52,607][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 16:59:52,608][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 16:59:52,610][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 16:59:53,345][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 16:59:53,345][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 16:59:53,346][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 16:59:53,346][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 16:59:54,080][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 16:59:54,081][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 16:59:54,081][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 16:59:54,083][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 16:59:54,822][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 16:59:55,424][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 16:59:55,434][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 16:59:55,440][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 16:59:56,169][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 16:59:56,170][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 16:59:56,170][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 16:59:56,172][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 16:59:56,910][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 16:59:56,912][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 16:59:56,912][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 16:59:56,913][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 16:59:57,648][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 16:59:57,648][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 16:59:57,648][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 16:59:57,649][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 16:59:58,377][root][INFO] - rank=3; last iteration 25
[2022-01-11 16:59:58,377][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:59:58,377][root][INFO] - rank=1; last iteration 25
[2022-01-11 16:59:58,377][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 16:59:58,377][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:59:58,377][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:58,377][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 16:59:58,377][root][INFO] - NLL Validation: loss = 0.408259. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:59:58,377][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:58,377][root][INFO] - NLL Validation: loss = 0.408259. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:59:58,377][root][INFO] - rank=2; last iteration 25
[2022-01-11 16:59:58,378][root][INFO] - rank=0; last iteration 25
[2022-01-11 16:59:58,378][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:59:58,378][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 16:59:58,378][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 16:59:58,378][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 16:59:58,378][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:58,378][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 16:59:58,378][root][INFO] - NLL Validation: loss = 0.408259. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:59:58,378][root][INFO] - NLL Validation: loss = 0.408259. correct prediction ratio  5718/6400 ~  0.893437
[2022-01-11 16:59:58,378][root][INFO] - Av Loss per epoch=0.024812
[2022-01-11 16:59:58,379][root][INFO] - epoch total correct predictions=58324
[2022-01-11 16:59:58,379][root][INFO] - Av Loss per epoch=0.024812
[2022-01-11 16:59:58,379][root][INFO] - epoch total correct predictions=58324
[2022-01-11 16:59:58,379][root][INFO] - Av Loss per epoch=0.024812
[2022-01-11 16:59:58,379][root][INFO] - epoch total correct predictions=58324
[2022-01-11 16:59:58,380][root][INFO] - ***** Epoch 24 *****
[2022-01-11 16:59:58,380][root][INFO] - ***** Epoch 24 *****
[2022-01-11 16:59:58,381][root][INFO] - ***** Epoch 24 *****
[2022-01-11 16:59:58,382][root][INFO] - rank=1; Iteration start
[2022-01-11 16:59:58,382][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:58,382][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:59:58,382][root][INFO] - rank=3; Iteration start
[2022-01-11 16:59:58,382][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:58,382][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:59:58,382][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 16:59:58,382][root][INFO] - rank=2; Iteration start
[2022-01-11 16:59:58,382][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 16:59:58,382][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 16:59:58,382][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 16:59:58,383][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 17:00:03,108][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.23
[2022-01-11 17:00:03,109][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.23
[2022-01-11 17:00:03,109][root][INFO] - Av Loss per epoch=0.024812
[2022-01-11 17:00:03,109][root][INFO] - epoch total correct predictions=58324
[2022-01-11 17:00:03,110][root][INFO] - ***** Epoch 24 *****
[2022-01-11 17:00:03,112][root][INFO] - rank=0; Iteration start
[2022-01-11 17:00:03,112][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:00:03,113][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:00:03,113][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 17:00:04,204][root][INFO] - Epoch: 24: Step: 1/920, loss=0.025551, lr=0.000004
[2022-01-11 17:00:04,205][root][INFO] - Epoch: 24: Step: 1/920, loss=0.025551, lr=0.000004
[2022-01-11 17:00:04,205][root][INFO] - Epoch: 24: Step: 1/920, loss=0.025551, lr=0.000004
[2022-01-11 17:00:04,206][root][INFO] - Epoch: 24: Step: 1/920, loss=0.025551, lr=0.000004
[2022-01-11 17:01:42,506][root][INFO] - Train batch 100
[2022-01-11 17:01:42,506][root][INFO] - Avg. loss per last 100 batches: 0.022273
[2022-01-11 17:01:42,506][root][INFO] - Train batch 100
[2022-01-11 17:01:42,506][root][INFO] - Avg. loss per last 100 batches: 0.022273
[2022-01-11 17:01:42,507][root][INFO] - Train batch 100
[2022-01-11 17:01:42,507][root][INFO] - Avg. loss per last 100 batches: 0.022273
[2022-01-11 17:01:42,508][root][INFO] - Train batch 100
[2022-01-11 17:01:42,508][root][INFO] - Avg. loss per last 100 batches: 0.022273
[2022-01-11 17:01:43,447][root][INFO] - Epoch: 24: Step: 101/920, loss=0.079937, lr=0.000004
[2022-01-11 17:01:43,447][root][INFO] - Epoch: 24: Step: 101/920, loss=0.079937, lr=0.000004
[2022-01-11 17:01:43,448][root][INFO] - Epoch: 24: Step: 101/920, loss=0.079937, lr=0.000004
[2022-01-11 17:01:43,449][root][INFO] - Epoch: 24: Step: 101/920, loss=0.079937, lr=0.000004
[2022-01-11 17:03:22,539][root][INFO] - Train batch 200
[2022-01-11 17:03:22,539][root][INFO] - Avg. loss per last 100 batches: 0.025164
[2022-01-11 17:03:22,540][root][INFO] - Train batch 200
[2022-01-11 17:03:22,540][root][INFO] - Train batch 200
[2022-01-11 17:03:22,541][root][INFO] - Avg. loss per last 100 batches: 0.025164
[2022-01-11 17:03:22,541][root][INFO] - Avg. loss per last 100 batches: 0.025164
[2022-01-11 17:03:22,541][root][INFO] - Train batch 200
[2022-01-11 17:03:22,542][root][INFO] - Avg. loss per last 100 batches: 0.025164
[2022-01-11 17:03:23,396][root][INFO] - Epoch: 24: Step: 201/920, loss=0.016383, lr=0.000004
[2022-01-11 17:03:23,397][root][INFO] - Epoch: 24: Step: 201/920, loss=0.016383, lr=0.000004
[2022-01-11 17:03:23,397][root][INFO] - Epoch: 24: Step: 201/920, loss=0.016383, lr=0.000004
[2022-01-11 17:03:23,397][root][INFO] - Epoch: 24: Step: 201/920, loss=0.016383, lr=0.000004
[2022-01-11 17:05:00,864][root][INFO] - Train batch 300
[2022-01-11 17:05:00,864][root][INFO] - Avg. loss per last 100 batches: 0.020257
[2022-01-11 17:05:00,865][root][INFO] - Train batch 300
[2022-01-11 17:05:00,865][root][INFO] - Avg. loss per last 100 batches: 0.020257
[2022-01-11 17:05:00,866][root][INFO] - Train batch 300
[2022-01-11 17:05:00,866][root][INFO] - Avg. loss per last 100 batches: 0.020257
[2022-01-11 17:05:00,867][root][INFO] - Train batch 300
[2022-01-11 17:05:00,867][root][INFO] - Avg. loss per last 100 batches: 0.020257
[2022-01-11 17:05:01,910][root][INFO] - Epoch: 24: Step: 301/920, loss=0.001923, lr=0.000004
[2022-01-11 17:05:01,911][root][INFO] - Epoch: 24: Step: 301/920, loss=0.001923, lr=0.000004
[2022-01-11 17:05:01,911][root][INFO] - Epoch: 24: Step: 301/920, loss=0.001923, lr=0.000004
[2022-01-11 17:05:01,912][root][INFO] - Epoch: 24: Step: 301/920, loss=0.001923, lr=0.000004
[2022-01-11 17:06:40,387][root][INFO] - Train batch 400
[2022-01-11 17:06:40,387][root][INFO] - Avg. loss per last 100 batches: 0.020505
[2022-01-11 17:06:40,387][root][INFO] - Train batch 400
[2022-01-11 17:06:40,387][root][INFO] - Train batch 400
[2022-01-11 17:06:40,388][root][INFO] - Avg. loss per last 100 batches: 0.020505
[2022-01-11 17:06:40,388][root][INFO] - Avg. loss per last 100 batches: 0.020505
[2022-01-11 17:06:40,388][root][INFO] - Train batch 400
[2022-01-11 17:06:40,388][root][INFO] - Avg. loss per last 100 batches: 0.020505
[2022-01-11 17:06:41,332][root][INFO] - Epoch: 24: Step: 401/920, loss=0.036849, lr=0.000004
[2022-01-11 17:06:41,335][root][INFO] - Epoch: 24: Step: 401/920, loss=0.036849, lr=0.000004
[2022-01-11 17:06:41,335][root][INFO] - Epoch: 24: Step: 401/920, loss=0.036849, lr=0.000004
[2022-01-11 17:06:41,336][root][INFO] - Epoch: 24: Step: 401/920, loss=0.036849, lr=0.000004
[2022-01-11 17:08:17,795][root][INFO] - Train batch 500
[2022-01-11 17:08:17,795][root][INFO] - Avg. loss per last 100 batches: 0.021103
[2022-01-11 17:08:17,796][root][INFO] - Train batch 500
[2022-01-11 17:08:17,797][root][INFO] - Avg. loss per last 100 batches: 0.021103
[2022-01-11 17:08:17,797][root][INFO] - Train batch 500
[2022-01-11 17:08:17,797][root][INFO] - Avg. loss per last 100 batches: 0.021103
[2022-01-11 17:08:17,797][root][INFO] - Train batch 500
[2022-01-11 17:08:17,797][root][INFO] - Avg. loss per last 100 batches: 0.021103
[2022-01-11 17:08:18,804][root][INFO] - Epoch: 24: Step: 501/920, loss=0.005370, lr=0.000004
[2022-01-11 17:08:18,805][root][INFO] - Epoch: 24: Step: 501/920, loss=0.005370, lr=0.000004
[2022-01-11 17:08:18,806][root][INFO] - Epoch: 24: Step: 501/920, loss=0.005370, lr=0.000004
[2022-01-11 17:08:18,806][root][INFO] - Epoch: 24: Step: 501/920, loss=0.005370, lr=0.000004
[2022-01-11 17:09:56,138][root][INFO] - Train batch 600
[2022-01-11 17:09:56,138][root][INFO] - Avg. loss per last 100 batches: 0.025495
[2022-01-11 17:09:56,138][root][INFO] - Train batch 600
[2022-01-11 17:09:56,138][root][INFO] - Avg. loss per last 100 batches: 0.025495
[2022-01-11 17:09:56,139][root][INFO] - Train batch 600
[2022-01-11 17:09:56,139][root][INFO] - Avg. loss per last 100 batches: 0.025495
[2022-01-11 17:09:56,139][root][INFO] - Train batch 600
[2022-01-11 17:09:56,139][root][INFO] - Avg. loss per last 100 batches: 0.025495
[2022-01-11 17:09:57,033][root][INFO] - Epoch: 24: Step: 601/920, loss=0.008311, lr=0.000004
[2022-01-11 17:09:57,033][root][INFO] - Epoch: 24: Step: 601/920, loss=0.008311, lr=0.000004
[2022-01-11 17:09:57,033][root][INFO] - Epoch: 24: Step: 601/920, loss=0.008311, lr=0.000004
[2022-01-11 17:09:57,034][root][INFO] - Epoch: 24: Step: 601/920, loss=0.008311, lr=0.000004
[2022-01-11 17:11:36,596][root][INFO] - Train batch 700
[2022-01-11 17:11:36,596][root][INFO] - Avg. loss per last 100 batches: 0.020098
[2022-01-11 17:11:36,597][root][INFO] - Train batch 700
[2022-01-11 17:11:36,597][root][INFO] - Avg. loss per last 100 batches: 0.020098
[2022-01-11 17:11:36,597][root][INFO] - Train batch 700
[2022-01-11 17:11:36,598][root][INFO] - Avg. loss per last 100 batches: 0.020098
[2022-01-11 17:11:36,598][root][INFO] - Train batch 700
[2022-01-11 17:11:36,598][root][INFO] - Avg. loss per last 100 batches: 0.020098
[2022-01-11 17:11:37,481][root][INFO] - Epoch: 24: Step: 701/920, loss=0.025791, lr=0.000004
[2022-01-11 17:11:37,481][root][INFO] - Epoch: 24: Step: 701/920, loss=0.025791, lr=0.000004
[2022-01-11 17:11:37,481][root][INFO] - Epoch: 24: Step: 701/920, loss=0.025791, lr=0.000004
[2022-01-11 17:11:37,482][root][INFO] - Epoch: 24: Step: 701/920, loss=0.025791, lr=0.000004
[2022-01-11 17:13:15,681][root][INFO] - Train batch 800
[2022-01-11 17:13:15,681][root][INFO] - Avg. loss per last 100 batches: 0.024099
[2022-01-11 17:13:15,684][root][INFO] - Train batch 800
[2022-01-11 17:13:15,684][root][INFO] - Avg. loss per last 100 batches: 0.024099
[2022-01-11 17:13:15,684][root][INFO] - Train batch 800
[2022-01-11 17:13:15,684][root][INFO] - Avg. loss per last 100 batches: 0.024099
[2022-01-11 17:13:15,684][root][INFO] - Train batch 800
[2022-01-11 17:13:15,685][root][INFO] - Avg. loss per last 100 batches: 0.024099
[2022-01-11 17:13:16,589][root][INFO] - Epoch: 24: Step: 801/920, loss=0.002262, lr=0.000004
[2022-01-11 17:13:16,591][root][INFO] - Epoch: 24: Step: 801/920, loss=0.002262, lr=0.000004
[2022-01-11 17:13:16,591][root][INFO] - Epoch: 24: Step: 801/920, loss=0.002262, lr=0.000004
[2022-01-11 17:13:16,591][root][INFO] - Epoch: 24: Step: 801/920, loss=0.002262, lr=0.000004
[2022-01-11 17:14:53,356][root][INFO] - Train batch 900
[2022-01-11 17:14:53,356][root][INFO] - Avg. loss per last 100 batches: 0.024646
[2022-01-11 17:14:53,356][root][INFO] - Train batch 900
[2022-01-11 17:14:53,356][root][INFO] - Train batch 900
[2022-01-11 17:14:53,356][root][INFO] - Avg. loss per last 100 batches: 0.024646
[2022-01-11 17:14:53,356][root][INFO] - Avg. loss per last 100 batches: 0.024646
[2022-01-11 17:14:53,357][root][INFO] - Train batch 900
[2022-01-11 17:14:53,357][root][INFO] - Avg. loss per last 100 batches: 0.024646
[2022-01-11 17:14:54,209][root][INFO] - Epoch: 24: Step: 901/920, loss=0.011757, lr=0.000004
[2022-01-11 17:14:54,211][root][INFO] - Epoch: 24: Step: 901/920, loss=0.011757, lr=0.000004
[2022-01-11 17:14:54,211][root][INFO] - Epoch: 24: Step: 901/920, loss=0.011757, lr=0.000004
[2022-01-11 17:14:54,211][root][INFO] - Epoch: 24: Step: 901/920, loss=0.011757, lr=0.000004
[2022-01-11 17:15:12,072][root][INFO] - rank=3, Validation: Epoch: 24 Step: 920/920
[2022-01-11 17:15:12,072][root][INFO] - NLL validation ...
[2022-01-11 17:15:12,074][root][INFO] - rank=3; Iteration start
[2022-01-11 17:15:12,074][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:12,074][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:15:12,074][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 17:15:12,084][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 17:15:12,085][root][INFO] - rank=0, Validation: Epoch: 24 Step: 920/920
[2022-01-11 17:15:12,085][root][INFO] - NLL validation ...
[2022-01-11 17:15:12,086][root][INFO] - rank=2, Validation: Epoch: 24 Step: 920/920
[2022-01-11 17:15:12,086][root][INFO] - NLL validation ...
[2022-01-11 17:15:12,086][root][INFO] - rank=1, Validation: Epoch: 24 Step: 920/920
[2022-01-11 17:15:12,086][root][INFO] - NLL validation ...
[2022-01-11 17:15:12,087][root][INFO] - rank=0; Iteration start
[2022-01-11 17:15:12,087][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:12,087][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:15:12,087][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 17:15:12,087][root][INFO] - rank=2; Iteration start
[2022-01-11 17:15:12,087][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:12,087][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:15:12,087][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 17:15:12,088][root][INFO] - rank=1; Iteration start
[2022-01-11 17:15:12,088][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:12,088][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:15:12,088][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 17:15:12,097][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 17:15:12,098][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 17:15:12,098][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 17:15:12,836][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 17:15:12,836][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 17:15:12,836][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 17:15:12,836][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 17:15:13,573][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 17:15:14,558][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 17:15:14,570][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 17:15:14,574][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 17:15:15,310][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 17:15:15,310][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 17:15:15,311][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 17:15:15,311][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 17:15:16,047][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 17:15:16,046][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 17:15:16,047][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 17:15:16,047][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 17:15:16,785][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 17:15:16,786][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 17:15:16,787][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 17:15:16,787][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 17:15:17,526][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 17:15:17,526][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 17:15:17,526][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 17:15:18,464][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 17:15:19,195][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 17:15:19,195][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 17:15:19,195][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 17:15:19,195][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 17:15:19,932][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 17:15:19,932][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 17:15:19,932][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 17:15:19,932][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 17:15:20,670][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 17:15:20,672][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 17:15:20,672][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 17:15:20,672][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 17:15:21,410][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 17:15:21,411][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 17:15:21,411][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 17:15:21,411][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 17:15:22,149][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 17:15:22,149][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 17:15:22,149][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 17:15:22,149][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 17:15:22,890][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 17:15:22,891][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 17:15:22,891][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 17:15:22,891][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 17:15:23,628][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 17:15:23,629][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 17:15:23,629][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 17:15:23,630][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 17:15:24,365][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 17:15:24,366][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 17:15:24,366][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 17:15:24,366][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 17:15:25,104][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 17:15:25,729][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 17:15:25,734][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 17:15:25,734][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 17:15:26,469][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 17:15:26,470][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 17:15:26,470][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 17:15:26,470][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 17:15:27,209][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 17:15:27,209][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 17:15:27,210][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 17:15:27,210][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 17:15:27,945][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 17:15:27,946][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 17:15:27,946][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 17:15:27,946][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 17:15:28,684][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 17:15:28,685][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 17:15:28,685][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 17:15:28,685][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 17:15:29,422][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 17:15:29,422][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 17:15:29,422][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 17:15:30,033][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 17:15:30,766][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 17:15:30,766][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 17:15:30,768][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 17:15:30,769][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 17:15:31,506][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 17:15:31,507][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 17:15:31,507][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 17:15:31,508][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 17:15:32,244][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 17:15:32,244][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 17:15:32,245][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 17:15:32,245][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 17:15:32,982][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 17:15:32,982][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 17:15:32,982][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 17:15:32,982][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 17:15:33,712][root][INFO] - rank=3; last iteration 25
[2022-01-11 17:15:33,712][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:15:33,713][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 17:15:33,713][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:33,713][root][INFO] - NLL Validation: loss = 0.411183. correct prediction ratio  5710/6400 ~  0.892188
[2022-01-11 17:15:33,714][root][INFO] - rank=1; last iteration 25
[2022-01-11 17:15:33,714][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:15:33,714][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 17:15:33,714][root][INFO] - rank=0; last iteration 25
[2022-01-11 17:15:33,714][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:15:33,714][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:33,714][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 17:15:33,714][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:33,714][root][INFO] - NLL Validation: loss = 0.411183. correct prediction ratio  5710/6400 ~  0.892188
[2022-01-11 17:15:33,714][root][INFO] - NLL Validation: loss = 0.411183. correct prediction ratio  5710/6400 ~  0.892188
[2022-01-11 17:15:33,714][root][INFO] - rank=2; last iteration 25
[2022-01-11 17:15:33,714][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:15:33,714][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 17:15:33,714][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:33,714][root][INFO] - NLL Validation: loss = 0.411183. correct prediction ratio  5710/6400 ~  0.892188
[2022-01-11 17:15:33,715][root][INFO] - rank=3; last iteration 920
[2022-01-11 17:15:33,715][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:15:33,715][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 17:15:33,716][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:33,716][root][INFO] - Epoch finished on 3
[2022-01-11 17:15:33,716][root][INFO] - NLL validation ...
[2022-01-11 17:15:33,717][root][INFO] - rank=1; last iteration 920
[2022-01-11 17:15:33,717][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:15:33,717][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 17:15:33,717][root][INFO] - rank=2; last iteration 920
[2022-01-11 17:15:33,717][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:15:33,717][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 17:15:33,717][root][INFO] - rank=3; Iteration start
[2022-01-11 17:15:33,717][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:33,717][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:15:33,717][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 17:15:33,717][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:33,717][root][INFO] - Epoch finished on 1
[2022-01-11 17:15:33,717][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:33,718][root][INFO] - NLL validation ...
[2022-01-11 17:15:33,718][root][INFO] - Epoch finished on 2
[2022-01-11 17:15:33,718][root][INFO] - NLL validation ...
[2022-01-11 17:15:33,719][root][INFO] - rank=1; Iteration start
[2022-01-11 17:15:33,719][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:33,719][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:15:33,719][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 17:15:33,719][root][INFO] - rank=2; Iteration start
[2022-01-11 17:15:33,719][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:33,719][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:15:33,719][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 17:15:33,725][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 17:15:33,727][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 17:15:33,728][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 17:15:37,736][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.24
[2022-01-11 17:15:37,737][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.24
[2022-01-11 17:15:37,738][root][INFO] - rank=0; last iteration 920
[2022-01-11 17:15:37,738][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:15:37,738][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 17:15:37,739][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:37,739][root][INFO] - Epoch finished on 0
[2022-01-11 17:15:37,739][root][INFO] - NLL validation ...
[2022-01-11 17:15:37,740][root][INFO] - rank=0; Iteration start
[2022-01-11 17:15:37,740][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:37,740][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:15:37,740][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 17:15:37,748][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 17:15:38,490][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 17:15:38,490][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 17:15:38,491][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 17:15:38,493][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 17:15:39,225][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 17:15:39,226][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 17:15:39,226][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 17:15:39,228][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 17:15:39,962][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 17:15:39,962][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 17:15:39,963][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 17:15:39,964][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 17:15:40,696][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 17:15:40,696][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 17:15:40,697][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 17:15:40,698][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 17:15:41,433][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 17:15:42,053][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 17:15:42,063][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 17:15:42,356][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 17:15:43,085][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 17:15:43,086][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 17:15:43,086][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 17:15:43,086][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 17:15:43,820][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 17:15:43,821][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 17:15:43,822][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 17:15:43,822][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 17:15:44,560][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 17:15:44,561][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 17:15:44,562][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 17:15:44,563][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 17:15:45,297][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 17:15:45,299][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 17:15:45,300][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 17:15:45,911][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 17:15:46,645][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 17:15:46,647][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 17:15:46,648][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 17:15:46,648][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 17:15:47,386][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 17:15:47,388][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 17:15:47,388][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 17:15:47,388][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 17:15:48,122][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 17:15:48,123][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 17:15:48,124][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 17:15:48,124][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 17:15:48,860][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 17:15:48,861][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 17:15:48,863][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 17:15:48,864][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 17:15:49,602][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 17:15:49,604][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 17:15:49,605][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 17:15:49,606][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 17:15:50,340][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 17:15:50,340][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 17:15:50,342][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 17:15:50,343][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 17:15:51,075][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 17:15:51,076][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 17:15:51,078][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 17:15:51,080][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 17:15:51,814][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 17:15:51,814][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 17:15:51,815][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 17:15:51,815][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 17:15:52,553][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 17:15:52,554][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 17:15:52,556][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 17:15:52,556][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 17:15:53,295][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 17:15:53,907][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 17:15:53,914][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 17:15:54,114][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 17:15:54,851][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 17:15:54,851][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 17:15:54,853][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 17:15:54,853][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 17:15:55,593][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 17:15:55,593][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 17:15:55,595][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 17:15:55,596][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 17:15:56,333][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 17:15:56,333][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 17:15:56,335][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 17:15:57,106][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 17:15:57,837][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 17:15:57,837][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 17:15:57,838][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 17:15:57,838][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 17:15:58,578][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 17:15:58,579][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 17:15:58,581][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 17:15:58,581][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 17:15:59,311][root][INFO] - rank=1; last iteration 25
[2022-01-11 17:15:59,311][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:15:59,311][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 17:15:59,311][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:59,311][root][INFO] - NLL Validation: loss = 0.411183. correct prediction ratio  5710/6400 ~  0.892188
[2022-01-11 17:15:59,311][root][INFO] - rank=3; last iteration 25
[2022-01-11 17:15:59,311][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:15:59,311][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 17:15:59,311][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:59,311][root][INFO] - rank=0; last iteration 25
[2022-01-11 17:15:59,311][root][INFO] - NLL Validation: loss = 0.411183. correct prediction ratio  5710/6400 ~  0.892188
[2022-01-11 17:15:59,311][root][INFO] - rank=2; last iteration 25
[2022-01-11 17:15:59,311][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:15:59,311][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:15:59,311][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 17:15:59,312][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 17:15:59,312][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:59,312][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:15:59,312][root][INFO] - NLL Validation: loss = 0.411183. correct prediction ratio  5710/6400 ~  0.892188
[2022-01-11 17:15:59,312][root][INFO] - NLL Validation: loss = 0.411183. correct prediction ratio  5710/6400 ~  0.892188
[2022-01-11 17:15:59,312][root][INFO] - Av Loss per epoch=0.022746
[2022-01-11 17:15:59,312][root][INFO] - epoch total correct predictions=58366
[2022-01-11 17:15:59,313][root][INFO] - Av Loss per epoch=0.022746
[2022-01-11 17:15:59,313][root][INFO] - epoch total correct predictions=58366
[2022-01-11 17:15:59,314][root][INFO] - Av Loss per epoch=0.022746
[2022-01-11 17:15:59,314][root][INFO] - epoch total correct predictions=58366
[2022-01-11 17:15:59,314][root][INFO] - ***** Epoch 25 *****
[2022-01-11 17:15:59,315][root][INFO] - ***** Epoch 25 *****
[2022-01-11 17:15:59,316][root][INFO] - rank=1; Iteration start
[2022-01-11 17:15:59,316][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:59,316][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:15:59,316][root][INFO] - ***** Epoch 25 *****
[2022-01-11 17:15:59,316][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 17:15:59,317][root][INFO] - rank=2; Iteration start
[2022-01-11 17:15:59,317][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:59,317][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:15:59,317][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 17:15:59,318][root][INFO] - rank=3; Iteration start
[2022-01-11 17:15:59,318][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:15:59,318][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:15:59,318][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 17:16:04,467][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.24
[2022-01-11 17:16:04,468][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.24
[2022-01-11 17:16:04,468][root][INFO] - Av Loss per epoch=0.022746
[2022-01-11 17:16:04,468][root][INFO] - epoch total correct predictions=58366
[2022-01-11 17:16:04,470][root][INFO] - ***** Epoch 25 *****
[2022-01-11 17:16:04,472][root][INFO] - rank=0; Iteration start
[2022-01-11 17:16:04,473][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:16:04,473][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:16:04,473][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 17:16:05,399][root][INFO] - Epoch: 25: Step: 1/920, loss=0.016289, lr=0.000004
[2022-01-11 17:16:05,400][root][INFO] - Epoch: 25: Step: 1/920, loss=0.016289, lr=0.000004
[2022-01-11 17:16:05,401][root][INFO] - Epoch: 25: Step: 1/920, loss=0.016289, lr=0.000004
[2022-01-11 17:16:05,402][root][INFO] - Epoch: 25: Step: 1/920, loss=0.016289, lr=0.000004
[2022-01-11 17:17:43,055][root][INFO] - Train batch 100
[2022-01-11 17:17:43,055][root][INFO] - Avg. loss per last 100 batches: 0.027596
[2022-01-11 17:17:43,055][root][INFO] - Train batch 100
[2022-01-11 17:17:43,055][root][INFO] - Avg. loss per last 100 batches: 0.027596
[2022-01-11 17:17:43,055][root][INFO] - Train batch 100
[2022-01-11 17:17:43,055][root][INFO] - Avg. loss per last 100 batches: 0.027596
[2022-01-11 17:17:43,055][root][INFO] - Train batch 100
[2022-01-11 17:17:43,056][root][INFO] - Avg. loss per last 100 batches: 0.027596
[2022-01-11 17:17:44,106][root][INFO] - Epoch: 25: Step: 101/920, loss=0.008131, lr=0.000004
[2022-01-11 17:17:44,107][root][INFO] - Epoch: 25: Step: 101/920, loss=0.008131, lr=0.000004
[2022-01-11 17:17:44,107][root][INFO] - Epoch: 25: Step: 101/920, loss=0.008131, lr=0.000004
[2022-01-11 17:17:44,107][root][INFO] - Epoch: 25: Step: 101/920, loss=0.008131, lr=0.000004
[2022-01-11 17:19:23,393][root][INFO] - Train batch 200
[2022-01-11 17:19:23,393][root][INFO] - Avg. loss per last 100 batches: 0.023796
[2022-01-11 17:19:23,398][root][INFO] - Train batch 200
[2022-01-11 17:19:23,399][root][INFO] - Avg. loss per last 100 batches: 0.023796
[2022-01-11 17:19:23,401][root][INFO] - Train batch 200
[2022-01-11 17:19:23,401][root][INFO] - Avg. loss per last 100 batches: 0.023796
[2022-01-11 17:19:23,402][root][INFO] - Train batch 200
[2022-01-11 17:19:23,403][root][INFO] - Avg. loss per last 100 batches: 0.023796
[2022-01-11 17:19:24,359][root][INFO] - Epoch: 25: Step: 201/920, loss=0.012926, lr=0.000004
[2022-01-11 17:19:24,359][root][INFO] - Epoch: 25: Step: 201/920, loss=0.012926, lr=0.000004
[2022-01-11 17:19:24,360][root][INFO] - Epoch: 25: Step: 201/920, loss=0.012926, lr=0.000004
[2022-01-11 17:19:24,361][root][INFO] - Epoch: 25: Step: 201/920, loss=0.012926, lr=0.000004
[2022-01-11 17:21:02,252][root][INFO] - Train batch 300
[2022-01-11 17:21:02,253][root][INFO] - Avg. loss per last 100 batches: 0.021130
[2022-01-11 17:21:02,256][root][INFO] - Train batch 300
[2022-01-11 17:21:02,256][root][INFO] - Avg. loss per last 100 batches: 0.021130
[2022-01-11 17:21:02,257][root][INFO] - Train batch 300
[2022-01-11 17:21:02,257][root][INFO] - Avg. loss per last 100 batches: 0.021130
[2022-01-11 17:21:02,257][root][INFO] - Train batch 300
[2022-01-11 17:21:02,257][root][INFO] - Avg. loss per last 100 batches: 0.021130
[2022-01-11 17:21:03,303][root][INFO] - Epoch: 25: Step: 301/920, loss=0.000599, lr=0.000004
[2022-01-11 17:21:03,304][root][INFO] - Epoch: 25: Step: 301/920, loss=0.000599, lr=0.000004
[2022-01-11 17:21:03,304][root][INFO] - Epoch: 25: Step: 301/920, loss=0.000599, lr=0.000004
[2022-01-11 17:21:03,305][root][INFO] - Epoch: 25: Step: 301/920, loss=0.000599, lr=0.000004
[2022-01-11 17:22:42,640][root][INFO] - Train batch 400
[2022-01-11 17:22:42,641][root][INFO] - Avg. loss per last 100 batches: 0.021474
[2022-01-11 17:22:42,644][root][INFO] - Train batch 400
[2022-01-11 17:22:42,644][root][INFO] - Avg. loss per last 100 batches: 0.021474
[2022-01-11 17:22:42,644][root][INFO] - Train batch 400
[2022-01-11 17:22:42,644][root][INFO] - Avg. loss per last 100 batches: 0.021474
[2022-01-11 17:22:42,646][root][INFO] - Train batch 400
[2022-01-11 17:22:42,646][root][INFO] - Avg. loss per last 100 batches: 0.021474
[2022-01-11 17:22:43,546][root][INFO] - Epoch: 25: Step: 401/920, loss=0.000156, lr=0.000004
[2022-01-11 17:22:43,550][root][INFO] - Epoch: 25: Step: 401/920, loss=0.000156, lr=0.000004
[2022-01-11 17:22:43,551][root][INFO] - Epoch: 25: Step: 401/920, loss=0.000156, lr=0.000004
[2022-01-11 17:22:43,551][root][INFO] - Epoch: 25: Step: 401/920, loss=0.000156, lr=0.000004
[2022-01-11 17:24:20,902][root][INFO] - Train batch 500
[2022-01-11 17:24:20,902][root][INFO] - Avg. loss per last 100 batches: 0.024103
[2022-01-11 17:24:20,905][root][INFO] - Train batch 500
[2022-01-11 17:24:20,905][root][INFO] - Avg. loss per last 100 batches: 0.024103
[2022-01-11 17:24:20,907][root][INFO] - Train batch 500
[2022-01-11 17:24:20,907][root][INFO] - Avg. loss per last 100 batches: 0.024103
[2022-01-11 17:24:20,918][root][INFO] - Train batch 500
[2022-01-11 17:24:20,918][root][INFO] - Avg. loss per last 100 batches: 0.024103
[2022-01-11 17:24:21,840][root][INFO] - Epoch: 25: Step: 501/920, loss=0.002673, lr=0.000004
[2022-01-11 17:24:21,841][root][INFO] - Epoch: 25: Step: 501/920, loss=0.002673, lr=0.000004
[2022-01-11 17:24:21,842][root][INFO] - Epoch: 25: Step: 501/920, loss=0.002673, lr=0.000004
[2022-01-11 17:24:21,855][root][INFO] - Epoch: 25: Step: 501/920, loss=0.002673, lr=0.000004
[2022-01-11 17:25:59,606][root][INFO] - Train batch 600
[2022-01-11 17:25:59,606][root][INFO] - Avg. loss per last 100 batches: 0.022540
[2022-01-11 17:25:59,609][root][INFO] - Train batch 600
[2022-01-11 17:25:59,609][root][INFO] - Avg. loss per last 100 batches: 0.022540
[2022-01-11 17:25:59,609][root][INFO] - Train batch 600
[2022-01-11 17:25:59,610][root][INFO] - Avg. loss per last 100 batches: 0.022540
[2022-01-11 17:25:59,612][root][INFO] - Train batch 600
[2022-01-11 17:25:59,612][root][INFO] - Avg. loss per last 100 batches: 0.022540
[2022-01-11 17:26:00,552][root][INFO] - Epoch: 25: Step: 601/920, loss=0.024595, lr=0.000004
[2022-01-11 17:26:00,552][root][INFO] - Epoch: 25: Step: 601/920, loss=0.024595, lr=0.000004
[2022-01-11 17:26:00,553][root][INFO] - Epoch: 25: Step: 601/920, loss=0.024595, lr=0.000004
[2022-01-11 17:26:00,555][root][INFO] - Epoch: 25: Step: 601/920, loss=0.024595, lr=0.000004
[2022-01-11 17:27:37,631][root][INFO] - Train batch 700
[2022-01-11 17:27:37,632][root][INFO] - Avg. loss per last 100 batches: 0.021781
[2022-01-11 17:27:37,639][root][INFO] - Train batch 700
[2022-01-11 17:27:37,640][root][INFO] - Avg. loss per last 100 batches: 0.021781
[2022-01-11 17:27:37,640][root][INFO] - Train batch 700
[2022-01-11 17:27:37,640][root][INFO] - Avg. loss per last 100 batches: 0.021781
[2022-01-11 17:27:37,640][root][INFO] - Train batch 700
[2022-01-11 17:27:37,640][root][INFO] - Avg. loss per last 100 batches: 0.021781
[2022-01-11 17:27:38,686][root][INFO] - Epoch: 25: Step: 701/920, loss=0.003718, lr=0.000004
[2022-01-11 17:27:38,686][root][INFO] - Epoch: 25: Step: 701/920, loss=0.003718, lr=0.000004
[2022-01-11 17:27:38,686][root][INFO] - Epoch: 25: Step: 701/920, loss=0.003718, lr=0.000004
[2022-01-11 17:27:38,687][root][INFO] - Epoch: 25: Step: 701/920, loss=0.003718, lr=0.000004
[2022-01-11 17:29:17,777][root][INFO] - Train batch 800
[2022-01-11 17:29:17,777][root][INFO] - Avg. loss per last 100 batches: 0.026123
[2022-01-11 17:29:17,777][root][INFO] - Train batch 800
[2022-01-11 17:29:17,777][root][INFO] - Avg. loss per last 100 batches: 0.026123
[2022-01-11 17:29:17,778][root][INFO] - Train batch 800
[2022-01-11 17:29:17,778][root][INFO] - Avg. loss per last 100 batches: 0.026123
[2022-01-11 17:29:17,778][root][INFO] - Train batch 800
[2022-01-11 17:29:17,778][root][INFO] - Avg. loss per last 100 batches: 0.026123
[2022-01-11 17:29:18,747][root][INFO] - Epoch: 25: Step: 801/920, loss=0.010817, lr=0.000004
[2022-01-11 17:29:18,748][root][INFO] - Epoch: 25: Step: 801/920, loss=0.010817, lr=0.000004
[2022-01-11 17:29:18,748][root][INFO] - Epoch: 25: Step: 801/920, loss=0.010817, lr=0.000004
[2022-01-11 17:29:18,749][root][INFO] - Epoch: 25: Step: 801/920, loss=0.010817, lr=0.000004
[2022-01-11 17:30:53,842][root][INFO] - Train batch 900
[2022-01-11 17:30:53,843][root][INFO] - Avg. loss per last 100 batches: 0.021148
[2022-01-11 17:30:53,846][root][INFO] - Train batch 900
[2022-01-11 17:30:53,846][root][INFO] - Train batch 900
[2022-01-11 17:30:53,846][root][INFO] - Avg. loss per last 100 batches: 0.021148
[2022-01-11 17:30:53,846][root][INFO] - Avg. loss per last 100 batches: 0.021148
[2022-01-11 17:30:53,847][root][INFO] - Train batch 900
[2022-01-11 17:30:53,847][root][INFO] - Avg. loss per last 100 batches: 0.021148
[2022-01-11 17:30:54,888][root][INFO] - Epoch: 25: Step: 901/920, loss=0.004587, lr=0.000004
[2022-01-11 17:30:54,888][root][INFO] - Epoch: 25: Step: 901/920, loss=0.004587, lr=0.000004
[2022-01-11 17:30:54,889][root][INFO] - Epoch: 25: Step: 901/920, loss=0.004587, lr=0.000004
[2022-01-11 17:30:54,889][root][INFO] - Epoch: 25: Step: 901/920, loss=0.004587, lr=0.000004
[2022-01-11 17:31:14,804][root][INFO] - rank=2, Validation: Epoch: 25 Step: 920/920
[2022-01-11 17:31:14,804][root][INFO] - NLL validation ...
[2022-01-11 17:31:14,805][root][INFO] - rank=2; Iteration start
[2022-01-11 17:31:14,805][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:31:14,805][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:31:14,805][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 17:31:14,812][root][INFO] - rank=0, Validation: Epoch: 25 Step: 920/920
[2022-01-11 17:31:14,812][root][INFO] - NLL validation ...
[2022-01-11 17:31:14,812][root][INFO] - rank=1, Validation: Epoch: 25 Step: 920/920
[2022-01-11 17:31:14,812][root][INFO] - NLL validation ...
[2022-01-11 17:31:14,813][root][INFO] - rank=3, Validation: Epoch: 25 Step: 920/920
[2022-01-11 17:31:14,813][root][INFO] - rank=0; Iteration start
[2022-01-11 17:31:14,813][root][INFO] - NLL validation ...
[2022-01-11 17:31:14,813][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:31:14,813][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:31:14,813][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 17:31:14,814][root][INFO] - rank=1; Iteration start
[2022-01-11 17:31:14,814][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:31:14,814][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:31:14,814][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 17:31:14,814][root][INFO] - rank=3; Iteration start
[2022-01-11 17:31:14,814][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:31:14,814][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:31:14,814][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 17:31:14,815][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 17:31:14,823][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 17:31:14,824][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 17:31:14,824][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 17:31:15,563][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 17:31:15,565][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 17:31:15,565][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 17:31:16,338][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 17:31:17,068][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 17:31:17,068][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 17:31:17,068][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 17:31:17,070][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 17:31:17,802][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 17:31:17,803][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 17:31:17,803][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 17:31:17,803][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 17:31:18,543][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 17:31:18,543][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 17:31:18,544][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 17:31:18,545][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 17:31:19,281][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 17:31:19,281][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 17:31:19,282][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 17:31:19,282][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 17:31:20,018][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 17:31:20,019][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 17:31:20,019][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 17:31:20,020][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 17:31:20,756][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 17:31:20,756][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 17:31:20,756][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 17:31:20,756][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 17:31:21,495][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 17:31:21,497][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 17:31:21,498][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 17:31:21,498][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 17:31:22,234][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 17:31:22,235][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 17:31:22,236][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 17:31:22,236][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 17:31:22,973][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 17:31:22,974][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 17:31:22,974][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 17:31:22,974][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 17:31:23,711][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 17:31:23,711][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 17:31:23,711][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 17:31:23,712][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 17:31:24,451][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 17:31:24,452][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 17:31:24,453][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 17:31:24,453][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 17:31:25,191][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 17:31:25,797][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 17:31:25,810][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 17:31:25,847][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 17:31:26,581][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 17:31:26,581][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 17:31:26,582][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 17:31:26,583][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 17:31:27,318][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 17:31:27,318][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 17:31:27,318][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 17:31:28,138][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 17:31:28,872][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 17:31:28,872][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 17:31:28,872][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 17:31:28,872][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 17:31:29,611][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 17:31:29,612][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 17:31:29,612][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 17:31:29,612][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 17:31:30,346][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 17:31:30,346][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 17:31:30,347][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 17:31:30,347][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 17:31:31,083][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 17:31:31,083][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 17:31:31,083][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 17:31:31,083][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 17:31:31,823][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 17:31:31,823][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 17:31:31,824][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 17:31:31,825][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 17:31:32,561][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 17:31:32,562][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 17:31:32,562][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 17:31:32,562][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 17:31:33,297][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 17:31:33,297][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 17:31:33,298][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 17:31:33,298][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 17:31:34,036][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 17:31:34,036][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 17:31:34,037][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 17:31:34,038][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 17:31:34,779][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 17:31:34,781][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 17:31:34,781][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 17:31:34,781][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 17:31:35,510][root][INFO] - rank=3; last iteration 25
[2022-01-11 17:31:35,510][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:31:35,510][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 17:31:35,510][root][INFO] - rank=1; last iteration 25
[2022-01-11 17:31:35,510][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:31:35,510][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:31:35,510][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 17:31:35,510][root][INFO] - NLL Validation: loss = 0.391233. correct prediction ratio  5729/6400 ~  0.895156
[2022-01-11 17:31:35,510][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:31:35,510][root][INFO] - NLL Validation: loss = 0.391233. correct prediction ratio  5729/6400 ~  0.895156
[2022-01-11 17:31:35,510][root][INFO] - rank=0; last iteration 25
[2022-01-11 17:31:35,510][root][INFO] - rank=2; last iteration 25
[2022-01-11 17:31:35,511][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:31:35,511][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:31:35,511][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 17:31:35,511][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 17:31:35,511][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:31:35,511][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:31:35,511][root][INFO] - NLL Validation: loss = 0.391233. correct prediction ratio  5729/6400 ~  0.895156
[2022-01-11 17:31:35,511][root][INFO] - NLL Validation: loss = 0.391233. correct prediction ratio  5729/6400 ~  0.895156
[2022-01-11 17:31:35,513][root][INFO] - rank=3; last iteration 920
[2022-01-11 17:31:35,513][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:31:35,513][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 17:31:35,513][root][INFO] - rank=1; last iteration 920
[2022-01-11 17:31:35,513][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:31:35,513][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 17:31:35,513][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:31:35,513][root][INFO] - rank=2; last iteration 920
[2022-01-11 17:31:35,513][root][INFO] - Epoch finished on 3
[2022-01-11 17:31:35,513][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:31:35,513][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:31:35,513][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 17:31:35,513][root][INFO] - NLL validation ...
[2022-01-11 17:31:35,513][root][INFO] - Epoch finished on 1
[2022-01-11 17:31:35,513][root][INFO] - NLL validation ...
[2022-01-11 17:31:35,514][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:31:35,514][root][INFO] - Epoch finished on 2
[2022-01-11 17:31:35,514][root][INFO] - NLL validation ...
[2022-01-11 17:31:35,515][root][INFO] - rank=3; Iteration start
[2022-01-11 17:31:35,515][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:31:35,515][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:31:35,515][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 17:31:35,515][root][INFO] - rank=1; Iteration start
[2022-01-11 17:31:35,515][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:31:35,515][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:31:35,515][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 17:31:35,515][root][INFO] - rank=2; Iteration start
[2022-01-11 17:31:35,515][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:31:35,515][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:31:35,515][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 17:31:35,522][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 17:31:35,522][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 17:31:35,524][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 17:31:39,595][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.25
[2022-01-11 17:31:39,596][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.25
[2022-01-11 17:31:39,597][root][INFO] - rank=0; last iteration 920
[2022-01-11 17:31:39,597][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:31:39,597][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 17:31:39,597][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:31:39,598][root][INFO] - Epoch finished on 0
[2022-01-11 17:31:39,598][root][INFO] - NLL validation ...
[2022-01-11 17:31:39,599][root][INFO] - rank=0; Iteration start
[2022-01-11 17:31:39,599][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:31:39,599][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:31:39,599][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 17:31:39,607][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 17:31:40,344][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 17:31:40,344][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 17:31:40,346][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 17:31:40,351][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 17:31:41,085][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 17:31:41,708][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 17:31:41,818][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 17:31:41,952][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 17:31:42,685][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 17:31:42,686][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 17:31:42,687][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 17:31:42,687][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 17:31:43,423][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 17:31:43,424][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 17:31:43,424][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 17:31:44,061][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 17:31:44,788][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 17:31:44,789][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 17:31:44,790][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 17:31:44,790][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 17:31:45,527][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 17:31:45,528][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 17:31:45,528][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 17:31:45,529][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 17:31:46,263][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 17:31:46,264][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 17:31:46,264][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 17:31:46,265][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 17:31:47,000][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 17:31:47,000][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 17:31:47,001][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 17:31:47,001][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 17:31:47,735][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 17:31:47,735][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 17:31:47,735][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 17:31:47,736][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 17:31:48,477][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 17:31:48,478][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 17:31:48,478][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 17:31:48,480][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 17:31:49,214][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 17:31:49,214][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 17:31:49,215][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 17:31:49,216][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 17:31:49,949][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 17:31:49,950][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 17:31:49,951][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 17:31:49,953][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 17:31:50,686][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 17:31:50,686][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 17:31:50,688][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 17:31:50,688][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 17:31:51,422][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 17:31:51,423][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 17:31:51,423][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 17:31:51,424][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 17:31:52,157][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 17:31:52,157][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 17:31:52,159][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 17:31:52,160][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 17:31:52,893][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 17:31:53,471][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 17:31:53,614][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 17:31:53,715][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 17:31:54,453][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 17:31:54,454][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 17:31:54,454][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 17:31:55,081][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 17:31:55,814][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 17:31:55,814][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 17:31:55,815][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 17:31:55,815][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 17:31:56,549][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 17:31:56,550][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 17:31:56,550][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 17:31:56,552][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 17:31:57,287][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 17:31:57,287][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 17:31:57,288][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 17:31:57,289][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 17:31:58,022][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 17:31:58,023][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 17:31:58,024][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 17:31:58,024][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 17:31:58,759][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 17:31:58,760][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 17:31:58,761][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 17:31:58,761][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 17:31:59,499][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 17:31:59,500][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 17:31:59,500][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 17:31:59,501][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 17:32:00,235][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 17:32:00,235][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 17:32:00,236][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 17:32:00,236][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 17:32:00,961][root][INFO] - rank=3; last iteration 25
[2022-01-11 17:32:00,961][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:32:00,961][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 17:32:00,961][root][INFO] - rank=1; last iteration 25
[2022-01-11 17:32:00,961][root][INFO] - rank=2; last iteration 25
[2022-01-11 17:32:00,961][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:32:00,961][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:32:00,961][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 17:32:00,961][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:32:00,961][root][INFO] - rank=0; last iteration 25
[2022-01-11 17:32:00,961][root][INFO] - NLL Validation: loss = 0.391233. correct prediction ratio  5729/6400 ~  0.895156
[2022-01-11 17:32:00,961][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 17:32:00,961][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:32:00,962][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:32:00,962][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:32:00,962][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 17:32:00,962][root][INFO] - NLL Validation: loss = 0.391233. correct prediction ratio  5729/6400 ~  0.895156
[2022-01-11 17:32:00,962][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:32:00,962][root][INFO] - NLL Validation: loss = 0.391233. correct prediction ratio  5729/6400 ~  0.895156
[2022-01-11 17:32:00,962][root][INFO] - NLL Validation: loss = 0.391233. correct prediction ratio  5729/6400 ~  0.895156
[2022-01-11 17:32:00,963][root][INFO] - Av Loss per epoch=0.023611
[2022-01-11 17:32:00,963][root][INFO] - epoch total correct predictions=58358
[2022-01-11 17:32:00,963][root][INFO] - Av Loss per epoch=0.023611
[2022-01-11 17:32:00,963][root][INFO] - epoch total correct predictions=58358
[2022-01-11 17:32:00,963][root][INFO] - Av Loss per epoch=0.023611
[2022-01-11 17:32:00,963][root][INFO] - epoch total correct predictions=58358
[2022-01-11 17:32:00,964][root][INFO] - ***** Epoch 26 *****
[2022-01-11 17:32:00,965][root][INFO] - ***** Epoch 26 *****
[2022-01-11 17:32:00,965][root][INFO] - ***** Epoch 26 *****
[2022-01-11 17:32:00,966][root][INFO] - rank=3; Iteration start
[2022-01-11 17:32:00,966][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:32:00,966][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:32:00,966][root][INFO] - rank=1; Iteration start
[2022-01-11 17:32:00,966][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:32:00,966][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:32:00,967][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 17:32:00,967][root][INFO] - rank=2; Iteration start
[2022-01-11 17:32:00,967][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:32:00,967][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 17:32:00,967][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:32:00,967][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 17:32:06,133][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.25
[2022-01-11 17:32:06,134][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.25
[2022-01-11 17:32:06,134][root][INFO] - Av Loss per epoch=0.023611
[2022-01-11 17:32:06,134][root][INFO] - epoch total correct predictions=58358
[2022-01-11 17:32:06,135][root][INFO] - ***** Epoch 26 *****
[2022-01-11 17:32:06,138][root][INFO] - rank=0; Iteration start
[2022-01-11 17:32:06,138][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:32:06,138][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:32:06,138][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 17:32:07,079][root][INFO] - Epoch: 26: Step: 1/920, loss=0.011545, lr=0.000004
[2022-01-11 17:32:07,080][root][INFO] - Epoch: 26: Step: 1/920, loss=0.011545, lr=0.000004
[2022-01-11 17:32:07,082][root][INFO] - Epoch: 26: Step: 1/920, loss=0.011545, lr=0.000004
[2022-01-11 17:32:07,082][root][INFO] - Epoch: 26: Step: 1/920, loss=0.011545, lr=0.000004
[2022-01-11 17:33:46,242][root][INFO] - Train batch 100
[2022-01-11 17:33:46,242][root][INFO] - Avg. loss per last 100 batches: 0.022427
[2022-01-11 17:33:46,242][root][INFO] - Train batch 100
[2022-01-11 17:33:46,243][root][INFO] - Avg. loss per last 100 batches: 0.022427
[2022-01-11 17:33:46,244][root][INFO] - Train batch 100
[2022-01-11 17:33:46,244][root][INFO] - Avg. loss per last 100 batches: 0.022427
[2022-01-11 17:33:46,244][root][INFO] - Train batch 100
[2022-01-11 17:33:46,244][root][INFO] - Avg. loss per last 100 batches: 0.022427
[2022-01-11 17:33:47,274][root][INFO] - Epoch: 26: Step: 101/920, loss=0.003142, lr=0.000004
[2022-01-11 17:33:47,275][root][INFO] - Epoch: 26: Step: 101/920, loss=0.003142, lr=0.000004
[2022-01-11 17:33:47,275][root][INFO] - Epoch: 26: Step: 101/920, loss=0.003142, lr=0.000004
[2022-01-11 17:33:47,276][root][INFO] - Epoch: 26: Step: 101/920, loss=0.003142, lr=0.000004
[2022-01-11 17:35:24,124][root][INFO] - Train batch 200
[2022-01-11 17:35:24,125][root][INFO] - Avg. loss per last 100 batches: 0.021174
[2022-01-11 17:35:24,125][root][INFO] - Train batch 200
[2022-01-11 17:35:24,125][root][INFO] - Avg. loss per last 100 batches: 0.021174
[2022-01-11 17:35:24,126][root][INFO] - Train batch 200
[2022-01-11 17:35:24,126][root][INFO] - Avg. loss per last 100 batches: 0.021174
[2022-01-11 17:35:24,126][root][INFO] - Train batch 200
[2022-01-11 17:35:24,127][root][INFO] - Avg. loss per last 100 batches: 0.021174
[2022-01-11 17:35:25,158][root][INFO] - Epoch: 26: Step: 201/920, loss=0.019507, lr=0.000004
[2022-01-11 17:35:25,159][root][INFO] - Epoch: 26: Step: 201/920, loss=0.019507, lr=0.000004
[2022-01-11 17:35:25,161][root][INFO] - Epoch: 26: Step: 201/920, loss=0.019507, lr=0.000004
[2022-01-11 17:35:25,161][root][INFO] - Epoch: 26: Step: 201/920, loss=0.019507, lr=0.000004
[2022-01-11 17:37:02,495][root][INFO] - Train batch 300
[2022-01-11 17:37:02,495][root][INFO] - Avg. loss per last 100 batches: 0.021663
[2022-01-11 17:37:02,495][root][INFO] - Train batch 300
[2022-01-11 17:37:02,495][root][INFO] - Avg. loss per last 100 batches: 0.021663
[2022-01-11 17:37:02,495][root][INFO] - Train batch 300
[2022-01-11 17:37:02,496][root][INFO] - Avg. loss per last 100 batches: 0.021663
[2022-01-11 17:37:02,495][root][INFO] - Train batch 300
[2022-01-11 17:37:02,496][root][INFO] - Avg. loss per last 100 batches: 0.021663
[2022-01-11 17:37:03,539][root][INFO] - Epoch: 26: Step: 301/920, loss=0.004303, lr=0.000004
[2022-01-11 17:37:03,544][root][INFO] - Epoch: 26: Step: 301/920, loss=0.004303, lr=0.000004
[2022-01-11 17:37:03,544][root][INFO] - Epoch: 26: Step: 301/920, loss=0.004303, lr=0.000004
[2022-01-11 17:37:03,545][root][INFO] - Epoch: 26: Step: 301/920, loss=0.004303, lr=0.000004
[2022-01-11 17:38:42,773][root][INFO] - Train batch 400
[2022-01-11 17:38:42,773][root][INFO] - Avg. loss per last 100 batches: 0.020106
[2022-01-11 17:38:42,786][root][INFO] - Train batch 400
[2022-01-11 17:38:42,786][root][INFO] - Avg. loss per last 100 batches: 0.020106
[2022-01-11 17:38:42,786][root][INFO] - Train batch 400
[2022-01-11 17:38:42,786][root][INFO] - Avg. loss per last 100 batches: 0.020106
[2022-01-11 17:38:42,786][root][INFO] - Train batch 400
[2022-01-11 17:38:42,787][root][INFO] - Avg. loss per last 100 batches: 0.020106
[2022-01-11 17:38:43,836][root][INFO] - Epoch: 26: Step: 401/920, loss=0.010168, lr=0.000004
[2022-01-11 17:38:43,837][root][INFO] - Epoch: 26: Step: 401/920, loss=0.010168, lr=0.000004
[2022-01-11 17:38:43,837][root][INFO] - Epoch: 26: Step: 401/920, loss=0.010168, lr=0.000004
[2022-01-11 17:38:43,837][root][INFO] - Epoch: 26: Step: 401/920, loss=0.010168, lr=0.000004
[2022-01-11 17:40:21,134][root][INFO] - Train batch 500
[2022-01-11 17:40:21,134][root][INFO] - Avg. loss per last 100 batches: 0.024223
[2022-01-11 17:40:21,135][root][INFO] - Train batch 500
[2022-01-11 17:40:21,135][root][INFO] - Avg. loss per last 100 batches: 0.024223
[2022-01-11 17:40:21,136][root][INFO] - Train batch 500
[2022-01-11 17:40:21,136][root][INFO] - Avg. loss per last 100 batches: 0.024223
[2022-01-11 17:40:21,136][root][INFO] - Train batch 500
[2022-01-11 17:40:21,136][root][INFO] - Avg. loss per last 100 batches: 0.024223
[2022-01-11 17:40:22,184][root][INFO] - Epoch: 26: Step: 501/920, loss=0.004156, lr=0.000004
[2022-01-11 17:40:22,185][root][INFO] - Epoch: 26: Step: 501/920, loss=0.004156, lr=0.000004
[2022-01-11 17:40:22,185][root][INFO] - Epoch: 26: Step: 501/920, loss=0.004156, lr=0.000004
[2022-01-11 17:40:22,186][root][INFO] - Epoch: 26: Step: 501/920, loss=0.004156, lr=0.000004
[2022-01-11 17:42:00,887][root][INFO] - Train batch 600
[2022-01-11 17:42:00,887][root][INFO] - Avg. loss per last 100 batches: 0.021876
[2022-01-11 17:42:00,889][root][INFO] - Train batch 600
[2022-01-11 17:42:00,889][root][INFO] - Avg. loss per last 100 batches: 0.021876
[2022-01-11 17:42:00,890][root][INFO] - Train batch 600
[2022-01-11 17:42:00,890][root][INFO] - Avg. loss per last 100 batches: 0.021876
[2022-01-11 17:42:00,890][root][INFO] - Train batch 600
[2022-01-11 17:42:00,890][root][INFO] - Avg. loss per last 100 batches: 0.021876
[2022-01-11 17:42:01,744][root][INFO] - Epoch: 26: Step: 601/920, loss=0.000570, lr=0.000004
[2022-01-11 17:42:01,745][root][INFO] - Epoch: 26: Step: 601/920, loss=0.000570, lr=0.000004
[2022-01-11 17:42:01,746][root][INFO] - Epoch: 26: Step: 601/920, loss=0.000570, lr=0.000004
[2022-01-11 17:42:01,746][root][INFO] - Epoch: 26: Step: 601/920, loss=0.000570, lr=0.000004
[2022-01-11 17:43:38,974][root][INFO] - Train batch 700
[2022-01-11 17:43:38,975][root][INFO] - Avg. loss per last 100 batches: 0.020800
[2022-01-11 17:43:38,980][root][INFO] - Train batch 700
[2022-01-11 17:43:38,980][root][INFO] - Avg. loss per last 100 batches: 0.020800
[2022-01-11 17:43:38,988][root][INFO] - Train batch 700
[2022-01-11 17:43:38,988][root][INFO] - Avg. loss per last 100 batches: 0.020800
[2022-01-11 17:43:38,991][root][INFO] - Train batch 700
[2022-01-11 17:43:38,991][root][INFO] - Avg. loss per last 100 batches: 0.020800
[2022-01-11 17:43:40,036][root][INFO] - Epoch: 26: Step: 701/920, loss=0.006471, lr=0.000004
[2022-01-11 17:43:40,038][root][INFO] - Epoch: 26: Step: 701/920, loss=0.006471, lr=0.000004
[2022-01-11 17:43:40,038][root][INFO] - Epoch: 26: Step: 701/920, loss=0.006471, lr=0.000004
[2022-01-11 17:43:40,038][root][INFO] - Epoch: 26: Step: 701/920, loss=0.006471, lr=0.000004
[2022-01-11 17:45:17,248][root][INFO] - Train batch 800
[2022-01-11 17:45:17,248][root][INFO] - Avg. loss per last 100 batches: 0.020543
[2022-01-11 17:45:17,254][root][INFO] - Train batch 800
[2022-01-11 17:45:17,254][root][INFO] - Avg. loss per last 100 batches: 0.020543
[2022-01-11 17:45:17,254][root][INFO] - Train batch 800
[2022-01-11 17:45:17,254][root][INFO] - Avg. loss per last 100 batches: 0.020543
[2022-01-11 17:45:17,255][root][INFO] - Train batch 800
[2022-01-11 17:45:17,255][root][INFO] - Avg. loss per last 100 batches: 0.020543
[2022-01-11 17:45:18,209][root][INFO] - Epoch: 26: Step: 801/920, loss=0.018218, lr=0.000004
[2022-01-11 17:45:18,211][root][INFO] - Epoch: 26: Step: 801/920, loss=0.018218, lr=0.000004
[2022-01-11 17:45:18,212][root][INFO] - Epoch: 26: Step: 801/920, loss=0.018218, lr=0.000004
[2022-01-11 17:45:18,214][root][INFO] - Epoch: 26: Step: 801/920, loss=0.018218, lr=0.000004
[2022-01-11 17:46:55,546][root][INFO] - Train batch 900
[2022-01-11 17:46:55,546][root][INFO] - Avg. loss per last 100 batches: 0.022843
[2022-01-11 17:46:55,546][root][INFO] - Train batch 900
[2022-01-11 17:46:55,546][root][INFO] - Train batch 900
[2022-01-11 17:46:55,547][root][INFO] - Avg. loss per last 100 batches: 0.022843
[2022-01-11 17:46:55,547][root][INFO] - Avg. loss per last 100 batches: 0.022843
[2022-01-11 17:46:55,547][root][INFO] - Train batch 900
[2022-01-11 17:46:55,547][root][INFO] - Avg. loss per last 100 batches: 0.022843
[2022-01-11 17:46:56,584][root][INFO] - Epoch: 26: Step: 901/920, loss=0.003770, lr=0.000003
[2022-01-11 17:46:56,591][root][INFO] - Epoch: 26: Step: 901/920, loss=0.003770, lr=0.000003
[2022-01-11 17:46:56,596][root][INFO] - Epoch: 26: Step: 901/920, loss=0.003770, lr=0.000003
[2022-01-11 17:46:56,596][root][INFO] - Epoch: 26: Step: 901/920, loss=0.003770, lr=0.000003
[2022-01-11 17:47:15,414][root][INFO] - rank=3, Validation: Epoch: 26 Step: 920/920
[2022-01-11 17:47:15,414][root][INFO] - NLL validation ...
[2022-01-11 17:47:15,415][root][INFO] - rank=3; Iteration start
[2022-01-11 17:47:15,415][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:47:15,415][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:47:15,415][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 17:47:15,416][root][INFO] - rank=0, Validation: Epoch: 26 Step: 920/920
[2022-01-11 17:47:15,416][root][INFO] - NLL validation ...
[2022-01-11 17:47:15,417][root][INFO] - rank=1, Validation: Epoch: 26 Step: 920/920
[2022-01-11 17:47:15,417][root][INFO] - rank=0; Iteration start
[2022-01-11 17:47:15,417][root][INFO] - NLL validation ...
[2022-01-11 17:47:15,417][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:47:15,417][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:47:15,417][root][INFO] - rank=2, Validation: Epoch: 26 Step: 920/920
[2022-01-11 17:47:15,417][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 17:47:15,417][root][INFO] - NLL validation ...
[2022-01-11 17:47:15,418][root][INFO] - rank=1; Iteration start
[2022-01-11 17:47:15,418][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:47:15,418][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:47:15,419][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 17:47:15,419][root][INFO] - rank=2; Iteration start
[2022-01-11 17:47:15,419][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:47:15,419][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:47:15,419][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 17:47:15,425][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 17:47:15,427][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 17:47:15,429][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 17:47:15,429][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 17:47:16,165][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 17:47:16,165][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 17:47:16,166][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 17:47:16,167][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 17:47:16,903][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 17:47:16,903][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 17:47:16,903][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 17:47:16,903][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 17:47:17,638][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 17:47:17,638][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 17:47:17,639][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 17:47:17,639][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 17:47:18,381][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 17:47:18,381][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 17:47:18,381][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 17:47:18,382][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 17:47:19,119][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 17:47:19,119][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 17:47:19,119][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 17:47:19,119][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 17:47:19,857][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 17:47:19,857][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 17:47:19,857][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 17:47:19,857][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 17:47:20,593][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 17:47:20,594][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 17:47:20,594][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 17:47:20,594][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 17:47:21,333][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 17:47:21,333][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 17:47:21,333][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 17:47:22,147][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 17:47:22,879][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 17:47:23,521][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 17:47:23,689][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 17:47:23,839][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 17:47:24,575][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 17:47:24,576][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 17:47:24,577][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 17:47:24,577][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 17:47:25,314][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 17:47:25,314][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 17:47:25,314][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 17:47:25,314][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 17:47:26,049][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 17:47:26,050][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 17:47:26,050][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 17:47:26,051][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 17:47:26,789][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 17:47:26,789][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 17:47:26,790][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 17:47:26,790][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 17:47:27,523][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 17:47:27,524][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 17:47:27,524][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 17:47:27,525][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 17:47:28,260][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 17:47:28,262][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 17:47:28,262][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 17:47:28,262][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 17:47:28,995][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 17:47:28,996][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 17:47:28,996][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 17:47:28,996][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 17:47:29,733][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 17:47:29,733][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 17:47:29,733][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 17:47:29,734][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 17:47:30,469][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 17:47:30,469][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 17:47:30,470][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 17:47:30,471][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 17:47:31,209][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 17:47:31,210][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 17:47:31,210][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 17:47:31,211][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 17:47:31,945][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 17:47:31,945][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 17:47:31,945][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 17:47:31,946][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 17:47:32,681][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 17:47:32,681][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 17:47:32,682][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 17:47:32,684][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 17:47:33,427][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 17:47:33,429][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 17:47:33,430][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 17:47:34,052][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 17:47:34,785][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 17:47:35,363][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 17:47:35,578][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 17:47:35,594][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 17:47:36,333][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 17:47:36,334][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 17:47:36,334][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 17:47:36,335][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 17:47:37,061][root][INFO] - rank=2; last iteration 25
[2022-01-11 17:47:37,061][root][INFO] - rank=0; last iteration 25
[2022-01-11 17:47:37,061][root][INFO] - rank=3; last iteration 25
[2022-01-11 17:47:37,061][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:47:37,061][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:47:37,061][root][INFO] - rank=1; last iteration 25
[2022-01-11 17:47:37,061][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 17:47:37,061][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 17:47:37,061][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:47:37,061][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 17:47:37,061][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:47:37,061][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:47:37,061][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:47:37,062][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 17:47:37,062][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:47:37,062][root][INFO] - NLL Validation: loss = 0.397686. correct prediction ratio  5740/6400 ~  0.896875
[2022-01-11 17:47:37,062][root][INFO] - NLL Validation: loss = 0.397686. correct prediction ratio  5740/6400 ~  0.896875
[2022-01-11 17:47:37,062][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:47:37,062][root][INFO] - NLL Validation: loss = 0.397686. correct prediction ratio  5740/6400 ~  0.896875
[2022-01-11 17:47:37,062][root][INFO] - NLL Validation: loss = 0.397686. correct prediction ratio  5740/6400 ~  0.896875
[2022-01-11 17:47:37,064][root][INFO] - rank=2; last iteration 920
[2022-01-11 17:47:37,064][root][INFO] - rank=3; last iteration 920
[2022-01-11 17:47:37,064][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:47:37,064][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:47:37,064][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 17:47:37,064][root][INFO] - rank=1; last iteration 920
[2022-01-11 17:47:37,064][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 17:47:37,064][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:47:37,064][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 17:47:37,065][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:47:37,065][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:47:37,065][root][INFO] - Epoch finished on 2
[2022-01-11 17:47:37,065][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:47:37,065][root][INFO] - Epoch finished on 3
[2022-01-11 17:47:37,065][root][INFO] - NLL validation ...
[2022-01-11 17:47:37,065][root][INFO] - Epoch finished on 1
[2022-01-11 17:47:37,065][root][INFO] - NLL validation ...
[2022-01-11 17:47:37,065][root][INFO] - NLL validation ...
[2022-01-11 17:47:37,066][root][INFO] - rank=2; Iteration start
[2022-01-11 17:47:37,066][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:47:37,066][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:47:37,066][root][INFO] - rank=3; Iteration start
[2022-01-11 17:47:37,066][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 17:47:37,066][root][INFO] - rank=1; Iteration start
[2022-01-11 17:47:37,066][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:47:37,066][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:47:37,066][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:47:37,066][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 17:47:37,066][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:47:37,066][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 17:47:37,074][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 17:47:37,074][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 17:47:37,076][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 17:47:40,976][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.26
[2022-01-11 17:47:40,976][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.26
[2022-01-11 17:47:40,978][root][INFO] - rank=0; last iteration 920
[2022-01-11 17:47:40,978][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 17:47:40,978][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 17:47:40,978][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:47:40,978][root][INFO] - Epoch finished on 0
[2022-01-11 17:47:40,978][root][INFO] - NLL validation ...
[2022-01-11 17:47:40,980][root][INFO] - rank=0; Iteration start
[2022-01-11 17:47:40,980][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:47:40,980][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 17:47:40,980][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 17:47:40,988][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 17:47:41,732][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 17:47:41,732][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 17:47:41,733][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 17:47:41,734][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 17:47:42,470][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 17:47:42,471][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 17:47:42,472][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 17:47:42,474][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 17:47:43,205][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 17:47:43,205][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 17:47:43,205][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 17:47:43,207][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 17:47:43,940][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 17:47:43,940][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 17:47:43,940][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 17:47:43,941][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 17:47:44,676][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 17:47:44,677][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 17:47:44,677][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 17:47:44,678][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 17:47:45,414][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 17:47:45,415][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 17:47:45,415][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 17:47:45,416][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 17:47:46,148][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 17:47:46,149][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 17:47:46,150][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 17:47:46,152][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 17:47:46,884][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 17:47:46,884][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 17:47:46,886][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 17:47:46,886][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 17:47:47,621][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 17:47:47,623][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 17:47:47,623][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 17:47:47,625][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 17:47:48,359][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 17:47:48,359][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 17:47:48,359][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 17:47:48,360][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 17:47:49,095][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 17:47:49,095][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 17:47:49,096][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 17:47:49,097][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 17:47:50,434][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 17:47:50,461][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 17:47:50,508][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 17:47:50,579][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 17:47:51,307][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 17:47:51,307][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 17:47:51,307][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 17:47:51,309][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 17:47:52,041][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 17:47:52,041][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 17:47:52,042][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 17:47:52,043][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 17:47:52,776][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 17:47:52,776][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 17:47:52,777][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 17:47:52,778][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 17:47:53,511][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 17:47:53,512][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 17:47:53,512][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 17:47:53,514][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 17:47:54,250][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 17:47:54,250][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 17:47:54,250][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 17:47:54,251][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 17:47:54,986][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 17:47:54,986][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 17:47:54,987][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 17:47:54,987][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 17:47:55,721][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 17:47:55,721][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 17:47:55,721][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 17:47:55,723][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 17:47:56,458][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 17:47:56,459][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 17:47:56,459][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 17:47:56,461][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 17:47:57,194][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 17:47:57,194][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 17:47:57,195][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 17:47:57,196][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 17:47:57,932][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 17:47:57,933][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 17:47:57,933][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 17:47:57,935][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 17:47:58,668][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 17:47:58,669][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 17:47:58,669][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 17:47:58,670][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 17:47:59,406][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 17:47:59,407][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 17:47:59,407][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 17:47:59,409][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 17:48:00,134][root][INFO] - rank=0; last iteration 25
[2022-01-11 17:48:00,134][root][INFO] - rank=2; last iteration 25
[2022-01-11 17:48:00,134][root][INFO] - rank=3; last iteration 25
[2022-01-11 17:48:00,134][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:48:00,134][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:48:00,134][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:48:00,134][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 17:48:00,134][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 17:48:00,134][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 17:48:00,134][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:48:00,134][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:48:00,134][root][INFO] - rank=1; last iteration 25
[2022-01-11 17:48:00,134][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:48:00,134][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 17:48:00,134][root][INFO] - NLL Validation: loss = 0.397686. correct prediction ratio  5740/6400 ~  0.896875
[2022-01-11 17:48:00,134][root][INFO] - NLL Validation: loss = 0.397686. correct prediction ratio  5740/6400 ~  0.896875
[2022-01-11 17:48:00,134][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 17:48:00,134][root][INFO] - NLL Validation: loss = 0.397686. correct prediction ratio  5740/6400 ~  0.896875
[2022-01-11 17:48:00,134][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 17:48:00,134][root][INFO] - NLL Validation: loss = 0.397686. correct prediction ratio  5740/6400 ~  0.896875
[2022-01-11 17:48:00,135][root][INFO] - Av Loss per epoch=0.021581
[2022-01-11 17:48:00,135][root][INFO] - epoch total correct predictions=58398
[2022-01-11 17:48:00,135][root][INFO] - Av Loss per epoch=0.021581
[2022-01-11 17:48:00,135][root][INFO] - epoch total correct predictions=58398
[2022-01-11 17:48:00,136][root][INFO] - Av Loss per epoch=0.021581
[2022-01-11 17:48:00,136][root][INFO] - epoch total correct predictions=58398
[2022-01-11 17:48:00,137][root][INFO] - ***** Epoch 27 *****
[2022-01-11 17:48:00,137][root][INFO] - ***** Epoch 27 *****
[2022-01-11 17:48:00,137][root][INFO] - ***** Epoch 27 *****
[2022-01-11 17:48:00,139][root][INFO] - rank=2; Iteration start
[2022-01-11 17:48:00,139][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:48:00,139][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:48:00,139][root][INFO] - rank=3; Iteration start
[2022-01-11 17:48:00,139][root][INFO] - rank=1; Iteration start
[2022-01-11 17:48:00,139][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:48:00,139][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:48:00,139][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:48:00,139][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:48:00,139][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 17:48:00,139][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 17:48:00,139][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 17:48:05,328][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.26
[2022-01-11 17:48:05,329][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.26
[2022-01-11 17:48:05,329][root][INFO] - Av Loss per epoch=0.021581
[2022-01-11 17:48:05,329][root][INFO] - epoch total correct predictions=58398
[2022-01-11 17:48:05,331][root][INFO] - ***** Epoch 27 *****
[2022-01-11 17:48:05,333][root][INFO] - rank=0; Iteration start
[2022-01-11 17:48:05,333][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 17:48:05,333][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 17:48:05,333][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 17:48:07,124][root][INFO] - Epoch: 27: Step: 1/920, loss=0.003209, lr=0.000003
[2022-01-11 17:48:07,134][root][INFO] - Epoch: 27: Step: 1/920, loss=0.003209, lr=0.000003
[2022-01-11 17:48:07,135][root][INFO] - Epoch: 27: Step: 1/920, loss=0.003209, lr=0.000003
[2022-01-11 17:48:07,136][root][INFO] - Epoch: 27: Step: 1/920, loss=0.003209, lr=0.000003
[2022-01-11 17:49:45,250][root][INFO] - Train batch 100
[2022-01-11 17:49:45,250][root][INFO] - Avg. loss per last 100 batches: 0.021602
[2022-01-11 17:49:45,250][root][INFO] - Train batch 100
[2022-01-11 17:49:45,250][root][INFO] - Avg. loss per last 100 batches: 0.021602
[2022-01-11 17:49:45,251][root][INFO] - Train batch 100
[2022-01-11 17:49:45,251][root][INFO] - Avg. loss per last 100 batches: 0.021602
[2022-01-11 17:49:45,252][root][INFO] - Train batch 100
[2022-01-11 17:49:45,252][root][INFO] - Avg. loss per last 100 batches: 0.021602
[2022-01-11 17:49:46,160][root][INFO] - Epoch: 27: Step: 101/920, loss=0.043092, lr=0.000003
[2022-01-11 17:49:46,160][root][INFO] - Epoch: 27: Step: 101/920, loss=0.043092, lr=0.000003
[2022-01-11 17:49:46,161][root][INFO] - Epoch: 27: Step: 101/920, loss=0.043092, lr=0.000003
[2022-01-11 17:49:46,162][root][INFO] - Epoch: 27: Step: 101/920, loss=0.043092, lr=0.000003
[2022-01-11 17:51:23,372][root][INFO] - Train batch 200
[2022-01-11 17:51:23,372][root][INFO] - Avg. loss per last 100 batches: 0.018327
[2022-01-11 17:51:23,385][root][INFO] - Train batch 200
[2022-01-11 17:51:23,385][root][INFO] - Train batch 200
[2022-01-11 17:51:23,385][root][INFO] - Avg. loss per last 100 batches: 0.018327
[2022-01-11 17:51:23,385][root][INFO] - Avg. loss per last 100 batches: 0.018327
[2022-01-11 17:51:23,386][root][INFO] - Train batch 200
[2022-01-11 17:51:23,386][root][INFO] - Avg. loss per last 100 batches: 0.018327
[2022-01-11 17:51:24,362][root][INFO] - Epoch: 27: Step: 201/920, loss=0.003961, lr=0.000003
[2022-01-11 17:51:24,372][root][INFO] - Epoch: 27: Step: 201/920, loss=0.003961, lr=0.000003
[2022-01-11 17:51:24,375][root][INFO] - Epoch: 27: Step: 201/920, loss=0.003961, lr=0.000003
[2022-01-11 17:51:24,376][root][INFO] - Epoch: 27: Step: 201/920, loss=0.003961, lr=0.000003
[2022-01-11 17:53:03,478][root][INFO] - Train batch 300
[2022-01-11 17:53:03,478][root][INFO] - Avg. loss per last 100 batches: 0.020485
[2022-01-11 17:53:03,479][root][INFO] - Train batch 300
[2022-01-11 17:53:03,479][root][INFO] - Avg. loss per last 100 batches: 0.020485
[2022-01-11 17:53:03,479][root][INFO] - Train batch 300
[2022-01-11 17:53:03,480][root][INFO] - Avg. loss per last 100 batches: 0.020485
[2022-01-11 17:53:03,480][root][INFO] - Train batch 300
[2022-01-11 17:53:03,480][root][INFO] - Avg. loss per last 100 batches: 0.020485
[2022-01-11 17:53:04,529][root][INFO] - Epoch: 27: Step: 301/920, loss=0.040609, lr=0.000003
[2022-01-11 17:53:04,530][root][INFO] - Epoch: 27: Step: 301/920, loss=0.040609, lr=0.000003
[2022-01-11 17:53:04,530][root][INFO] - Epoch: 27: Step: 301/920, loss=0.040609, lr=0.000003
[2022-01-11 17:53:04,531][root][INFO] - Epoch: 27: Step: 301/920, loss=0.040609, lr=0.000003
[2022-01-11 17:54:41,849][root][INFO] - Train batch 400
[2022-01-11 17:54:41,849][root][INFO] - Avg. loss per last 100 batches: 0.019457
[2022-01-11 17:54:41,850][root][INFO] - Train batch 400
[2022-01-11 17:54:41,850][root][INFO] - Avg. loss per last 100 batches: 0.019457
[2022-01-11 17:54:41,851][root][INFO] - Train batch 400
[2022-01-11 17:54:41,851][root][INFO] - Avg. loss per last 100 batches: 0.019457
[2022-01-11 17:54:41,851][root][INFO] - Train batch 400
[2022-01-11 17:54:41,852][root][INFO] - Avg. loss per last 100 batches: 0.019457
[2022-01-11 17:54:42,876][root][INFO] - Epoch: 27: Step: 401/920, loss=0.053625, lr=0.000003
[2022-01-11 17:54:42,876][root][INFO] - Epoch: 27: Step: 401/920, loss=0.053625, lr=0.000003
[2022-01-11 17:54:42,877][root][INFO] - Epoch: 27: Step: 401/920, loss=0.053625, lr=0.000003
[2022-01-11 17:54:42,878][root][INFO] - Epoch: 27: Step: 401/920, loss=0.053625, lr=0.000003
[2022-01-11 17:56:20,910][root][INFO] - Train batch 500
[2022-01-11 17:56:20,910][root][INFO] - Avg. loss per last 100 batches: 0.017253
[2022-01-11 17:56:20,914][root][INFO] - Train batch 500
[2022-01-11 17:56:20,914][root][INFO] - Train batch 500
[2022-01-11 17:56:20,914][root][INFO] - Avg. loss per last 100 batches: 0.017253
[2022-01-11 17:56:20,914][root][INFO] - Avg. loss per last 100 batches: 0.017253
[2022-01-11 17:56:20,914][root][INFO] - Train batch 500
[2022-01-11 17:56:20,914][root][INFO] - Avg. loss per last 100 batches: 0.017253
[2022-01-11 17:56:21,831][root][INFO] - Epoch: 27: Step: 501/920, loss=0.059135, lr=0.000003
[2022-01-11 17:56:21,832][root][INFO] - Epoch: 27: Step: 501/920, loss=0.059135, lr=0.000003
[2022-01-11 17:56:21,833][root][INFO] - Epoch: 27: Step: 501/920, loss=0.059135, lr=0.000003
[2022-01-11 17:56:21,833][root][INFO] - Epoch: 27: Step: 501/920, loss=0.059135, lr=0.000003
[2022-01-11 17:58:00,745][root][INFO] - Train batch 600
[2022-01-11 17:58:00,745][root][INFO] - Avg. loss per last 100 batches: 0.021087
[2022-01-11 17:58:00,745][root][INFO] - Train batch 600
[2022-01-11 17:58:00,746][root][INFO] - Avg. loss per last 100 batches: 0.021087
[2022-01-11 17:58:00,747][root][INFO] - Train batch 600
[2022-01-11 17:58:00,747][root][INFO] - Avg. loss per last 100 batches: 0.021087
[2022-01-11 17:58:00,748][root][INFO] - Train batch 600
[2022-01-11 17:58:00,748][root][INFO] - Avg. loss per last 100 batches: 0.021087
[2022-01-11 17:58:01,797][root][INFO] - Epoch: 27: Step: 601/920, loss=0.024946, lr=0.000003
[2022-01-11 17:58:01,797][root][INFO] - Epoch: 27: Step: 601/920, loss=0.024946, lr=0.000003
[2022-01-11 17:58:01,798][root][INFO] - Epoch: 27: Step: 601/920, loss=0.024946, lr=0.000003
[2022-01-11 17:58:01,800][root][INFO] - Epoch: 27: Step: 601/920, loss=0.024946, lr=0.000003
[2022-01-11 17:59:40,703][root][INFO] - Train batch 700
[2022-01-11 17:59:40,704][root][INFO] - Avg. loss per last 100 batches: 0.016088
[2022-01-11 17:59:40,714][root][INFO] - Train batch 700
[2022-01-11 17:59:40,714][root][INFO] - Avg. loss per last 100 batches: 0.016088
[2022-01-11 17:59:40,714][root][INFO] - Train batch 700
[2022-01-11 17:59:40,715][root][INFO] - Avg. loss per last 100 batches: 0.016088
[2022-01-11 17:59:40,715][root][INFO] - Train batch 700
[2022-01-11 17:59:40,716][root][INFO] - Avg. loss per last 100 batches: 0.016088
[2022-01-11 17:59:41,721][root][INFO] - Epoch: 27: Step: 701/920, loss=0.027255, lr=0.000003
[2022-01-11 17:59:41,721][root][INFO] - Epoch: 27: Step: 701/920, loss=0.027255, lr=0.000003
[2022-01-11 17:59:41,722][root][INFO] - Epoch: 27: Step: 701/920, loss=0.027255, lr=0.000003
[2022-01-11 17:59:41,722][root][INFO] - Epoch: 27: Step: 701/920, loss=0.027255, lr=0.000003
[2022-01-11 18:01:17,582][root][INFO] - Train batch 800
[2022-01-11 18:01:17,582][root][INFO] - Avg. loss per last 100 batches: 0.015261
[2022-01-11 18:01:17,590][root][INFO] - Train batch 800
[2022-01-11 18:01:17,591][root][INFO] - Avg. loss per last 100 batches: 0.015261
[2022-01-11 18:01:17,591][root][INFO] - Train batch 800
[2022-01-11 18:01:17,591][root][INFO] - Train batch 800
[2022-01-11 18:01:17,591][root][INFO] - Avg. loss per last 100 batches: 0.015261
[2022-01-11 18:01:17,591][root][INFO] - Avg. loss per last 100 batches: 0.015261
[2022-01-11 18:01:18,489][root][INFO] - Epoch: 27: Step: 801/920, loss=0.000217, lr=0.000003
[2022-01-11 18:01:18,498][root][INFO] - Epoch: 27: Step: 801/920, loss=0.000217, lr=0.000003
[2022-01-11 18:01:18,498][root][INFO] - Epoch: 27: Step: 801/920, loss=0.000217, lr=0.000003
[2022-01-11 18:01:18,498][root][INFO] - Epoch: 27: Step: 801/920, loss=0.000217, lr=0.000003
[2022-01-11 18:02:58,124][root][INFO] - Train batch 900
[2022-01-11 18:02:58,124][root][INFO] - Avg. loss per last 100 batches: 0.023026
[2022-01-11 18:02:58,133][root][INFO] - Train batch 900
[2022-01-11 18:02:58,133][root][INFO] - Avg. loss per last 100 batches: 0.023026
[2022-01-11 18:02:58,134][root][INFO] - Train batch 900
[2022-01-11 18:02:58,134][root][INFO] - Avg. loss per last 100 batches: 0.023026
[2022-01-11 18:02:58,135][root][INFO] - Train batch 900
[2022-01-11 18:02:58,135][root][INFO] - Avg. loss per last 100 batches: 0.023026
[2022-01-11 18:02:59,000][root][INFO] - Epoch: 27: Step: 901/920, loss=0.039073, lr=0.000003
[2022-01-11 18:02:59,000][root][INFO] - Epoch: 27: Step: 901/920, loss=0.039073, lr=0.000003
[2022-01-11 18:02:59,001][root][INFO] - Epoch: 27: Step: 901/920, loss=0.039073, lr=0.000003
[2022-01-11 18:02:59,001][root][INFO] - Epoch: 27: Step: 901/920, loss=0.039073, lr=0.000003
[2022-01-11 18:03:17,326][root][INFO] - rank=2, Validation: Epoch: 27 Step: 920/920
[2022-01-11 18:03:17,327][root][INFO] - NLL validation ...
[2022-01-11 18:03:17,328][root][INFO] - rank=2; Iteration start
[2022-01-11 18:03:17,328][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:03:17,328][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:03:17,328][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 18:03:17,335][root][INFO] - rank=0, Validation: Epoch: 27 Step: 920/920
[2022-01-11 18:03:17,335][root][INFO] - NLL validation ...
[2022-01-11 18:03:17,337][root][INFO] - rank=0; Iteration start
[2022-01-11 18:03:17,337][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:03:17,337][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:03:17,337][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 18:03:17,337][root][INFO] - rank=1, Validation: Epoch: 27 Step: 920/920
[2022-01-11 18:03:17,337][root][INFO] - NLL validation ...
[2022-01-11 18:03:17,337][root][INFO] - rank=3, Validation: Epoch: 27 Step: 920/920
[2022-01-11 18:03:17,337][root][INFO] - NLL validation ...
[2022-01-11 18:03:17,338][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 18:03:17,338][root][INFO] - rank=1; Iteration start
[2022-01-11 18:03:17,338][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:03:17,338][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:03:17,338][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 18:03:17,339][root][INFO] - rank=3; Iteration start
[2022-01-11 18:03:17,339][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:03:17,339][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:03:17,339][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 18:03:17,347][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 18:03:17,348][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 18:03:17,349][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 18:03:18,084][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 18:03:18,084][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 18:03:18,085][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 18:03:19,066][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 18:03:19,797][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 18:03:19,797][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 18:03:19,798][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 18:03:19,798][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 18:03:20,532][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 18:03:20,532][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 18:03:20,532][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 18:03:20,533][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 18:03:21,269][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 18:03:21,269][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 18:03:21,269][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 18:03:21,269][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 18:03:22,010][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 18:03:22,777][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 18:03:22,993][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 18:03:22,995][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 18:03:23,730][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 18:03:23,731][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 18:03:23,732][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 18:03:23,732][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 18:03:24,465][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 18:03:24,465][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 18:03:24,465][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 18:03:24,466][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 18:03:25,202][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 18:03:25,202][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 18:03:25,202][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 18:03:25,203][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 18:03:25,942][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 18:03:25,943][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 18:03:25,943][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 18:03:25,943][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 18:03:26,681][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 18:03:26,681][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 18:03:26,682][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 18:03:26,682][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 18:03:27,420][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 18:03:27,420][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 18:03:27,420][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 18:03:27,420][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 18:03:28,155][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 18:03:28,156][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 18:03:28,156][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 18:03:28,156][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 18:03:28,897][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 18:03:28,898][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 18:03:28,898][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 18:03:28,898][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 18:03:29,635][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 18:03:29,635][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 18:03:29,636][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 18:03:29,636][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 18:03:30,372][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 18:03:30,372][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 18:03:30,372][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 18:03:30,970][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 18:03:31,702][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 18:03:31,702][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 18:03:31,702][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 18:03:31,702][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 18:03:32,442][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 18:03:32,442][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 18:03:32,442][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 18:03:32,442][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 18:03:33,178][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 18:03:33,178][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 18:03:33,178][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 18:03:33,178][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 18:03:33,917][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 18:03:34,518][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 18:03:34,529][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 18:03:34,535][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 18:03:35,266][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 18:03:35,266][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 18:03:35,267][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 18:03:35,268][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 18:03:36,003][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 18:03:36,003][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 18:03:36,003][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 18:03:36,004][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 18:03:36,746][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 18:03:36,747][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 18:03:36,748][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 18:03:36,748][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 18:03:37,486][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 18:03:37,487][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 18:03:37,487][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 18:03:37,488][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 18:03:38,222][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 18:03:38,222][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 18:03:38,222][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 18:03:38,223][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 18:03:38,950][root][INFO] - rank=0; last iteration 25
[2022-01-11 18:03:38,950][root][INFO] - rank=2; last iteration 25
[2022-01-11 18:03:38,950][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:03:38,950][root][INFO] - rank=3; last iteration 25
[2022-01-11 18:03:38,950][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 18:03:38,950][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:03:38,950][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 18:03:38,950][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:03:38,950][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:03:38,950][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 18:03:38,950][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:03:38,950][root][INFO] - rank=1; last iteration 25
[2022-01-11 18:03:38,950][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:03:38,950][root][INFO] - NLL Validation: loss = 0.396577. correct prediction ratio  5733/6400 ~  0.895781
[2022-01-11 18:03:38,950][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:03:38,950][root][INFO] - NLL Validation: loss = 0.396577. correct prediction ratio  5733/6400 ~  0.895781
[2022-01-11 18:03:38,950][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 18:03:38,950][root][INFO] - NLL Validation: loss = 0.396577. correct prediction ratio  5733/6400 ~  0.895781
[2022-01-11 18:03:38,951][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:03:38,951][root][INFO] - NLL Validation: loss = 0.396577. correct prediction ratio  5733/6400 ~  0.895781
[2022-01-11 18:03:38,953][root][INFO] - rank=3; last iteration 920
[2022-01-11 18:03:38,953][root][INFO] - rank=2; last iteration 920
[2022-01-11 18:03:38,953][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:03:38,953][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:03:38,953][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 18:03:38,953][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 18:03:38,953][root][INFO] - rank=1; last iteration 920
[2022-01-11 18:03:38,953][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:03:38,953][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 18:03:38,953][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:03:38,953][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:03:38,953][root][INFO] - Epoch finished on 3
[2022-01-11 18:03:38,953][root][INFO] - Epoch finished on 2
[2022-01-11 18:03:38,954][root][INFO] - NLL validation ...
[2022-01-11 18:03:38,954][root][INFO] - NLL validation ...
[2022-01-11 18:03:38,954][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:03:38,954][root][INFO] - Epoch finished on 1
[2022-01-11 18:03:38,954][root][INFO] - NLL validation ...
[2022-01-11 18:03:38,955][root][INFO] - rank=3; Iteration start
[2022-01-11 18:03:38,955][root][INFO] - rank=2; Iteration start
[2022-01-11 18:03:38,955][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:03:38,955][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:03:38,955][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:03:38,955][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:03:38,955][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 18:03:38,955][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 18:03:38,956][root][INFO] - rank=1; Iteration start
[2022-01-11 18:03:38,956][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:03:38,956][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:03:38,956][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 18:03:38,962][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 18:03:38,962][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 18:03:38,965][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 18:03:42,861][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.27
[2022-01-11 18:03:42,861][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.27
[2022-01-11 18:03:42,863][root][INFO] - rank=0; last iteration 920
[2022-01-11 18:03:42,863][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:03:42,863][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 18:03:42,863][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:03:42,863][root][INFO] - Epoch finished on 0
[2022-01-11 18:03:42,863][root][INFO] - NLL validation ...
[2022-01-11 18:03:42,865][root][INFO] - rank=0; Iteration start
[2022-01-11 18:03:42,865][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:03:42,865][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:03:42,865][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 18:03:42,872][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 18:03:43,618][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 18:03:43,618][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 18:03:43,619][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 18:03:43,620][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 18:03:44,353][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 18:03:44,354][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 18:03:44,354][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 18:03:44,355][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 18:03:45,086][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 18:03:45,087][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 18:03:45,088][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 18:03:45,710][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 18:03:46,444][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 18:03:46,445][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 18:03:46,446][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 18:03:46,447][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 18:03:47,183][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 18:03:47,183][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 18:03:47,183][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 18:03:47,185][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 18:03:47,920][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 18:03:47,922][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 18:03:47,923][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 18:03:47,923][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 18:03:48,659][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 18:03:48,660][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 18:03:48,661][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 18:03:48,663][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 18:03:49,409][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 18:03:50,014][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 18:03:50,056][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 18:03:50,302][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 18:03:51,030][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 18:03:51,031][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 18:03:51,032][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 18:03:51,034][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 18:03:51,769][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 18:03:51,771][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 18:03:51,771][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 18:03:51,772][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 18:03:52,507][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 18:03:52,509][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 18:03:52,509][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 18:03:52,510][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 18:03:53,251][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 18:03:53,255][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 18:03:53,255][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 18:03:53,256][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 18:03:53,994][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 18:03:53,995][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 18:03:53,996][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 18:03:53,996][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 18:03:54,731][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 18:03:54,733][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 18:03:54,733][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 18:03:54,734][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 18:03:55,468][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 18:03:55,470][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 18:03:55,470][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 18:03:55,470][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 18:03:56,208][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 18:03:56,212][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 18:03:56,212][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 18:03:56,212][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 18:03:56,949][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 18:03:56,951][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 18:03:56,951][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 18:03:57,710][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 18:03:58,444][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 18:03:58,445][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 18:03:58,445][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 18:03:58,447][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 18:03:59,185][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 18:03:59,186][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 18:03:59,186][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 18:03:59,187][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 18:03:59,924][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 18:03:59,925][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 18:03:59,925][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 18:03:59,926][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 18:04:00,661][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 18:04:00,662][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 18:04:00,664][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 18:04:00,665][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 18:04:01,402][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 18:04:02,060][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 18:04:02,115][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 18:04:02,278][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 18:04:03,016][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 18:04:03,017][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 18:04:03,019][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 18:04:03,019][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 18:04:03,754][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 18:04:03,756][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 18:04:03,757][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 18:04:03,757][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 18:04:04,486][root][INFO] - rank=3; last iteration 25
[2022-01-11 18:04:04,486][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:04:04,486][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 18:04:04,486][root][INFO] - rank=1; last iteration 25
[2022-01-11 18:04:04,486][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:04:04,486][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:04:04,486][root][INFO] - NLL Validation: loss = 0.396577. correct prediction ratio  5733/6400 ~  0.895781
[2022-01-11 18:04:04,486][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 18:04:04,486][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:04:04,486][root][INFO] - NLL Validation: loss = 0.396577. correct prediction ratio  5733/6400 ~  0.895781
[2022-01-11 18:04:04,486][root][INFO] - rank=0; last iteration 25
[2022-01-11 18:04:04,486][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:04:04,486][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 18:04:04,486][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:04:04,487][root][INFO] - NLL Validation: loss = 0.396577. correct prediction ratio  5733/6400 ~  0.895781
[2022-01-11 18:04:04,487][root][INFO] - Av Loss per epoch=0.019030
[2022-01-11 18:04:04,487][root][INFO] - epoch total correct predictions=58455
[2022-01-11 18:04:04,487][root][INFO] - Av Loss per epoch=0.019030
[2022-01-11 18:04:04,488][root][INFO] - epoch total correct predictions=58455
[2022-01-11 18:04:04,488][root][INFO] - rank=2; last iteration 25
[2022-01-11 18:04:04,488][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:04:04,489][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 18:04:04,489][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:04:04,489][root][INFO] - NLL Validation: loss = 0.396577. correct prediction ratio  5733/6400 ~  0.895781
[2022-01-11 18:04:04,489][root][INFO] - ***** Epoch 28 *****
[2022-01-11 18:04:04,489][root][INFO] - ***** Epoch 28 *****
[2022-01-11 18:04:04,490][root][INFO] - Av Loss per epoch=0.019030
[2022-01-11 18:04:04,490][root][INFO] - epoch total correct predictions=58455
[2022-01-11 18:04:04,491][root][INFO] - rank=3; Iteration start
[2022-01-11 18:04:04,491][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:04:04,491][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:04:04,491][root][INFO] - rank=1; Iteration start
[2022-01-11 18:04:04,491][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:04:04,491][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:04:04,491][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 18:04:04,491][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 18:04:04,492][root][INFO] - ***** Epoch 28 *****
[2022-01-11 18:04:04,494][root][INFO] - rank=2; Iteration start
[2022-01-11 18:04:04,494][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:04:04,494][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:04:04,494][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 18:04:09,604][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.27
[2022-01-11 18:04:09,605][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.27
[2022-01-11 18:04:09,605][root][INFO] - Av Loss per epoch=0.019030
[2022-01-11 18:04:09,605][root][INFO] - epoch total correct predictions=58455
[2022-01-11 18:04:09,607][root][INFO] - ***** Epoch 28 *****
[2022-01-11 18:04:09,610][root][INFO] - rank=0; Iteration start
[2022-01-11 18:04:09,610][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:04:09,610][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:04:09,610][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 18:04:10,529][root][INFO] - Epoch: 28: Step: 1/920, loss=0.006196, lr=0.000003
[2022-01-11 18:04:10,537][root][INFO] - Epoch: 28: Step: 1/920, loss=0.006196, lr=0.000003
[2022-01-11 18:04:10,537][root][INFO] - Epoch: 28: Step: 1/920, loss=0.006196, lr=0.000003
[2022-01-11 18:04:10,537][root][INFO] - Epoch: 28: Step: 1/920, loss=0.006196, lr=0.000003
[2022-01-11 18:05:46,271][root][INFO] - Train batch 100
[2022-01-11 18:05:46,271][root][INFO] - Avg. loss per last 100 batches: 0.019847
[2022-01-11 18:05:46,272][root][INFO] - Train batch 100
[2022-01-11 18:05:46,272][root][INFO] - Avg. loss per last 100 batches: 0.019847
[2022-01-11 18:05:46,272][root][INFO] - Train batch 100
[2022-01-11 18:05:46,272][root][INFO] - Avg. loss per last 100 batches: 0.019847
[2022-01-11 18:05:46,273][root][INFO] - Train batch 100
[2022-01-11 18:05:46,274][root][INFO] - Avg. loss per last 100 batches: 0.019847
[2022-01-11 18:05:47,130][root][INFO] - Epoch: 28: Step: 101/920, loss=0.002921, lr=0.000003
[2022-01-11 18:05:47,131][root][INFO] - Epoch: 28: Step: 101/920, loss=0.002921, lr=0.000003
[2022-01-11 18:05:47,131][root][INFO] - Epoch: 28: Step: 101/920, loss=0.002921, lr=0.000003
[2022-01-11 18:05:47,132][root][INFO] - Epoch: 28: Step: 101/920, loss=0.002921, lr=0.000003
[2022-01-11 18:07:24,484][root][INFO] - Train batch 200
[2022-01-11 18:07:24,485][root][INFO] - Avg. loss per last 100 batches: 0.020350
[2022-01-11 18:07:24,490][root][INFO] - Train batch 200
[2022-01-11 18:07:24,490][root][INFO] - Avg. loss per last 100 batches: 0.020350
[2022-01-11 18:07:24,494][root][INFO] - Train batch 200
[2022-01-11 18:07:24,494][root][INFO] - Avg. loss per last 100 batches: 0.020350
[2022-01-11 18:07:24,494][root][INFO] - Train batch 200
[2022-01-11 18:07:24,494][root][INFO] - Avg. loss per last 100 batches: 0.020350
[2022-01-11 18:07:25,375][root][INFO] - Epoch: 28: Step: 201/920, loss=0.050807, lr=0.000003
[2022-01-11 18:07:25,379][root][INFO] - Epoch: 28: Step: 201/920, loss=0.050807, lr=0.000003
[2022-01-11 18:07:25,380][root][INFO] - Epoch: 28: Step: 201/920, loss=0.050807, lr=0.000003
[2022-01-11 18:07:25,380][root][INFO] - Epoch: 28: Step: 201/920, loss=0.050807, lr=0.000003
[2022-01-11 18:09:04,713][root][INFO] - Train batch 300
[2022-01-11 18:09:04,713][root][INFO] - Avg. loss per last 100 batches: 0.024615
[2022-01-11 18:09:04,716][root][INFO] - Train batch 300
[2022-01-11 18:09:04,716][root][INFO] - Avg. loss per last 100 batches: 0.024615
[2022-01-11 18:09:04,719][root][INFO] - Train batch 300
[2022-01-11 18:09:04,720][root][INFO] - Avg. loss per last 100 batches: 0.024615
[2022-01-11 18:09:04,724][root][INFO] - Train batch 300
[2022-01-11 18:09:04,724][root][INFO] - Avg. loss per last 100 batches: 0.024615
[2022-01-11 18:09:05,617][root][INFO] - Epoch: 28: Step: 301/920, loss=0.014022, lr=0.000003
[2022-01-11 18:09:05,618][root][INFO] - Epoch: 28: Step: 301/920, loss=0.014022, lr=0.000003
[2022-01-11 18:09:05,619][root][INFO] - Epoch: 28: Step: 301/920, loss=0.014022, lr=0.000003
[2022-01-11 18:09:05,619][root][INFO] - Epoch: 28: Step: 301/920, loss=0.014022, lr=0.000003
[2022-01-11 18:10:42,126][root][INFO] - Train batch 400
[2022-01-11 18:10:42,126][root][INFO] - Avg. loss per last 100 batches: 0.019960
[2022-01-11 18:10:42,126][root][INFO] - Train batch 400
[2022-01-11 18:10:42,126][root][INFO] - Avg. loss per last 100 batches: 0.019960
[2022-01-11 18:10:42,127][root][INFO] - Train batch 400
[2022-01-11 18:10:42,127][root][INFO] - Avg. loss per last 100 batches: 0.019960
[2022-01-11 18:10:42,127][root][INFO] - Train batch 400
[2022-01-11 18:10:42,127][root][INFO] - Avg. loss per last 100 batches: 0.019960
[2022-01-11 18:10:43,169][root][INFO] - Epoch: 28: Step: 401/920, loss=0.007464, lr=0.000003
[2022-01-11 18:10:43,170][root][INFO] - Epoch: 28: Step: 401/920, loss=0.007464, lr=0.000003
[2022-01-11 18:10:43,170][root][INFO] - Epoch: 28: Step: 401/920, loss=0.007464, lr=0.000003
[2022-01-11 18:10:43,170][root][INFO] - Epoch: 28: Step: 401/920, loss=0.007464, lr=0.000003
[2022-01-11 18:12:21,641][root][INFO] - Train batch 500
[2022-01-11 18:12:21,641][root][INFO] - Avg. loss per last 100 batches: 0.018757
[2022-01-11 18:12:21,642][root][INFO] - Train batch 500
[2022-01-11 18:12:21,643][root][INFO] - Avg. loss per last 100 batches: 0.018757
[2022-01-11 18:12:21,644][root][INFO] - Train batch 500
[2022-01-11 18:12:21,644][root][INFO] - Avg. loss per last 100 batches: 0.018757
[2022-01-11 18:12:21,645][root][INFO] - Train batch 500
[2022-01-11 18:12:21,645][root][INFO] - Avg. loss per last 100 batches: 0.018757
[2022-01-11 18:12:22,503][root][INFO] - Epoch: 28: Step: 501/920, loss=0.009681, lr=0.000003
[2022-01-11 18:12:22,504][root][INFO] - Epoch: 28: Step: 501/920, loss=0.009681, lr=0.000003
[2022-01-11 18:12:22,504][root][INFO] - Epoch: 28: Step: 501/920, loss=0.009681, lr=0.000003
[2022-01-11 18:12:22,504][root][INFO] - Epoch: 28: Step: 501/920, loss=0.009681, lr=0.000003
[2022-01-11 18:14:01,278][root][INFO] - Train batch 600
[2022-01-11 18:14:01,278][root][INFO] - Avg. loss per last 100 batches: 0.020028
[2022-01-11 18:14:01,279][root][INFO] - Train batch 600
[2022-01-11 18:14:01,279][root][INFO] - Avg. loss per last 100 batches: 0.020028
[2022-01-11 18:14:01,279][root][INFO] - Train batch 600
[2022-01-11 18:14:01,279][root][INFO] - Avg. loss per last 100 batches: 0.020028
[2022-01-11 18:14:01,279][root][INFO] - Train batch 600
[2022-01-11 18:14:01,280][root][INFO] - Avg. loss per last 100 batches: 0.020028
[2022-01-11 18:14:02,332][root][INFO] - Epoch: 28: Step: 601/920, loss=0.007859, lr=0.000003
[2022-01-11 18:14:02,332][root][INFO] - Epoch: 28: Step: 601/920, loss=0.007859, lr=0.000003
[2022-01-11 18:14:02,332][root][INFO] - Epoch: 28: Step: 601/920, loss=0.007859, lr=0.000003
[2022-01-11 18:14:02,333][root][INFO] - Epoch: 28: Step: 601/920, loss=0.007859, lr=0.000003
[2022-01-11 18:15:39,246][root][INFO] - Train batch 700
[2022-01-11 18:15:39,246][root][INFO] - Avg. loss per last 100 batches: 0.020863
[2022-01-11 18:15:39,247][root][INFO] - Train batch 700
[2022-01-11 18:15:39,247][root][INFO] - Avg. loss per last 100 batches: 0.020863
[2022-01-11 18:15:39,247][root][INFO] - Train batch 700
[2022-01-11 18:15:39,247][root][INFO] - Avg. loss per last 100 batches: 0.020863
[2022-01-11 18:15:39,247][root][INFO] - Train batch 700
[2022-01-11 18:15:39,248][root][INFO] - Avg. loss per last 100 batches: 0.020863
[2022-01-11 18:15:40,298][root][INFO] - Epoch: 28: Step: 701/920, loss=0.002487, lr=0.000003
[2022-01-11 18:15:40,298][root][INFO] - Epoch: 28: Step: 701/920, loss=0.002487, lr=0.000003
[2022-01-11 18:15:40,299][root][INFO] - Epoch: 28: Step: 701/920, loss=0.002487, lr=0.000003
[2022-01-11 18:15:40,299][root][INFO] - Epoch: 28: Step: 701/920, loss=0.002487, lr=0.000003
[2022-01-11 18:17:18,790][root][INFO] - Train batch 800
[2022-01-11 18:17:18,790][root][INFO] - Avg. loss per last 100 batches: 0.021336
[2022-01-11 18:17:18,790][root][INFO] - Train batch 800
[2022-01-11 18:17:18,791][root][INFO] - Avg. loss per last 100 batches: 0.021336
[2022-01-11 18:17:18,791][root][INFO] - Train batch 800
[2022-01-11 18:17:18,791][root][INFO] - Avg. loss per last 100 batches: 0.021336
[2022-01-11 18:17:18,792][root][INFO] - Train batch 800
[2022-01-11 18:17:18,792][root][INFO] - Avg. loss per last 100 batches: 0.021336
[2022-01-11 18:17:19,683][root][INFO] - Epoch: 28: Step: 801/920, loss=0.030941, lr=0.000003
[2022-01-11 18:17:19,683][root][INFO] - Epoch: 28: Step: 801/920, loss=0.030941, lr=0.000003
[2022-01-11 18:17:19,684][root][INFO] - Epoch: 28: Step: 801/920, loss=0.030941, lr=0.000003
[2022-01-11 18:17:19,684][root][INFO] - Epoch: 28: Step: 801/920, loss=0.030941, lr=0.000003
[2022-01-11 18:18:58,445][root][INFO] - Train batch 900
[2022-01-11 18:18:58,445][root][INFO] - Avg. loss per last 100 batches: 0.021362
[2022-01-11 18:18:58,448][root][INFO] - Train batch 900
[2022-01-11 18:18:58,448][root][INFO] - Avg. loss per last 100 batches: 0.021362
[2022-01-11 18:18:58,448][root][INFO] - Train batch 900
[2022-01-11 18:18:58,448][root][INFO] - Avg. loss per last 100 batches: 0.021362
[2022-01-11 18:18:58,448][root][INFO] - Train batch 900
[2022-01-11 18:18:58,449][root][INFO] - Avg. loss per last 100 batches: 0.021362
[2022-01-11 18:18:59,498][root][INFO] - Epoch: 28: Step: 901/920, loss=0.003628, lr=0.000003
[2022-01-11 18:18:59,499][root][INFO] - Epoch: 28: Step: 901/920, loss=0.003628, lr=0.000003
[2022-01-11 18:18:59,499][root][INFO] - Epoch: 28: Step: 901/920, loss=0.003628, lr=0.000003
[2022-01-11 18:18:59,500][root][INFO] - Epoch: 28: Step: 901/920, loss=0.003628, lr=0.000003
[2022-01-11 18:19:18,305][root][INFO] - rank=3, Validation: Epoch: 28 Step: 920/920
[2022-01-11 18:19:18,305][root][INFO] - NLL validation ...
[2022-01-11 18:19:18,306][root][INFO] - rank=0, Validation: Epoch: 28 Step: 920/920
[2022-01-11 18:19:18,306][root][INFO] - NLL validation ...
[2022-01-11 18:19:18,306][root][INFO] - rank=1, Validation: Epoch: 28 Step: 920/920
[2022-01-11 18:19:18,307][root][INFO] - NLL validation ...
[2022-01-11 18:19:18,307][root][INFO] - rank=3; Iteration start
[2022-01-11 18:19:18,307][root][INFO] - rank=2, Validation: Epoch: 28 Step: 920/920
[2022-01-11 18:19:18,307][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:19:18,307][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:19:18,307][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 18:19:18,307][root][INFO] - NLL validation ...
[2022-01-11 18:19:18,308][root][INFO] - rank=0; Iteration start
[2022-01-11 18:19:18,308][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:19:18,308][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:19:18,308][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 18:19:18,308][root][INFO] - rank=1; Iteration start
[2022-01-11 18:19:18,308][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:19:18,308][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:19:18,308][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 18:19:18,308][root][INFO] - rank=2; Iteration start
[2022-01-11 18:19:18,308][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:19:18,308][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:19:18,308][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 18:19:18,317][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 18:19:18,318][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 18:19:18,318][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 18:19:18,318][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 18:19:19,057][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 18:19:20,036][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 18:19:20,037][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 18:19:20,049][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 18:19:20,785][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 18:19:20,785][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 18:19:20,785][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 18:19:20,786][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 18:19:21,521][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 18:19:21,522][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 18:19:21,522][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 18:19:21,522][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 18:19:22,258][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 18:19:22,258][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 18:19:22,258][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 18:19:22,259][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 18:19:22,997][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 18:19:22,998][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 18:19:22,998][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 18:19:22,998][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 18:19:23,735][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 18:19:23,735][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 18:19:23,735][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 18:19:23,735][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 18:19:24,472][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 18:19:24,472][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 18:19:24,472][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 18:19:24,472][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 18:19:25,212][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 18:19:25,213][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 18:19:25,213][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 18:19:25,213][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 18:19:25,949][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 18:19:25,950][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 18:19:25,950][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 18:19:26,575][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 18:19:27,306][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 18:19:27,307][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 18:19:27,307][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 18:19:27,307][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 18:19:28,045][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 18:19:28,046][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 18:19:28,046][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 18:19:28,046][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 18:19:28,783][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 18:19:28,783][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 18:19:28,783][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 18:19:28,783][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 18:19:29,520][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 18:19:29,520][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 18:19:29,520][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 18:19:29,521][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 18:19:30,257][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 18:19:30,257][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 18:19:30,258][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 18:19:30,258][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 18:19:30,997][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 18:19:31,602][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 18:19:31,608][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 18:19:31,634][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 18:19:32,370][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 18:19:32,370][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 18:19:32,370][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 18:19:32,372][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 18:19:33,108][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 18:19:33,108][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 18:19:33,108][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 18:19:33,110][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 18:19:33,850][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 18:19:33,852][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 18:19:33,852][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 18:19:33,852][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 18:19:34,591][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 18:19:34,591][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 18:19:34,592][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 18:19:34,592][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 18:19:35,328][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 18:19:35,329][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 18:19:35,329][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 18:19:35,330][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 18:19:36,065][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 18:19:36,065][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 18:19:36,065][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 18:19:36,065][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 18:19:36,806][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 18:19:36,808][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 18:19:36,809][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 18:19:36,809][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 18:19:37,545][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 18:19:37,545][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 18:19:37,545][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 18:19:38,242][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 18:19:38,977][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 18:19:38,977][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 18:19:38,978][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 18:19:38,979][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 18:19:39,704][root][INFO] - rank=2; last iteration 25
[2022-01-11 18:19:39,705][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:19:39,705][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 18:19:39,705][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:19:39,705][root][INFO] - NLL Validation: loss = 0.401157. correct prediction ratio  5746/6400 ~  0.897813
[2022-01-11 18:19:39,705][root][INFO] - rank=3; last iteration 25
[2022-01-11 18:19:39,705][root][INFO] - rank=1; last iteration 25
[2022-01-11 18:19:39,705][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:19:39,705][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:19:39,705][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 18:19:39,705][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 18:19:39,705][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:19:39,705][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:19:39,705][root][INFO] - NLL Validation: loss = 0.401157. correct prediction ratio  5746/6400 ~  0.897813
[2022-01-11 18:19:39,705][root][INFO] - NLL Validation: loss = 0.401157. correct prediction ratio  5746/6400 ~  0.897813
[2022-01-11 18:19:39,706][root][INFO] - rank=0; last iteration 25
[2022-01-11 18:19:39,706][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:19:39,706][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 18:19:39,706][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:19:39,706][root][INFO] - NLL Validation: loss = 0.401157. correct prediction ratio  5746/6400 ~  0.897813
[2022-01-11 18:19:39,707][root][INFO] - rank=2; last iteration 920
[2022-01-11 18:19:39,707][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:19:39,707][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 18:19:39,708][root][INFO] - rank=3; last iteration 920
[2022-01-11 18:19:39,708][root][INFO] - rank=1; last iteration 920
[2022-01-11 18:19:39,708][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:19:39,708][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:19:39,708][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 18:19:39,708][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 18:19:39,708][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:19:39,708][root][INFO] - Epoch finished on 2
[2022-01-11 18:19:39,708][root][INFO] - NLL validation ...
[2022-01-11 18:19:39,708][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:19:39,708][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:19:39,708][root][INFO] - Epoch finished on 3
[2022-01-11 18:19:39,708][root][INFO] - Epoch finished on 1
[2022-01-11 18:19:39,708][root][INFO] - NLL validation ...
[2022-01-11 18:19:39,708][root][INFO] - NLL validation ...
[2022-01-11 18:19:39,709][root][INFO] - rank=2; Iteration start
[2022-01-11 18:19:39,709][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:19:39,709][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:19:39,709][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 18:19:39,710][root][INFO] - rank=3; Iteration start
[2022-01-11 18:19:39,710][root][INFO] - rank=1; Iteration start
[2022-01-11 18:19:39,710][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:19:39,710][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:19:39,710][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:19:39,710][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:19:39,710][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 18:19:39,710][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 18:19:39,717][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 18:19:39,717][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 18:19:39,719][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 18:19:43,750][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.28
[2022-01-11 18:19:43,750][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.28
[2022-01-11 18:19:43,751][root][INFO] - rank=0; last iteration 920
[2022-01-11 18:19:43,751][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:19:43,751][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 18:19:43,752][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:19:43,752][root][INFO] - Epoch finished on 0
[2022-01-11 18:19:43,752][root][INFO] - NLL validation ...
[2022-01-11 18:19:43,753][root][INFO] - rank=0; Iteration start
[2022-01-11 18:19:43,753][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:19:43,753][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:19:43,753][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 18:19:43,762][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 18:19:44,508][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 18:19:44,508][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 18:19:44,509][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 18:19:44,509][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 18:19:45,243][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 18:19:45,243][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 18:19:45,244][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 18:19:45,245][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 18:19:45,983][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 18:19:46,606][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 18:19:46,611][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 18:19:46,887][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 18:19:47,618][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 18:19:47,618][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 18:19:47,619][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 18:19:47,619][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 18:19:48,354][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 18:19:48,354][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 18:19:48,356][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 18:19:48,356][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 18:19:49,091][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 18:19:49,091][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 18:19:49,093][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 18:19:49,093][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 18:19:49,830][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 18:19:49,831][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 18:19:49,833][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 18:19:49,833][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 18:19:50,567][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 18:19:50,568][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 18:19:50,569][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 18:19:50,569][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 18:19:51,305][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 18:19:51,305][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 18:19:51,305][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 18:19:51,305][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 18:19:52,043][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 18:19:52,046][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 18:19:52,046][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 18:19:52,049][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 18:19:52,782][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 18:19:52,784][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 18:19:52,784][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 18:19:53,625][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 18:19:54,355][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 18:19:54,355][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 18:19:54,356][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 18:19:54,358][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 18:19:55,091][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 18:19:55,092][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 18:19:55,093][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 18:19:55,094][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 18:19:55,828][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 18:19:55,829][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 18:19:55,831][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 18:19:55,831][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 18:19:56,564][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 18:19:56,564][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 18:19:56,564][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 18:19:56,566][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 18:19:57,299][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 18:19:57,300][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 18:19:57,301][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 18:19:57,302][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 18:19:58,036][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 18:19:58,632][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 18:19:58,647][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 18:19:58,760][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 18:19:59,487][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 18:19:59,488][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 18:19:59,488][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 18:19:59,490][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 18:20:00,222][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 18:20:00,223][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 18:20:00,223][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 18:20:00,224][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 18:20:00,957][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 18:20:00,957][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 18:20:00,959][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 18:20:00,963][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 18:20:01,702][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 18:20:01,703][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 18:20:01,704][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 18:20:01,704][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 18:20:02,445][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 18:20:02,445][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 18:20:02,446][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 18:20:02,446][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 18:20:03,182][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 18:20:03,182][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 18:20:03,183][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 18:20:03,186][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 18:20:03,920][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 18:20:03,921][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 18:20:03,922][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 18:20:03,922][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 18:20:04,647][root][INFO] - rank=3; last iteration 25
[2022-01-11 18:20:04,648][root][INFO] - rank=1; last iteration 25
[2022-01-11 18:20:04,648][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:20:04,648][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 18:20:04,648][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:20:04,648][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 18:20:04,648][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:20:04,648][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:20:04,648][root][INFO] - rank=2; last iteration 25
[2022-01-11 18:20:04,648][root][INFO] - NLL Validation: loss = 0.401157. correct prediction ratio  5746/6400 ~  0.897813
[2022-01-11 18:20:04,648][root][INFO] - NLL Validation: loss = 0.401157. correct prediction ratio  5746/6400 ~  0.897813
[2022-01-11 18:20:04,648][root][INFO] - rank=0; last iteration 25
[2022-01-11 18:20:04,648][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:20:04,648][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 18:20:04,648][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:20:04,648][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 18:20:04,648][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:20:04,648][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:20:04,648][root][INFO] - NLL Validation: loss = 0.401157. correct prediction ratio  5746/6400 ~  0.897813
[2022-01-11 18:20:04,648][root][INFO] - NLL Validation: loss = 0.401157. correct prediction ratio  5746/6400 ~  0.897813
[2022-01-11 18:20:04,649][root][INFO] - Av Loss per epoch=0.020849
[2022-01-11 18:20:04,649][root][INFO] - epoch total correct predictions=58388
[2022-01-11 18:20:04,649][root][INFO] - Av Loss per epoch=0.020849
[2022-01-11 18:20:04,649][root][INFO] - epoch total correct predictions=58388
[2022-01-11 18:20:04,649][root][INFO] - Av Loss per epoch=0.020849
[2022-01-11 18:20:04,649][root][INFO] - epoch total correct predictions=58388
[2022-01-11 18:20:04,651][root][INFO] - ***** Epoch 29 *****
[2022-01-11 18:20:04,651][root][INFO] - ***** Epoch 29 *****
[2022-01-11 18:20:04,651][root][INFO] - ***** Epoch 29 *****
[2022-01-11 18:20:04,653][root][INFO] - rank=3; Iteration start
[2022-01-11 18:20:04,653][root][INFO] - rank=1; Iteration start
[2022-01-11 18:20:04,653][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:20:04,653][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:20:04,653][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:20:04,653][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:20:04,653][root][INFO] - rank=2; Iteration start
[2022-01-11 18:20:04,653][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:20:04,653][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:20:04,653][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 18:20:04,653][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 18:20:04,653][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 18:20:09,774][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.28
[2022-01-11 18:20:09,775][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.28
[2022-01-11 18:20:09,775][root][INFO] - Av Loss per epoch=0.020849
[2022-01-11 18:20:09,775][root][INFO] - epoch total correct predictions=58388
[2022-01-11 18:20:09,777][root][INFO] - ***** Epoch 29 *****
[2022-01-11 18:20:09,778][root][INFO] - rank=0; Iteration start
[2022-01-11 18:20:09,779][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:20:09,779][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:20:09,779][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 18:20:10,662][root][INFO] - Epoch: 29: Step: 1/920, loss=0.000291, lr=0.000003
[2022-01-11 18:20:10,663][root][INFO] - Epoch: 29: Step: 1/920, loss=0.000291, lr=0.000003
[2022-01-11 18:20:10,665][root][INFO] - Epoch: 29: Step: 1/920, loss=0.000291, lr=0.000003
[2022-01-11 18:20:10,665][root][INFO] - Epoch: 29: Step: 1/920, loss=0.000291, lr=0.000003
[2022-01-11 18:21:47,565][root][INFO] - Train batch 100
[2022-01-11 18:21:47,566][root][INFO] - Avg. loss per last 100 batches: 0.023504
[2022-01-11 18:21:47,579][root][INFO] - Train batch 100
[2022-01-11 18:21:47,579][root][INFO] - Avg. loss per last 100 batches: 0.023504
[2022-01-11 18:21:47,580][root][INFO] - Train batch 100
[2022-01-11 18:21:47,580][root][INFO] - Avg. loss per last 100 batches: 0.023504
[2022-01-11 18:21:47,580][root][INFO] - Train batch 100
[2022-01-11 18:21:47,580][root][INFO] - Avg. loss per last 100 batches: 0.023504
[2022-01-11 18:21:48,623][root][INFO] - Epoch: 29: Step: 101/920, loss=0.012139, lr=0.000003
[2022-01-11 18:21:48,624][root][INFO] - Epoch: 29: Step: 101/920, loss=0.012139, lr=0.000003
[2022-01-11 18:21:48,625][root][INFO] - Epoch: 29: Step: 101/920, loss=0.012139, lr=0.000003
[2022-01-11 18:21:48,625][root][INFO] - Epoch: 29: Step: 101/920, loss=0.012139, lr=0.000003
[2022-01-11 18:23:27,972][root][INFO] - Train batch 200
[2022-01-11 18:23:27,972][root][INFO] - Train batch 200
[2022-01-11 18:23:27,972][root][INFO] - Avg. loss per last 100 batches: 0.018264
[2022-01-11 18:23:27,972][root][INFO] - Avg. loss per last 100 batches: 0.018264
[2022-01-11 18:23:27,972][root][INFO] - Train batch 200
[2022-01-11 18:23:27,972][root][INFO] - Avg. loss per last 100 batches: 0.018264
[2022-01-11 18:23:27,972][root][INFO] - Train batch 200
[2022-01-11 18:23:27,973][root][INFO] - Avg. loss per last 100 batches: 0.018264
[2022-01-11 18:23:28,930][root][INFO] - Epoch: 29: Step: 201/920, loss=0.055468, lr=0.000003
[2022-01-11 18:23:28,931][root][INFO] - Epoch: 29: Step: 201/920, loss=0.055468, lr=0.000003
[2022-01-11 18:23:28,931][root][INFO] - Epoch: 29: Step: 201/920, loss=0.055468, lr=0.000003
[2022-01-11 18:23:28,931][root][INFO] - Epoch: 29: Step: 201/920, loss=0.055468, lr=0.000003
[2022-01-11 18:25:06,435][root][INFO] - Train batch 300
[2022-01-11 18:25:06,435][root][INFO] - Avg. loss per last 100 batches: 0.014812
[2022-01-11 18:25:06,436][root][INFO] - Train batch 300
[2022-01-11 18:25:06,436][root][INFO] - Avg. loss per last 100 batches: 0.014812
[2022-01-11 18:25:06,437][root][INFO] - Train batch 300
[2022-01-11 18:25:06,438][root][INFO] - Avg. loss per last 100 batches: 0.014812
[2022-01-11 18:25:06,438][root][INFO] - Train batch 300
[2022-01-11 18:25:06,438][root][INFO] - Avg. loss per last 100 batches: 0.014812
[2022-01-11 18:25:07,290][root][INFO] - Epoch: 29: Step: 301/920, loss=0.004910, lr=0.000003
[2022-01-11 18:25:07,291][root][INFO] - Epoch: 29: Step: 301/920, loss=0.004910, lr=0.000003
[2022-01-11 18:25:07,292][root][INFO] - Epoch: 29: Step: 301/920, loss=0.004910, lr=0.000003
[2022-01-11 18:25:07,292][root][INFO] - Epoch: 29: Step: 301/920, loss=0.004910, lr=0.000003
[2022-01-11 18:26:42,813][root][INFO] - Train batch 400
[2022-01-11 18:26:42,814][root][INFO] - Avg. loss per last 100 batches: 0.020690
[2022-01-11 18:26:42,822][root][INFO] - Train batch 400
[2022-01-11 18:26:42,822][root][INFO] - Avg. loss per last 100 batches: 0.020690
[2022-01-11 18:26:42,823][root][INFO] - Train batch 400
[2022-01-11 18:26:42,823][root][INFO] - Avg. loss per last 100 batches: 0.020690
[2022-01-11 18:26:42,823][root][INFO] - Train batch 400
[2022-01-11 18:26:42,823][root][INFO] - Avg. loss per last 100 batches: 0.020690
[2022-01-11 18:26:43,876][root][INFO] - Epoch: 29: Step: 401/920, loss=0.026279, lr=0.000003
[2022-01-11 18:26:43,878][root][INFO] - Epoch: 29: Step: 401/920, loss=0.026279, lr=0.000003
[2022-01-11 18:26:43,879][root][INFO] - Epoch: 29: Step: 401/920, loss=0.026279, lr=0.000003
[2022-01-11 18:26:43,879][root][INFO] - Epoch: 29: Step: 401/920, loss=0.026279, lr=0.000003
[2022-01-11 18:28:23,129][root][INFO] - Train batch 500
[2022-01-11 18:28:23,129][root][INFO] - Avg. loss per last 100 batches: 0.020954
[2022-01-11 18:28:23,137][root][INFO] - Train batch 500
[2022-01-11 18:28:23,137][root][INFO] - Avg. loss per last 100 batches: 0.020954
[2022-01-11 18:28:23,138][root][INFO] - Train batch 500
[2022-01-11 18:28:23,138][root][INFO] - Avg. loss per last 100 batches: 0.020954
[2022-01-11 18:28:23,138][root][INFO] - Train batch 500
[2022-01-11 18:28:23,139][root][INFO] - Avg. loss per last 100 batches: 0.020954
[2022-01-11 18:28:24,186][root][INFO] - Epoch: 29: Step: 501/920, loss=0.002159, lr=0.000003
[2022-01-11 18:28:24,194][root][INFO] - Epoch: 29: Step: 501/920, loss=0.002159, lr=0.000003
[2022-01-11 18:28:24,195][root][INFO] - Epoch: 29: Step: 501/920, loss=0.002159, lr=0.000003
[2022-01-11 18:28:24,195][root][INFO] - Epoch: 29: Step: 501/920, loss=0.002159, lr=0.000003
[2022-01-11 18:30:04,097][root][INFO] - Train batch 600
[2022-01-11 18:30:04,097][root][INFO] - Avg. loss per last 100 batches: 0.019717
[2022-01-11 18:30:04,106][root][INFO] - Train batch 600
[2022-01-11 18:30:04,106][root][INFO] - Avg. loss per last 100 batches: 0.019717
[2022-01-11 18:30:04,113][root][INFO] - Train batch 600
[2022-01-11 18:30:04,113][root][INFO] - Avg. loss per last 100 batches: 0.019717
[2022-01-11 18:30:04,113][root][INFO] - Train batch 600
[2022-01-11 18:30:04,113][root][INFO] - Avg. loss per last 100 batches: 0.019717
[2022-01-11 18:30:05,150][root][INFO] - Epoch: 29: Step: 601/920, loss=0.011803, lr=0.000003
[2022-01-11 18:30:05,150][root][INFO] - Epoch: 29: Step: 601/920, loss=0.011803, lr=0.000003
[2022-01-11 18:30:05,151][root][INFO] - Epoch: 29: Step: 601/920, loss=0.011803, lr=0.000003
[2022-01-11 18:30:05,151][root][INFO] - Epoch: 29: Step: 601/920, loss=0.011803, lr=0.000003
[2022-01-11 18:31:39,848][root][INFO] - Train batch 700
[2022-01-11 18:31:39,848][root][INFO] - Avg. loss per last 100 batches: 0.015553
[2022-01-11 18:31:39,849][root][INFO] - Train batch 700
[2022-01-11 18:31:39,849][root][INFO] - Avg. loss per last 100 batches: 0.015553
[2022-01-11 18:31:39,849][root][INFO] - Train batch 700
[2022-01-11 18:31:39,849][root][INFO] - Avg. loss per last 100 batches: 0.015553
[2022-01-11 18:31:39,851][root][INFO] - Train batch 700
[2022-01-11 18:31:39,851][root][INFO] - Avg. loss per last 100 batches: 0.015553
[2022-01-11 18:31:40,893][root][INFO] - Epoch: 29: Step: 701/920, loss=0.026356, lr=0.000003
[2022-01-11 18:31:40,894][root][INFO] - Epoch: 29: Step: 701/920, loss=0.026356, lr=0.000003
[2022-01-11 18:31:40,894][root][INFO] - Epoch: 29: Step: 701/920, loss=0.026356, lr=0.000003
[2022-01-11 18:31:40,894][root][INFO] - Epoch: 29: Step: 701/920, loss=0.026356, lr=0.000003
[2022-01-11 18:33:19,905][root][INFO] - Train batch 800
[2022-01-11 18:33:19,905][root][INFO] - Avg. loss per last 100 batches: 0.020524
[2022-01-11 18:33:19,906][root][INFO] - Train batch 800
[2022-01-11 18:33:19,906][root][INFO] - Avg. loss per last 100 batches: 0.020524
[2022-01-11 18:33:19,906][root][INFO] - Train batch 800
[2022-01-11 18:33:19,906][root][INFO] - Avg. loss per last 100 batches: 0.020524
[2022-01-11 18:33:19,906][root][INFO] - Train batch 800
[2022-01-11 18:33:19,906][root][INFO] - Avg. loss per last 100 batches: 0.020524
[2022-01-11 18:33:20,950][root][INFO] - Epoch: 29: Step: 801/920, loss=0.076576, lr=0.000003
[2022-01-11 18:33:20,959][root][INFO] - Epoch: 29: Step: 801/920, loss=0.076576, lr=0.000003
[2022-01-11 18:33:20,959][root][INFO] - Epoch: 29: Step: 801/920, loss=0.076576, lr=0.000003
[2022-01-11 18:33:20,959][root][INFO] - Epoch: 29: Step: 801/920, loss=0.076576, lr=0.000003
[2022-01-11 18:35:00,210][root][INFO] - Train batch 900
[2022-01-11 18:35:00,210][root][INFO] - Train batch 900
[2022-01-11 18:35:00,210][root][INFO] - Avg. loss per last 100 batches: 0.017679
[2022-01-11 18:35:00,210][root][INFO] - Avg. loss per last 100 batches: 0.017679
[2022-01-11 18:35:00,210][root][INFO] - Train batch 900
[2022-01-11 18:35:00,211][root][INFO] - Avg. loss per last 100 batches: 0.017679
[2022-01-11 18:35:00,211][root][INFO] - Train batch 900
[2022-01-11 18:35:00,211][root][INFO] - Avg. loss per last 100 batches: 0.017679
[2022-01-11 18:35:01,131][root][INFO] - Epoch: 29: Step: 901/920, loss=0.000649, lr=0.000003
[2022-01-11 18:35:01,131][root][INFO] - Epoch: 29: Step: 901/920, loss=0.000649, lr=0.000003
[2022-01-11 18:35:01,131][root][INFO] - Epoch: 29: Step: 901/920, loss=0.000649, lr=0.000003
[2022-01-11 18:35:01,131][root][INFO] - Epoch: 29: Step: 901/920, loss=0.000649, lr=0.000003
[2022-01-11 18:35:19,818][root][INFO] - rank=0, Validation: Epoch: 29 Step: 920/920
[2022-01-11 18:35:19,818][root][INFO] - NLL validation ...
[2022-01-11 18:35:19,818][root][INFO] - rank=2, Validation: Epoch: 29 Step: 920/920
[2022-01-11 18:35:19,819][root][INFO] - NLL validation ...
[2022-01-11 18:35:19,819][root][INFO] - rank=0; Iteration start
[2022-01-11 18:35:19,819][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:35:19,819][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:35:19,819][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 18:35:19,820][root][INFO] - rank=2; Iteration start
[2022-01-11 18:35:19,820][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:35:19,820][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:35:19,820][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 18:35:19,820][root][INFO] - rank=3, Validation: Epoch: 29 Step: 920/920
[2022-01-11 18:35:19,820][root][INFO] - NLL validation ...
[2022-01-11 18:35:19,821][root][INFO] - rank=1, Validation: Epoch: 29 Step: 920/920
[2022-01-11 18:35:19,821][root][INFO] - NLL validation ...
[2022-01-11 18:35:19,822][root][INFO] - rank=3; Iteration start
[2022-01-11 18:35:19,822][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:35:19,822][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:35:19,822][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 18:35:19,822][root][INFO] - rank=1; Iteration start
[2022-01-11 18:35:19,822][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:35:19,822][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:35:19,822][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 18:35:19,829][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 18:35:19,830][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 18:35:19,831][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 18:35:19,832][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 18:35:20,567][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 18:35:20,567][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 18:35:20,567][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 18:35:20,567][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 18:35:21,305][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 18:35:21,305][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 18:35:21,306][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 18:35:21,306][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 18:35:22,044][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 18:35:22,045][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 18:35:22,046][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 18:35:22,046][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 18:35:22,785][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 18:35:22,786][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 18:35:22,786][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 18:35:22,787][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 18:35:23,524][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 18:35:23,525][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 18:35:23,525][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 18:35:24,275][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 18:35:25,004][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 18:35:25,004][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 18:35:25,005][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 18:35:25,005][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 18:35:25,744][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 18:35:25,745][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 18:35:25,745][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 18:35:25,745][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 18:35:26,482][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 18:35:26,483][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 18:35:26,483][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 18:35:26,483][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 18:35:27,220][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 18:35:27,893][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 18:35:28,053][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 18:35:28,152][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 18:35:28,890][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 18:35:28,890][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 18:35:28,891][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 18:35:28,892][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 18:35:29,640][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 18:35:29,640][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 18:35:29,641][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 18:35:29,641][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 18:35:30,384][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 18:35:30,385][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 18:35:30,386][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 18:35:30,386][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 18:35:31,127][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 18:35:31,127][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 18:35:31,128][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 18:35:31,128][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 18:35:31,865][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 18:35:31,865][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 18:35:31,866][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 18:35:31,866][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 18:35:32,608][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 18:35:32,608][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 18:35:32,608][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 18:35:32,609][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 18:35:33,342][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 18:35:33,342][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 18:35:33,342][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 18:35:33,342][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 18:35:34,082][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 18:35:34,082][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 18:35:34,083][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 18:35:34,084][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 18:35:34,818][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 18:35:34,819][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 18:35:34,819][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 18:35:35,552][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 18:35:36,285][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 18:35:36,285][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 18:35:36,285][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 18:35:36,285][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 18:35:37,024][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 18:35:37,024][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 18:35:37,024][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 18:35:37,024][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 18:35:37,760][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 18:35:37,760][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 18:35:37,760][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 18:35:37,760][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 18:35:38,500][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 18:35:38,500][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 18:35:38,501][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 18:35:38,503][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 18:35:39,240][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 18:35:39,887][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 18:35:39,899][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 18:35:39,971][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 18:35:40,706][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 18:35:40,706][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 18:35:40,706][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 18:35:40,706][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 18:35:41,437][root][INFO] - rank=3; last iteration 25
[2022-01-11 18:35:41,437][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:35:41,437][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 18:35:41,437][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:35:41,437][root][INFO] - NLL Validation: loss = 0.396946. correct prediction ratio  5741/6400 ~  0.897031
[2022-01-11 18:35:41,438][root][INFO] - rank=2; last iteration 25
[2022-01-11 18:35:41,438][root][INFO] - rank=1; last iteration 25
[2022-01-11 18:35:41,438][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:35:41,438][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:35:41,438][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 18:35:41,438][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 18:35:41,438][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:35:41,438][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:35:41,438][root][INFO] - NLL Validation: loss = 0.396946. correct prediction ratio  5741/6400 ~  0.897031
[2022-01-11 18:35:41,438][root][INFO] - NLL Validation: loss = 0.396946. correct prediction ratio  5741/6400 ~  0.897031
[2022-01-11 18:35:41,440][root][INFO] - rank=3; last iteration 920
[2022-01-11 18:35:41,440][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:35:41,440][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 18:35:41,440][root][INFO] - rank=0; last iteration 25
[2022-01-11 18:35:41,440][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:35:41,440][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 18:35:41,440][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:35:41,440][root][INFO] - NLL Validation: loss = 0.396946. correct prediction ratio  5741/6400 ~  0.897031
[2022-01-11 18:35:41,440][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:35:41,440][root][INFO] - Epoch finished on 3
[2022-01-11 18:35:41,440][root][INFO] - NLL validation ...
[2022-01-11 18:35:41,441][root][INFO] - rank=2; last iteration 920
[2022-01-11 18:35:41,441][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:35:41,441][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 18:35:41,441][root][INFO] - rank=1; last iteration 920
[2022-01-11 18:35:41,441][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:35:41,441][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 18:35:41,441][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:35:41,441][root][INFO] - Epoch finished on 2
[2022-01-11 18:35:41,442][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:35:41,442][root][INFO] - rank=3; Iteration start
[2022-01-11 18:35:41,442][root][INFO] - NLL validation ...
[2022-01-11 18:35:41,442][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:35:41,442][root][INFO] - Epoch finished on 1
[2022-01-11 18:35:41,442][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:35:41,442][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 18:35:41,442][root][INFO] - NLL validation ...
[2022-01-11 18:35:41,443][root][INFO] - rank=2; Iteration start
[2022-01-11 18:35:41,443][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:35:41,443][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:35:41,443][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 18:35:41,443][root][INFO] - rank=1; Iteration start
[2022-01-11 18:35:41,443][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:35:41,443][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:35:41,443][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 18:35:41,451][root][INFO] - Eval step: 0 ,rnk=3
[2022-01-11 18:35:41,451][root][INFO] - Eval step: 0 ,rnk=2
[2022-01-11 18:35:41,451][root][INFO] - Eval step: 0 ,rnk=1
[2022-01-11 18:35:45,554][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.29
[2022-01-11 18:35:45,554][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.29
[2022-01-11 18:35:45,556][root][INFO] - rank=0; last iteration 920
[2022-01-11 18:35:45,556][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:35:45,556][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 18:35:45,556][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:35:45,557][root][INFO] - Epoch finished on 0
[2022-01-11 18:35:45,557][root][INFO] - NLL validation ...
[2022-01-11 18:35:45,558][root][INFO] - rank=0; Iteration start
[2022-01-11 18:35:45,558][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:35:45,558][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:35:45,558][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 18:35:45,567][root][INFO] - Eval step: 0 ,rnk=0
[2022-01-11 18:35:46,313][root][INFO] - Eval step: 1 ,rnk=1
[2022-01-11 18:35:46,313][root][INFO] - Eval step: 1 ,rnk=2
[2022-01-11 18:35:46,314][root][INFO] - Eval step: 1 ,rnk=3
[2022-01-11 18:35:46,314][root][INFO] - Eval step: 1 ,rnk=0
[2022-01-11 18:35:47,049][root][INFO] - Eval step: 2 ,rnk=1
[2022-01-11 18:35:47,049][root][INFO] - Eval step: 2 ,rnk=2
[2022-01-11 18:35:47,050][root][INFO] - Eval step: 2 ,rnk=3
[2022-01-11 18:35:47,050][root][INFO] - Eval step: 2 ,rnk=0
[2022-01-11 18:35:47,782][root][INFO] - Eval step: 3 ,rnk=2
[2022-01-11 18:35:47,783][root][INFO] - Eval step: 3 ,rnk=1
[2022-01-11 18:35:47,784][root][INFO] - Eval step: 3 ,rnk=3
[2022-01-11 18:35:47,784][root][INFO] - Eval step: 3 ,rnk=0
[2022-01-11 18:35:48,522][root][INFO] - Eval step: 4 ,rnk=1
[2022-01-11 18:35:48,523][root][INFO] - Eval step: 4 ,rnk=2
[2022-01-11 18:35:48,523][root][INFO] - Eval step: 4 ,rnk=0
[2022-01-11 18:35:48,523][root][INFO] - Eval step: 4 ,rnk=3
[2022-01-11 18:35:49,261][root][INFO] - Eval step: 5 ,rnk=1
[2022-01-11 18:35:49,261][root][INFO] - Eval step: 5 ,rnk=2
[2022-01-11 18:35:49,262][root][INFO] - Eval step: 5 ,rnk=3
[2022-01-11 18:35:49,263][root][INFO] - Eval step: 5 ,rnk=0
[2022-01-11 18:35:49,997][root][INFO] - Eval step: 6 ,rnk=1
[2022-01-11 18:35:49,998][root][INFO] - Eval step: 6 ,rnk=2
[2022-01-11 18:35:49,998][root][INFO] - Eval step: 6 ,rnk=3
[2022-01-11 18:35:49,999][root][INFO] - Eval step: 6 ,rnk=0
[2022-01-11 18:35:50,733][root][INFO] - Eval step: 7 ,rnk=2
[2022-01-11 18:35:50,733][root][INFO] - Eval step: 7 ,rnk=1
[2022-01-11 18:35:50,734][root][INFO] - Eval step: 7 ,rnk=3
[2022-01-11 18:35:51,533][root][INFO] - Eval step: 7 ,rnk=0
[2022-01-11 18:35:52,264][root][INFO] - Eval step: 8 ,rnk=0
[2022-01-11 18:35:52,264][root][INFO] - Eval step: 8 ,rnk=2
[2022-01-11 18:35:52,264][root][INFO] - Eval step: 8 ,rnk=1
[2022-01-11 18:35:52,266][root][INFO] - Eval step: 8 ,rnk=3
[2022-01-11 18:35:53,001][root][INFO] - Eval step: 9 ,rnk=1
[2022-01-11 18:35:53,001][root][INFO] - Eval step: 9 ,rnk=2
[2022-01-11 18:35:53,001][root][INFO] - Eval step: 9 ,rnk=0
[2022-01-11 18:35:53,002][root][INFO] - Eval step: 9 ,rnk=3
[2022-01-11 18:35:53,742][root][INFO] - Eval step: 10 ,rnk=0
[2022-01-11 18:35:53,742][root][INFO] - Eval step: 10 ,rnk=1
[2022-01-11 18:35:53,742][root][INFO] - Eval step: 10 ,rnk=2
[2022-01-11 18:35:53,742][root][INFO] - Eval step: 10 ,rnk=3
[2022-01-11 18:35:54,482][root][INFO] - Eval step: 11 ,rnk=0
[2022-01-11 18:35:55,089][root][INFO] - Eval step: 11 ,rnk=1
[2022-01-11 18:35:55,100][root][INFO] - Eval step: 11 ,rnk=2
[2022-01-11 18:35:55,392][root][INFO] - Eval step: 11 ,rnk=3
[2022-01-11 18:35:56,124][root][INFO] - Eval step: 12 ,rnk=1
[2022-01-11 18:35:56,125][root][INFO] - Eval step: 12 ,rnk=0
[2022-01-11 18:35:56,125][root][INFO] - Eval step: 12 ,rnk=2
[2022-01-11 18:35:56,125][root][INFO] - Eval step: 12 ,rnk=3
[2022-01-11 18:35:56,861][root][INFO] - Eval step: 13 ,rnk=0
[2022-01-11 18:35:56,861][root][INFO] - Eval step: 13 ,rnk=2
[2022-01-11 18:35:56,861][root][INFO] - Eval step: 13 ,rnk=1
[2022-01-11 18:35:56,863][root][INFO] - Eval step: 13 ,rnk=3
[2022-01-11 18:35:57,602][root][INFO] - Eval step: 14 ,rnk=3
[2022-01-11 18:35:57,602][root][INFO] - Eval step: 14 ,rnk=0
[2022-01-11 18:35:57,602][root][INFO] - Eval step: 14 ,rnk=2
[2022-01-11 18:35:57,603][root][INFO] - Eval step: 14 ,rnk=1
[2022-01-11 18:35:58,336][root][INFO] - Eval step: 15 ,rnk=1
[2022-01-11 18:35:58,336][root][INFO] - Eval step: 15 ,rnk=2
[2022-01-11 18:35:58,336][root][INFO] - Eval step: 15 ,rnk=0
[2022-01-11 18:35:58,337][root][INFO] - Eval step: 15 ,rnk=3
[2022-01-11 18:35:59,070][root][INFO] - Eval step: 16 ,rnk=0
[2022-01-11 18:35:59,070][root][INFO] - Eval step: 16 ,rnk=2
[2022-01-11 18:35:59,070][root][INFO] - Eval step: 16 ,rnk=1
[2022-01-11 18:35:59,071][root][INFO] - Eval step: 16 ,rnk=3
[2022-01-11 18:35:59,809][root][INFO] - Eval step: 17 ,rnk=1
[2022-01-11 18:35:59,809][root][INFO] - Eval step: 17 ,rnk=0
[2022-01-11 18:35:59,810][root][INFO] - Eval step: 17 ,rnk=2
[2022-01-11 18:35:59,811][root][INFO] - Eval step: 17 ,rnk=3
[2022-01-11 18:36:00,545][root][INFO] - Eval step: 18 ,rnk=1
[2022-01-11 18:36:00,545][root][INFO] - Eval step: 18 ,rnk=0
[2022-01-11 18:36:00,546][root][INFO] - Eval step: 18 ,rnk=2
[2022-01-11 18:36:00,546][root][INFO] - Eval step: 18 ,rnk=3
[2022-01-11 18:36:01,282][root][INFO] - Eval step: 19 ,rnk=1
[2022-01-11 18:36:01,282][root][INFO] - Eval step: 19 ,rnk=2
[2022-01-11 18:36:01,282][root][INFO] - Eval step: 19 ,rnk=0
[2022-01-11 18:36:01,283][root][INFO] - Eval step: 19 ,rnk=3
[2022-01-11 18:36:02,018][root][INFO] - Eval step: 20 ,rnk=1
[2022-01-11 18:36:02,018][root][INFO] - Eval step: 20 ,rnk=2
[2022-01-11 18:36:02,018][root][INFO] - Eval step: 20 ,rnk=0
[2022-01-11 18:36:02,019][root][INFO] - Eval step: 20 ,rnk=3
[2022-01-11 18:36:02,755][root][INFO] - Eval step: 21 ,rnk=1
[2022-01-11 18:36:02,755][root][INFO] - Eval step: 21 ,rnk=2
[2022-01-11 18:36:02,755][root][INFO] - Eval step: 21 ,rnk=3
[2022-01-11 18:36:03,344][root][INFO] - Eval step: 21 ,rnk=0
[2022-01-11 18:36:04,074][root][INFO] - Eval step: 22 ,rnk=0
[2022-01-11 18:36:04,075][root][INFO] - Eval step: 22 ,rnk=3
[2022-01-11 18:36:04,075][root][INFO] - Eval step: 22 ,rnk=2
[2022-01-11 18:36:04,075][root][INFO] - Eval step: 22 ,rnk=1
[2022-01-11 18:36:04,812][root][INFO] - Eval step: 23 ,rnk=0
[2022-01-11 18:36:04,813][root][INFO] - Eval step: 23 ,rnk=3
[2022-01-11 18:36:04,813][root][INFO] - Eval step: 23 ,rnk=1
[2022-01-11 18:36:04,813][root][INFO] - Eval step: 23 ,rnk=2
[2022-01-11 18:36:05,551][root][INFO] - Eval step: 24 ,rnk=3
[2022-01-11 18:36:05,552][root][INFO] - Eval step: 24 ,rnk=2
[2022-01-11 18:36:05,553][root][INFO] - Eval step: 24 ,rnk=1
[2022-01-11 18:36:05,553][root][INFO] - Eval step: 24 ,rnk=0
[2022-01-11 18:36:06,280][root][INFO] - rank=1; last iteration 25
[2022-01-11 18:36:06,280][root][INFO] - rank=3; last iteration 25
[2022-01-11 18:36:06,280][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:36:06,280][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 18:36:06,280][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:36:06,280][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 18:36:06,280][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:36:06,280][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:36:06,280][root][INFO] - NLL Validation: loss = 0.396946. correct prediction ratio  5741/6400 ~  0.897031
[2022-01-11 18:36:06,280][root][INFO] - NLL Validation: loss = 0.396946. correct prediction ratio  5741/6400 ~  0.897031
[2022-01-11 18:36:06,280][root][INFO] - rank=2; last iteration 25
[2022-01-11 18:36:06,281][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:36:06,281][root][INFO] - rank=0; last iteration 25
[2022-01-11 18:36:06,281][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 18:36:06,281][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:36:06,281][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:36:06,281][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 18:36:06,281][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:36:06,281][root][INFO] - NLL Validation: loss = 0.396946. correct prediction ratio  5741/6400 ~  0.897031
[2022-01-11 18:36:06,281][root][INFO] - NLL Validation: loss = 0.396946. correct prediction ratio  5741/6400 ~  0.897031
[2022-01-11 18:36:06,282][root][INFO] - Av Loss per epoch=0.018912
[2022-01-11 18:36:06,282][root][INFO] - epoch total correct predictions=58447
[2022-01-11 18:36:06,282][root][INFO] - Av Loss per epoch=0.018912
[2022-01-11 18:36:06,282][root][INFO] - epoch total correct predictions=58447
[2022-01-11 18:36:06,282][root][INFO] - Av Loss per epoch=0.018912
[2022-01-11 18:36:06,282][root][INFO] - epoch total correct predictions=58447
[2022-01-11 18:36:06,283][root][INFO] - ***** Epoch 30 *****
[2022-01-11 18:36:06,284][root][INFO] - ***** Epoch 30 *****
[2022-01-11 18:36:06,284][root][INFO] - ***** Epoch 30 *****
[2022-01-11 18:36:06,285][root][INFO] - rank=1; Iteration start
[2022-01-11 18:36:06,285][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:36:06,285][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:36:06,285][root][INFO] - rank=3; Iteration start
[2022-01-11 18:36:06,285][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:36:06,285][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:36:06,285][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 18:36:06,285][root][INFO] - rank=2; Iteration start
[2022-01-11 18:36:06,286][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:36:06,286][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:36:06,286][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 18:36:06,286][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 18:36:11,378][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.29
[2022-01-11 18:36:11,379][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.29
[2022-01-11 18:36:11,379][root][INFO] - Av Loss per epoch=0.018912
[2022-01-11 18:36:11,379][root][INFO] - epoch total correct predictions=58447
[2022-01-11 18:36:11,381][root][INFO] - ***** Epoch 30 *****
[2022-01-11 18:36:11,383][root][INFO] - rank=0; Iteration start
[2022-01-11 18:36:11,383][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:36:11,383][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 18:36:11,384][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 18:36:12,281][root][INFO] - Epoch: 30: Step: 1/920, loss=0.001458, lr=0.000003
[2022-01-11 18:36:12,281][root][INFO] - Epoch: 30: Step: 1/920, loss=0.001458, lr=0.000003
[2022-01-11 18:36:12,281][root][INFO] - Epoch: 30: Step: 1/920, loss=0.001458, lr=0.000003
[2022-01-11 18:36:12,282][root][INFO] - Epoch: 30: Step: 1/920, loss=0.001458, lr=0.000003
[2022-01-11 18:37:50,725][root][INFO] - Train batch 100
[2022-01-11 18:37:50,725][root][INFO] - Avg. loss per last 100 batches: 0.016658
[2022-01-11 18:37:50,726][root][INFO] - Train batch 100
[2022-01-11 18:37:50,726][root][INFO] - Avg. loss per last 100 batches: 0.016658
[2022-01-11 18:37:50,726][root][INFO] - Train batch 100
[2022-01-11 18:37:50,726][root][INFO] - Avg. loss per last 100 batches: 0.016658
[2022-01-11 18:37:50,727][root][INFO] - Train batch 100
[2022-01-11 18:37:50,728][root][INFO] - Avg. loss per last 100 batches: 0.016658
[2022-01-11 18:37:51,592][root][INFO] - Epoch: 30: Step: 101/920, loss=0.040541, lr=0.000003
[2022-01-11 18:37:51,592][root][INFO] - Epoch: 30: Step: 101/920, loss=0.040541, lr=0.000003
[2022-01-11 18:37:51,593][root][INFO] - Epoch: 30: Step: 101/920, loss=0.040541, lr=0.000003
[2022-01-11 18:37:51,593][root][INFO] - Epoch: 30: Step: 101/920, loss=0.040541, lr=0.000003
[2022-01-11 18:39:29,503][root][INFO] - Train batch 200
[2022-01-11 18:39:29,503][root][INFO] - Avg. loss per last 100 batches: 0.021673
[2022-01-11 18:39:29,504][root][INFO] - Train batch 200
[2022-01-11 18:39:29,504][root][INFO] - Avg. loss per last 100 batches: 0.021673
[2022-01-11 18:39:29,505][root][INFO] - Train batch 200
[2022-01-11 18:39:29,505][root][INFO] - Avg. loss per last 100 batches: 0.021673
[2022-01-11 18:39:29,506][root][INFO] - Train batch 200
[2022-01-11 18:39:29,506][root][INFO] - Avg. loss per last 100 batches: 0.021673
[2022-01-11 18:39:30,518][root][INFO] - Epoch: 30: Step: 201/920, loss=0.003030, lr=0.000003
[2022-01-11 18:39:30,518][root][INFO] - Epoch: 30: Step: 201/920, loss=0.003030, lr=0.000003
[2022-01-11 18:39:30,518][root][INFO] - Epoch: 30: Step: 201/920, loss=0.003030, lr=0.000003
[2022-01-11 18:39:30,519][root][INFO] - Epoch: 30: Step: 201/920, loss=0.003030, lr=0.000003
[2022-01-11 18:41:07,867][root][INFO] - Train batch 300
[2022-01-11 18:41:07,867][root][INFO] - Avg. loss per last 100 batches: 0.016965
[2022-01-11 18:41:07,868][root][INFO] - Train batch 300
[2022-01-11 18:41:07,868][root][INFO] - Avg. loss per last 100 batches: 0.016965
[2022-01-11 18:41:07,869][root][INFO] - Train batch 300
[2022-01-11 18:41:07,870][root][INFO] - Avg. loss per last 100 batches: 0.016965
[2022-01-11 18:41:07,870][root][INFO] - Train batch 300
[2022-01-11 18:41:07,870][root][INFO] - Avg. loss per last 100 batches: 0.016965
[2022-01-11 18:41:08,716][root][INFO] - Epoch: 30: Step: 301/920, loss=0.013713, lr=0.000003
[2022-01-11 18:41:08,723][root][INFO] - Epoch: 30: Step: 301/920, loss=0.013713, lr=0.000003
[2022-01-11 18:41:08,724][root][INFO] - Epoch: 30: Step: 301/920, loss=0.013713, lr=0.000003
[2022-01-11 18:41:08,725][root][INFO] - Epoch: 30: Step: 301/920, loss=0.013713, lr=0.000003
[2022-01-11 18:42:46,881][root][INFO] - Train batch 400
[2022-01-11 18:42:46,881][root][INFO] - Avg. loss per last 100 batches: 0.015347
[2022-01-11 18:42:46,882][root][INFO] - Train batch 400
[2022-01-11 18:42:46,882][root][INFO] - Avg. loss per last 100 batches: 0.015347
[2022-01-11 18:42:46,882][root][INFO] - Train batch 400
[2022-01-11 18:42:46,882][root][INFO] - Avg. loss per last 100 batches: 0.015347
[2022-01-11 18:42:46,883][root][INFO] - Train batch 400
[2022-01-11 18:42:46,883][root][INFO] - Avg. loss per last 100 batches: 0.015347
[2022-01-11 18:42:47,935][root][INFO] - Epoch: 30: Step: 401/920, loss=0.017927, lr=0.000003
[2022-01-11 18:42:47,935][root][INFO] - Epoch: 30: Step: 401/920, loss=0.017927, lr=0.000003
[2022-01-11 18:42:47,936][root][INFO] - Epoch: 30: Step: 401/920, loss=0.017927, lr=0.000003
[2022-01-11 18:42:47,948][root][INFO] - Epoch: 30: Step: 401/920, loss=0.017927, lr=0.000003
[2022-01-11 18:44:26,184][root][INFO] - Train batch 500
[2022-01-11 18:44:26,184][root][INFO] - Avg. loss per last 100 batches: 0.017676
[2022-01-11 18:44:26,184][root][INFO] - Train batch 500
[2022-01-11 18:44:26,184][root][INFO] - Avg. loss per last 100 batches: 0.017676
[2022-01-11 18:44:26,185][root][INFO] - Train batch 500
[2022-01-11 18:44:26,185][root][INFO] - Avg. loss per last 100 batches: 0.017676
[2022-01-11 18:44:26,187][root][INFO] - Train batch 500
[2022-01-11 18:44:26,187][root][INFO] - Avg. loss per last 100 batches: 0.017676
[2022-01-11 18:44:27,233][root][INFO] - Epoch: 30: Step: 501/920, loss=0.001577, lr=0.000003
[2022-01-11 18:44:27,233][root][INFO] - Epoch: 30: Step: 501/920, loss=0.001577, lr=0.000003
[2022-01-11 18:44:27,235][root][INFO] - Epoch: 30: Step: 501/920, loss=0.001577, lr=0.000003
[2022-01-11 18:44:27,235][root][INFO] - Epoch: 30: Step: 501/920, loss=0.001577, lr=0.000003
[2022-01-11 18:46:01,901][root][INFO] - Train batch 600
[2022-01-11 18:46:01,901][root][INFO] - Avg. loss per last 100 batches: 0.019601
[2022-01-11 18:46:01,901][root][INFO] - Train batch 600
[2022-01-11 18:46:01,902][root][INFO] - Avg. loss per last 100 batches: 0.019601
[2022-01-11 18:46:01,901][root][INFO] - Train batch 600
[2022-01-11 18:46:01,902][root][INFO] - Avg. loss per last 100 batches: 0.019601
[2022-01-11 18:46:01,902][root][INFO] - Train batch 600
[2022-01-11 18:46:01,902][root][INFO] - Avg. loss per last 100 batches: 0.019601
[2022-01-11 18:46:02,947][root][INFO] - Epoch: 30: Step: 601/920, loss=0.070753, lr=0.000003
[2022-01-11 18:46:02,961][root][INFO] - Epoch: 30: Step: 601/920, loss=0.070753, lr=0.000003
[2022-01-11 18:46:02,961][root][INFO] - Epoch: 30: Step: 601/920, loss=0.070753, lr=0.000003
[2022-01-11 18:46:02,961][root][INFO] - Epoch: 30: Step: 601/920, loss=0.070753, lr=0.000003
[2022-01-11 18:47:42,291][root][INFO] - Train batch 700
[2022-01-11 18:47:42,291][root][INFO] - Avg. loss per last 100 batches: 0.019752
[2022-01-11 18:47:42,296][root][INFO] - Train batch 700
[2022-01-11 18:47:42,296][root][INFO] - Avg. loss per last 100 batches: 0.019752
[2022-01-11 18:47:42,296][root][INFO] - Train batch 700
[2022-01-11 18:47:42,296][root][INFO] - Avg. loss per last 100 batches: 0.019752
[2022-01-11 18:47:42,298][root][INFO] - Train batch 700
[2022-01-11 18:47:42,298][root][INFO] - Avg. loss per last 100 batches: 0.019752
[2022-01-11 18:47:43,343][root][INFO] - Epoch: 30: Step: 701/920, loss=0.000953, lr=0.000002
[2022-01-11 18:47:43,347][root][INFO] - Epoch: 30: Step: 701/920, loss=0.000953, lr=0.000002
[2022-01-11 18:47:43,347][root][INFO] - Epoch: 30: Step: 701/920, loss=0.000953, lr=0.000002
[2022-01-11 18:47:43,349][root][INFO] - Epoch: 30: Step: 701/920, loss=0.000953, lr=0.000002
[2022-01-11 18:49:21,770][root][INFO] - Train batch 800
[2022-01-11 18:49:21,770][root][INFO] - Avg. loss per last 100 batches: 0.019328
[2022-01-11 18:49:21,778][root][INFO] - Train batch 800
[2022-01-11 18:49:21,778][root][INFO] - Avg. loss per last 100 batches: 0.019328
[2022-01-11 18:49:21,779][root][INFO] - Train batch 800
[2022-01-11 18:49:21,779][root][INFO] - Avg. loss per last 100 batches: 0.019328
[2022-01-11 18:49:21,779][root][INFO] - Train batch 800
[2022-01-11 18:49:21,780][root][INFO] - Avg. loss per last 100 batches: 0.019328
[2022-01-11 18:49:22,782][root][INFO] - Epoch: 30: Step: 801/920, loss=0.008491, lr=0.000002
[2022-01-11 18:49:22,788][root][INFO] - Epoch: 30: Step: 801/920, loss=0.008491, lr=0.000002
[2022-01-11 18:49:22,790][root][INFO] - Epoch: 30: Step: 801/920, loss=0.008491, lr=0.000002
[2022-01-11 18:49:22,790][root][INFO] - Epoch: 30: Step: 801/920, loss=0.008491, lr=0.000002
[2022-01-11 18:50:59,084][root][INFO] - Train batch 900
[2022-01-11 18:50:59,084][root][INFO] - Avg. loss per last 100 batches: 0.019134
[2022-01-11 18:50:59,095][root][INFO] - Train batch 900
[2022-01-11 18:50:59,096][root][INFO] - Avg. loss per last 100 batches: 0.019134
[2022-01-11 18:50:59,096][root][INFO] - Train batch 900
[2022-01-11 18:50:59,096][root][INFO] - Avg. loss per last 100 batches: 0.019134
[2022-01-11 18:50:59,096][root][INFO] - Train batch 900
[2022-01-11 18:50:59,096][root][INFO] - Avg. loss per last 100 batches: 0.019134
[2022-01-11 18:51:00,019][root][INFO] - Epoch: 30: Step: 901/920, loss=0.015504, lr=0.000002
[2022-01-11 18:51:00,032][root][INFO] - Epoch: 30: Step: 901/920, loss=0.015504, lr=0.000002
[2022-01-11 18:51:00,032][root][INFO] - Epoch: 30: Step: 901/920, loss=0.015504, lr=0.000002
[2022-01-11 18:51:00,035][root][INFO] - Epoch: 30: Step: 901/920, loss=0.015504, lr=0.000002
[2022-01-11 18:51:18,384][root][INFO] - rank=1, Validation: Epoch: 30 Step: 920/920
[2022-01-11 18:51:18,385][root][INFO] - Average rank validation ...
[2022-01-11 18:51:18,385][root][INFO] - rank=0, Validation: Epoch: 30 Step: 920/920
[2022-01-11 18:51:18,385][root][INFO] - rank=3, Validation: Epoch: 30 Step: 920/920
[2022-01-11 18:51:18,385][root][INFO] - Average rank validation ...
[2022-01-11 18:51:18,385][root][INFO] - Average rank validation ...
[2022-01-11 18:51:18,385][root][INFO] - rank=2, Validation: Epoch: 30 Step: 920/920
[2022-01-11 18:51:18,385][root][INFO] - Average rank validation ...
[2022-01-11 18:51:18,386][root][INFO] - rank=1; Iteration start
[2022-01-11 18:51:18,386][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:51:18,386][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:51:18,386][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 18:51:18,386][root][INFO] - rank=0; Iteration start
[2022-01-11 18:51:18,386][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:51:18,386][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:51:18,386][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 18:51:18,386][root][INFO] - rank=3; Iteration start
[2022-01-11 18:51:18,386][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:51:18,386][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:51:18,386][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 18:51:18,387][root][INFO] - rank=2; Iteration start
[2022-01-11 18:51:18,387][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:51:18,387][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:51:18,387][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 18:57:45,109][root][INFO] - rank=0; last iteration 25
[2022-01-11 18:57:45,109][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:57:45,109][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 18:57:45,110][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:57:45,385][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 18:57:45,386][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 18:57:45,590][root][INFO] - rank=1; last iteration 25
[2022-01-11 18:57:45,591][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:57:45,591][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 18:57:45,591][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:57:45,835][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 18:57:45,835][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 18:57:49,168][root][INFO] - rank=3; last iteration 25
[2022-01-11 18:57:49,169][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:57:49,169][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 18:57:49,169][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:57:49,409][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 18:57:49,409][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 18:57:49,765][root][INFO] - rank=2; last iteration 25
[2022-01-11 18:57:49,765][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 18:57:49,765][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 18:57:49,765][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:57:50,018][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 18:57:50,019][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 18:58:03,363][root][INFO] - Av.rank validation: average rank 38.209375, total questions=6400
[2022-01-11 18:58:03,363][root][INFO] - Av.rank validation: average rank 38.209375, total questions=6400
[2022-01-11 18:58:03,363][root][INFO] - Av.rank validation: average rank 38.209375, total questions=6400
[2022-01-11 18:58:03,363][root][INFO] - Av.rank validation: average rank 38.209375, total questions=6400
[2022-01-11 18:58:03,562][root][INFO] - rank=3; last iteration 920
[2022-01-11 18:58:03,562][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:58:03,562][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 18:58:03,563][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:58:03,563][root][INFO] - Epoch finished on 3
[2022-01-11 18:58:03,563][root][INFO] - Average rank validation ...
[2022-01-11 18:58:03,565][root][INFO] - rank=3; Iteration start
[2022-01-11 18:58:03,565][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:58:03,565][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:58:03,565][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 18:58:03,574][root][INFO] - rank=1; last iteration 920
[2022-01-11 18:58:03,575][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:58:03,575][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 18:58:03,575][root][INFO] - rank=2; last iteration 920
[2022-01-11 18:58:03,575][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:58:03,575][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 18:58:03,575][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:58:03,576][root][INFO] - Epoch finished on 1
[2022-01-11 18:58:03,576][root][INFO] - Average rank validation ...
[2022-01-11 18:58:03,576][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:58:03,576][root][INFO] - Epoch finished on 2
[2022-01-11 18:58:03,576][root][INFO] - Average rank validation ...
[2022-01-11 18:58:03,577][root][INFO] - rank=1; Iteration start
[2022-01-11 18:58:03,577][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:58:03,577][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:58:03,577][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 18:58:03,578][root][INFO] - rank=2; Iteration start
[2022-01-11 18:58:03,578][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:58:03,578][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:58:03,578][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 18:58:07,416][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.30
[2022-01-11 18:58:07,416][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.30
[2022-01-11 18:58:07,416][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.30
[2022-01-11 18:58:07,417][root][INFO] - rank=0; last iteration 920
[2022-01-11 18:58:07,417][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 18:58:07,417][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 18:58:07,418][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 18:58:07,418][root][INFO] - Epoch finished on 0
[2022-01-11 18:58:07,419][root][INFO] - Average rank validation ...
[2022-01-11 18:58:07,420][root][INFO] - rank=0; Iteration start
[2022-01-11 18:58:07,420][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 18:58:07,420][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 18:58:07,420][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 19:04:30,620][root][INFO] - rank=1; last iteration 25
[2022-01-11 19:04:30,620][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:04:30,620][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 19:04:30,620][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:04:30,861][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:04:30,861][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 19:04:34,640][root][INFO] - rank=3; last iteration 25
[2022-01-11 19:04:34,640][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:04:34,640][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 19:04:34,641][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:04:34,844][root][INFO] - rank=0; last iteration 25
[2022-01-11 19:04:34,844][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:04:34,844][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 19:04:34,844][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:04:34,863][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:04:34,863][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 19:04:35,082][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:04:35,082][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 19:04:35,094][root][INFO] - rank=2; last iteration 25
[2022-01-11 19:04:35,095][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:04:35,095][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 19:04:35,095][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:04:35,331][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:04:35,331][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 19:04:48,371][root][INFO] - Av.rank validation: average rank 38.209375, total questions=6400
[2022-01-11 19:04:48,371][root][INFO] - Av.rank validation: average rank 38.209375, total questions=6400
[2022-01-11 19:04:48,371][root][INFO] - Av.rank validation: average rank 38.209375, total questions=6400
[2022-01-11 19:04:48,371][root][INFO] - Av.rank validation: average rank 38.209375, total questions=6400
[2022-01-11 19:04:48,516][root][INFO] - Av Loss per epoch=0.018640
[2022-01-11 19:04:48,516][root][INFO] - epoch total correct predictions=58451
[2022-01-11 19:04:48,518][root][INFO] - ***** Epoch 31 *****
[2022-01-11 19:04:48,520][root][INFO] - rank=1; Iteration start
[2022-01-11 19:04:48,520][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:04:48,520][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 19:04:48,521][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 19:04:48,531][root][INFO] - Av Loss per epoch=0.018640
[2022-01-11 19:04:48,531][root][INFO] - epoch total correct predictions=58451
[2022-01-11 19:04:48,533][root][INFO] - ***** Epoch 31 *****
[2022-01-11 19:04:48,535][root][INFO] - rank=3; Iteration start
[2022-01-11 19:04:48,535][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:04:48,535][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 19:04:48,536][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 19:04:48,538][root][INFO] - Av Loss per epoch=0.018640
[2022-01-11 19:04:48,538][root][INFO] - epoch total correct predictions=58451
[2022-01-11 19:04:48,540][root][INFO] - ***** Epoch 31 *****
[2022-01-11 19:04:48,542][root][INFO] - rank=2; Iteration start
[2022-01-11 19:04:48,542][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:04:48,542][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 19:04:48,542][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 19:04:53,353][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.30
[2022-01-11 19:04:53,354][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.30
[2022-01-11 19:04:53,354][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.30
[2022-01-11 19:04:53,354][root][INFO] - Av Loss per epoch=0.018640
[2022-01-11 19:04:53,354][root][INFO] - epoch total correct predictions=58451
[2022-01-11 19:04:53,356][root][INFO] - ***** Epoch 31 *****
[2022-01-11 19:04:53,358][root][INFO] - rank=0; Iteration start
[2022-01-11 19:04:53,358][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:04:53,358][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 19:04:53,359][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 19:04:54,428][root][INFO] - Epoch: 31: Step: 1/920, loss=0.046658, lr=0.000002
[2022-01-11 19:04:54,429][root][INFO] - Epoch: 31: Step: 1/920, loss=0.046658, lr=0.000002
[2022-01-11 19:04:54,429][root][INFO] - Epoch: 31: Step: 1/920, loss=0.046658, lr=0.000002
[2022-01-11 19:04:54,430][root][INFO] - Epoch: 31: Step: 1/920, loss=0.046658, lr=0.000002
[2022-01-11 19:06:33,261][root][INFO] - Train batch 100
[2022-01-11 19:06:33,262][root][INFO] - Avg. loss per last 100 batches: 0.017677
[2022-01-11 19:06:33,262][root][INFO] - Train batch 100
[2022-01-11 19:06:33,262][root][INFO] - Avg. loss per last 100 batches: 0.017677
[2022-01-11 19:06:33,262][root][INFO] - Train batch 100
[2022-01-11 19:06:33,263][root][INFO] - Avg. loss per last 100 batches: 0.017677
[2022-01-11 19:06:33,263][root][INFO] - Train batch 100
[2022-01-11 19:06:33,263][root][INFO] - Avg. loss per last 100 batches: 0.017677
[2022-01-11 19:06:34,312][root][INFO] - Epoch: 31: Step: 101/920, loss=0.003017, lr=0.000002
[2022-01-11 19:06:34,312][root][INFO] - Epoch: 31: Step: 101/920, loss=0.003017, lr=0.000002
[2022-01-11 19:06:34,312][root][INFO] - Epoch: 31: Step: 101/920, loss=0.003017, lr=0.000002
[2022-01-11 19:06:34,313][root][INFO] - Epoch: 31: Step: 101/920, loss=0.003017, lr=0.000002
[2022-01-11 19:08:13,308][root][INFO] - Train batch 200
[2022-01-11 19:08:13,308][root][INFO] - Avg. loss per last 100 batches: 0.017360
[2022-01-11 19:08:13,308][root][INFO] - Train batch 200
[2022-01-11 19:08:13,309][root][INFO] - Avg. loss per last 100 batches: 0.017360
[2022-01-11 19:08:13,309][root][INFO] - Train batch 200
[2022-01-11 19:08:13,309][root][INFO] - Avg. loss per last 100 batches: 0.017360
[2022-01-11 19:08:13,309][root][INFO] - Train batch 200
[2022-01-11 19:08:13,309][root][INFO] - Avg. loss per last 100 batches: 0.017360
[2022-01-11 19:08:14,176][root][INFO] - Epoch: 31: Step: 201/920, loss=0.004110, lr=0.000002
[2022-01-11 19:08:14,177][root][INFO] - Epoch: 31: Step: 201/920, loss=0.004110, lr=0.000002
[2022-01-11 19:08:14,177][root][INFO] - Epoch: 31: Step: 201/920, loss=0.004110, lr=0.000002
[2022-01-11 19:08:14,177][root][INFO] - Epoch: 31: Step: 201/920, loss=0.004110, lr=0.000002
[2022-01-11 19:09:53,535][root][INFO] - Train batch 300
[2022-01-11 19:09:53,535][root][INFO] - Avg. loss per last 100 batches: 0.017502
[2022-01-11 19:09:53,539][root][INFO] - Train batch 300
[2022-01-11 19:09:53,539][root][INFO] - Avg. loss per last 100 batches: 0.017502
[2022-01-11 19:09:53,540][root][INFO] - Train batch 300
[2022-01-11 19:09:53,540][root][INFO] - Avg. loss per last 100 batches: 0.017502
[2022-01-11 19:09:53,540][root][INFO] - Train batch 300
[2022-01-11 19:09:53,540][root][INFO] - Avg. loss per last 100 batches: 0.017502
[2022-01-11 19:09:54,589][root][INFO] - Epoch: 31: Step: 301/920, loss=0.000127, lr=0.000002
[2022-01-11 19:09:54,589][root][INFO] - Epoch: 31: Step: 301/920, loss=0.000127, lr=0.000002
[2022-01-11 19:09:54,589][root][INFO] - Epoch: 31: Step: 301/920, loss=0.000127, lr=0.000002
[2022-01-11 19:09:54,589][root][INFO] - Epoch: 31: Step: 301/920, loss=0.000127, lr=0.000002
[2022-01-11 19:11:34,745][root][INFO] - Train batch 400
[2022-01-11 19:11:34,745][root][INFO] - Avg. loss per last 100 batches: 0.020332
[2022-01-11 19:11:34,745][root][INFO] - Train batch 400
[2022-01-11 19:11:34,745][root][INFO] - Avg. loss per last 100 batches: 0.020332
[2022-01-11 19:11:34,746][root][INFO] - Train batch 400
[2022-01-11 19:11:34,747][root][INFO] - Avg. loss per last 100 batches: 0.020332
[2022-01-11 19:11:34,747][root][INFO] - Train batch 400
[2022-01-11 19:11:34,747][root][INFO] - Avg. loss per last 100 batches: 0.020332
[2022-01-11 19:11:35,726][root][INFO] - Epoch: 31: Step: 401/920, loss=0.059416, lr=0.000002
[2022-01-11 19:11:35,729][root][INFO] - Epoch: 31: Step: 401/920, loss=0.059416, lr=0.000002
[2022-01-11 19:11:35,731][root][INFO] - Epoch: 31: Step: 401/920, loss=0.059416, lr=0.000002
[2022-01-11 19:11:35,731][root][INFO] - Epoch: 31: Step: 401/920, loss=0.059416, lr=0.000002
[2022-01-11 19:13:16,418][root][INFO] - Train batch 500
[2022-01-11 19:13:16,419][root][INFO] - Avg. loss per last 100 batches: 0.026056
[2022-01-11 19:13:16,419][root][INFO] - Train batch 500
[2022-01-11 19:13:16,419][root][INFO] - Avg. loss per last 100 batches: 0.026056
[2022-01-11 19:13:16,420][root][INFO] - Train batch 500
[2022-01-11 19:13:16,420][root][INFO] - Avg. loss per last 100 batches: 0.026056
[2022-01-11 19:13:16,432][root][INFO] - Train batch 500
[2022-01-11 19:13:16,433][root][INFO] - Avg. loss per last 100 batches: 0.026056
[2022-01-11 19:13:17,351][root][INFO] - Epoch: 31: Step: 501/920, loss=0.047714, lr=0.000002
[2022-01-11 19:13:17,351][root][INFO] - Epoch: 31: Step: 501/920, loss=0.047714, lr=0.000002
[2022-01-11 19:13:17,352][root][INFO] - Epoch: 31: Step: 501/920, loss=0.047714, lr=0.000002
[2022-01-11 19:13:17,364][root][INFO] - Epoch: 31: Step: 501/920, loss=0.047714, lr=0.000002
[2022-01-11 19:14:55,807][root][INFO] - Train batch 600
[2022-01-11 19:14:55,807][root][INFO] - Avg. loss per last 100 batches: 0.016258
[2022-01-11 19:14:55,807][root][INFO] - Train batch 600
[2022-01-11 19:14:55,807][root][INFO] - Avg. loss per last 100 batches: 0.016258
[2022-01-11 19:14:55,807][root][INFO] - Train batch 600
[2022-01-11 19:14:55,807][root][INFO] - Train batch 600
[2022-01-11 19:14:55,807][root][INFO] - Avg. loss per last 100 batches: 0.016258
[2022-01-11 19:14:55,807][root][INFO] - Avg. loss per last 100 batches: 0.016258
[2022-01-11 19:14:56,868][root][INFO] - Epoch: 31: Step: 601/920, loss=0.004917, lr=0.000002
[2022-01-11 19:14:56,868][root][INFO] - Epoch: 31: Step: 601/920, loss=0.004917, lr=0.000002
[2022-01-11 19:14:56,868][root][INFO] - Epoch: 31: Step: 601/920, loss=0.004917, lr=0.000002
[2022-01-11 19:14:56,868][root][INFO] - Epoch: 31: Step: 601/920, loss=0.004917, lr=0.000002
[2022-01-11 19:16:38,186][root][INFO] - Train batch 700
[2022-01-11 19:16:38,186][root][INFO] - Avg. loss per last 100 batches: 0.018907
[2022-01-11 19:16:38,186][root][INFO] - Train batch 700
[2022-01-11 19:16:38,186][root][INFO] - Avg. loss per last 100 batches: 0.018907
[2022-01-11 19:16:38,187][root][INFO] - Train batch 700
[2022-01-11 19:16:38,187][root][INFO] - Avg. loss per last 100 batches: 0.018907
[2022-01-11 19:16:38,187][root][INFO] - Train batch 700
[2022-01-11 19:16:38,187][root][INFO] - Avg. loss per last 100 batches: 0.018907
[2022-01-11 19:16:39,041][root][INFO] - Epoch: 31: Step: 701/920, loss=0.006231, lr=0.000002
[2022-01-11 19:16:39,041][root][INFO] - Epoch: 31: Step: 701/920, loss=0.006231, lr=0.000002
[2022-01-11 19:16:39,042][root][INFO] - Epoch: 31: Step: 701/920, loss=0.006231, lr=0.000002
[2022-01-11 19:16:39,042][root][INFO] - Epoch: 31: Step: 701/920, loss=0.006231, lr=0.000002
[2022-01-11 19:18:18,601][root][INFO] - Train batch 800
[2022-01-11 19:18:18,602][root][INFO] - Avg. loss per last 100 batches: 0.017890
[2022-01-11 19:18:18,602][root][INFO] - Train batch 800
[2022-01-11 19:18:18,602][root][INFO] - Avg. loss per last 100 batches: 0.017890
[2022-01-11 19:18:18,602][root][INFO] - Train batch 800
[2022-01-11 19:18:18,603][root][INFO] - Avg. loss per last 100 batches: 0.017890
[2022-01-11 19:18:18,603][root][INFO] - Train batch 800
[2022-01-11 19:18:18,603][root][INFO] - Avg. loss per last 100 batches: 0.017890
[2022-01-11 19:18:19,617][root][INFO] - Epoch: 31: Step: 801/920, loss=0.002142, lr=0.000002
[2022-01-11 19:18:19,617][root][INFO] - Epoch: 31: Step: 801/920, loss=0.002142, lr=0.000002
[2022-01-11 19:18:19,617][root][INFO] - Epoch: 31: Step: 801/920, loss=0.002142, lr=0.000002
[2022-01-11 19:18:19,618][root][INFO] - Epoch: 31: Step: 801/920, loss=0.002142, lr=0.000002
[2022-01-11 19:19:58,944][root][INFO] - Train batch 900
[2022-01-11 19:19:58,944][root][INFO] - Avg. loss per last 100 batches: 0.018940
[2022-01-11 19:19:58,958][root][INFO] - Train batch 900
[2022-01-11 19:19:58,958][root][INFO] - Avg. loss per last 100 batches: 0.018940
[2022-01-11 19:19:58,958][root][INFO] - Train batch 900
[2022-01-11 19:19:58,958][root][INFO] - Avg. loss per last 100 batches: 0.018940
[2022-01-11 19:19:58,959][root][INFO] - Train batch 900
[2022-01-11 19:19:58,959][root][INFO] - Avg. loss per last 100 batches: 0.018940
[2022-01-11 19:20:00,009][root][INFO] - Epoch: 31: Step: 901/920, loss=0.117921, lr=0.000002
[2022-01-11 19:20:00,009][root][INFO] - Epoch: 31: Step: 901/920, loss=0.117921, lr=0.000002
[2022-01-11 19:20:00,010][root][INFO] - Epoch: 31: Step: 901/920, loss=0.117921, lr=0.000002
[2022-01-11 19:20:00,011][root][INFO] - Epoch: 31: Step: 901/920, loss=0.117921, lr=0.000002
[2022-01-11 19:20:18,712][root][INFO] - rank=3, Validation: Epoch: 31 Step: 920/920
[2022-01-11 19:20:18,712][root][INFO] - Average rank validation ...
[2022-01-11 19:20:18,713][root][INFO] - rank=3; Iteration start
[2022-01-11 19:20:18,714][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:20:18,713][root][INFO] - rank=0, Validation: Epoch: 31 Step: 920/920
[2022-01-11 19:20:18,714][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:20:18,714][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 19:20:18,714][root][INFO] - Average rank validation ...
[2022-01-11 19:20:18,714][root][INFO] - rank=2, Validation: Epoch: 31 Step: 920/920
[2022-01-11 19:20:18,714][root][INFO] - Average rank validation ...
[2022-01-11 19:20:18,715][root][INFO] - rank=1, Validation: Epoch: 31 Step: 920/920
[2022-01-11 19:20:18,715][root][INFO] - Average rank validation ...
[2022-01-11 19:20:18,715][root][INFO] - rank=0; Iteration start
[2022-01-11 19:20:18,715][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:20:18,715][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:20:18,715][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 19:20:18,716][root][INFO] - rank=2; Iteration start
[2022-01-11 19:20:18,716][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:20:18,716][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:20:18,716][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 19:20:18,716][root][INFO] - rank=1; Iteration start
[2022-01-11 19:20:18,716][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:20:18,716][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:20:18,716][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 19:26:45,091][root][INFO] - rank=0; last iteration 25
[2022-01-11 19:26:45,091][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:26:45,091][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 19:26:45,091][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:26:45,322][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:26:45,322][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 19:26:45,894][root][INFO] - rank=1; last iteration 25
[2022-01-11 19:26:45,894][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:26:45,895][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 19:26:45,895][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:26:46,138][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:26:46,138][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 19:26:49,483][root][INFO] - rank=3; last iteration 25
[2022-01-11 19:26:49,483][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:26:49,483][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 19:26:49,483][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:26:49,702][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:26:49,702][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 19:26:49,744][root][INFO] - rank=2; last iteration 25
[2022-01-11 19:26:49,744][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:26:49,744][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 19:26:49,744][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:26:49,977][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:26:49,977][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 19:27:02,931][root][INFO] - Av.rank validation: average rank 35.8384375, total questions=6400
[2022-01-11 19:27:02,931][root][INFO] - Av.rank validation: average rank 35.8384375, total questions=6400
[2022-01-11 19:27:02,931][root][INFO] - Av.rank validation: average rank 35.8384375, total questions=6400
[2022-01-11 19:27:02,932][root][INFO] - Av.rank validation: average rank 35.8384375, total questions=6400
[2022-01-11 19:27:03,063][root][INFO] - rank=1; last iteration 920
[2022-01-11 19:27:03,063][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 19:27:03,063][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 19:27:03,064][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:27:03,064][root][INFO] - Epoch finished on 1
[2022-01-11 19:27:03,065][root][INFO] - Average rank validation ...
[2022-01-11 19:27:03,066][root][INFO] - rank=1; Iteration start
[2022-01-11 19:27:03,066][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:27:03,066][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:27:03,066][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 19:27:03,072][root][INFO] - rank=3; last iteration 920
[2022-01-11 19:27:03,072][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 19:27:03,072][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 19:27:03,072][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:27:03,073][root][INFO] - Epoch finished on 3
[2022-01-11 19:27:03,073][root][INFO] - Average rank validation ...
[2022-01-11 19:27:03,074][root][INFO] - rank=2; last iteration 920
[2022-01-11 19:27:03,074][root][INFO] - rank=3; Iteration start
[2022-01-11 19:27:03,074][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:27:03,074][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 19:27:03,074][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:27:03,074][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 19:27:03,074][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 19:27:03,075][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:27:03,075][root][INFO] - Epoch finished on 2
[2022-01-11 19:27:03,075][root][INFO] - Average rank validation ...
[2022-01-11 19:27:03,077][root][INFO] - rank=2; Iteration start
[2022-01-11 19:27:03,077][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:27:03,077][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:27:03,077][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 19:27:06,693][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.31
[2022-01-11 19:27:06,693][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.31
[2022-01-11 19:27:06,693][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.31
[2022-01-11 19:27:06,695][root][INFO] - rank=0; last iteration 920
[2022-01-11 19:27:06,695][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 19:27:06,695][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 19:27:06,696][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:27:06,696][root][INFO] - Epoch finished on 0
[2022-01-11 19:27:06,696][root][INFO] - Average rank validation ...
[2022-01-11 19:27:06,697][root][INFO] - rank=0; Iteration start
[2022-01-11 19:27:06,697][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:27:06,697][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:27:06,697][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 19:33:30,304][root][INFO] - rank=1; last iteration 25
[2022-01-11 19:33:30,305][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:33:30,305][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 19:33:30,305][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:33:30,548][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:33:30,548][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 19:33:31,967][root][INFO] - rank=3; last iteration 25
[2022-01-11 19:33:31,967][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:33:31,968][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 19:33:31,968][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:33:32,198][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:33:32,198][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 19:33:33,440][root][INFO] - rank=0; last iteration 25
[2022-01-11 19:33:33,440][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:33:33,440][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 19:33:33,440][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:33:33,678][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:33:33,678][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 19:33:34,064][root][INFO] - rank=2; last iteration 25
[2022-01-11 19:33:34,065][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:33:34,065][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 19:33:34,065][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:33:34,298][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:33:34,298][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 19:33:47,311][root][INFO] - Av.rank validation: average rank 35.8384375, total questions=6400
[2022-01-11 19:33:47,311][root][INFO] - Av.rank validation: average rank 35.8384375, total questions=6400
[2022-01-11 19:33:47,311][root][INFO] - Av.rank validation: average rank 35.8384375, total questions=6400
[2022-01-11 19:33:47,311][root][INFO] - Av.rank validation: average rank 35.8384375, total questions=6400
[2022-01-11 19:33:47,446][root][INFO] - Av Loss per epoch=0.019067
[2022-01-11 19:33:47,447][root][INFO] - epoch total correct predictions=58434
[2022-01-11 19:33:47,448][root][INFO] - Av Loss per epoch=0.019067
[2022-01-11 19:33:47,448][root][INFO] - epoch total correct predictions=58434
[2022-01-11 19:33:47,450][root][INFO] - ***** Epoch 32 *****
[2022-01-11 19:33:47,451][root][INFO] - ***** Epoch 32 *****
[2022-01-11 19:33:47,452][root][INFO] - rank=3; Iteration start
[2022-01-11 19:33:47,452][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:33:47,452][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 19:33:47,452][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 19:33:47,453][root][INFO] - rank=1; Iteration start
[2022-01-11 19:33:47,453][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:33:47,453][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 19:33:47,453][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 19:33:47,479][root][INFO] - Av Loss per epoch=0.019067
[2022-01-11 19:33:47,480][root][INFO] - epoch total correct predictions=58434
[2022-01-11 19:33:47,482][root][INFO] - ***** Epoch 32 *****
[2022-01-11 19:33:47,484][root][INFO] - rank=2; Iteration start
[2022-01-11 19:33:47,484][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:33:47,484][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 19:33:47,485][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 19:33:52,341][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.31
[2022-01-11 19:33:52,342][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.31
[2022-01-11 19:33:52,342][root][INFO] - Av Loss per epoch=0.019067
[2022-01-11 19:33:52,342][root][INFO] - epoch total correct predictions=58434
[2022-01-11 19:33:52,345][root][INFO] - ***** Epoch 32 *****
[2022-01-11 19:33:52,348][root][INFO] - rank=0; Iteration start
[2022-01-11 19:33:52,348][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:33:52,348][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 19:33:52,349][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 19:33:53,429][root][INFO] - Epoch: 32: Step: 1/920, loss=0.040933, lr=0.000002
[2022-01-11 19:33:53,430][root][INFO] - Epoch: 32: Step: 1/920, loss=0.040933, lr=0.000002
[2022-01-11 19:33:53,430][root][INFO] - Epoch: 32: Step: 1/920, loss=0.040933, lr=0.000002
[2022-01-11 19:33:53,430][root][INFO] - Epoch: 32: Step: 1/920, loss=0.040933, lr=0.000002
[2022-01-11 19:35:33,400][root][INFO] - Train batch 100
[2022-01-11 19:35:33,400][root][INFO] - Avg. loss per last 100 batches: 0.024280
[2022-01-11 19:35:33,401][root][INFO] - Train batch 100
[2022-01-11 19:35:33,401][root][INFO] - Avg. loss per last 100 batches: 0.024280
[2022-01-11 19:35:33,401][root][INFO] - Train batch 100
[2022-01-11 19:35:33,401][root][INFO] - Avg. loss per last 100 batches: 0.024280
[2022-01-11 19:35:33,401][root][INFO] - Train batch 100
[2022-01-11 19:35:33,402][root][INFO] - Avg. loss per last 100 batches: 0.024280
[2022-01-11 19:35:35,408][root][INFO] - Epoch: 32: Step: 101/920, loss=0.008306, lr=0.000002
[2022-01-11 19:35:35,408][root][INFO] - Epoch: 32: Step: 101/920, loss=0.008306, lr=0.000002
[2022-01-11 19:35:35,409][root][INFO] - Epoch: 32: Step: 101/920, loss=0.008306, lr=0.000002
[2022-01-11 19:35:35,410][root][INFO] - Epoch: 32: Step: 101/920, loss=0.008306, lr=0.000002
[2022-01-11 19:37:13,570][root][INFO] - Train batch 200
[2022-01-11 19:37:13,570][root][INFO] - Avg. loss per last 100 batches: 0.021646
[2022-01-11 19:37:13,570][root][INFO] - Train batch 200
[2022-01-11 19:37:13,570][root][INFO] - Avg. loss per last 100 batches: 0.021646
[2022-01-11 19:37:13,571][root][INFO] - Train batch 200
[2022-01-11 19:37:13,571][root][INFO] - Avg. loss per last 100 batches: 0.021646
[2022-01-11 19:37:13,571][root][INFO] - Train batch 200
[2022-01-11 19:37:13,571][root][INFO] - Avg. loss per last 100 batches: 0.021646
[2022-01-11 19:37:14,594][root][INFO] - Epoch: 32: Step: 201/920, loss=0.025644, lr=0.000002
[2022-01-11 19:37:14,597][root][INFO] - Epoch: 32: Step: 201/920, loss=0.025644, lr=0.000002
[2022-01-11 19:37:14,598][root][INFO] - Epoch: 32: Step: 201/920, loss=0.025644, lr=0.000002
[2022-01-11 19:37:14,598][root][INFO] - Epoch: 32: Step: 201/920, loss=0.025644, lr=0.000002
[2022-01-11 19:38:53,972][root][INFO] - Train batch 300
[2022-01-11 19:38:53,972][root][INFO] - Avg. loss per last 100 batches: 0.019733
[2022-01-11 19:38:53,979][root][INFO] - Train batch 300
[2022-01-11 19:38:53,979][root][INFO] - Avg. loss per last 100 batches: 0.019733
[2022-01-11 19:38:53,982][root][INFO] - Train batch 300
[2022-01-11 19:38:53,982][root][INFO] - Avg. loss per last 100 batches: 0.019733
[2022-01-11 19:38:53,982][root][INFO] - Train batch 300
[2022-01-11 19:38:53,982][root][INFO] - Avg. loss per last 100 batches: 0.019733
[2022-01-11 19:38:55,039][root][INFO] - Epoch: 32: Step: 301/920, loss=0.004798, lr=0.000002
[2022-01-11 19:38:55,039][root][INFO] - Epoch: 32: Step: 301/920, loss=0.004798, lr=0.000002
[2022-01-11 19:38:55,041][root][INFO] - Epoch: 32: Step: 301/920, loss=0.004798, lr=0.000002
[2022-01-11 19:38:55,041][root][INFO] - Epoch: 32: Step: 301/920, loss=0.004798, lr=0.000002
[2022-01-11 19:40:33,738][root][INFO] - Train batch 400
[2022-01-11 19:40:33,738][root][INFO] - Avg. loss per last 100 batches: 0.017407
[2022-01-11 19:40:33,741][root][INFO] - Train batch 400
[2022-01-11 19:40:33,741][root][INFO] - Avg. loss per last 100 batches: 0.017407
[2022-01-11 19:40:33,742][root][INFO] - Train batch 400
[2022-01-11 19:40:33,742][root][INFO] - Avg. loss per last 100 batches: 0.017407
[2022-01-11 19:40:33,742][root][INFO] - Train batch 400
[2022-01-11 19:40:33,742][root][INFO] - Avg. loss per last 100 batches: 0.017407
[2022-01-11 19:40:34,634][root][INFO] - Epoch: 32: Step: 401/920, loss=0.009926, lr=0.000002
[2022-01-11 19:40:34,635][root][INFO] - Epoch: 32: Step: 401/920, loss=0.009926, lr=0.000002
[2022-01-11 19:40:34,635][root][INFO] - Epoch: 32: Step: 401/920, loss=0.009926, lr=0.000002
[2022-01-11 19:40:34,636][root][INFO] - Epoch: 32: Step: 401/920, loss=0.009926, lr=0.000002
[2022-01-11 19:42:14,205][root][INFO] - Train batch 500
[2022-01-11 19:42:14,205][root][INFO] - Avg. loss per last 100 batches: 0.019451
[2022-01-11 19:42:14,205][root][INFO] - Train batch 500
[2022-01-11 19:42:14,205][root][INFO] - Avg. loss per last 100 batches: 0.019451
[2022-01-11 19:42:14,205][root][INFO] - Train batch 500
[2022-01-11 19:42:14,205][root][INFO] - Avg. loss per last 100 batches: 0.019451
[2022-01-11 19:42:14,207][root][INFO] - Train batch 500
[2022-01-11 19:42:14,207][root][INFO] - Avg. loss per last 100 batches: 0.019451
[2022-01-11 19:42:15,252][root][INFO] - Epoch: 32: Step: 501/920, loss=0.010550, lr=0.000002
[2022-01-11 19:42:15,252][root][INFO] - Epoch: 32: Step: 501/920, loss=0.010550, lr=0.000002
[2022-01-11 19:42:15,252][root][INFO] - Epoch: 32: Step: 501/920, loss=0.010550, lr=0.000002
[2022-01-11 19:42:15,252][root][INFO] - Epoch: 32: Step: 501/920, loss=0.010550, lr=0.000002
[2022-01-11 19:43:53,754][root][INFO] - Train batch 600
[2022-01-11 19:43:53,754][root][INFO] - Avg. loss per last 100 batches: 0.013519
[2022-01-11 19:43:53,755][root][INFO] - Train batch 600
[2022-01-11 19:43:53,755][root][INFO] - Avg. loss per last 100 batches: 0.013519
[2022-01-11 19:43:53,755][root][INFO] - Train batch 600
[2022-01-11 19:43:53,755][root][INFO] - Avg. loss per last 100 batches: 0.013519
[2022-01-11 19:43:53,755][root][INFO] - Train batch 600
[2022-01-11 19:43:53,755][root][INFO] - Avg. loss per last 100 batches: 0.013519
[2022-01-11 19:43:54,802][root][INFO] - Epoch: 32: Step: 601/920, loss=0.022943, lr=0.000002
[2022-01-11 19:43:54,803][root][INFO] - Epoch: 32: Step: 601/920, loss=0.022943, lr=0.000002
[2022-01-11 19:43:54,804][root][INFO] - Epoch: 32: Step: 601/920, loss=0.022943, lr=0.000002
[2022-01-11 19:43:54,804][root][INFO] - Epoch: 32: Step: 601/920, loss=0.022943, lr=0.000002
[2022-01-11 19:45:36,260][root][INFO] - Train batch 700
[2022-01-11 19:45:36,260][root][INFO] - Avg. loss per last 100 batches: 0.020200
[2022-01-11 19:45:36,260][root][INFO] - Train batch 700
[2022-01-11 19:45:36,260][root][INFO] - Avg. loss per last 100 batches: 0.020200
[2022-01-11 19:45:36,260][root][INFO] - Train batch 700
[2022-01-11 19:45:36,261][root][INFO] - Avg. loss per last 100 batches: 0.020200
[2022-01-11 19:45:36,261][root][INFO] - Train batch 700
[2022-01-11 19:45:36,261][root][INFO] - Avg. loss per last 100 batches: 0.020200
[2022-01-11 19:45:37,230][root][INFO] - Epoch: 32: Step: 701/920, loss=0.007111, lr=0.000002
[2022-01-11 19:45:37,234][root][INFO] - Epoch: 32: Step: 701/920, loss=0.007111, lr=0.000002
[2022-01-11 19:45:37,234][root][INFO] - Epoch: 32: Step: 701/920, loss=0.007111, lr=0.000002
[2022-01-11 19:45:37,235][root][INFO] - Epoch: 32: Step: 701/920, loss=0.007111, lr=0.000002
[2022-01-11 19:47:17,087][root][INFO] - Train batch 800
[2022-01-11 19:47:17,087][root][INFO] - Avg. loss per last 100 batches: 0.022001
[2022-01-11 19:47:17,087][root][INFO] - Train batch 800
[2022-01-11 19:47:17,087][root][INFO] - Avg. loss per last 100 batches: 0.022001
[2022-01-11 19:47:17,088][root][INFO] - Train batch 800
[2022-01-11 19:47:17,088][root][INFO] - Avg. loss per last 100 batches: 0.022001
[2022-01-11 19:47:17,088][root][INFO] - Train batch 800
[2022-01-11 19:47:17,088][root][INFO] - Avg. loss per last 100 batches: 0.022001
[2022-01-11 19:47:18,086][root][INFO] - Epoch: 32: Step: 801/920, loss=0.018701, lr=0.000002
[2022-01-11 19:47:18,086][root][INFO] - Epoch: 32: Step: 801/920, loss=0.018701, lr=0.000002
[2022-01-11 19:47:18,088][root][INFO] - Epoch: 32: Step: 801/920, loss=0.018701, lr=0.000002
[2022-01-11 19:47:18,088][root][INFO] - Epoch: 32: Step: 801/920, loss=0.018701, lr=0.000002
[2022-01-11 19:48:55,217][root][INFO] - Train batch 900
[2022-01-11 19:48:55,218][root][INFO] - Avg. loss per last 100 batches: 0.018827
[2022-01-11 19:48:55,221][root][INFO] - Train batch 900
[2022-01-11 19:48:55,221][root][INFO] - Avg. loss per last 100 batches: 0.018827
[2022-01-11 19:48:55,221][root][INFO] - Train batch 900
[2022-01-11 19:48:55,221][root][INFO] - Avg. loss per last 100 batches: 0.018827
[2022-01-11 19:48:55,221][root][INFO] - Train batch 900
[2022-01-11 19:48:55,222][root][INFO] - Avg. loss per last 100 batches: 0.018827
[2022-01-11 19:48:56,141][root][INFO] - Epoch: 32: Step: 901/920, loss=0.009338, lr=0.000002
[2022-01-11 19:48:56,142][root][INFO] - Epoch: 32: Step: 901/920, loss=0.009338, lr=0.000002
[2022-01-11 19:48:56,143][root][INFO] - Epoch: 32: Step: 901/920, loss=0.009338, lr=0.000002
[2022-01-11 19:48:56,143][root][INFO] - Epoch: 32: Step: 901/920, loss=0.009338, lr=0.000002
[2022-01-11 19:49:16,729][root][INFO] - rank=2, Validation: Epoch: 32 Step: 920/920
[2022-01-11 19:49:16,729][root][INFO] - Average rank validation ...
[2022-01-11 19:49:16,730][root][INFO] - rank=2; Iteration start
[2022-01-11 19:49:16,730][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:49:16,730][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:49:16,730][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 19:49:16,731][root][INFO] - rank=3, Validation: Epoch: 32 Step: 920/920
[2022-01-11 19:49:16,731][root][INFO] - Average rank validation ...
[2022-01-11 19:49:16,732][root][INFO] - rank=0, Validation: Epoch: 32 Step: 920/920
[2022-01-11 19:49:16,732][root][INFO] - Average rank validation ...
[2022-01-11 19:49:16,732][root][INFO] - rank=3; Iteration start
[2022-01-11 19:49:16,732][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:49:16,732][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:49:16,732][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 19:49:16,733][root][INFO] - rank=0; Iteration start
[2022-01-11 19:49:16,733][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:49:16,733][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:49:16,734][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 19:49:16,734][root][INFO] - rank=1, Validation: Epoch: 32 Step: 920/920
[2022-01-11 19:49:16,734][root][INFO] - Average rank validation ...
[2022-01-11 19:49:16,735][root][INFO] - rank=1; Iteration start
[2022-01-11 19:49:16,735][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:49:16,735][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:49:16,735][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 19:55:43,521][root][INFO] - rank=0; last iteration 25
[2022-01-11 19:55:43,522][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:55:43,522][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 19:55:43,522][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:55:43,759][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:55:43,759][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 19:55:43,796][root][INFO] - rank=1; last iteration 25
[2022-01-11 19:55:43,796][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:55:43,796][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 19:55:43,796][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:55:44,032][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:55:44,032][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 19:55:46,490][root][INFO] - rank=3; last iteration 25
[2022-01-11 19:55:46,490][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:55:46,490][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 19:55:46,490][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:55:46,721][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:55:46,722][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 19:55:47,038][root][INFO] - rank=2; last iteration 25
[2022-01-11 19:55:47,038][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 19:55:47,038][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 19:55:47,038][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:55:47,273][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 19:55:47,273][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 19:56:00,247][root][INFO] - Av.rank validation: average rank 35.985625, total questions=6400
[2022-01-11 19:56:00,247][root][INFO] - Av.rank validation: average rank 35.985625, total questions=6400
[2022-01-11 19:56:00,247][root][INFO] - Av.rank validation: average rank 35.985625, total questions=6400
[2022-01-11 19:56:00,247][root][INFO] - Av.rank validation: average rank 35.985625, total questions=6400
[2022-01-11 19:56:00,381][root][INFO] - rank=1; last iteration 920
[2022-01-11 19:56:00,381][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 19:56:00,381][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 19:56:00,382][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:56:00,382][root][INFO] - Epoch finished on 1
[2022-01-11 19:56:00,382][root][INFO] - Average rank validation ...
[2022-01-11 19:56:00,383][root][INFO] - rank=1; Iteration start
[2022-01-11 19:56:00,383][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:56:00,384][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:56:00,384][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 19:56:00,394][root][INFO] - rank=3; last iteration 920
[2022-01-11 19:56:00,394][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 19:56:00,394][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 19:56:00,395][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:56:00,395][root][INFO] - Epoch finished on 3
[2022-01-11 19:56:00,395][root][INFO] - Average rank validation ...
[2022-01-11 19:56:00,396][root][INFO] - rank=3; Iteration start
[2022-01-11 19:56:00,396][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:56:00,396][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:56:00,396][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 19:56:00,396][root][INFO] - rank=2; last iteration 920
[2022-01-11 19:56:00,397][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 19:56:00,397][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 19:56:00,398][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:56:00,398][root][INFO] - Epoch finished on 2
[2022-01-11 19:56:00,398][root][INFO] - Average rank validation ...
[2022-01-11 19:56:00,399][root][INFO] - rank=2; Iteration start
[2022-01-11 19:56:00,399][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:56:00,399][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:56:00,399][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 19:56:03,952][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.32
[2022-01-11 19:56:03,953][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.32
[2022-01-11 19:56:03,954][root][INFO] - rank=0; last iteration 920
[2022-01-11 19:56:03,954][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 19:56:03,954][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 19:56:03,955][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 19:56:03,955][root][INFO] - Epoch finished on 0
[2022-01-11 19:56:03,955][root][INFO] - Average rank validation ...
[2022-01-11 19:56:03,956][root][INFO] - rank=0; Iteration start
[2022-01-11 19:56:03,956][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 19:56:03,957][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 19:56:03,957][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 20:02:27,297][root][INFO] - rank=1; last iteration 25
[2022-01-11 20:02:27,297][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:02:27,297][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 20:02:27,297][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:02:27,534][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:02:27,534][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 20:02:30,459][root][INFO] - rank=3; last iteration 25
[2022-01-11 20:02:30,459][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:02:30,459][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 20:02:30,459][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:02:30,685][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:02:30,685][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 20:02:31,269][root][INFO] - rank=0; last iteration 25
[2022-01-11 20:02:31,269][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:02:31,269][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 20:02:31,270][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:02:31,498][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:02:31,498][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 20:02:31,984][root][INFO] - rank=2; last iteration 25
[2022-01-11 20:02:31,984][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:02:31,984][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 20:02:31,984][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:02:32,213][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:02:32,213][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 20:02:45,472][root][INFO] - Av.rank validation: average rank 35.985625, total questions=6400
[2022-01-11 20:02:45,472][root][INFO] - Av.rank validation: average rank 35.985625, total questions=6400
[2022-01-11 20:02:45,472][root][INFO] - Av.rank validation: average rank 35.985625, total questions=6400
[2022-01-11 20:02:45,472][root][INFO] - Av.rank validation: average rank 35.985625, total questions=6400
[2022-01-11 20:02:45,604][root][INFO] - Av Loss per epoch=0.019604
[2022-01-11 20:02:45,604][root][INFO] - epoch total correct predictions=58409
[2022-01-11 20:02:45,606][root][INFO] - ***** Epoch 33 *****
[2022-01-11 20:02:45,608][root][INFO] - rank=1; Iteration start
[2022-01-11 20:02:45,608][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:02:45,608][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 20:02:45,609][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 20:02:45,617][root][INFO] - Av Loss per epoch=0.019604
[2022-01-11 20:02:45,617][root][INFO] - epoch total correct predictions=58409
[2022-01-11 20:02:45,620][root][INFO] - ***** Epoch 33 *****
[2022-01-11 20:02:45,621][root][INFO] - rank=3; Iteration start
[2022-01-11 20:02:45,622][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:02:45,622][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 20:02:45,622][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 20:02:45,649][root][INFO] - Av Loss per epoch=0.019604
[2022-01-11 20:02:45,649][root][INFO] - epoch total correct predictions=58409
[2022-01-11 20:02:45,652][root][INFO] - ***** Epoch 33 *****
[2022-01-11 20:02:45,654][root][INFO] - rank=2; Iteration start
[2022-01-11 20:02:45,654][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:02:45,654][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 20:02:45,654][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 20:02:50,268][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.32
[2022-01-11 20:02:50,268][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.32
[2022-01-11 20:02:50,269][root][INFO] - Av Loss per epoch=0.019604
[2022-01-11 20:02:50,269][root][INFO] - epoch total correct predictions=58409
[2022-01-11 20:02:50,271][root][INFO] - ***** Epoch 33 *****
[2022-01-11 20:02:50,273][root][INFO] - rank=0; Iteration start
[2022-01-11 20:02:50,273][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:02:50,273][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 20:02:50,273][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 20:02:51,323][root][INFO] - Epoch: 33: Step: 1/920, loss=0.008173, lr=0.000002
[2022-01-11 20:02:51,323][root][INFO] - Epoch: 33: Step: 1/920, loss=0.008173, lr=0.000002
[2022-01-11 20:02:51,323][root][INFO] - Epoch: 33: Step: 1/920, loss=0.008173, lr=0.000002
[2022-01-11 20:02:51,324][root][INFO] - Epoch: 33: Step: 1/920, loss=0.008173, lr=0.000002
[2022-01-11 20:04:30,919][root][INFO] - Train batch 100
[2022-01-11 20:04:30,919][root][INFO] - Avg. loss per last 100 batches: 0.014664
[2022-01-11 20:04:30,919][root][INFO] - Train batch 100
[2022-01-11 20:04:30,920][root][INFO] - Avg. loss per last 100 batches: 0.014664
[2022-01-11 20:04:30,920][root][INFO] - Train batch 100
[2022-01-11 20:04:30,920][root][INFO] - Avg. loss per last 100 batches: 0.014664
[2022-01-11 20:04:30,922][root][INFO] - Train batch 100
[2022-01-11 20:04:30,922][root][INFO] - Avg. loss per last 100 batches: 0.014664
[2022-01-11 20:04:32,737][root][INFO] - Epoch: 33: Step: 101/920, loss=0.038151, lr=0.000002
[2022-01-11 20:04:32,742][root][INFO] - Epoch: 33: Step: 101/920, loss=0.038151, lr=0.000002
[2022-01-11 20:04:32,750][root][INFO] - Epoch: 33: Step: 101/920, loss=0.038151, lr=0.000002
[2022-01-11 20:04:32,750][root][INFO] - Epoch: 33: Step: 101/920, loss=0.038151, lr=0.000002
[2022-01-11 20:06:11,969][root][INFO] - Train batch 200
[2022-01-11 20:06:11,969][root][INFO] - Train batch 200
[2022-01-11 20:06:11,969][root][INFO] - Avg. loss per last 100 batches: 0.019101
[2022-01-11 20:06:11,969][root][INFO] - Avg. loss per last 100 batches: 0.019101
[2022-01-11 20:06:11,969][root][INFO] - Train batch 200
[2022-01-11 20:06:11,969][root][INFO] - Avg. loss per last 100 batches: 0.019101
[2022-01-11 20:06:11,970][root][INFO] - Train batch 200
[2022-01-11 20:06:11,970][root][INFO] - Avg. loss per last 100 batches: 0.019101
[2022-01-11 20:06:12,935][root][INFO] - Epoch: 33: Step: 201/920, loss=0.000637, lr=0.000002
[2022-01-11 20:06:12,936][root][INFO] - Epoch: 33: Step: 201/920, loss=0.000637, lr=0.000002
[2022-01-11 20:06:12,936][root][INFO] - Epoch: 33: Step: 201/920, loss=0.000637, lr=0.000002
[2022-01-11 20:06:12,936][root][INFO] - Epoch: 33: Step: 201/920, loss=0.000637, lr=0.000002
[2022-01-11 20:07:51,627][root][INFO] - Train batch 300
[2022-01-11 20:07:51,628][root][INFO] - Avg. loss per last 100 batches: 0.016964
[2022-01-11 20:07:51,628][root][INFO] - Train batch 300
[2022-01-11 20:07:51,628][root][INFO] - Avg. loss per last 100 batches: 0.016964
[2022-01-11 20:07:51,629][root][INFO] - Train batch 300
[2022-01-11 20:07:51,629][root][INFO] - Avg. loss per last 100 batches: 0.016964
[2022-01-11 20:07:51,629][root][INFO] - Train batch 300
[2022-01-11 20:07:51,629][root][INFO] - Avg. loss per last 100 batches: 0.016964
[2022-01-11 20:07:52,561][root][INFO] - Epoch: 33: Step: 301/920, loss=0.001100, lr=0.000002
[2022-01-11 20:07:52,563][root][INFO] - Epoch: 33: Step: 301/920, loss=0.001100, lr=0.000002
[2022-01-11 20:07:52,564][root][INFO] - Epoch: 33: Step: 301/920, loss=0.001100, lr=0.000002
[2022-01-11 20:07:52,564][root][INFO] - Epoch: 33: Step: 301/920, loss=0.001100, lr=0.000002
[2022-01-11 20:09:33,854][root][INFO] - Train batch 400
[2022-01-11 20:09:33,854][root][INFO] - Avg. loss per last 100 batches: 0.014377
[2022-01-11 20:09:33,854][root][INFO] - Train batch 400
[2022-01-11 20:09:33,854][root][INFO] - Train batch 400
[2022-01-11 20:09:33,855][root][INFO] - Avg. loss per last 100 batches: 0.014377
[2022-01-11 20:09:33,855][root][INFO] - Avg. loss per last 100 batches: 0.014377
[2022-01-11 20:09:33,855][root][INFO] - Train batch 400
[2022-01-11 20:09:33,855][root][INFO] - Avg. loss per last 100 batches: 0.014377
[2022-01-11 20:09:34,857][root][INFO] - Epoch: 33: Step: 401/920, loss=0.000646, lr=0.000002
[2022-01-11 20:09:34,860][root][INFO] - Epoch: 33: Step: 401/920, loss=0.000646, lr=0.000002
[2022-01-11 20:09:34,861][root][INFO] - Epoch: 33: Step: 401/920, loss=0.000646, lr=0.000002
[2022-01-11 20:09:34,861][root][INFO] - Epoch: 33: Step: 401/920, loss=0.000646, lr=0.000002
[2022-01-11 20:11:13,984][root][INFO] - Train batch 500
[2022-01-11 20:11:13,984][root][INFO] - Avg. loss per last 100 batches: 0.014395
[2022-01-11 20:11:13,984][root][INFO] - Train batch 500
[2022-01-11 20:11:13,984][root][INFO] - Avg. loss per last 100 batches: 0.014395
[2022-01-11 20:11:13,984][root][INFO] - Train batch 500
[2022-01-11 20:11:13,984][root][INFO] - Avg. loss per last 100 batches: 0.014395
[2022-01-11 20:11:13,984][root][INFO] - Train batch 500
[2022-01-11 20:11:13,985][root][INFO] - Avg. loss per last 100 batches: 0.014395
[2022-01-11 20:11:15,001][root][INFO] - Epoch: 33: Step: 501/920, loss=0.003771, lr=0.000002
[2022-01-11 20:11:15,002][root][INFO] - Epoch: 33: Step: 501/920, loss=0.003771, lr=0.000002
[2022-01-11 20:11:15,002][root][INFO] - Epoch: 33: Step: 501/920, loss=0.003771, lr=0.000002
[2022-01-11 20:11:15,002][root][INFO] - Epoch: 33: Step: 501/920, loss=0.003771, lr=0.000002
[2022-01-11 20:12:52,673][root][INFO] - Train batch 600
[2022-01-11 20:12:52,673][root][INFO] - Avg. loss per last 100 batches: 0.016477
[2022-01-11 20:12:52,676][root][INFO] - Train batch 600
[2022-01-11 20:12:52,676][root][INFO] - Avg. loss per last 100 batches: 0.016477
[2022-01-11 20:12:52,677][root][INFO] - Train batch 600
[2022-01-11 20:12:52,677][root][INFO] - Avg. loss per last 100 batches: 0.016477
[2022-01-11 20:12:52,683][root][INFO] - Train batch 600
[2022-01-11 20:12:52,683][root][INFO] - Avg. loss per last 100 batches: 0.016477
[2022-01-11 20:12:53,591][root][INFO] - Epoch: 33: Step: 601/920, loss=0.011750, lr=0.000002
[2022-01-11 20:12:53,591][root][INFO] - Epoch: 33: Step: 601/920, loss=0.011750, lr=0.000002
[2022-01-11 20:12:53,591][root][INFO] - Epoch: 33: Step: 601/920, loss=0.011750, lr=0.000002
[2022-01-11 20:12:53,592][root][INFO] - Epoch: 33: Step: 601/920, loss=0.011750, lr=0.000002
[2022-01-11 20:14:34,735][root][INFO] - Train batch 700
[2022-01-11 20:14:34,735][root][INFO] - Avg. loss per last 100 batches: 0.017932
[2022-01-11 20:14:34,738][root][INFO] - Train batch 700
[2022-01-11 20:14:34,738][root][INFO] - Avg. loss per last 100 batches: 0.017932
[2022-01-11 20:14:34,738][root][INFO] - Train batch 700
[2022-01-11 20:14:34,738][root][INFO] - Avg. loss per last 100 batches: 0.017932
[2022-01-11 20:14:34,738][root][INFO] - Train batch 700
[2022-01-11 20:14:34,739][root][INFO] - Avg. loss per last 100 batches: 0.017932
[2022-01-11 20:14:35,614][root][INFO] - Epoch: 33: Step: 701/920, loss=0.000726, lr=0.000002
[2022-01-11 20:14:35,615][root][INFO] - Epoch: 33: Step: 701/920, loss=0.000726, lr=0.000002
[2022-01-11 20:14:35,615][root][INFO] - Epoch: 33: Step: 701/920, loss=0.000726, lr=0.000002
[2022-01-11 20:14:35,616][root][INFO] - Epoch: 33: Step: 701/920, loss=0.000726, lr=0.000002
[2022-01-11 20:16:15,731][root][INFO] - Train batch 800
[2022-01-11 20:16:15,731][root][INFO] - Avg. loss per last 100 batches: 0.021873
[2022-01-11 20:16:15,738][root][INFO] - Train batch 800
[2022-01-11 20:16:15,738][root][INFO] - Avg. loss per last 100 batches: 0.021873
[2022-01-11 20:16:15,738][root][INFO] - Train batch 800
[2022-01-11 20:16:15,738][root][INFO] - Avg. loss per last 100 batches: 0.021873
[2022-01-11 20:16:15,739][root][INFO] - Train batch 800
[2022-01-11 20:16:15,739][root][INFO] - Avg. loss per last 100 batches: 0.021873
[2022-01-11 20:16:16,628][root][INFO] - Epoch: 33: Step: 801/920, loss=0.052109, lr=0.000002
[2022-01-11 20:16:16,632][root][INFO] - Epoch: 33: Step: 801/920, loss=0.052109, lr=0.000002
[2022-01-11 20:16:16,632][root][INFO] - Epoch: 33: Step: 801/920, loss=0.052109, lr=0.000002
[2022-01-11 20:16:16,632][root][INFO] - Epoch: 33: Step: 801/920, loss=0.052109, lr=0.000002
[2022-01-11 20:17:53,450][root][INFO] - Train batch 900
[2022-01-11 20:17:53,450][root][INFO] - Avg. loss per last 100 batches: 0.019606
[2022-01-11 20:17:53,451][root][INFO] - Train batch 900
[2022-01-11 20:17:53,451][root][INFO] - Train batch 900
[2022-01-11 20:17:53,452][root][INFO] - Avg. loss per last 100 batches: 0.019606
[2022-01-11 20:17:53,452][root][INFO] - Avg. loss per last 100 batches: 0.019606
[2022-01-11 20:17:53,452][root][INFO] - Train batch 900
[2022-01-11 20:17:53,452][root][INFO] - Avg. loss per last 100 batches: 0.019606
[2022-01-11 20:17:54,306][root][INFO] - Epoch: 33: Step: 901/920, loss=0.035763, lr=0.000002
[2022-01-11 20:17:54,307][root][INFO] - Epoch: 33: Step: 901/920, loss=0.035763, lr=0.000002
[2022-01-11 20:17:54,309][root][INFO] - Epoch: 33: Step: 901/920, loss=0.035763, lr=0.000002
[2022-01-11 20:17:54,309][root][INFO] - Epoch: 33: Step: 901/920, loss=0.035763, lr=0.000002
[2022-01-11 20:18:14,077][root][INFO] - rank=2, Validation: Epoch: 33 Step: 920/920
[2022-01-11 20:18:14,077][root][INFO] - Average rank validation ...
[2022-01-11 20:18:14,078][root][INFO] - rank=2; Iteration start
[2022-01-11 20:18:14,078][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:18:14,078][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:18:14,078][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 20:18:14,079][root][INFO] - rank=0, Validation: Epoch: 33 Step: 920/920
[2022-01-11 20:18:14,079][root][INFO] - Average rank validation ...
[2022-01-11 20:18:14,081][root][INFO] - rank=0; Iteration start
[2022-01-11 20:18:14,081][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:18:14,081][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:18:14,081][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 20:18:14,081][root][INFO] - rank=1, Validation: Epoch: 33 Step: 920/920
[2022-01-11 20:18:14,081][root][INFO] - Average rank validation ...
[2022-01-11 20:18:14,082][root][INFO] - rank=3, Validation: Epoch: 33 Step: 920/920
[2022-01-11 20:18:14,082][root][INFO] - Average rank validation ...
[2022-01-11 20:18:14,083][root][INFO] - rank=1; Iteration start
[2022-01-11 20:18:14,083][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:18:14,083][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:18:14,083][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 20:18:14,083][root][INFO] - rank=3; Iteration start
[2022-01-11 20:18:14,083][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:18:14,083][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:18:14,083][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 20:24:40,576][root][INFO] - rank=0; last iteration 25
[2022-01-11 20:24:40,576][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:24:40,576][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 20:24:40,576][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:24:40,801][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:24:40,801][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 20:24:41,076][root][INFO] - rank=1; last iteration 25
[2022-01-11 20:24:41,076][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:24:41,076][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 20:24:41,076][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:24:41,310][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:24:41,310][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 20:24:45,199][root][INFO] - rank=3; last iteration 25
[2022-01-11 20:24:45,199][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:24:45,200][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 20:24:45,200][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:24:45,420][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:24:45,420][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 20:24:45,564][root][INFO] - rank=2; last iteration 25
[2022-01-11 20:24:45,564][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:24:45,564][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 20:24:45,564][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:24:45,795][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:24:45,795][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 20:24:58,742][root][INFO] - Av.rank validation: average rank 35.77421875, total questions=6400
[2022-01-11 20:24:58,742][root][INFO] - Av.rank validation: average rank 35.77421875, total questions=6400
[2022-01-11 20:24:58,742][root][INFO] - Av.rank validation: average rank 35.77421875, total questions=6400
[2022-01-11 20:24:58,742][root][INFO] - Av.rank validation: average rank 35.77421875, total questions=6400
[2022-01-11 20:24:58,870][root][INFO] - rank=1; last iteration 920
[2022-01-11 20:24:58,871][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 20:24:58,871][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 20:24:58,871][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:24:58,871][root][INFO] - Epoch finished on 1
[2022-01-11 20:24:58,872][root][INFO] - Average rank validation ...
[2022-01-11 20:24:58,873][root][INFO] - rank=1; Iteration start
[2022-01-11 20:24:58,873][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:24:58,873][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:24:58,873][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 20:24:58,889][root][INFO] - rank=3; last iteration 920
[2022-01-11 20:24:58,889][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 20:24:58,889][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 20:24:58,890][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:24:58,890][root][INFO] - Epoch finished on 3
[2022-01-11 20:24:58,890][root][INFO] - Average rank validation ...
[2022-01-11 20:24:58,890][root][INFO] - rank=2; last iteration 920
[2022-01-11 20:24:58,890][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 20:24:58,890][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 20:24:58,891][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:24:58,891][root][INFO] - Epoch finished on 2
[2022-01-11 20:24:58,891][root][INFO] - rank=3; Iteration start
[2022-01-11 20:24:58,891][root][INFO] - Average rank validation ...
[2022-01-11 20:24:58,891][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:24:58,891][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:24:58,891][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 20:24:58,892][root][INFO] - rank=2; Iteration start
[2022-01-11 20:24:58,893][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:24:58,893][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:24:58,893][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 20:25:02,460][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.33
[2022-01-11 20:25:02,460][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.33
[2022-01-11 20:25:02,460][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.33
[2022-01-11 20:25:02,462][root][INFO] - rank=0; last iteration 920
[2022-01-11 20:25:02,462][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 20:25:02,462][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 20:25:02,463][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:25:02,463][root][INFO] - Epoch finished on 0
[2022-01-11 20:25:02,463][root][INFO] - Average rank validation ...
[2022-01-11 20:25:02,464][root][INFO] - rank=0; Iteration start
[2022-01-11 20:25:02,464][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:25:02,464][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:25:02,464][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 20:31:24,815][root][INFO] - rank=1; last iteration 25
[2022-01-11 20:31:24,816][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:31:24,816][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 20:31:24,816][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:31:25,053][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:31:25,053][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 20:31:27,785][root][INFO] - rank=3; last iteration 25
[2022-01-11 20:31:27,785][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:31:27,785][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 20:31:27,785][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:31:27,866][root][INFO] - rank=0; last iteration 25
[2022-01-11 20:31:27,866][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:31:27,866][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 20:31:27,866][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:31:28,012][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:31:28,012][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 20:31:28,099][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:31:28,100][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 20:31:30,387][root][INFO] - rank=2; last iteration 25
[2022-01-11 20:31:30,387][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:31:30,387][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 20:31:30,387][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:31:30,619][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:31:30,619][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 20:31:43,715][root][INFO] - Av.rank validation: average rank 35.77421875, total questions=6400
[2022-01-11 20:31:43,715][root][INFO] - Av.rank validation: average rank 35.77421875, total questions=6400
[2022-01-11 20:31:43,715][root][INFO] - Av.rank validation: average rank 35.77421875, total questions=6400
[2022-01-11 20:31:43,715][root][INFO] - Av.rank validation: average rank 35.77421875, total questions=6400
[2022-01-11 20:31:43,866][root][INFO] - Av Loss per epoch=0.017350
[2022-01-11 20:31:43,866][root][INFO] - epoch total correct predictions=58486
[2022-01-11 20:31:43,869][root][INFO] - ***** Epoch 34 *****
[2022-01-11 20:31:43,871][root][INFO] - rank=3; Iteration start
[2022-01-11 20:31:43,871][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:31:43,871][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 20:31:43,871][root][INFO] - Av Loss per epoch=0.017350
[2022-01-11 20:31:43,871][root][INFO] - epoch total correct predictions=58486
[2022-01-11 20:31:43,872][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 20:31:43,874][root][INFO] - ***** Epoch 34 *****
[2022-01-11 20:31:43,876][root][INFO] - rank=1; Iteration start
[2022-01-11 20:31:43,876][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:31:43,876][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 20:31:43,877][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 20:31:43,902][root][INFO] - Av Loss per epoch=0.017350
[2022-01-11 20:31:43,902][root][INFO] - epoch total correct predictions=58486
[2022-01-11 20:31:43,904][root][INFO] - ***** Epoch 34 *****
[2022-01-11 20:31:43,906][root][INFO] - rank=2; Iteration start
[2022-01-11 20:31:43,906][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:31:43,906][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 20:31:43,907][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 20:31:48,604][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.33
[2022-01-11 20:31:48,604][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.33
[2022-01-11 20:31:48,604][root][INFO] - Av Loss per epoch=0.017350
[2022-01-11 20:31:48,604][root][INFO] - epoch total correct predictions=58486
[2022-01-11 20:31:48,607][root][INFO] - ***** Epoch 34 *****
[2022-01-11 20:31:48,609][root][INFO] - rank=0; Iteration start
[2022-01-11 20:31:48,609][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:31:48,609][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 20:31:48,609][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 20:31:49,688][root][INFO] - Epoch: 34: Step: 1/920, loss=0.058947, lr=0.000002
[2022-01-11 20:31:49,688][root][INFO] - Epoch: 34: Step: 1/920, loss=0.058947, lr=0.000002
[2022-01-11 20:31:49,689][root][INFO] - Epoch: 34: Step: 1/920, loss=0.058947, lr=0.000002
[2022-01-11 20:31:49,689][root][INFO] - Epoch: 34: Step: 1/920, loss=0.058947, lr=0.000002
[2022-01-11 20:33:30,973][root][INFO] - Train batch 100
[2022-01-11 20:33:30,974][root][INFO] - Avg. loss per last 100 batches: 0.018256
[2022-01-11 20:33:30,975][root][INFO] - Train batch 100
[2022-01-11 20:33:30,975][root][INFO] - Avg. loss per last 100 batches: 0.018256
[2022-01-11 20:33:30,977][root][INFO] - Train batch 100
[2022-01-11 20:33:30,977][root][INFO] - Avg. loss per last 100 batches: 0.018256
[2022-01-11 20:33:30,983][root][INFO] - Train batch 100
[2022-01-11 20:33:30,984][root][INFO] - Avg. loss per last 100 batches: 0.018256
[2022-01-11 20:33:31,840][root][INFO] - Epoch: 34: Step: 101/920, loss=0.001904, lr=0.000002
[2022-01-11 20:33:31,840][root][INFO] - Epoch: 34: Step: 101/920, loss=0.001904, lr=0.000002
[2022-01-11 20:33:31,841][root][INFO] - Epoch: 34: Step: 101/920, loss=0.001904, lr=0.000002
[2022-01-11 20:33:31,852][root][INFO] - Epoch: 34: Step: 101/920, loss=0.001904, lr=0.000002
[2022-01-11 20:35:13,318][root][INFO] - Train batch 200
[2022-01-11 20:35:13,318][root][INFO] - Avg. loss per last 100 batches: 0.017585
[2022-01-11 20:35:13,318][root][INFO] - Train batch 200
[2022-01-11 20:35:13,319][root][INFO] - Avg. loss per last 100 batches: 0.017585
[2022-01-11 20:35:13,319][root][INFO] - Train batch 200
[2022-01-11 20:35:13,319][root][INFO] - Avg. loss per last 100 batches: 0.017585
[2022-01-11 20:35:13,319][root][INFO] - Train batch 200
[2022-01-11 20:35:13,319][root][INFO] - Avg. loss per last 100 batches: 0.017585
[2022-01-11 20:35:14,368][root][INFO] - Epoch: 34: Step: 201/920, loss=0.000421, lr=0.000002
[2022-01-11 20:35:14,368][root][INFO] - Epoch: 34: Step: 201/920, loss=0.000421, lr=0.000002
[2022-01-11 20:35:14,369][root][INFO] - Epoch: 34: Step: 201/920, loss=0.000421, lr=0.000002
[2022-01-11 20:35:14,369][root][INFO] - Epoch: 34: Step: 201/920, loss=0.000421, lr=0.000002
[2022-01-11 20:36:50,633][root][INFO] - Train batch 300
[2022-01-11 20:36:50,633][root][INFO] - Avg. loss per last 100 batches: 0.015599
[2022-01-11 20:36:50,633][root][INFO] - Train batch 300
[2022-01-11 20:36:50,634][root][INFO] - Avg. loss per last 100 batches: 0.015599
[2022-01-11 20:36:50,634][root][INFO] - Train batch 300
[2022-01-11 20:36:50,635][root][INFO] - Avg. loss per last 100 batches: 0.015599
[2022-01-11 20:36:50,635][root][INFO] - Train batch 300
[2022-01-11 20:36:50,635][root][INFO] - Avg. loss per last 100 batches: 0.015599
[2022-01-11 20:36:51,659][root][INFO] - Epoch: 34: Step: 301/920, loss=0.019722, lr=0.000002
[2022-01-11 20:36:51,659][root][INFO] - Epoch: 34: Step: 301/920, loss=0.019722, lr=0.000002
[2022-01-11 20:36:51,660][root][INFO] - Epoch: 34: Step: 301/920, loss=0.019722, lr=0.000002
[2022-01-11 20:36:51,660][root][INFO] - Epoch: 34: Step: 301/920, loss=0.019722, lr=0.000002
[2022-01-11 20:38:30,599][root][INFO] - Train batch 400
[2022-01-11 20:38:30,599][root][INFO] - Avg. loss per last 100 batches: 0.016544
[2022-01-11 20:38:30,600][root][INFO] - Train batch 400
[2022-01-11 20:38:30,601][root][INFO] - Avg. loss per last 100 batches: 0.016544
[2022-01-11 20:38:30,601][root][INFO] - Train batch 400
[2022-01-11 20:38:30,601][root][INFO] - Avg. loss per last 100 batches: 0.016544
[2022-01-11 20:38:30,602][root][INFO] - Train batch 400
[2022-01-11 20:38:30,602][root][INFO] - Avg. loss per last 100 batches: 0.016544
[2022-01-11 20:38:31,466][root][INFO] - Epoch: 34: Step: 401/920, loss=0.014684, lr=0.000001
[2022-01-11 20:38:31,466][root][INFO] - Epoch: 34: Step: 401/920, loss=0.014684, lr=0.000001
[2022-01-11 20:38:31,466][root][INFO] - Epoch: 34: Step: 401/920, loss=0.014684, lr=0.000001
[2022-01-11 20:38:31,466][root][INFO] - Epoch: 34: Step: 401/920, loss=0.014684, lr=0.000001
[2022-01-11 20:40:13,434][root][INFO] - Train batch 500
[2022-01-11 20:40:13,435][root][INFO] - Avg. loss per last 100 batches: 0.023742
[2022-01-11 20:40:13,435][root][INFO] - Train batch 500
[2022-01-11 20:40:13,436][root][INFO] - Avg. loss per last 100 batches: 0.023742
[2022-01-11 20:40:13,436][root][INFO] - Train batch 500
[2022-01-11 20:40:13,436][root][INFO] - Avg. loss per last 100 batches: 0.023742
[2022-01-11 20:40:13,448][root][INFO] - Train batch 500
[2022-01-11 20:40:13,448][root][INFO] - Avg. loss per last 100 batches: 0.023742
[2022-01-11 20:40:14,501][root][INFO] - Epoch: 34: Step: 501/920, loss=0.007225, lr=0.000001
[2022-01-11 20:40:14,502][root][INFO] - Epoch: 34: Step: 501/920, loss=0.007225, lr=0.000001
[2022-01-11 20:40:14,503][root][INFO] - Epoch: 34: Step: 501/920, loss=0.007225, lr=0.000001
[2022-01-11 20:40:14,504][root][INFO] - Epoch: 34: Step: 501/920, loss=0.007225, lr=0.000001
[2022-01-11 20:41:52,657][root][INFO] - Train batch 600
[2022-01-11 20:41:52,657][root][INFO] - Avg. loss per last 100 batches: 0.015769
[2022-01-11 20:41:52,657][root][INFO] - Train batch 600
[2022-01-11 20:41:52,657][root][INFO] - Avg. loss per last 100 batches: 0.015769
[2022-01-11 20:41:52,658][root][INFO] - Train batch 600
[2022-01-11 20:41:52,658][root][INFO] - Avg. loss per last 100 batches: 0.015769
[2022-01-11 20:41:52,658][root][INFO] - Train batch 600
[2022-01-11 20:41:52,658][root][INFO] - Avg. loss per last 100 batches: 0.015769
[2022-01-11 20:41:53,711][root][INFO] - Epoch: 34: Step: 601/920, loss=0.004279, lr=0.000001
[2022-01-11 20:41:53,712][root][INFO] - Epoch: 34: Step: 601/920, loss=0.004279, lr=0.000001
[2022-01-11 20:41:53,713][root][INFO] - Epoch: 34: Step: 601/920, loss=0.004279, lr=0.000001
[2022-01-11 20:41:53,714][root][INFO] - Epoch: 34: Step: 601/920, loss=0.004279, lr=0.000001
[2022-01-11 20:43:33,949][root][INFO] - Train batch 700
[2022-01-11 20:43:33,949][root][INFO] - Avg. loss per last 100 batches: 0.013666
[2022-01-11 20:43:33,949][root][INFO] - Train batch 700
[2022-01-11 20:43:33,950][root][INFO] - Avg. loss per last 100 batches: 0.013666
[2022-01-11 20:43:33,950][root][INFO] - Train batch 700
[2022-01-11 20:43:33,950][root][INFO] - Avg. loss per last 100 batches: 0.013666
[2022-01-11 20:43:33,950][root][INFO] - Train batch 700
[2022-01-11 20:43:33,950][root][INFO] - Avg. loss per last 100 batches: 0.013666
[2022-01-11 20:43:35,002][root][INFO] - Epoch: 34: Step: 701/920, loss=0.004051, lr=0.000001
[2022-01-11 20:43:35,002][root][INFO] - Epoch: 34: Step: 701/920, loss=0.004051, lr=0.000001
[2022-01-11 20:43:35,004][root][INFO] - Epoch: 34: Step: 701/920, loss=0.004051, lr=0.000001
[2022-01-11 20:43:35,004][root][INFO] - Epoch: 34: Step: 701/920, loss=0.004051, lr=0.000001
[2022-01-11 20:45:14,251][root][INFO] - Train batch 800
[2022-01-11 20:45:14,251][root][INFO] - Avg. loss per last 100 batches: 0.017213
[2022-01-11 20:45:14,252][root][INFO] - Train batch 800
[2022-01-11 20:45:14,252][root][INFO] - Avg. loss per last 100 batches: 0.017213
[2022-01-11 20:45:14,252][root][INFO] - Train batch 800
[2022-01-11 20:45:14,252][root][INFO] - Avg. loss per last 100 batches: 0.017213
[2022-01-11 20:45:14,253][root][INFO] - Train batch 800
[2022-01-11 20:45:14,253][root][INFO] - Avg. loss per last 100 batches: 0.017213
[2022-01-11 20:45:15,259][root][INFO] - Epoch: 34: Step: 801/920, loss=0.001552, lr=0.000001
[2022-01-11 20:45:15,260][root][INFO] - Epoch: 34: Step: 801/920, loss=0.001552, lr=0.000001
[2022-01-11 20:45:15,260][root][INFO] - Epoch: 34: Step: 801/920, loss=0.001552, lr=0.000001
[2022-01-11 20:45:15,262][root][INFO] - Epoch: 34: Step: 801/920, loss=0.001552, lr=0.000001
[2022-01-11 20:46:46,057][root][INFO] - Train batch 900
[2022-01-11 20:46:46,057][root][INFO] - Avg. loss per last 100 batches: 0.017908
[2022-01-11 20:46:46,057][root][INFO] - Train batch 900
[2022-01-11 20:46:46,058][root][INFO] - Avg. loss per last 100 batches: 0.017908
[2022-01-11 20:46:46,058][root][INFO] - Train batch 900
[2022-01-11 20:46:46,058][root][INFO] - Avg. loss per last 100 batches: 0.017908
[2022-01-11 20:46:46,059][root][INFO] - Train batch 900
[2022-01-11 20:46:46,059][root][INFO] - Avg. loss per last 100 batches: 0.017908
[2022-01-11 20:46:46,898][root][INFO] - Epoch: 34: Step: 901/920, loss=0.005410, lr=0.000001
[2022-01-11 20:46:46,903][root][INFO] - Epoch: 34: Step: 901/920, loss=0.005410, lr=0.000001
[2022-01-11 20:46:46,906][root][INFO] - Epoch: 34: Step: 901/920, loss=0.005410, lr=0.000001
[2022-01-11 20:46:46,906][root][INFO] - Epoch: 34: Step: 901/920, loss=0.005410, lr=0.000001
[2022-01-11 20:47:03,964][root][INFO] - rank=0, Validation: Epoch: 34 Step: 920/920
[2022-01-11 20:47:03,965][root][INFO] - Average rank validation ...
[2022-01-11 20:47:03,966][root][INFO] - rank=2, Validation: Epoch: 34 Step: 920/920
[2022-01-11 20:47:03,966][root][INFO] - Average rank validation ...
[2022-01-11 20:47:03,966][root][INFO] - rank=0; Iteration start
[2022-01-11 20:47:03,966][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:47:03,966][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:47:03,966][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 20:47:03,967][root][INFO] - rank=3, Validation: Epoch: 34 Step: 920/920
[2022-01-11 20:47:03,967][root][INFO] - Average rank validation ...
[2022-01-11 20:47:03,967][root][INFO] - rank=2; Iteration start
[2022-01-11 20:47:03,967][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:47:03,967][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:47:03,967][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 20:47:03,967][root][INFO] - rank=1, Validation: Epoch: 34 Step: 920/920
[2022-01-11 20:47:03,967][root][INFO] - Average rank validation ...
[2022-01-11 20:47:03,968][root][INFO] - rank=3; Iteration start
[2022-01-11 20:47:03,968][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:47:03,968][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:47:03,968][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 20:47:03,969][root][INFO] - rank=1; Iteration start
[2022-01-11 20:47:03,969][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:47:03,969][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:47:03,969][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 20:53:27,771][root][INFO] - rank=0; last iteration 25
[2022-01-11 20:53:27,772][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:53:27,772][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 20:53:27,772][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:53:28,014][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:53:28,014][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 20:53:29,890][root][INFO] - rank=1; last iteration 25
[2022-01-11 20:53:29,890][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:53:29,890][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 20:53:29,890][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:53:30,129][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:53:30,130][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 20:53:32,036][root][INFO] - rank=3; last iteration 25
[2022-01-11 20:53:32,036][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:53:32,036][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 20:53:32,036][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:53:32,266][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:53:32,266][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 20:53:32,596][root][INFO] - rank=2; last iteration 25
[2022-01-11 20:53:32,596][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 20:53:32,596][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 20:53:32,596][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:53:32,830][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 20:53:32,831][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 20:53:45,606][root][INFO] - Av.rank validation: average rank 33.1559375, total questions=6400
[2022-01-11 20:53:45,607][root][INFO] - Av.rank validation: average rank 33.1559375, total questions=6400
[2022-01-11 20:53:45,607][root][INFO] - Av.rank validation: average rank 33.1559375, total questions=6400
[2022-01-11 20:53:45,607][root][INFO] - Av.rank validation: average rank 33.1559375, total questions=6400
[2022-01-11 20:53:45,731][root][INFO] - rank=3; last iteration 920
[2022-01-11 20:53:45,731][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 20:53:45,731][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 20:53:45,732][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:53:45,733][root][INFO] - Epoch finished on 3
[2022-01-11 20:53:45,733][root][INFO] - Average rank validation ...
[2022-01-11 20:53:45,734][root][INFO] - rank=3; Iteration start
[2022-01-11 20:53:45,734][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:53:45,734][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:53:45,734][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 20:53:45,736][root][INFO] - rank=2; last iteration 920
[2022-01-11 20:53:45,736][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 20:53:45,736][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 20:53:45,737][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:53:45,737][root][INFO] - Epoch finished on 2
[2022-01-11 20:53:45,737][root][INFO] - Average rank validation ...
[2022-01-11 20:53:45,738][root][INFO] - rank=2; Iteration start
[2022-01-11 20:53:45,738][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:53:45,738][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:53:45,738][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 20:53:45,746][root][INFO] - rank=1; last iteration 920
[2022-01-11 20:53:45,746][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 20:53:45,746][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 20:53:45,747][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:53:45,747][root][INFO] - Epoch finished on 1
[2022-01-11 20:53:45,748][root][INFO] - Average rank validation ...
[2022-01-11 20:53:45,749][root][INFO] - rank=1; Iteration start
[2022-01-11 20:53:45,749][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:53:45,749][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:53:45,749][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 20:53:49,277][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.34
[2022-01-11 20:53:49,277][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.34
[2022-01-11 20:53:49,277][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.34
[2022-01-11 20:53:49,279][root][INFO] - rank=0; last iteration 920
[2022-01-11 20:53:49,279][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 20:53:49,279][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 20:53:49,279][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 20:53:49,280][root][INFO] - Epoch finished on 0
[2022-01-11 20:53:49,280][root][INFO] - Average rank validation ...
[2022-01-11 20:53:49,281][root][INFO] - rank=0; Iteration start
[2022-01-11 20:53:49,281][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 20:53:49,281][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 20:53:49,281][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 21:00:13,092][root][INFO] - rank=1; last iteration 25
[2022-01-11 21:00:13,092][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:00:13,092][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 21:00:13,092][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:00:13,235][root][INFO] - rank=2; last iteration 25
[2022-01-11 21:00:13,236][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:00:13,236][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 21:00:13,236][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:00:13,318][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:00:13,319][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 21:00:13,465][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:00:13,465][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:00:14,135][root][INFO] - rank=3; last iteration 25
[2022-01-11 21:00:14,135][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:00:14,135][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 21:00:14,135][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:00:14,157][root][INFO] - rank=0; last iteration 25
[2022-01-11 21:00:14,157][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:00:14,157][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 21:00:14,157][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:00:14,361][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:00:14,361][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 21:00:14,385][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:00:14,385][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:00:27,418][root][INFO] - Av.rank validation: average rank 33.1559375, total questions=6400
[2022-01-11 21:00:27,418][root][INFO] - Av.rank validation: average rank 33.1559375, total questions=6400
[2022-01-11 21:00:27,418][root][INFO] - Av.rank validation: average rank 33.1559375, total questions=6400
[2022-01-11 21:00:27,418][root][INFO] - Av.rank validation: average rank 33.1559375, total questions=6400
[2022-01-11 21:00:27,537][root][INFO] - Av Loss per epoch=0.017358
[2022-01-11 21:00:27,537][root][INFO] - epoch total correct predictions=58496
[2022-01-11 21:00:27,540][root][INFO] - ***** Epoch 35 *****
[2022-01-11 21:00:27,541][root][INFO] - rank=2; Iteration start
[2022-01-11 21:00:27,541][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:00:27,541][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:00:27,542][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 21:00:27,546][root][INFO] - Av Loss per epoch=0.017358
[2022-01-11 21:00:27,546][root][INFO] - epoch total correct predictions=58496
[2022-01-11 21:00:27,549][root][INFO] - ***** Epoch 35 *****
[2022-01-11 21:00:27,549][root][INFO] - Av Loss per epoch=0.017358
[2022-01-11 21:00:27,549][root][INFO] - epoch total correct predictions=58496
[2022-01-11 21:00:27,551][root][INFO] - rank=3; Iteration start
[2022-01-11 21:00:27,551][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:00:27,551][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:00:27,551][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 21:00:27,551][root][INFO] - ***** Epoch 35 *****
[2022-01-11 21:00:27,553][root][INFO] - rank=1; Iteration start
[2022-01-11 21:00:27,553][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:00:27,553][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:00:27,554][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 21:00:32,140][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.34
[2022-01-11 21:00:32,141][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.34
[2022-01-11 21:00:32,141][root][INFO] - Av Loss per epoch=0.017358
[2022-01-11 21:00:32,141][root][INFO] - epoch total correct predictions=58496
[2022-01-11 21:00:32,144][root][INFO] - ***** Epoch 35 *****
[2022-01-11 21:00:32,147][root][INFO] - rank=0; Iteration start
[2022-01-11 21:00:32,147][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:00:32,147][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:00:32,148][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 21:00:33,031][root][INFO] - Epoch: 35: Step: 1/920, loss=0.001541, lr=0.000001
[2022-01-11 21:00:33,031][root][INFO] - Epoch: 35: Step: 1/920, loss=0.001541, lr=0.000001
[2022-01-11 21:00:33,031][root][INFO] - Epoch: 35: Step: 1/920, loss=0.001541, lr=0.000001
[2022-01-11 21:00:33,032][root][INFO] - Epoch: 35: Step: 1/920, loss=0.001541, lr=0.000001
[2022-01-11 21:01:57,941][root][INFO] - Train batch 100
[2022-01-11 21:01:57,941][root][INFO] - Avg. loss per last 100 batches: 0.013000
[2022-01-11 21:01:57,948][root][INFO] - Train batch 100
[2022-01-11 21:01:57,948][root][INFO] - Avg. loss per last 100 batches: 0.013000
[2022-01-11 21:01:57,948][root][INFO] - Train batch 100
[2022-01-11 21:01:57,948][root][INFO] - Avg. loss per last 100 batches: 0.013000
[2022-01-11 21:01:57,948][root][INFO] - Train batch 100
[2022-01-11 21:01:57,949][root][INFO] - Avg. loss per last 100 batches: 0.013000
[2022-01-11 21:01:58,786][root][INFO] - Epoch: 35: Step: 101/920, loss=0.019610, lr=0.000001
[2022-01-11 21:01:58,788][root][INFO] - Epoch: 35: Step: 101/920, loss=0.019610, lr=0.000001
[2022-01-11 21:01:58,793][root][INFO] - Epoch: 35: Step: 101/920, loss=0.019610, lr=0.000001
[2022-01-11 21:01:58,795][root][INFO] - Epoch: 35: Step: 101/920, loss=0.019610, lr=0.000001
[2022-01-11 21:03:26,518][root][INFO] - Train batch 200
[2022-01-11 21:03:26,518][root][INFO] - Avg. loss per last 100 batches: 0.018321
[2022-01-11 21:03:26,524][root][INFO] - Train batch 200
[2022-01-11 21:03:26,524][root][INFO] - Avg. loss per last 100 batches: 0.018321
[2022-01-11 21:03:26,527][root][INFO] - Train batch 200
[2022-01-11 21:03:26,527][root][INFO] - Avg. loss per last 100 batches: 0.018321
[2022-01-11 21:03:26,528][root][INFO] - Train batch 200
[2022-01-11 21:03:26,528][root][INFO] - Avg. loss per last 100 batches: 0.018321
[2022-01-11 21:03:27,366][root][INFO] - Epoch: 35: Step: 201/920, loss=0.039907, lr=0.000001
[2022-01-11 21:03:27,372][root][INFO] - Epoch: 35: Step: 201/920, loss=0.039907, lr=0.000001
[2022-01-11 21:03:27,375][root][INFO] - Epoch: 35: Step: 201/920, loss=0.039907, lr=0.000001
[2022-01-11 21:03:27,376][root][INFO] - Epoch: 35: Step: 201/920, loss=0.039907, lr=0.000001
[2022-01-11 21:04:54,171][root][INFO] - Train batch 300
[2022-01-11 21:04:54,171][root][INFO] - Avg. loss per last 100 batches: 0.015194
[2022-01-11 21:04:54,172][root][INFO] - Train batch 300
[2022-01-11 21:04:54,172][root][INFO] - Avg. loss per last 100 batches: 0.015194
[2022-01-11 21:04:54,173][root][INFO] - Train batch 300
[2022-01-11 21:04:54,173][root][INFO] - Avg. loss per last 100 batches: 0.015194
[2022-01-11 21:04:54,175][root][INFO] - Train batch 300
[2022-01-11 21:04:54,175][root][INFO] - Avg. loss per last 100 batches: 0.015194
[2022-01-11 21:04:55,011][root][INFO] - Epoch: 35: Step: 301/920, loss=0.020251, lr=0.000001
[2022-01-11 21:04:55,018][root][INFO] - Epoch: 35: Step: 301/920, loss=0.020251, lr=0.000001
[2022-01-11 21:04:55,019][root][INFO] - Epoch: 35: Step: 301/920, loss=0.020251, lr=0.000001
[2022-01-11 21:04:55,024][root][INFO] - Epoch: 35: Step: 301/920, loss=0.020251, lr=0.000001
[2022-01-11 21:06:19,850][root][INFO] - Train batch 400
[2022-01-11 21:06:19,850][root][INFO] - Avg. loss per last 100 batches: 0.018512
[2022-01-11 21:06:19,853][root][INFO] - Train batch 400
[2022-01-11 21:06:19,853][root][INFO] - Avg. loss per last 100 batches: 0.018512
[2022-01-11 21:06:19,853][root][INFO] - Train batch 400
[2022-01-11 21:06:19,853][root][INFO] - Avg. loss per last 100 batches: 0.018512
[2022-01-11 21:06:19,854][root][INFO] - Train batch 400
[2022-01-11 21:06:19,854][root][INFO] - Avg. loss per last 100 batches: 0.018512
[2022-01-11 21:06:20,694][root][INFO] - Epoch: 35: Step: 401/920, loss=0.003579, lr=0.000001
[2022-01-11 21:06:20,702][root][INFO] - Epoch: 35: Step: 401/920, loss=0.003579, lr=0.000001
[2022-01-11 21:06:20,702][root][INFO] - Epoch: 35: Step: 401/920, loss=0.003579, lr=0.000001
[2022-01-11 21:06:20,703][root][INFO] - Epoch: 35: Step: 401/920, loss=0.003579, lr=0.000001
[2022-01-11 21:07:48,410][root][INFO] - Train batch 500
[2022-01-11 21:07:48,410][root][INFO] - Avg. loss per last 100 batches: 0.013697
[2022-01-11 21:07:48,411][root][INFO] - Train batch 500
[2022-01-11 21:07:48,411][root][INFO] - Avg. loss per last 100 batches: 0.013697
[2022-01-11 21:07:48,416][root][INFO] - Train batch 500
[2022-01-11 21:07:48,416][root][INFO] - Avg. loss per last 100 batches: 0.013697
[2022-01-11 21:07:48,416][root][INFO] - Train batch 500
[2022-01-11 21:07:48,416][root][INFO] - Avg. loss per last 100 batches: 0.013697
[2022-01-11 21:07:49,259][root][INFO] - Epoch: 35: Step: 501/920, loss=0.007256, lr=0.000001
[2022-01-11 21:07:49,259][root][INFO] - Epoch: 35: Step: 501/920, loss=0.007256, lr=0.000001
[2022-01-11 21:07:49,263][root][INFO] - Epoch: 35: Step: 501/920, loss=0.007256, lr=0.000001
[2022-01-11 21:07:49,263][root][INFO] - Epoch: 35: Step: 501/920, loss=0.007256, lr=0.000001
[2022-01-11 21:09:16,685][root][INFO] - Train batch 600
[2022-01-11 21:09:16,686][root][INFO] - Avg. loss per last 100 batches: 0.016742
[2022-01-11 21:09:16,686][root][INFO] - Train batch 600
[2022-01-11 21:09:16,686][root][INFO] - Avg. loss per last 100 batches: 0.016742
[2022-01-11 21:09:16,690][root][INFO] - Train batch 600
[2022-01-11 21:09:16,690][root][INFO] - Avg. loss per last 100 batches: 0.016742
[2022-01-11 21:09:16,691][root][INFO] - Train batch 600
[2022-01-11 21:09:16,691][root][INFO] - Avg. loss per last 100 batches: 0.016742
[2022-01-11 21:09:17,534][root][INFO] - Epoch: 35: Step: 601/920, loss=0.006465, lr=0.000001
[2022-01-11 21:09:17,535][root][INFO] - Epoch: 35: Step: 601/920, loss=0.006465, lr=0.000001
[2022-01-11 21:09:17,538][root][INFO] - Epoch: 35: Step: 601/920, loss=0.006465, lr=0.000001
[2022-01-11 21:09:17,538][root][INFO] - Epoch: 35: Step: 601/920, loss=0.006465, lr=0.000001
[2022-01-11 21:10:43,177][root][INFO] - Train batch 700
[2022-01-11 21:10:43,178][root][INFO] - Avg. loss per last 100 batches: 0.012034
[2022-01-11 21:10:43,181][root][INFO] - Train batch 700
[2022-01-11 21:10:43,181][root][INFO] - Avg. loss per last 100 batches: 0.012034
[2022-01-11 21:10:43,183][root][INFO] - Train batch 700
[2022-01-11 21:10:43,183][root][INFO] - Avg. loss per last 100 batches: 0.012034
[2022-01-11 21:10:43,184][root][INFO] - Train batch 700
[2022-01-11 21:10:43,185][root][INFO] - Avg. loss per last 100 batches: 0.012034
[2022-01-11 21:10:44,023][root][INFO] - Epoch: 35: Step: 701/920, loss=0.005946, lr=0.000001
[2022-01-11 21:10:44,032][root][INFO] - Epoch: 35: Step: 701/920, loss=0.005946, lr=0.000001
[2022-01-11 21:10:44,032][root][INFO] - Epoch: 35: Step: 701/920, loss=0.005946, lr=0.000001
[2022-01-11 21:10:44,033][root][INFO] - Epoch: 35: Step: 701/920, loss=0.005946, lr=0.000001
[2022-01-11 21:12:09,798][root][INFO] - Train batch 800
[2022-01-11 21:12:09,798][root][INFO] - Avg. loss per last 100 batches: 0.018977
[2022-01-11 21:12:09,803][root][INFO] - Train batch 800
[2022-01-11 21:12:09,804][root][INFO] - Avg. loss per last 100 batches: 0.018977
[2022-01-11 21:12:09,805][root][INFO] - Train batch 800
[2022-01-11 21:12:09,805][root][INFO] - Avg. loss per last 100 batches: 0.018977
[2022-01-11 21:12:09,810][root][INFO] - Train batch 800
[2022-01-11 21:12:09,810][root][INFO] - Avg. loss per last 100 batches: 0.018977
[2022-01-11 21:12:10,644][root][INFO] - Epoch: 35: Step: 801/920, loss=0.032553, lr=0.000001
[2022-01-11 21:12:10,650][root][INFO] - Epoch: 35: Step: 801/920, loss=0.032553, lr=0.000001
[2022-01-11 21:12:10,655][root][INFO] - Epoch: 35: Step: 801/920, loss=0.032553, lr=0.000001
[2022-01-11 21:12:10,656][root][INFO] - Epoch: 35: Step: 801/920, loss=0.032553, lr=0.000001
[2022-01-11 21:13:38,315][root][INFO] - Train batch 900
[2022-01-11 21:13:38,315][root][INFO] - Avg. loss per last 100 batches: 0.016627
[2022-01-11 21:13:38,319][root][INFO] - Train batch 900
[2022-01-11 21:13:38,319][root][INFO] - Avg. loss per last 100 batches: 0.016627
[2022-01-11 21:13:38,322][root][INFO] - Train batch 900
[2022-01-11 21:13:38,322][root][INFO] - Avg. loss per last 100 batches: 0.016627
[2022-01-11 21:13:38,324][root][INFO] - Train batch 900
[2022-01-11 21:13:38,324][root][INFO] - Avg. loss per last 100 batches: 0.016627
[2022-01-11 21:13:39,165][root][INFO] - Epoch: 35: Step: 901/920, loss=0.011668, lr=0.000001
[2022-01-11 21:13:39,166][root][INFO] - Epoch: 35: Step: 901/920, loss=0.011668, lr=0.000001
[2022-01-11 21:13:39,167][root][INFO] - Epoch: 35: Step: 901/920, loss=0.011668, lr=0.000001
[2022-01-11 21:13:39,171][root][INFO] - Epoch: 35: Step: 901/920, loss=0.011668, lr=0.000001
[2022-01-11 21:13:55,264][root][INFO] - rank=0, Validation: Epoch: 35 Step: 920/920
[2022-01-11 21:13:55,265][root][INFO] - Average rank validation ...
[2022-01-11 21:13:55,266][root][INFO] - rank=0; Iteration start
[2022-01-11 21:13:55,266][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:13:55,266][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:13:55,266][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 21:13:55,273][root][INFO] - rank=2, Validation: Epoch: 35 Step: 920/920
[2022-01-11 21:13:55,273][root][INFO] - Average rank validation ...
[2022-01-11 21:13:55,274][root][INFO] - rank=1, Validation: Epoch: 35 Step: 920/920
[2022-01-11 21:13:55,274][root][INFO] - Average rank validation ...
[2022-01-11 21:13:55,274][root][INFO] - rank=3, Validation: Epoch: 35 Step: 920/920
[2022-01-11 21:13:55,274][root][INFO] - Average rank validation ...
[2022-01-11 21:13:55,274][root][INFO] - rank=2; Iteration start
[2022-01-11 21:13:55,274][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:13:55,275][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:13:55,275][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 21:13:55,275][root][INFO] - rank=1; Iteration start
[2022-01-11 21:13:55,275][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:13:55,275][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:13:55,275][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 21:13:55,275][root][INFO] - rank=3; Iteration start
[2022-01-11 21:13:55,276][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:13:55,276][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:13:55,276][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 21:20:19,922][root][INFO] - rank=0; last iteration 25
[2022-01-11 21:20:19,923][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:20:19,923][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 21:20:19,923][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:20:20,154][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:20:20,154][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:20:20,486][root][INFO] - rank=1; last iteration 25
[2022-01-11 21:20:20,486][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:20:20,486][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 21:20:20,486][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:20:20,720][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:20:20,720][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 21:20:22,714][root][INFO] - rank=3; last iteration 25
[2022-01-11 21:20:22,715][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:20:22,715][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 21:20:22,715][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:20:22,941][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:20:22,942][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 21:20:24,457][root][INFO] - rank=2; last iteration 25
[2022-01-11 21:20:24,457][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:20:24,457][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 21:20:24,457][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:20:24,692][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:20:24,692][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:20:37,515][root][INFO] - Av.rank validation: average rank 32.1096875, total questions=6400
[2022-01-11 21:20:37,515][root][INFO] - Av.rank validation: average rank 32.1096875, total questions=6400
[2022-01-11 21:20:37,515][root][INFO] - Av.rank validation: average rank 32.1096875, total questions=6400
[2022-01-11 21:20:37,516][root][INFO] - Av.rank validation: average rank 32.1096875, total questions=6400
[2022-01-11 21:20:37,637][root][INFO] - rank=2; last iteration 920
[2022-01-11 21:20:37,637][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 21:20:37,637][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 21:20:37,638][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:20:37,638][root][INFO] - Epoch finished on 2
[2022-01-11 21:20:37,638][root][INFO] - Average rank validation ...
[2022-01-11 21:20:37,640][root][INFO] - rank=2; Iteration start
[2022-01-11 21:20:37,640][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:20:37,640][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:20:37,640][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 21:20:37,643][root][INFO] - rank=3; last iteration 920
[2022-01-11 21:20:37,643][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 21:20:37,643][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 21:20:37,644][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:20:37,644][root][INFO] - Epoch finished on 3
[2022-01-11 21:20:37,644][root][INFO] - Average rank validation ...
[2022-01-11 21:20:37,645][root][INFO] - rank=3; Iteration start
[2022-01-11 21:20:37,645][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:20:37,645][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:20:37,645][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 21:20:37,654][root][INFO] - rank=1; last iteration 920
[2022-01-11 21:20:37,654][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 21:20:37,654][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 21:20:37,655][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:20:37,655][root][INFO] - Epoch finished on 1
[2022-01-11 21:20:37,655][root][INFO] - Average rank validation ...
[2022-01-11 21:20:37,656][root][INFO] - rank=1; Iteration start
[2022-01-11 21:20:37,657][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:20:37,657][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:20:37,657][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 21:20:41,059][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.35
[2022-01-11 21:20:41,060][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.35
[2022-01-11 21:20:41,060][root][INFO] - New Best validation checkpoint ./nq_out/dpr_biencoder.35
[2022-01-11 21:20:41,061][root][INFO] - rank=0; last iteration 920
[2022-01-11 21:20:41,061][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 21:20:41,061][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 21:20:41,062][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:20:41,062][root][INFO] - Epoch finished on 0
[2022-01-11 21:20:41,063][root][INFO] - Average rank validation ...
[2022-01-11 21:20:41,064][root][INFO] - rank=0; Iteration start
[2022-01-11 21:20:41,064][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:20:41,064][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:20:41,064][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 21:27:03,119][root][INFO] - rank=1; last iteration 25
[2022-01-11 21:27:03,119][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:27:03,119][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 21:27:03,119][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:27:03,352][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:27:03,352][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 21:27:05,163][root][INFO] - rank=0; last iteration 25
[2022-01-11 21:27:05,163][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:27:05,163][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 21:27:05,163][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:27:05,366][root][INFO] - rank=3; last iteration 25
[2022-01-11 21:27:05,366][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:27:05,366][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 21:27:05,366][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:27:05,401][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:27:05,401][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:27:05,597][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:27:05,597][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 21:27:07,769][root][INFO] - rank=2; last iteration 25
[2022-01-11 21:27:07,769][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:27:07,769][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 21:27:07,769][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:27:07,995][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:27:07,995][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:27:21,222][root][INFO] - Av.rank validation: average rank 32.1096875, total questions=6400
[2022-01-11 21:27:21,223][root][INFO] - Av.rank validation: average rank 32.1096875, total questions=6400
[2022-01-11 21:27:21,223][root][INFO] - Av.rank validation: average rank 32.1096875, total questions=6400
[2022-01-11 21:27:21,223][root][INFO] - Av.rank validation: average rank 32.1096875, total questions=6400
[2022-01-11 21:27:21,389][root][INFO] - Av Loss per epoch=0.015922
[2022-01-11 21:27:21,389][root][INFO] - epoch total correct predictions=58506
[2022-01-11 21:27:21,391][root][INFO] - ***** Epoch 36 *****
[2022-01-11 21:27:21,393][root][INFO] - rank=3; Iteration start
[2022-01-11 21:27:21,393][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:27:21,393][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:27:21,393][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 21:27:21,397][root][INFO] - Av Loss per epoch=0.015922
[2022-01-11 21:27:21,397][root][INFO] - epoch total correct predictions=58506
[2022-01-11 21:27:21,399][root][INFO] - ***** Epoch 36 *****
[2022-01-11 21:27:21,401][root][INFO] - rank=2; Iteration start
[2022-01-11 21:27:21,401][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:27:21,401][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:27:21,401][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 21:27:21,404][root][INFO] - Av Loss per epoch=0.015922
[2022-01-11 21:27:21,404][root][INFO] - epoch total correct predictions=58506
[2022-01-11 21:27:21,406][root][INFO] - ***** Epoch 36 *****
[2022-01-11 21:27:21,408][root][INFO] - rank=1; Iteration start
[2022-01-11 21:27:21,408][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:27:21,408][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:27:21,408][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 21:27:25,781][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.35
[2022-01-11 21:27:25,782][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.35
[2022-01-11 21:27:25,782][root][INFO] - Av Loss per epoch=0.015922
[2022-01-11 21:27:25,782][root][INFO] - epoch total correct predictions=58506
[2022-01-11 21:27:25,785][root][INFO] - ***** Epoch 36 *****
[2022-01-11 21:27:25,788][root][INFO] - rank=0; Iteration start
[2022-01-11 21:27:25,788][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:27:25,788][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:27:25,789][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 21:27:26,671][root][INFO] - Epoch: 36: Step: 1/920, loss=0.017410, lr=0.000001
[2022-01-11 21:27:26,671][root][INFO] - Epoch: 36: Step: 1/920, loss=0.017410, lr=0.000001
[2022-01-11 21:27:26,672][root][INFO] - Epoch: 36: Step: 1/920, loss=0.017410, lr=0.000001
[2022-01-11 21:27:26,675][root][INFO] - Epoch: 36: Step: 1/920, loss=0.017410, lr=0.000001
[2022-01-11 21:28:52,447][root][INFO] - Train batch 100
[2022-01-11 21:28:52,448][root][INFO] - Avg. loss per last 100 batches: 0.017736
[2022-01-11 21:28:52,448][root][INFO] - Train batch 100
[2022-01-11 21:28:52,448][root][INFO] - Avg. loss per last 100 batches: 0.017736
[2022-01-11 21:28:52,457][root][INFO] - Train batch 100
[2022-01-11 21:28:52,457][root][INFO] - Avg. loss per last 100 batches: 0.017736
[2022-01-11 21:28:52,458][root][INFO] - Train batch 100
[2022-01-11 21:28:52,458][root][INFO] - Avg. loss per last 100 batches: 0.017736
[2022-01-11 21:28:53,296][root][INFO] - Epoch: 36: Step: 101/920, loss=0.011251, lr=0.000001
[2022-01-11 21:28:53,301][root][INFO] - Epoch: 36: Step: 101/920, loss=0.011251, lr=0.000001
[2022-01-11 21:28:53,303][root][INFO] - Epoch: 36: Step: 101/920, loss=0.011251, lr=0.000001
[2022-01-11 21:28:53,305][root][INFO] - Epoch: 36: Step: 101/920, loss=0.011251, lr=0.000001
[2022-01-11 21:30:20,065][root][INFO] - Train batch 200
[2022-01-11 21:30:20,065][root][INFO] - Avg. loss per last 100 batches: 0.016474
[2022-01-11 21:30:20,066][root][INFO] - Train batch 200
[2022-01-11 21:30:20,066][root][INFO] - Avg. loss per last 100 batches: 0.016474
[2022-01-11 21:30:20,072][root][INFO] - Train batch 200
[2022-01-11 21:30:20,073][root][INFO] - Avg. loss per last 100 batches: 0.016474
[2022-01-11 21:30:20,075][root][INFO] - Train batch 200
[2022-01-11 21:30:20,075][root][INFO] - Avg. loss per last 100 batches: 0.016474
[2022-01-11 21:30:20,917][root][INFO] - Epoch: 36: Step: 201/920, loss=0.003541, lr=0.000001
[2022-01-11 21:30:20,917][root][INFO] - Epoch: 36: Step: 201/920, loss=0.003541, lr=0.000001
[2022-01-11 21:30:20,923][root][INFO] - Epoch: 36: Step: 201/920, loss=0.003541, lr=0.000001
[2022-01-11 21:30:20,924][root][INFO] - Epoch: 36: Step: 201/920, loss=0.003541, lr=0.000001
[2022-01-11 21:31:46,650][root][INFO] - Train batch 300
[2022-01-11 21:31:46,651][root][INFO] - Avg. loss per last 100 batches: 0.013550
[2022-01-11 21:31:46,655][root][INFO] - Train batch 300
[2022-01-11 21:31:46,655][root][INFO] - Avg. loss per last 100 batches: 0.013550
[2022-01-11 21:31:46,660][root][INFO] - Train batch 300
[2022-01-11 21:31:46,660][root][INFO] - Avg. loss per last 100 batches: 0.013550
[2022-01-11 21:31:46,661][root][INFO] - Train batch 300
[2022-01-11 21:31:46,661][root][INFO] - Avg. loss per last 100 batches: 0.013550
[2022-01-11 21:31:47,502][root][INFO] - Epoch: 36: Step: 301/920, loss=0.005154, lr=0.000001
[2022-01-11 21:31:47,508][root][INFO] - Epoch: 36: Step: 301/920, loss=0.005154, lr=0.000001
[2022-01-11 21:31:47,509][root][INFO] - Epoch: 36: Step: 301/920, loss=0.005154, lr=0.000001
[2022-01-11 21:31:47,509][root][INFO] - Epoch: 36: Step: 301/920, loss=0.005154, lr=0.000001
[2022-01-11 21:33:14,964][root][INFO] - Train batch 400
[2022-01-11 21:33:14,964][root][INFO] - Avg. loss per last 100 batches: 0.013944
[2022-01-11 21:33:14,969][root][INFO] - Train batch 400
[2022-01-11 21:33:14,969][root][INFO] - Avg. loss per last 100 batches: 0.013944
[2022-01-11 21:33:14,976][root][INFO] - Train batch 400
[2022-01-11 21:33:14,977][root][INFO] - Avg. loss per last 100 batches: 0.013944
[2022-01-11 21:33:14,977][root][INFO] - Train batch 400
[2022-01-11 21:33:14,977][root][INFO] - Avg. loss per last 100 batches: 0.013944
[2022-01-11 21:33:15,812][root][INFO] - Epoch: 36: Step: 401/920, loss=0.005075, lr=0.000001
[2022-01-11 21:33:15,822][root][INFO] - Epoch: 36: Step: 401/920, loss=0.005075, lr=0.000001
[2022-01-11 21:33:15,825][root][INFO] - Epoch: 36: Step: 401/920, loss=0.005075, lr=0.000001
[2022-01-11 21:33:15,826][root][INFO] - Epoch: 36: Step: 401/920, loss=0.005075, lr=0.000001
[2022-01-11 21:34:42,476][root][INFO] - Train batch 500
[2022-01-11 21:34:42,476][root][INFO] - Avg. loss per last 100 batches: 0.019606
[2022-01-11 21:34:42,476][root][INFO] - Train batch 500
[2022-01-11 21:34:42,476][root][INFO] - Avg. loss per last 100 batches: 0.019606
[2022-01-11 21:34:42,476][root][INFO] - Train batch 500
[2022-01-11 21:34:42,476][root][INFO] - Avg. loss per last 100 batches: 0.019606
[2022-01-11 21:34:42,477][root][INFO] - Train batch 500
[2022-01-11 21:34:42,477][root][INFO] - Avg. loss per last 100 batches: 0.019606
[2022-01-11 21:34:43,326][root][INFO] - Epoch: 36: Step: 501/920, loss=0.000884, lr=0.000001
[2022-01-11 21:34:43,326][root][INFO] - Epoch: 36: Step: 501/920, loss=0.000884, lr=0.000001
[2022-01-11 21:34:43,327][root][INFO] - Epoch: 36: Step: 501/920, loss=0.000884, lr=0.000001
[2022-01-11 21:34:43,327][root][INFO] - Epoch: 36: Step: 501/920, loss=0.000884, lr=0.000001
[2022-01-11 21:36:09,911][root][INFO] - Train batch 600
[2022-01-11 21:36:09,912][root][INFO] - Avg. loss per last 100 batches: 0.016996
[2022-01-11 21:36:09,912][root][INFO] - Train batch 600
[2022-01-11 21:36:09,912][root][INFO] - Avg. loss per last 100 batches: 0.016996
[2022-01-11 21:36:09,913][root][INFO] - Train batch 600
[2022-01-11 21:36:09,913][root][INFO] - Avg. loss per last 100 batches: 0.016996
[2022-01-11 21:36:09,913][root][INFO] - Train batch 600
[2022-01-11 21:36:09,913][root][INFO] - Avg. loss per last 100 batches: 0.016996
[2022-01-11 21:36:10,760][root][INFO] - Epoch: 36: Step: 601/920, loss=0.010472, lr=0.000001
[2022-01-11 21:36:10,760][root][INFO] - Epoch: 36: Step: 601/920, loss=0.010472, lr=0.000001
[2022-01-11 21:36:10,760][root][INFO] - Epoch: 36: Step: 601/920, loss=0.010472, lr=0.000001
[2022-01-11 21:36:10,760][root][INFO] - Epoch: 36: Step: 601/920, loss=0.010472, lr=0.000001
[2022-01-11 21:37:36,569][root][INFO] - Train batch 700
[2022-01-11 21:37:36,569][root][INFO] - Avg. loss per last 100 batches: 0.017822
[2022-01-11 21:37:36,577][root][INFO] - Train batch 700
[2022-01-11 21:37:36,578][root][INFO] - Avg. loss per last 100 batches: 0.017822
[2022-01-11 21:37:36,578][root][INFO] - Train batch 700
[2022-01-11 21:37:36,578][root][INFO] - Avg. loss per last 100 batches: 0.017822
[2022-01-11 21:37:36,579][root][INFO] - Train batch 700
[2022-01-11 21:37:36,579][root][INFO] - Avg. loss per last 100 batches: 0.017822
[2022-01-11 21:37:37,427][root][INFO] - Epoch: 36: Step: 701/920, loss=0.001600, lr=0.000001
[2022-01-11 21:37:37,427][root][INFO] - Epoch: 36: Step: 701/920, loss=0.001600, lr=0.000001
[2022-01-11 21:37:37,428][root][INFO] - Epoch: 36: Step: 701/920, loss=0.001600, lr=0.000001
[2022-01-11 21:37:37,428][root][INFO] - Epoch: 36: Step: 701/920, loss=0.001600, lr=0.000001
[2022-01-11 21:39:04,786][root][INFO] - Train batch 800
[2022-01-11 21:39:04,786][root][INFO] - Avg. loss per last 100 batches: 0.018024
[2022-01-11 21:39:04,791][root][INFO] - Train batch 800
[2022-01-11 21:39:04,791][root][INFO] - Avg. loss per last 100 batches: 0.018024
[2022-01-11 21:39:04,794][root][INFO] - Train batch 800
[2022-01-11 21:39:04,794][root][INFO] - Avg. loss per last 100 batches: 0.018024
[2022-01-11 21:39:04,795][root][INFO] - Train batch 800
[2022-01-11 21:39:04,795][root][INFO] - Avg. loss per last 100 batches: 0.018024
[2022-01-11 21:39:05,639][root][INFO] - Epoch: 36: Step: 801/920, loss=0.045659, lr=0.000001
[2022-01-11 21:39:05,639][root][INFO] - Epoch: 36: Step: 801/920, loss=0.045659, lr=0.000001
[2022-01-11 21:39:05,639][root][INFO] - Epoch: 36: Step: 801/920, loss=0.045659, lr=0.000001
[2022-01-11 21:39:05,642][root][INFO] - Epoch: 36: Step: 801/920, loss=0.045659, lr=0.000001
[2022-01-11 21:40:32,418][root][INFO] - Train batch 900
[2022-01-11 21:40:32,418][root][INFO] - Avg. loss per last 100 batches: 0.019306
[2022-01-11 21:40:32,426][root][INFO] - Train batch 900
[2022-01-11 21:40:32,426][root][INFO] - Avg. loss per last 100 batches: 0.019306
[2022-01-11 21:40:32,427][root][INFO] - Train batch 900
[2022-01-11 21:40:32,427][root][INFO] - Avg. loss per last 100 batches: 0.019306
[2022-01-11 21:40:32,427][root][INFO] - Train batch 900
[2022-01-11 21:40:32,427][root][INFO] - Avg. loss per last 100 batches: 0.019306
[2022-01-11 21:40:33,274][root][INFO] - Epoch: 36: Step: 901/920, loss=0.025618, lr=0.000001
[2022-01-11 21:40:33,274][root][INFO] - Epoch: 36: Step: 901/920, loss=0.025618, lr=0.000001
[2022-01-11 21:40:33,275][root][INFO] - Epoch: 36: Step: 901/920, loss=0.025618, lr=0.000001
[2022-01-11 21:40:33,275][root][INFO] - Epoch: 36: Step: 901/920, loss=0.025618, lr=0.000001
[2022-01-11 21:40:49,379][root][INFO] - rank=1, Validation: Epoch: 36 Step: 920/920
[2022-01-11 21:40:49,379][root][INFO] - Average rank validation ...
[2022-01-11 21:40:49,380][root][INFO] - rank=3, Validation: Epoch: 36 Step: 920/920
[2022-01-11 21:40:49,380][root][INFO] - Average rank validation ...
[2022-01-11 21:40:49,380][root][INFO] - rank=1; Iteration start
[2022-01-11 21:40:49,381][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:40:49,381][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:40:49,381][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 21:40:49,381][root][INFO] - rank=3; Iteration start
[2022-01-11 21:40:49,381][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:40:49,381][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:40:49,382][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 21:40:49,385][root][INFO] - rank=0, Validation: Epoch: 36 Step: 920/920
[2022-01-11 21:40:49,385][root][INFO] - Average rank validation ...
[2022-01-11 21:40:49,386][root][INFO] - rank=2, Validation: Epoch: 36 Step: 920/920
[2022-01-11 21:40:49,386][root][INFO] - Average rank validation ...
[2022-01-11 21:40:49,386][root][INFO] - rank=0; Iteration start
[2022-01-11 21:40:49,386][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:40:49,386][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:40:49,387][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 21:40:49,387][root][INFO] - rank=2; Iteration start
[2022-01-11 21:40:49,387][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:40:49,387][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:40:49,387][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 21:47:13,217][root][INFO] - rank=0; last iteration 25
[2022-01-11 21:47:13,218][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:47:13,218][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 21:47:13,218][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:47:13,436][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:47:13,437][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:47:15,538][root][INFO] - rank=1; last iteration 25
[2022-01-11 21:47:15,539][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:47:15,539][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 21:47:15,539][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:47:15,778][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:47:15,778][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 21:47:17,334][root][INFO] - rank=3; last iteration 25
[2022-01-11 21:47:17,334][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:47:17,334][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 21:47:17,334][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:47:17,562][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:47:17,562][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 21:47:18,166][root][INFO] - rank=2; last iteration 25
[2022-01-11 21:47:18,166][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:47:18,166][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 21:47:18,166][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:47:18,402][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:47:18,402][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:47:31,608][root][INFO] - Av.rank validation: average rank 33.0565625, total questions=6400
[2022-01-11 21:47:31,608][root][INFO] - Av.rank validation: average rank 33.0565625, total questions=6400
[2022-01-11 21:47:31,608][root][INFO] - Av.rank validation: average rank 33.0565625, total questions=6400
[2022-01-11 21:47:31,608][root][INFO] - Av.rank validation: average rank 33.0565625, total questions=6400
[2022-01-11 21:47:31,777][root][INFO] - rank=3; last iteration 920
[2022-01-11 21:47:31,777][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 21:47:31,777][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 21:47:31,778][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:47:31,778][root][INFO] - Epoch finished on 3
[2022-01-11 21:47:31,778][root][INFO] - rank=2; last iteration 920
[2022-01-11 21:47:31,778][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 21:47:31,779][root][INFO] - Average rank validation ...
[2022-01-11 21:47:31,779][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 21:47:31,779][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:47:31,780][root][INFO] - Epoch finished on 2
[2022-01-11 21:47:31,780][root][INFO] - Average rank validation ...
[2022-01-11 21:47:31,780][root][INFO] - rank=3; Iteration start
[2022-01-11 21:47:31,780][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:47:31,780][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:47:31,780][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 21:47:31,781][root][INFO] - rank=2; Iteration start
[2022-01-11 21:47:31,781][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:47:31,781][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:47:31,781][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 21:47:31,783][root][INFO] - rank=1; last iteration 920
[2022-01-11 21:47:31,783][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 21:47:31,783][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 21:47:31,784][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:47:31,784][root][INFO] - Epoch finished on 1
[2022-01-11 21:47:31,784][root][INFO] - Average rank validation ...
[2022-01-11 21:47:31,786][root][INFO] - rank=1; Iteration start
[2022-01-11 21:47:31,786][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:47:31,786][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:47:31,786][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 21:47:35,122][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.36
[2022-01-11 21:47:35,122][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.36
[2022-01-11 21:47:35,124][root][INFO] - rank=0; last iteration 920
[2022-01-11 21:47:35,124][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 21:47:35,124][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 21:47:35,125][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:47:35,125][root][INFO] - Epoch finished on 0
[2022-01-11 21:47:35,125][root][INFO] - Average rank validation ...
[2022-01-11 21:47:35,126][root][INFO] - rank=0; Iteration start
[2022-01-11 21:47:35,126][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:47:35,126][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 21:47:35,126][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 21:53:57,854][root][INFO] - rank=1; last iteration 25
[2022-01-11 21:53:57,854][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:53:57,854][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 21:53:57,854][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:53:58,086][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:53:58,086][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 21:53:58,968][root][INFO] - rank=0; last iteration 25
[2022-01-11 21:53:58,969][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:53:58,969][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 21:53:58,969][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:53:59,198][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:53:59,198][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:54:00,023][root][INFO] - rank=3; last iteration 25
[2022-01-11 21:54:00,023][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:54:00,023][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 21:54:00,023][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:54:00,248][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:54:00,248][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 21:54:00,382][root][INFO] - rank=2; last iteration 25
[2022-01-11 21:54:00,382][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 21:54:00,382][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 21:54:00,382][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 21:54:00,659][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 21:54:00,659][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 21:54:14,145][root][INFO] - Av.rank validation: average rank 33.0565625, total questions=6400
[2022-01-11 21:54:14,145][root][INFO] - Av.rank validation: average rank 33.0565625, total questions=6400
[2022-01-11 21:54:14,145][root][INFO] - Av.rank validation: average rank 33.0565625, total questions=6400
[2022-01-11 21:54:14,145][root][INFO] - Av.rank validation: average rank 33.0565625, total questions=6400
[2022-01-11 21:54:14,361][root][INFO] - Av Loss per epoch=0.017015
[2022-01-11 21:54:14,361][root][INFO] - epoch total correct predictions=58488
[2022-01-11 21:54:14,362][root][INFO] - Av Loss per epoch=0.017015
[2022-01-11 21:54:14,362][root][INFO] - epoch total correct predictions=58488
[2022-01-11 21:54:14,364][root][INFO] - ***** Epoch 37 *****
[2022-01-11 21:54:14,365][root][INFO] - ***** Epoch 37 *****
[2022-01-11 21:54:14,365][root][INFO] - rank=3; Iteration start
[2022-01-11 21:54:14,365][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:54:14,366][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:54:14,366][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 21:54:14,367][root][INFO] - rank=2; Iteration start
[2022-01-11 21:54:14,367][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:54:14,367][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:54:14,367][root][INFO] - Av Loss per epoch=0.017015
[2022-01-11 21:54:14,367][root][INFO] - epoch total correct predictions=58488
[2022-01-11 21:54:14,367][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 21:54:14,370][root][INFO] - ***** Epoch 37 *****
[2022-01-11 21:54:14,372][root][INFO] - rank=1; Iteration start
[2022-01-11 21:54:14,372][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:54:14,372][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:54:14,372][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 21:54:18,807][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.36
[2022-01-11 21:54:18,807][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.36
[2022-01-11 21:54:18,808][root][INFO] - Av Loss per epoch=0.017015
[2022-01-11 21:54:18,808][root][INFO] - epoch total correct predictions=58488
[2022-01-11 21:54:18,810][root][INFO] - ***** Epoch 37 *****
[2022-01-11 21:54:18,812][root][INFO] - rank=0; Iteration start
[2022-01-11 21:54:18,813][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 21:54:18,813][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 21:54:18,813][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 21:54:19,693][root][INFO] - Epoch: 37: Step: 1/920, loss=0.006335, lr=0.000001
[2022-01-11 21:54:19,694][root][INFO] - Epoch: 37: Step: 1/920, loss=0.006335, lr=0.000001
[2022-01-11 21:54:19,694][root][INFO] - Epoch: 37: Step: 1/920, loss=0.006335, lr=0.000001
[2022-01-11 21:54:19,695][root][INFO] - Epoch: 37: Step: 1/920, loss=0.006335, lr=0.000001
[2022-01-11 21:55:45,516][root][INFO] - Train batch 100
[2022-01-11 21:55:45,516][root][INFO] - Avg. loss per last 100 batches: 0.017200
[2022-01-11 21:55:45,520][root][INFO] - Train batch 100
[2022-01-11 21:55:45,521][root][INFO] - Avg. loss per last 100 batches: 0.017200
[2022-01-11 21:55:45,520][root][INFO] - Train batch 100
[2022-01-11 21:55:45,521][root][INFO] - Avg. loss per last 100 batches: 0.017200
[2022-01-11 21:55:45,521][root][INFO] - Train batch 100
[2022-01-11 21:55:45,521][root][INFO] - Avg. loss per last 100 batches: 0.017200
[2022-01-11 21:55:46,363][root][INFO] - Epoch: 37: Step: 101/920, loss=0.000352, lr=0.000001
[2022-01-11 21:55:46,369][root][INFO] - Epoch: 37: Step: 101/920, loss=0.000352, lr=0.000001
[2022-01-11 21:55:46,369][root][INFO] - Epoch: 37: Step: 101/920, loss=0.000352, lr=0.000001
[2022-01-11 21:55:46,369][root][INFO] - Epoch: 37: Step: 101/920, loss=0.000352, lr=0.000001
[2022-01-11 21:57:13,175][root][INFO] - Train batch 200
[2022-01-11 21:57:13,175][root][INFO] - Avg. loss per last 100 batches: 0.018083
[2022-01-11 21:57:13,175][root][INFO] - Train batch 200
[2022-01-11 21:57:13,175][root][INFO] - Avg. loss per last 100 batches: 0.018083
[2022-01-11 21:57:13,175][root][INFO] - Train batch 200
[2022-01-11 21:57:13,175][root][INFO] - Avg. loss per last 100 batches: 0.018083
[2022-01-11 21:57:13,175][root][INFO] - Train batch 200
[2022-01-11 21:57:13,175][root][INFO] - Avg. loss per last 100 batches: 0.018083
[2022-01-11 21:57:14,016][root][INFO] - Epoch: 37: Step: 201/920, loss=0.064581, lr=0.000001
[2022-01-11 21:57:14,021][root][INFO] - Epoch: 37: Step: 201/920, loss=0.064581, lr=0.000001
[2022-01-11 21:57:14,024][root][INFO] - Epoch: 37: Step: 201/920, loss=0.064581, lr=0.000001
[2022-01-11 21:57:14,025][root][INFO] - Epoch: 37: Step: 201/920, loss=0.064581, lr=0.000001
[2022-01-11 21:58:39,614][root][INFO] - Train batch 300
[2022-01-11 21:58:39,614][root][INFO] - Avg. loss per last 100 batches: 0.018929
[2022-01-11 21:58:39,616][root][INFO] - Train batch 300
[2022-01-11 21:58:39,617][root][INFO] - Avg. loss per last 100 batches: 0.018929
[2022-01-11 21:58:39,617][root][INFO] - Train batch 300
[2022-01-11 21:58:39,617][root][INFO] - Avg. loss per last 100 batches: 0.018929
[2022-01-11 21:58:39,618][root][INFO] - Train batch 300
[2022-01-11 21:58:39,618][root][INFO] - Avg. loss per last 100 batches: 0.018929
[2022-01-11 21:58:40,453][root][INFO] - Epoch: 37: Step: 301/920, loss=0.013147, lr=0.000001
[2022-01-11 21:58:40,454][root][INFO] - Epoch: 37: Step: 301/920, loss=0.013147, lr=0.000001
[2022-01-11 21:58:40,461][root][INFO] - Epoch: 37: Step: 301/920, loss=0.013147, lr=0.000001
[2022-01-11 21:58:40,463][root][INFO] - Epoch: 37: Step: 301/920, loss=0.013147, lr=0.000001
[2022-01-11 22:00:07,632][root][INFO] - Train batch 400
[2022-01-11 22:00:07,632][root][INFO] - Train batch 400
[2022-01-11 22:00:07,632][root][INFO] - Avg. loss per last 100 batches: 0.017836
[2022-01-11 22:00:07,632][root][INFO] - Avg. loss per last 100 batches: 0.017836
[2022-01-11 22:00:07,636][root][INFO] - Train batch 400
[2022-01-11 22:00:07,636][root][INFO] - Avg. loss per last 100 batches: 0.017836
[2022-01-11 22:00:07,647][root][INFO] - Train batch 400
[2022-01-11 22:00:07,647][root][INFO] - Avg. loss per last 100 batches: 0.017836
[2022-01-11 22:00:08,493][root][INFO] - Epoch: 37: Step: 401/920, loss=0.002914, lr=0.000001
[2022-01-11 22:00:08,496][root][INFO] - Epoch: 37: Step: 401/920, loss=0.002914, lr=0.000001
[2022-01-11 22:00:08,496][root][INFO] - Epoch: 37: Step: 401/920, loss=0.002914, lr=0.000001
[2022-01-11 22:00:08,512][root][INFO] - Epoch: 37: Step: 401/920, loss=0.002914, lr=0.000001
[2022-01-11 22:01:36,296][root][INFO] - Train batch 500
[2022-01-11 22:01:36,296][root][INFO] - Avg. loss per last 100 batches: 0.012319
[2022-01-11 22:01:36,299][root][INFO] - Train batch 500
[2022-01-11 22:01:36,299][root][INFO] - Avg. loss per last 100 batches: 0.012319
[2022-01-11 22:01:36,300][root][INFO] - Train batch 500
[2022-01-11 22:01:36,300][root][INFO] - Avg. loss per last 100 batches: 0.012319
[2022-01-11 22:01:36,314][root][INFO] - Train batch 500
[2022-01-11 22:01:36,314][root][INFO] - Avg. loss per last 100 batches: 0.012319
[2022-01-11 22:01:37,159][root][INFO] - Epoch: 37: Step: 501/920, loss=0.048557, lr=0.000001
[2022-01-11 22:01:37,162][root][INFO] - Epoch: 37: Step: 501/920, loss=0.048557, lr=0.000001
[2022-01-11 22:01:37,163][root][INFO] - Epoch: 37: Step: 501/920, loss=0.048557, lr=0.000001
[2022-01-11 22:01:37,172][root][INFO] - Epoch: 37: Step: 501/920, loss=0.048557, lr=0.000001
[2022-01-11 22:03:05,103][root][INFO] - Train batch 600
[2022-01-11 22:03:05,103][root][INFO] - Avg. loss per last 100 batches: 0.017279
[2022-01-11 22:03:05,105][root][INFO] - Train batch 600
[2022-01-11 22:03:05,105][root][INFO] - Avg. loss per last 100 batches: 0.017279
[2022-01-11 22:03:05,106][root][INFO] - Train batch 600
[2022-01-11 22:03:05,106][root][INFO] - Avg. loss per last 100 batches: 0.017279
[2022-01-11 22:03:05,118][root][INFO] - Train batch 600
[2022-01-11 22:03:05,118][root][INFO] - Avg. loss per last 100 batches: 0.017279
[2022-01-11 22:03:06,930][root][INFO] - Epoch: 37: Step: 601/920, loss=0.023966, lr=0.000001
[2022-01-11 22:03:06,932][root][INFO] - Epoch: 37: Step: 601/920, loss=0.023966, lr=0.000001
[2022-01-11 22:03:06,935][root][INFO] - Epoch: 37: Step: 601/920, loss=0.023966, lr=0.000001
[2022-01-11 22:03:06,946][root][INFO] - Epoch: 37: Step: 601/920, loss=0.023966, lr=0.000001
[2022-01-11 22:04:33,977][root][INFO] - Train batch 700
[2022-01-11 22:04:33,977][root][INFO] - Avg. loss per last 100 batches: 0.014189
[2022-01-11 22:04:33,978][root][INFO] - Train batch 700
[2022-01-11 22:04:33,978][root][INFO] - Avg. loss per last 100 batches: 0.014189
[2022-01-11 22:04:33,986][root][INFO] - Train batch 700
[2022-01-11 22:04:33,986][root][INFO] - Avg. loss per last 100 batches: 0.014189
[2022-01-11 22:04:33,999][root][INFO] - Train batch 700
[2022-01-11 22:04:33,999][root][INFO] - Avg. loss per last 100 batches: 0.014189
[2022-01-11 22:04:34,838][root][INFO] - Epoch: 37: Step: 701/920, loss=0.003712, lr=0.000001
[2022-01-11 22:04:34,844][root][INFO] - Epoch: 37: Step: 701/920, loss=0.003712, lr=0.000001
[2022-01-11 22:04:34,848][root][INFO] - Epoch: 37: Step: 701/920, loss=0.003712, lr=0.000001
[2022-01-11 22:04:34,862][root][INFO] - Epoch: 37: Step: 701/920, loss=0.003712, lr=0.000001
[2022-01-11 22:06:01,460][root][INFO] - Train batch 800
[2022-01-11 22:06:01,460][root][INFO] - Avg. loss per last 100 batches: 0.014741
[2022-01-11 22:06:01,462][root][INFO] - Train batch 800
[2022-01-11 22:06:01,462][root][INFO] - Avg. loss per last 100 batches: 0.014741
[2022-01-11 22:06:01,462][root][INFO] - Train batch 800
[2022-01-11 22:06:01,462][root][INFO] - Avg. loss per last 100 batches: 0.014741
[2022-01-11 22:06:01,464][root][INFO] - Train batch 800
[2022-01-11 22:06:01,464][root][INFO] - Avg. loss per last 100 batches: 0.014741
[2022-01-11 22:06:02,301][root][INFO] - Epoch: 37: Step: 801/920, loss=0.002933, lr=0.000001
[2022-01-11 22:06:02,311][root][INFO] - Epoch: 37: Step: 801/920, loss=0.002933, lr=0.000001
[2022-01-11 22:06:02,313][root][INFO] - Epoch: 37: Step: 801/920, loss=0.002933, lr=0.000001
[2022-01-11 22:06:02,314][root][INFO] - Epoch: 37: Step: 801/920, loss=0.002933, lr=0.000001
[2022-01-11 22:07:29,013][root][INFO] - Train batch 900
[2022-01-11 22:07:29,013][root][INFO] - Avg. loss per last 100 batches: 0.014234
[2022-01-11 22:07:29,018][root][INFO] - Train batch 900
[2022-01-11 22:07:29,019][root][INFO] - Avg. loss per last 100 batches: 0.014234
[2022-01-11 22:07:29,021][root][INFO] - Train batch 900
[2022-01-11 22:07:29,021][root][INFO] - Avg. loss per last 100 batches: 0.014234
[2022-01-11 22:07:29,021][root][INFO] - Train batch 900
[2022-01-11 22:07:29,022][root][INFO] - Avg. loss per last 100 batches: 0.014234
[2022-01-11 22:07:29,866][root][INFO] - Epoch: 37: Step: 901/920, loss=0.028278, lr=0.000001
[2022-01-11 22:07:29,869][root][INFO] - Epoch: 37: Step: 901/920, loss=0.028278, lr=0.000001
[2022-01-11 22:07:29,869][root][INFO] - Epoch: 37: Step: 901/920, loss=0.028278, lr=0.000001
[2022-01-11 22:07:29,870][root][INFO] - Epoch: 37: Step: 901/920, loss=0.028278, lr=0.000001
[2022-01-11 22:07:46,929][root][INFO] - rank=3, Validation: Epoch: 37 Step: 920/920
[2022-01-11 22:07:46,929][root][INFO] - Average rank validation ...
[2022-01-11 22:07:46,931][root][INFO] - rank=3; Iteration start
[2022-01-11 22:07:46,931][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:07:46,931][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:07:46,931][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 22:07:46,932][root][INFO] - rank=2, Validation: Epoch: 37 Step: 920/920
[2022-01-11 22:07:46,932][root][INFO] - Average rank validation ...
[2022-01-11 22:07:46,934][root][INFO] - rank=2; Iteration start
[2022-01-11 22:07:46,934][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:07:46,934][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:07:46,934][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 22:07:46,936][root][INFO] - rank=0, Validation: Epoch: 37 Step: 920/920
[2022-01-11 22:07:46,936][root][INFO] - Average rank validation ...
[2022-01-11 22:07:46,937][root][INFO] - rank=1, Validation: Epoch: 37 Step: 920/920
[2022-01-11 22:07:46,937][root][INFO] - Average rank validation ...
[2022-01-11 22:07:46,938][root][INFO] - rank=0; Iteration start
[2022-01-11 22:07:46,938][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:07:46,938][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:07:46,938][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 22:07:46,938][root][INFO] - rank=1; Iteration start
[2022-01-11 22:07:46,938][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:07:46,938][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:07:46,938][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 22:14:10,636][root][INFO] - rank=0; last iteration 25
[2022-01-11 22:14:10,636][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:14:10,636][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 22:14:10,637][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:14:10,874][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:14:10,874][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 22:14:13,036][root][INFO] - rank=1; last iteration 25
[2022-01-11 22:14:13,036][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:14:13,037][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 22:14:13,037][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:14:13,280][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:14:13,281][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 22:14:14,800][root][INFO] - rank=3; last iteration 25
[2022-01-11 22:14:14,801][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:14:14,801][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 22:14:14,801][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:14:15,038][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:14:15,039][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 22:14:15,465][root][INFO] - rank=2; last iteration 25
[2022-01-11 22:14:15,465][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:14:15,465][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 22:14:15,465][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:14:15,732][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:14:15,732][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 22:14:29,225][root][INFO] - Av.rank validation: average rank 32.719375, total questions=6400
[2022-01-11 22:14:29,225][root][INFO] - Av.rank validation: average rank 32.719375, total questions=6400
[2022-01-11 22:14:29,225][root][INFO] - Av.rank validation: average rank 32.719375, total questions=6400
[2022-01-11 22:14:29,225][root][INFO] - Av.rank validation: average rank 32.719375, total questions=6400
[2022-01-11 22:14:29,440][root][INFO] - rank=1; last iteration 920
[2022-01-11 22:14:29,440][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 22:14:29,440][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 22:14:29,441][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:14:29,442][root][INFO] - Epoch finished on 1
[2022-01-11 22:14:29,442][root][INFO] - Average rank validation ...
[2022-01-11 22:14:29,443][root][INFO] - rank=3; last iteration 920
[2022-01-11 22:14:29,443][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 22:14:29,443][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 22:14:29,443][root][INFO] - rank=1; Iteration start
[2022-01-11 22:14:29,443][root][INFO] - rank=2; last iteration 920
[2022-01-11 22:14:29,443][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:14:29,443][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 22:14:29,443][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:14:29,443][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 22:14:29,443][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 22:14:29,444][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:14:29,444][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:14:29,444][root][INFO] - Epoch finished on 2
[2022-01-11 22:14:29,444][root][INFO] - Epoch finished on 3
[2022-01-11 22:14:29,444][root][INFO] - Average rank validation ...
[2022-01-11 22:14:29,444][root][INFO] - Average rank validation ...
[2022-01-11 22:14:29,445][root][INFO] - rank=2; Iteration start
[2022-01-11 22:14:29,445][root][INFO] - rank=3; Iteration start
[2022-01-11 22:14:29,445][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:14:29,445][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:14:29,445][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:14:29,445][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 22:14:29,445][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:14:29,445][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 22:14:33,572][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.37
[2022-01-11 22:14:33,572][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.37
[2022-01-11 22:14:33,574][root][INFO] - rank=0; last iteration 920
[2022-01-11 22:14:33,574][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 22:14:33,574][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 22:14:33,574][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:14:33,575][root][INFO] - Epoch finished on 0
[2022-01-11 22:14:33,575][root][INFO] - Average rank validation ...
[2022-01-11 22:14:33,576][root][INFO] - rank=0; Iteration start
[2022-01-11 22:14:33,576][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:14:33,576][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:14:33,576][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 22:20:53,964][root][INFO] - rank=1; last iteration 25
[2022-01-11 22:20:53,964][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:20:53,964][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 22:20:53,964][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:20:54,195][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:20:54,195][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 22:20:56,156][root][INFO] - rank=3; last iteration 25
[2022-01-11 22:20:56,156][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:20:56,156][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 22:20:56,156][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:20:56,391][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:20:56,391][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 22:20:58,060][root][INFO] - rank=0; last iteration 25
[2022-01-11 22:20:58,060][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:20:58,060][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 22:20:58,060][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:20:58,269][root][INFO] - rank=2; last iteration 25
[2022-01-11 22:20:58,269][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:20:58,269][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 22:20:58,269][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:20:58,355][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:20:58,355][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 22:20:58,556][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:20:58,556][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 22:21:11,959][root][INFO] - Av.rank validation: average rank 32.719375, total questions=6400
[2022-01-11 22:21:11,959][root][INFO] - Av.rank validation: average rank 32.719375, total questions=6400
[2022-01-11 22:21:11,959][root][INFO] - Av.rank validation: average rank 32.719375, total questions=6400
[2022-01-11 22:21:11,959][root][INFO] - Av.rank validation: average rank 32.719375, total questions=6400
[2022-01-11 22:21:12,175][root][INFO] - Av Loss per epoch=0.016112
[2022-01-11 22:21:12,175][root][INFO] - epoch total correct predictions=58516
[2022-01-11 22:21:12,177][root][INFO] - Av Loss per epoch=0.016112
[2022-01-11 22:21:12,177][root][INFO] - epoch total correct predictions=58516
[2022-01-11 22:21:12,177][root][INFO] - ***** Epoch 38 *****
[2022-01-11 22:21:12,179][root][INFO] - rank=3; Iteration start
[2022-01-11 22:21:12,179][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:21:12,179][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 22:21:12,180][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 22:21:12,179][root][INFO] - ***** Epoch 38 *****
[2022-01-11 22:21:12,181][root][INFO] - Av Loss per epoch=0.016112
[2022-01-11 22:21:12,181][root][INFO] - epoch total correct predictions=58516
[2022-01-11 22:21:12,181][root][INFO] - rank=1; Iteration start
[2022-01-11 22:21:12,181][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:21:12,181][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 22:21:12,182][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 22:21:12,184][root][INFO] - ***** Epoch 38 *****
[2022-01-11 22:21:12,186][root][INFO] - rank=2; Iteration start
[2022-01-11 22:21:12,186][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:21:12,186][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 22:21:12,186][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 22:21:17,435][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.37
[2022-01-11 22:21:17,436][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.37
[2022-01-11 22:21:17,436][root][INFO] - Av Loss per epoch=0.016112
[2022-01-11 22:21:17,436][root][INFO] - epoch total correct predictions=58516
[2022-01-11 22:21:17,438][root][INFO] - ***** Epoch 38 *****
[2022-01-11 22:21:17,440][root][INFO] - rank=0; Iteration start
[2022-01-11 22:21:17,440][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:21:17,440][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 22:21:17,440][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 22:21:18,319][root][INFO] - Epoch: 38: Step: 1/920, loss=0.003789, lr=0.000001
[2022-01-11 22:21:18,320][root][INFO] - Epoch: 38: Step: 1/920, loss=0.003789, lr=0.000001
[2022-01-11 22:21:18,320][root][INFO] - Epoch: 38: Step: 1/920, loss=0.003789, lr=0.000001
[2022-01-11 22:21:18,320][root][INFO] - Epoch: 38: Step: 1/920, loss=0.003789, lr=0.000001
[2022-01-11 22:22:45,079][root][INFO] - Train batch 100
[2022-01-11 22:22:45,079][root][INFO] - Avg. loss per last 100 batches: 0.010077
[2022-01-11 22:22:45,086][root][INFO] - Train batch 100
[2022-01-11 22:22:45,086][root][INFO] - Avg. loss per last 100 batches: 0.010077
[2022-01-11 22:22:45,086][root][INFO] - Train batch 100
[2022-01-11 22:22:45,086][root][INFO] - Avg. loss per last 100 batches: 0.010077
[2022-01-11 22:22:45,087][root][INFO] - Train batch 100
[2022-01-11 22:22:45,087][root][INFO] - Avg. loss per last 100 batches: 0.010077
[2022-01-11 22:22:45,933][root][INFO] - Epoch: 38: Step: 101/920, loss=0.002706, lr=0.000001
[2022-01-11 22:22:45,933][root][INFO] - Epoch: 38: Step: 101/920, loss=0.002706, lr=0.000001
[2022-01-11 22:22:45,934][root][INFO] - Epoch: 38: Step: 101/920, loss=0.002706, lr=0.000001
[2022-01-11 22:22:45,935][root][INFO] - Epoch: 38: Step: 101/920, loss=0.002706, lr=0.000001
[2022-01-11 22:24:12,467][root][INFO] - Train batch 200
[2022-01-11 22:24:12,467][root][INFO] - Avg. loss per last 100 batches: 0.016470
[2022-01-11 22:24:12,472][root][INFO] - Train batch 200
[2022-01-11 22:24:12,472][root][INFO] - Avg. loss per last 100 batches: 0.016470
[2022-01-11 22:24:12,478][root][INFO] - Train batch 200
[2022-01-11 22:24:12,478][root][INFO] - Avg. loss per last 100 batches: 0.016470
[2022-01-11 22:24:12,478][root][INFO] - Train batch 200
[2022-01-11 22:24:12,478][root][INFO] - Avg. loss per last 100 batches: 0.016470
[2022-01-11 22:24:13,319][root][INFO] - Epoch: 38: Step: 201/920, loss=0.000672, lr=0.000000
[2022-01-11 22:24:13,327][root][INFO] - Epoch: 38: Step: 201/920, loss=0.000672, lr=0.000000
[2022-01-11 22:24:13,327][root][INFO] - Epoch: 38: Step: 201/920, loss=0.000672, lr=0.000000
[2022-01-11 22:24:13,328][root][INFO] - Epoch: 38: Step: 201/920, loss=0.000672, lr=0.000000
[2022-01-11 22:25:39,057][root][INFO] - Train batch 300
[2022-01-11 22:25:39,057][root][INFO] - Avg. loss per last 100 batches: 0.017990
[2022-01-11 22:25:39,061][root][INFO] - Train batch 300
[2022-01-11 22:25:39,061][root][INFO] - Avg. loss per last 100 batches: 0.017990
[2022-01-11 22:25:39,065][root][INFO] - Train batch 300
[2022-01-11 22:25:39,065][root][INFO] - Avg. loss per last 100 batches: 0.017990
[2022-01-11 22:25:39,066][root][INFO] - Train batch 300
[2022-01-11 22:25:39,066][root][INFO] - Avg. loss per last 100 batches: 0.017990
[2022-01-11 22:25:39,901][root][INFO] - Epoch: 38: Step: 301/920, loss=0.055966, lr=0.000000
[2022-01-11 22:25:39,904][root][INFO] - Epoch: 38: Step: 301/920, loss=0.055966, lr=0.000000
[2022-01-11 22:25:39,905][root][INFO] - Epoch: 38: Step: 301/920, loss=0.055966, lr=0.000000
[2022-01-11 22:25:39,915][root][INFO] - Epoch: 38: Step: 301/920, loss=0.055966, lr=0.000000
[2022-01-11 22:27:07,585][root][INFO] - Train batch 400
[2022-01-11 22:27:07,585][root][INFO] - Avg. loss per last 100 batches: 0.015527
[2022-01-11 22:27:07,586][root][INFO] - Train batch 400
[2022-01-11 22:27:07,586][root][INFO] - Avg. loss per last 100 batches: 0.015527
[2022-01-11 22:27:07,587][root][INFO] - Train batch 400
[2022-01-11 22:27:07,587][root][INFO] - Avg. loss per last 100 batches: 0.015527
[2022-01-11 22:27:07,589][root][INFO] - Train batch 400
[2022-01-11 22:27:07,589][root][INFO] - Avg. loss per last 100 batches: 0.015527
[2022-01-11 22:27:08,422][root][INFO] - Epoch: 38: Step: 401/920, loss=0.022550, lr=0.000000
[2022-01-11 22:27:08,429][root][INFO] - Epoch: 38: Step: 401/920, loss=0.022550, lr=0.000000
[2022-01-11 22:27:08,431][root][INFO] - Epoch: 38: Step: 401/920, loss=0.022550, lr=0.000000
[2022-01-11 22:27:08,434][root][INFO] - Epoch: 38: Step: 401/920, loss=0.022550, lr=0.000000
[2022-01-11 22:28:36,089][root][INFO] - Train batch 500
[2022-01-11 22:28:36,089][root][INFO] - Avg. loss per last 100 batches: 0.018337
[2022-01-11 22:28:36,092][root][INFO] - Train batch 500
[2022-01-11 22:28:36,092][root][INFO] - Avg. loss per last 100 batches: 0.018337
[2022-01-11 22:28:36,092][root][INFO] - Train batch 500
[2022-01-11 22:28:36,092][root][INFO] - Avg. loss per last 100 batches: 0.018337
[2022-01-11 22:28:36,096][root][INFO] - Train batch 500
[2022-01-11 22:28:36,096][root][INFO] - Avg. loss per last 100 batches: 0.018337
[2022-01-11 22:28:36,937][root][INFO] - Epoch: 38: Step: 501/920, loss=0.000894, lr=0.000000
[2022-01-11 22:28:36,941][root][INFO] - Epoch: 38: Step: 501/920, loss=0.000894, lr=0.000000
[2022-01-11 22:28:36,944][root][INFO] - Epoch: 38: Step: 501/920, loss=0.000894, lr=0.000000
[2022-01-11 22:28:36,944][root][INFO] - Epoch: 38: Step: 501/920, loss=0.000894, lr=0.000000
[2022-01-11 22:30:02,449][root][INFO] - Train batch 600
[2022-01-11 22:30:02,449][root][INFO] - Avg. loss per last 100 batches: 0.015866
[2022-01-11 22:30:02,452][root][INFO] - Train batch 600
[2022-01-11 22:30:02,452][root][INFO] - Avg. loss per last 100 batches: 0.015866
[2022-01-11 22:30:02,452][root][INFO] - Train batch 600
[2022-01-11 22:30:02,453][root][INFO] - Avg. loss per last 100 batches: 0.015866
[2022-01-11 22:30:02,453][root][INFO] - Train batch 600
[2022-01-11 22:30:02,453][root][INFO] - Avg. loss per last 100 batches: 0.015866
[2022-01-11 22:30:03,293][root][INFO] - Epoch: 38: Step: 601/920, loss=0.005017, lr=0.000000
[2022-01-11 22:30:03,298][root][INFO] - Epoch: 38: Step: 601/920, loss=0.005017, lr=0.000000
[2022-01-11 22:30:03,298][root][INFO] - Epoch: 38: Step: 601/920, loss=0.005017, lr=0.000000
[2022-01-11 22:30:03,301][root][INFO] - Epoch: 38: Step: 601/920, loss=0.005017, lr=0.000000
[2022-01-11 22:31:28,935][root][INFO] - Train batch 700
[2022-01-11 22:31:28,935][root][INFO] - Avg. loss per last 100 batches: 0.017092
[2022-01-11 22:31:28,935][root][INFO] - Train batch 700
[2022-01-11 22:31:28,935][root][INFO] - Avg. loss per last 100 batches: 0.017092
[2022-01-11 22:31:28,943][root][INFO] - Train batch 700
[2022-01-11 22:31:28,943][root][INFO] - Avg. loss per last 100 batches: 0.017092
[2022-01-11 22:31:28,943][root][INFO] - Train batch 700
[2022-01-11 22:31:28,943][root][INFO] - Avg. loss per last 100 batches: 0.017092
[2022-01-11 22:31:29,785][root][INFO] - Epoch: 38: Step: 701/920, loss=0.020458, lr=0.000000
[2022-01-11 22:31:29,785][root][INFO] - Epoch: 38: Step: 701/920, loss=0.020458, lr=0.000000
[2022-01-11 22:31:29,789][root][INFO] - Epoch: 38: Step: 701/920, loss=0.020458, lr=0.000000
[2022-01-11 22:31:29,790][root][INFO] - Epoch: 38: Step: 701/920, loss=0.020458, lr=0.000000
[2022-01-11 22:32:57,267][root][INFO] - Train batch 800
[2022-01-11 22:32:57,267][root][INFO] - Avg. loss per last 100 batches: 0.013844
[2022-01-11 22:32:57,268][root][INFO] - Train batch 800
[2022-01-11 22:32:57,268][root][INFO] - Train batch 800
[2022-01-11 22:32:57,268][root][INFO] - Avg. loss per last 100 batches: 0.013844
[2022-01-11 22:32:57,268][root][INFO] - Avg. loss per last 100 batches: 0.013844
[2022-01-11 22:32:57,277][root][INFO] - Train batch 800
[2022-01-11 22:32:57,277][root][INFO] - Avg. loss per last 100 batches: 0.013844
[2022-01-11 22:32:58,121][root][INFO] - Epoch: 38: Step: 801/920, loss=0.003257, lr=0.000000
[2022-01-11 22:32:58,122][root][INFO] - Epoch: 38: Step: 801/920, loss=0.003257, lr=0.000000
[2022-01-11 22:32:58,125][root][INFO] - Epoch: 38: Step: 801/920, loss=0.003257, lr=0.000000
[2022-01-11 22:32:58,126][root][INFO] - Epoch: 38: Step: 801/920, loss=0.003257, lr=0.000000
[2022-01-11 22:34:24,721][root][INFO] - Train batch 900
[2022-01-11 22:34:24,721][root][INFO] - Avg. loss per last 100 batches: 0.016518
[2022-01-11 22:34:24,721][root][INFO] - Train batch 900
[2022-01-11 22:34:24,722][root][INFO] - Avg. loss per last 100 batches: 0.016518
[2022-01-11 22:34:24,722][root][INFO] - Train batch 900
[2022-01-11 22:34:24,722][root][INFO] - Avg. loss per last 100 batches: 0.016518
[2022-01-11 22:34:24,725][root][INFO] - Train batch 900
[2022-01-11 22:34:24,725][root][INFO] - Avg. loss per last 100 batches: 0.016518
[2022-01-11 22:34:25,570][root][INFO] - Epoch: 38: Step: 901/920, loss=0.003916, lr=0.000000
[2022-01-11 22:34:25,571][root][INFO] - Epoch: 38: Step: 901/920, loss=0.003916, lr=0.000000
[2022-01-11 22:34:25,571][root][INFO] - Epoch: 38: Step: 901/920, loss=0.003916, lr=0.000000
[2022-01-11 22:34:25,573][root][INFO] - Epoch: 38: Step: 901/920, loss=0.003916, lr=0.000000
[2022-01-11 22:34:42,613][root][INFO] - rank=3, Validation: Epoch: 38 Step: 920/920
[2022-01-11 22:34:42,613][root][INFO] - Average rank validation ...
[2022-01-11 22:34:42,614][root][INFO] - rank=3; Iteration start
[2022-01-11 22:34:42,614][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:34:42,614][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:34:42,614][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 22:34:42,615][root][INFO] - rank=2, Validation: Epoch: 38 Step: 920/920
[2022-01-11 22:34:42,615][root][INFO] - Average rank validation ...
[2022-01-11 22:34:42,616][root][INFO] - rank=2; Iteration start
[2022-01-11 22:34:42,617][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:34:42,617][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:34:42,617][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 22:34:42,619][root][INFO] - rank=0, Validation: Epoch: 38 Step: 920/920
[2022-01-11 22:34:42,619][root][INFO] - Average rank validation ...
[2022-01-11 22:34:42,620][root][INFO] - rank=0; Iteration start
[2022-01-11 22:34:42,620][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:34:42,621][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:34:42,620][root][INFO] - rank=1, Validation: Epoch: 38 Step: 920/920
[2022-01-11 22:34:42,621][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 22:34:42,621][root][INFO] - Average rank validation ...
[2022-01-11 22:34:42,622][root][INFO] - rank=1; Iteration start
[2022-01-11 22:34:42,622][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:34:42,622][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:34:42,622][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 22:41:06,806][root][INFO] - rank=0; last iteration 25
[2022-01-11 22:41:06,806][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:41:06,807][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 22:41:06,807][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:41:07,084][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:41:07,084][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 22:41:07,921][root][INFO] - rank=1; last iteration 25
[2022-01-11 22:41:07,921][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:41:07,921][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 22:41:07,921][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:41:08,157][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:41:08,157][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 22:41:10,283][root][INFO] - rank=2; last iteration 25
[2022-01-11 22:41:10,283][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:41:10,283][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 22:41:10,283][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:41:10,505][root][INFO] - rank=3; last iteration 25
[2022-01-11 22:41:10,505][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:41:10,505][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 22:41:10,506][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:41:10,567][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:41:10,568][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 22:41:10,730][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:41:10,730][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 22:41:23,912][root][INFO] - Av.rank validation: average rank 33.1040625, total questions=6400
[2022-01-11 22:41:23,912][root][INFO] - Av.rank validation: average rank 33.1040625, total questions=6400
[2022-01-11 22:41:23,912][root][INFO] - Av.rank validation: average rank 33.1040625, total questions=6400
[2022-01-11 22:41:23,912][root][INFO] - Av.rank validation: average rank 33.1040625, total questions=6400
[2022-01-11 22:41:24,131][root][INFO] - rank=3; last iteration 920
[2022-01-11 22:41:24,131][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 22:41:24,131][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 22:41:24,132][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:41:24,132][root][INFO] - Epoch finished on 3
[2022-01-11 22:41:24,132][root][INFO] - Average rank validation ...
[2022-01-11 22:41:24,133][root][INFO] - rank=3; Iteration start
[2022-01-11 22:41:24,133][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:41:24,133][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:41:24,134][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 22:41:24,138][root][INFO] - rank=1; last iteration 920
[2022-01-11 22:41:24,138][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 22:41:24,138][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 22:41:24,139][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:41:24,140][root][INFO] - Epoch finished on 1
[2022-01-11 22:41:24,140][root][INFO] - Average rank validation ...
[2022-01-11 22:41:24,141][root][INFO] - rank=1; Iteration start
[2022-01-11 22:41:24,141][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:41:24,141][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:41:24,141][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 22:41:24,145][root][INFO] - rank=2; last iteration 920
[2022-01-11 22:41:24,145][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 22:41:24,145][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 22:41:24,146][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:41:24,146][root][INFO] - Epoch finished on 2
[2022-01-11 22:41:24,146][root][INFO] - Average rank validation ...
[2022-01-11 22:41:24,147][root][INFO] - rank=2; Iteration start
[2022-01-11 22:41:24,147][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:41:24,148][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:41:24,148][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 22:41:28,500][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.38
[2022-01-11 22:41:28,501][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.38
[2022-01-11 22:41:28,502][root][INFO] - rank=0; last iteration 920
[2022-01-11 22:41:28,502][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 22:41:28,502][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 22:41:28,503][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:41:28,503][root][INFO] - Epoch finished on 0
[2022-01-11 22:41:28,503][root][INFO] - Average rank validation ...
[2022-01-11 22:41:28,505][root][INFO] - rank=0; Iteration start
[2022-01-11 22:41:28,505][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:41:28,505][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 22:41:28,505][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 22:47:50,166][root][INFO] - rank=1; last iteration 25
[2022-01-11 22:47:50,166][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:47:50,166][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 22:47:50,166][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:47:50,385][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:47:50,385][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 22:47:51,532][root][INFO] - rank=3; last iteration 25
[2022-01-11 22:47:51,533][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:47:51,533][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 22:47:51,533][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:47:51,764][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:47:51,764][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 22:47:52,222][root][INFO] - rank=0; last iteration 25
[2022-01-11 22:47:52,222][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:47:52,222][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 22:47:52,222][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:47:52,512][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:47:52,512][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 22:47:52,713][root][INFO] - rank=2; last iteration 25
[2022-01-11 22:47:52,714][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 22:47:52,714][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 22:47:52,714][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 22:47:52,995][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 22:47:52,995][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 22:48:06,197][root][INFO] - Av.rank validation: average rank 33.1040625, total questions=6400
[2022-01-11 22:48:06,197][root][INFO] - Av.rank validation: average rank 33.1040625, total questions=6400
[2022-01-11 22:48:06,198][root][INFO] - Av.rank validation: average rank 33.1040625, total questions=6400
[2022-01-11 22:48:06,198][root][INFO] - Av.rank validation: average rank 33.1040625, total questions=6400
[2022-01-11 22:48:06,400][root][INFO] - Av Loss per epoch=0.015881
[2022-01-11 22:48:06,400][root][INFO] - epoch total correct predictions=58516
[2022-01-11 22:48:06,402][root][INFO] - Av Loss per epoch=0.015881
[2022-01-11 22:48:06,402][root][INFO] - epoch total correct predictions=58516
[2022-01-11 22:48:06,402][root][INFO] - ***** Epoch 39 *****
[2022-01-11 22:48:06,404][root][INFO] - rank=3; Iteration start
[2022-01-11 22:48:06,404][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:48:06,404][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 22:48:06,405][root][INFO] - rank=3; data_src_indices len=920
[2022-01-11 22:48:06,405][root][INFO] - ***** Epoch 39 *****
[2022-01-11 22:48:06,406][root][INFO] - rank=1; Iteration start
[2022-01-11 22:48:06,406][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:48:06,407][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 22:48:06,407][root][INFO] - rank=1; data_src_indices len=920
[2022-01-11 22:48:06,417][root][INFO] - Av Loss per epoch=0.015881
[2022-01-11 22:48:06,417][root][INFO] - epoch total correct predictions=58516
[2022-01-11 22:48:06,419][root][INFO] - ***** Epoch 39 *****
[2022-01-11 22:48:06,421][root][INFO] - rank=2; Iteration start
[2022-01-11 22:48:06,421][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:48:06,421][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 22:48:06,421][root][INFO] - rank=2; data_src_indices len=920
[2022-01-11 22:48:11,361][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.38
[2022-01-11 22:48:11,362][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.38
[2022-01-11 22:48:11,362][root][INFO] - Av Loss per epoch=0.015881
[2022-01-11 22:48:11,362][root][INFO] - epoch total correct predictions=58516
[2022-01-11 22:48:11,365][root][INFO] - ***** Epoch 39 *****
[2022-01-11 22:48:11,367][root][INFO] - rank=0; Iteration start
[2022-01-11 22:48:11,367][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 22:48:11,367][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 920
[2022-01-11 22:48:11,368][root][INFO] - rank=0; data_src_indices len=920
[2022-01-11 22:48:12,237][root][INFO] - Epoch: 39: Step: 1/920, loss=0.014009, lr=0.000000
[2022-01-11 22:48:12,245][root][INFO] - Epoch: 39: Step: 1/920, loss=0.014009, lr=0.000000
[2022-01-11 22:48:12,246][root][INFO] - Epoch: 39: Step: 1/920, loss=0.014009, lr=0.000000
[2022-01-11 22:48:12,246][root][INFO] - Epoch: 39: Step: 1/920, loss=0.014009, lr=0.000000
[2022-01-11 22:49:38,901][root][INFO] - Train batch 100
[2022-01-11 22:49:38,902][root][INFO] - Avg. loss per last 100 batches: 0.019402
[2022-01-11 22:49:38,902][root][INFO] - Train batch 100
[2022-01-11 22:49:38,902][root][INFO] - Avg. loss per last 100 batches: 0.019402
[2022-01-11 22:49:38,904][root][INFO] - Train batch 100
[2022-01-11 22:49:38,904][root][INFO] - Avg. loss per last 100 batches: 0.019402
[2022-01-11 22:49:38,917][root][INFO] - Train batch 100
[2022-01-11 22:49:38,918][root][INFO] - Avg. loss per last 100 batches: 0.019402
[2022-01-11 22:49:39,756][root][INFO] - Epoch: 39: Step: 101/920, loss=0.006542, lr=0.000000
[2022-01-11 22:49:39,757][root][INFO] - Epoch: 39: Step: 101/920, loss=0.006542, lr=0.000000
[2022-01-11 22:49:39,760][root][INFO] - Epoch: 39: Step: 101/920, loss=0.006542, lr=0.000000
[2022-01-11 22:49:39,767][root][INFO] - Epoch: 39: Step: 101/920, loss=0.006542, lr=0.000000
[2022-01-11 22:51:07,325][root][INFO] - Train batch 200
[2022-01-11 22:51:07,326][root][INFO] - Avg. loss per last 100 batches: 0.013892
[2022-01-11 22:51:07,327][root][INFO] - Train batch 200
[2022-01-11 22:51:07,327][root][INFO] - Avg. loss per last 100 batches: 0.013892
[2022-01-11 22:51:07,329][root][INFO] - Train batch 200
[2022-01-11 22:51:07,329][root][INFO] - Avg. loss per last 100 batches: 0.013892
[2022-01-11 22:51:07,334][root][INFO] - Train batch 200
[2022-01-11 22:51:07,335][root][INFO] - Avg. loss per last 100 batches: 0.013892
[2022-01-11 22:51:08,172][root][INFO] - Epoch: 39: Step: 201/920, loss=0.000579, lr=0.000000
[2022-01-11 22:51:08,176][root][INFO] - Epoch: 39: Step: 201/920, loss=0.000579, lr=0.000000
[2022-01-11 22:51:08,180][root][INFO] - Epoch: 39: Step: 201/920, loss=0.000579, lr=0.000000
[2022-01-11 22:51:08,180][root][INFO] - Epoch: 39: Step: 201/920, loss=0.000579, lr=0.000000
[2022-01-11 22:52:33,055][root][INFO] - Train batch 300
[2022-01-11 22:52:33,055][root][INFO] - Avg. loss per last 100 batches: 0.014591
[2022-01-11 22:52:33,059][root][INFO] - Train batch 300
[2022-01-11 22:52:33,059][root][INFO] - Avg. loss per last 100 batches: 0.014591
[2022-01-11 22:52:33,059][root][INFO] - Train batch 300
[2022-01-11 22:52:33,060][root][INFO] - Avg. loss per last 100 batches: 0.014591
[2022-01-11 22:52:33,066][root][INFO] - Train batch 300
[2022-01-11 22:52:33,066][root][INFO] - Avg. loss per last 100 batches: 0.014591
[2022-01-11 22:52:33,910][root][INFO] - Epoch: 39: Step: 301/920, loss=0.004642, lr=0.000000
[2022-01-11 22:52:33,912][root][INFO] - Epoch: 39: Step: 301/920, loss=0.004642, lr=0.000000
[2022-01-11 22:52:33,915][root][INFO] - Epoch: 39: Step: 301/920, loss=0.004642, lr=0.000000
[2022-01-11 22:52:33,915][root][INFO] - Epoch: 39: Step: 301/920, loss=0.004642, lr=0.000000
[2022-01-11 22:54:01,432][root][INFO] - Train batch 400
[2022-01-11 22:54:01,432][root][INFO] - Avg. loss per last 100 batches: 0.013166
[2022-01-11 22:54:01,436][root][INFO] - Train batch 400
[2022-01-11 22:54:01,436][root][INFO] - Avg. loss per last 100 batches: 0.013166
[2022-01-11 22:54:01,440][root][INFO] - Train batch 400
[2022-01-11 22:54:01,440][root][INFO] - Avg. loss per last 100 batches: 0.013166
[2022-01-11 22:54:01,453][root][INFO] - Train batch 400
[2022-01-11 22:54:01,453][root][INFO] - Avg. loss per last 100 batches: 0.013166
[2022-01-11 22:54:02,298][root][INFO] - Epoch: 39: Step: 401/920, loss=0.008096, lr=0.000000
[2022-01-11 22:54:02,299][root][INFO] - Epoch: 39: Step: 401/920, loss=0.008096, lr=0.000000
[2022-01-11 22:54:02,301][root][INFO] - Epoch: 39: Step: 401/920, loss=0.008096, lr=0.000000
[2022-01-11 22:54:02,315][root][INFO] - Epoch: 39: Step: 401/920, loss=0.008096, lr=0.000000
[2022-01-11 22:55:31,098][root][INFO] - Train batch 500
[2022-01-11 22:55:31,098][root][INFO] - Avg. loss per last 100 batches: 0.014396
[2022-01-11 22:55:31,108][root][INFO] - Train batch 500
[2022-01-11 22:55:31,108][root][INFO] - Avg. loss per last 100 batches: 0.014396
[2022-01-11 22:55:31,108][root][INFO] - Train batch 500
[2022-01-11 22:55:31,108][root][INFO] - Avg. loss per last 100 batches: 0.014396
[2022-01-11 22:55:31,120][root][INFO] - Train batch 500
[2022-01-11 22:55:31,120][root][INFO] - Avg. loss per last 100 batches: 0.014396
[2022-01-11 22:55:31,964][root][INFO] - Epoch: 39: Step: 501/920, loss=0.000242, lr=0.000000
[2022-01-11 22:55:31,965][root][INFO] - Epoch: 39: Step: 501/920, loss=0.000242, lr=0.000000
[2022-01-11 22:55:31,969][root][INFO] - Epoch: 39: Step: 501/920, loss=0.000242, lr=0.000000
[2022-01-11 22:55:31,971][root][INFO] - Epoch: 39: Step: 501/920, loss=0.000242, lr=0.000000
[2022-01-11 22:56:59,675][root][INFO] - Train batch 600
[2022-01-11 22:56:59,675][root][INFO] - Avg. loss per last 100 batches: 0.015934
[2022-01-11 22:56:59,679][root][INFO] - Train batch 600
[2022-01-11 22:56:59,679][root][INFO] - Avg. loss per last 100 batches: 0.015934
[2022-01-11 22:56:59,683][root][INFO] - Train batch 600
[2022-01-11 22:56:59,683][root][INFO] - Avg. loss per last 100 batches: 0.015934
[2022-01-11 22:56:59,698][root][INFO] - Train batch 600
[2022-01-11 22:56:59,699][root][INFO] - Avg. loss per last 100 batches: 0.015934
[2022-01-11 22:57:00,538][root][INFO] - Epoch: 39: Step: 601/920, loss=0.003476, lr=0.000000
[2022-01-11 22:57:00,540][root][INFO] - Epoch: 39: Step: 601/920, loss=0.003476, lr=0.000000
[2022-01-11 22:57:00,546][root][INFO] - Epoch: 39: Step: 601/920, loss=0.003476, lr=0.000000
[2022-01-11 22:57:00,558][root][INFO] - Epoch: 39: Step: 601/920, loss=0.003476, lr=0.000000
[2022-01-11 22:58:25,817][root][INFO] - Train batch 700
[2022-01-11 22:58:25,817][root][INFO] - Train batch 700
[2022-01-11 22:58:25,817][root][INFO] - Avg. loss per last 100 batches: 0.020152
[2022-01-11 22:58:25,817][root][INFO] - Avg. loss per last 100 batches: 0.020152
[2022-01-11 22:58:25,820][root][INFO] - Train batch 700
[2022-01-11 22:58:25,820][root][INFO] - Avg. loss per last 100 batches: 0.020152
[2022-01-11 22:58:25,820][root][INFO] - Train batch 700
[2022-01-11 22:58:25,820][root][INFO] - Avg. loss per last 100 batches: 0.020152
[2022-01-11 22:58:26,660][root][INFO] - Epoch: 39: Step: 701/920, loss=0.037562, lr=0.000000
[2022-01-11 22:58:26,664][root][INFO] - Epoch: 39: Step: 701/920, loss=0.037562, lr=0.000000
[2022-01-11 22:58:26,665][root][INFO] - Epoch: 39: Step: 701/920, loss=0.037562, lr=0.000000
[2022-01-11 22:58:26,669][root][INFO] - Epoch: 39: Step: 701/920, loss=0.037562, lr=0.000000
[2022-01-11 22:59:53,372][root][INFO] - Train batch 800
[2022-01-11 22:59:53,372][root][INFO] - Avg. loss per last 100 batches: 0.013541
[2022-01-11 22:59:53,377][root][INFO] - Train batch 800
[2022-01-11 22:59:53,377][root][INFO] - Avg. loss per last 100 batches: 0.013541
[2022-01-11 22:59:53,383][root][INFO] - Train batch 800
[2022-01-11 22:59:53,383][root][INFO] - Avg. loss per last 100 batches: 0.013541
[2022-01-11 22:59:53,384][root][INFO] - Train batch 800
[2022-01-11 22:59:53,384][root][INFO] - Avg. loss per last 100 batches: 0.013541
[2022-01-11 22:59:54,230][root][INFO] - Epoch: 39: Step: 801/920, loss=0.004236, lr=0.000000
[2022-01-11 22:59:54,231][root][INFO] - Epoch: 39: Step: 801/920, loss=0.004236, lr=0.000000
[2022-01-11 22:59:54,233][root][INFO] - Epoch: 39: Step: 801/920, loss=0.004236, lr=0.000000
[2022-01-11 22:59:54,233][root][INFO] - Epoch: 39: Step: 801/920, loss=0.004236, lr=0.000000
[2022-01-11 23:01:21,694][root][INFO] - Train batch 900
[2022-01-11 23:01:21,694][root][INFO] - Avg. loss per last 100 batches: 0.020491
[2022-01-11 23:01:21,695][root][INFO] - Train batch 900
[2022-01-11 23:01:21,695][root][INFO] - Avg. loss per last 100 batches: 0.020491
[2022-01-11 23:01:21,700][root][INFO] - Train batch 900
[2022-01-11 23:01:21,700][root][INFO] - Avg. loss per last 100 batches: 0.020491
[2022-01-11 23:01:21,702][root][INFO] - Train batch 900
[2022-01-11 23:01:21,702][root][INFO] - Avg. loss per last 100 batches: 0.020491
[2022-01-11 23:01:22,540][root][INFO] - Epoch: 39: Step: 901/920, loss=0.008254, lr=0.000000
[2022-01-11 23:01:22,540][root][INFO] - Epoch: 39: Step: 901/920, loss=0.008254, lr=0.000000
[2022-01-11 23:01:22,543][root][INFO] - Epoch: 39: Step: 901/920, loss=0.008254, lr=0.000000
[2022-01-11 23:01:22,544][root][INFO] - Epoch: 39: Step: 901/920, loss=0.008254, lr=0.000000
[2022-01-11 23:01:38,631][root][INFO] - rank=0, Validation: Epoch: 39 Step: 920/920
[2022-01-11 23:01:38,631][root][INFO] - Average rank validation ...
[2022-01-11 23:01:38,632][root][INFO] - rank=0; Iteration start
[2022-01-11 23:01:38,632][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 23:01:38,632][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 23:01:38,633][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 23:01:38,633][root][INFO] - rank=3, Validation: Epoch: 39 Step: 920/920
[2022-01-11 23:01:38,633][root][INFO] - Average rank validation ...
[2022-01-11 23:01:38,633][root][INFO] - rank=1, Validation: Epoch: 39 Step: 920/920
[2022-01-11 23:01:38,633][root][INFO] - Average rank validation ...
[2022-01-11 23:01:38,634][root][INFO] - rank=3; Iteration start
[2022-01-11 23:01:38,634][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 23:01:38,634][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 23:01:38,634][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 23:01:38,635][root][INFO] - rank=1; Iteration start
[2022-01-11 23:01:38,635][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 23:01:38,635][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 23:01:38,635][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 23:01:38,636][root][INFO] - rank=2, Validation: Epoch: 39 Step: 920/920
[2022-01-11 23:01:38,637][root][INFO] - Average rank validation ...
[2022-01-11 23:01:38,638][root][INFO] - rank=2; Iteration start
[2022-01-11 23:01:38,638][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 23:01:38,638][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 23:01:38,638][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 23:08:02,963][root][INFO] - rank=0; last iteration 25
[2022-01-11 23:08:02,963][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 23:08:02,963][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 23:08:02,963][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:08:03,234][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 23:08:03,234][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 23:08:04,960][root][INFO] - rank=1; last iteration 25
[2022-01-11 23:08:04,960][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 23:08:04,960][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 23:08:04,960][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:08:05,192][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 23:08:05,192][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 23:08:06,500][root][INFO] - rank=3; last iteration 25
[2022-01-11 23:08:06,500][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 23:08:06,500][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 23:08:06,500][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:08:06,732][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 23:08:06,732][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 23:08:07,464][root][INFO] - rank=2; last iteration 25
[2022-01-11 23:08:07,464][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 23:08:07,464][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 23:08:07,464][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:08:07,739][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 23:08:07,739][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 23:08:21,062][root][INFO] - Av.rank validation: average rank 33.30640625, total questions=6400
[2022-01-11 23:08:21,062][root][INFO] - Av.rank validation: average rank 33.30640625, total questions=6400
[2022-01-11 23:08:21,062][root][INFO] - Av.rank validation: average rank 33.30640625, total questions=6400
[2022-01-11 23:08:21,062][root][INFO] - Av.rank validation: average rank 33.30640625, total questions=6400
[2022-01-11 23:08:21,281][root][INFO] - rank=3; last iteration 920
[2022-01-11 23:08:21,281][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [920]
[2022-01-11 23:08:21,281][root][INFO] - Finished iterating, iteration=920, shard=3
[2022-01-11 23:08:21,282][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:08:21,282][root][INFO] - Epoch finished on 3
[2022-01-11 23:08:21,282][root][INFO] - Average rank validation ...
[2022-01-11 23:08:21,283][root][INFO] - rank=3; Iteration start
[2022-01-11 23:08:21,283][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 23:08:21,283][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 23:08:21,283][root][INFO] - rank=3; data_src_indices len=25
[2022-01-11 23:08:21,287][root][INFO] - rank=2; last iteration 920
[2022-01-11 23:08:21,287][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [920]
[2022-01-11 23:08:21,287][root][INFO] - Finished iterating, iteration=920, shard=2
[2022-01-11 23:08:21,287][root][INFO] - rank=1; last iteration 920
[2022-01-11 23:08:21,287][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [920]
[2022-01-11 23:08:21,287][root][INFO] - Finished iterating, iteration=920, shard=1
[2022-01-11 23:08:21,288][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:08:21,288][root][INFO] - Epoch finished on 2
[2022-01-11 23:08:21,288][root][INFO] - Average rank validation ...
[2022-01-11 23:08:21,288][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:08:21,288][root][INFO] - Epoch finished on 1
[2022-01-11 23:08:21,288][root][INFO] - Average rank validation ...
[2022-01-11 23:08:21,289][root][INFO] - rank=2; Iteration start
[2022-01-11 23:08:21,289][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 23:08:21,289][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 23:08:21,289][root][INFO] - rank=2; data_src_indices len=25
[2022-01-11 23:08:21,290][root][INFO] - rank=1; Iteration start
[2022-01-11 23:08:21,290][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 23:08:21,290][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 23:08:21,290][root][INFO] - rank=1; data_src_indices len=25
[2022-01-11 23:08:25,609][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.39
[2022-01-11 23:08:25,610][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.39
[2022-01-11 23:08:25,611][root][INFO] - rank=0; last iteration 920
[2022-01-11 23:08:25,611][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [920]
[2022-01-11 23:08:25,611][root][INFO] - Finished iterating, iteration=920, shard=0
[2022-01-11 23:08:25,612][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:08:25,612][root][INFO] - Epoch finished on 0
[2022-01-11 23:08:25,612][root][INFO] - Average rank validation ...
[2022-01-11 23:08:25,613][root][INFO] - rank=0; Iteration start
[2022-01-11 23:08:25,613][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2022-01-11 23:08:25,613][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 25
[2022-01-11 23:08:25,613][root][INFO] - rank=0; data_src_indices len=25
[2022-01-11 23:14:46,744][root][INFO] - rank=1; last iteration 25
[2022-01-11 23:14:46,744][root][INFO] - rank=1; Multi set iteration finished: iteration per set: [25]
[2022-01-11 23:14:46,744][root][INFO] - Finished iterating, iteration=25, shard=1
[2022-01-11 23:14:46,744][root][INFO] - rank=1; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:14:46,964][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 23:14:46,964][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97400, 768])
[2022-01-11 23:14:49,066][root][INFO] - rank=3; last iteration 25
[2022-01-11 23:14:49,066][root][INFO] - rank=3; Multi set iteration finished: iteration per set: [25]
[2022-01-11 23:14:49,066][root][INFO] - Finished iterating, iteration=25, shard=3
[2022-01-11 23:14:49,066][root][INFO] - rank=3; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:14:49,296][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 23:14:49,297][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97429, 768])
[2022-01-11 23:14:49,312][root][INFO] - rank=0; last iteration 25
[2022-01-11 23:14:49,312][root][INFO] - rank=0; Multi set iteration finished: iteration per set: [25]
[2022-01-11 23:14:49,312][root][INFO] - Finished iterating, iteration=25, shard=0
[2022-01-11 23:14:49,312][root][INFO] - rank=0; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:14:49,591][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 23:14:49,591][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 23:14:50,004][root][INFO] - rank=2; last iteration 25
[2022-01-11 23:14:50,004][root][INFO] - rank=2; Multi set iteration finished: iteration per set: [25]
[2022-01-11 23:14:50,004][root][INFO] - Finished iterating, iteration=25, shard=2
[2022-01-11 23:14:50,004][root][INFO] - rank=2; Multi set iteration finished after next: iteration per set: [0]
[2022-01-11 23:14:50,288][root][INFO] - Av.rank validation: total q_vectors size=torch.Size([1600, 768])
[2022-01-11 23:14:50,288][root][INFO] - Av.rank validation: total ctx_vectors size=torch.Size([97280, 768])
[2022-01-11 23:15:03,394][root][INFO] - Av.rank validation: average rank 33.30640625, total questions=6400
[2022-01-11 23:15:03,394][root][INFO] - Av.rank validation: average rank 33.30640625, total questions=6400
[2022-01-11 23:15:03,394][root][INFO] - Av.rank validation: average rank 33.30640625, total questions=6400
[2022-01-11 23:15:03,394][root][INFO] - Av.rank validation: average rank 33.30640625, total questions=6400
[2022-01-11 23:15:03,593][root][INFO] - Av Loss per epoch=0.016177
[2022-01-11 23:15:03,593][root][INFO] - epoch total correct predictions=58514
[2022-01-11 23:15:03,594][root][INFO] - Av Loss per epoch=0.016177
[2022-01-11 23:15:03,594][root][INFO] - epoch total correct predictions=58514
[2022-01-11 23:15:03,605][root][INFO] - Av Loss per epoch=0.016177
[2022-01-11 23:15:03,606][root][INFO] - epoch total correct predictions=58514
[2022-01-11 23:15:08,488][root][INFO] - Saved checkpoint at ./nq_out/dpr_biencoder.39
[2022-01-11 23:15:08,488][root][INFO] - Saved checkpoint to ./nq_out/dpr_biencoder.39
[2022-01-11 23:15:08,488][root][INFO] - Av Loss per epoch=0.016177
[2022-01-11 23:15:08,488][root][INFO] - epoch total correct predictions=58514
[2022-01-11 23:15:08,491][root][INFO] - Training finished. Best validation checkpoint ./nq_out/dpr_biencoder.35
